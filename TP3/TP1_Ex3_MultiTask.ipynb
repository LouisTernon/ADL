{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-task problem: colored MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colored [MNIST Dataset](https://pytorch.org/docs/stable/torchvision/datasets.html#mnist)\n",
    "* Handwritten digits with 10 classes\n",
    "* Size of each image: 28x28 pixels \n",
    "* 50 000 data examples in training set, 10 000 examples in validation set, 10 000 in test set\n",
    "* We colorize each image with a random color within 7 (red, green, blue, magenta, yellow, cyan, white)\n",
    "* Each image has two labels: the number it represents (10 classes) and the color of the number (7 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a loaded MNIST dataset, create a colozied version of it\n",
    "def colorize_dataset(dataset):\n",
    "    # array of colors\n",
    "    COLORS = torch.tensor([\n",
    "        [1.0, 0.0, 0.0], # 0 RED\n",
    "        [0.0, 1.0, 0.0], # 1 GREEN\n",
    "        [0.0, 0.0, 1.0], # 2 BLUE\n",
    "        [1.0, 1.0, 0.0], # 3 YELLOW\n",
    "        [1.0, 0.0, 1.0], # 4 MAGENTA\n",
    "        [0.0, 1.0, 1.0], # 5 CYAN\n",
    "        [1.0, 1.0, 1.0], # 6 WHITE\n",
    "    ])\n",
    "    N = len(dataset)\n",
    "    images = dataset.data.view(N, 1, 28, 28)\n",
    "    labels = dataset.targets.view(N, 1)\n",
    "    color_labels = torch.randint(0, 6, (N,))\n",
    "    colorized_images = images * COLORS[color_labels, :].view(N,3,1,1)\n",
    "    full_labels = torch.cat((labels, color_labels.view(N, 1)), dim=1)\n",
    "    return TensorDataset(colorized_images, full_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading MNIST dataset from torchvision.dataset\n",
    "dataset = torchvision.datasets.MNIST(root='data/',\n",
    "                                           train=True,\n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "dataset = colorize_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is : torch.Size([60000, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the dataset is :\", dataset.tensors[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation sets\n",
    "train_set, val_set = random_split(dataset, [50000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'image label: tensor([9, 5])')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_index = 80\n",
    "\n",
    "plt.imshow(dataset[sample_index][0].permute(1, 2, 0), interpolation='nearest')\n",
    "plt.title(\"image label: {}\".format(dataset[sample_index][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        # The input size is 28*28. For a standard classification task, the output size should be the same as the number of classes\n",
    "        self.l_number = nn.Linear(28*28*3, 10)\n",
    "        # However here we deal with 2 tasks: the network outputs 2 labels, so there are two \"last\" layers in parallel\n",
    "        self.l_color = nn.Linear(28*28*3, 7)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        h = inputs.view(-1, 28*28*3)\n",
    "        # Use softmax as the activation function for the last layer(s)\n",
    "        output_number = F.softmax(self.l_number(h), dim=1)\n",
    "        output_color = F.softmax(self.l_color(h), dim=1)\n",
    "        \n",
    "        return (output_number, output_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model: \n",
    "model = Model()\n",
    "\n",
    "# Choose the hyperparameters for training: \n",
    "num_epochs = 10\n",
    "batch_size = 10\n",
    "\n",
    "# Use mean squared loss function \n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Use SGD optimizer with a learning rate of 0.01\n",
    "# It is initialized on our model\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for training\n",
    "def train(num_epochs, batch_size, criterion, optimizer, model, dataset):\n",
    "    train_error = []\n",
    "    train_loader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_average_loss = 0.0\n",
    "        for (images, labels) in train_loader:\n",
    "            (y_number, y_color) = model(images)\n",
    "            \n",
    "            # One-hot encoding or labels so as to calculate MSE error:\n",
    "            number_onehot = F.one_hot(labels[:,0], 10).float()\n",
    "            color_onehot = F.one_hot(labels[:,1], 7).float()\n",
    "            \n",
    "            loss = criterion(y_number, number_onehot) + criterion(y_color, color_onehot)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_average_loss += loss.item() * batch_size / len(dataset)\n",
    "        train_error.append(epoch_average_loss)\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, epoch_average_loss))\n",
    "    return train_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.3584\n",
      "Epoch [2/10], Loss: 0.2856\n",
      "Epoch [3/10], Loss: 0.2755\n",
      "Epoch [4/10], Loss: 0.2716\n",
      "Epoch [5/10], Loss: 0.2713\n",
      "Epoch [6/10], Loss: 0.2750\n",
      "Epoch [7/10], Loss: 0.2715\n",
      "Epoch [8/10], Loss: 0.2705\n",
      "Epoch [9/10], Loss: 0.2712\n",
      "Epoch [10/10], Loss: 0.2700\n"
     ]
    }
   ],
   "source": [
    "train_error = train(num_epochs, batch_size, criterion, optimizer, model, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Visualization of convergence')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training error wrt. the number of epochs: \n",
    "plt.plot(range(1, num_epochs+1), train_error)\n",
    "plt.xlabel(\"num_epochs\")\n",
    "plt.ylabel(\"Train error\")\n",
    "plt.title(\"Visualization of convergence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy to evaluate the model\n",
    "def accuracy(dataset, model, model_type='linear'):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        number_correct = 0\n",
    "        color_correct = 0\n",
    "        both_correct = 0\n",
    "        dataloader = DataLoader(dataset)\n",
    "        for images, labels in dataloader:\n",
    "            images = images.view(-1, 28*28) if model_type == \"linear\" else images\n",
    "            (y_number, y_color) = model(images)\n",
    "            _, number_predicted = torch.max(y_number.data, 1) \n",
    "            number_correct += (number_predicted == labels[:, 0]).sum()\n",
    "            _, color_predicted = torch.max(y_color.data, 1) \n",
    "            color_correct += (color_predicted == labels[:, 1]).sum()\n",
    "            both_correct += ((color_predicted == labels[:, 1]) and (number_predicted == labels[:, 0])).sum()\n",
    "    acc_color = 100*color_correct.item()/ len(dataset)\n",
    "    acc_number = 100*number_correct.item()/ len(dataset)\n",
    "    acc_both = 100*both_correct.item()/ len(dataset)\n",
    "    print('Accuracy of the model for numbers : {:.2f} %'.format(acc_number))\n",
    "    print('Accuracy of the model for colors : {:.2f} %'.format(acc_color))\n",
    "    print('Accuracy of the model for both : {:.2f} %'.format(acc_both))\n",
    "    return acc_number, acc_color, acc_both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model for numbers : 13.50 %\n",
      "Accuracy of the model for colors : 18.59 %\n",
      "Accuracy of the model for both : 2.27 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(13.5, 18.59, 2.27)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(val_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Prediction: number=8, color=0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_index = 66\n",
    "\n",
    "(image, label) = val_set[val_index]\n",
    "(y_number, y_color) = model(image)\n",
    "_, number_prediction = torch.max(y_number.data, 1)\n",
    "_, color_prediction = torch.max(y_color.data, 1)\n",
    "\n",
    "plt.imshow(image.permute(1, 2, 0), interpolation='nearest')\n",
    "plt.title(\"Prediction: number=%d, color=%d\" % (number_prediction, color_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Impact of the architecture of the model\n",
    "Define your own class `Model` to improve the predictions:\n",
    "\n",
    "* The convolutional layer can be a good choice to deal with images. Replace nn.Linear with [nn.Conv2d](https://pytorch.org/docs/stable/nn.html#conv2d).\n",
    "* Try to add more layers (1, 2, 3, more ?)\n",
    "* Change the number of neurons in hidden layers (5, 10, 20, more ?)\n",
    "* Try different activation functions such as [sigmoid](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.sigmoid), [tanh](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.tanh), [relu](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.relu), etc.\n",
    "* __Your network generates two different outputs, how much weight-sharing (i.e. how many common layers) between these two paths is appropriate?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels, kernel_size, activation, *args, **kwargs):\n",
    "    block = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size, *args, **kwargs), activation)\n",
    "    return block\n",
    "\n",
    "def linear_block(in_features, out_features, activation, *args, **kwargs):\n",
    "    block = nn.Sequential(nn.Linear(in_features, out_features), activation)\n",
    "    return block\n",
    "\n",
    "class ConvModel(nn.Module):\n",
    "\n",
    "    def __init__(self, activation:str, n_common_filters:list, n_number_filters:list, n_color_filters:list, n_common_neurons:list, n_number_neurons:list, n_color_neurons:list, in_channels=3, in_dim=28*28, out_dim=(10, 7), logits=False):\n",
    "        super(ConvModel, self).__init__()\n",
    "\n",
    "        activations = nn.ModuleDict([[\"relu\", nn.ReLU()], [\"lrelu\", nn.LeakyReLU()], [\"sigmoid\", nn.Sigmoid()], [\"tanh\", nn.Tanh()]])\n",
    "        self.logits = logits\n",
    "\n",
    "        # Common encoder\n",
    "        self.conv_common_space_dim = [in_channels, *n_common_filters]\n",
    "        self.conv_common_blocks = [conv_block(in_channels, out_channels, kernel_size=3, activation=activations[activation], padding=1)\n",
    "        for in_channels, out_channels in zip(self.conv_common_space_dim, self.conv_common_space_dim[1:])]\n",
    "        self.common_encoder = nn.Sequential(*self.conv_common_blocks)\n",
    "\n",
    "        # Color conv branch\n",
    "        in_color_conv_channels = in_channels if not n_common_filters else n_common_filters[-1]\n",
    "        self.conv_color_space_dim = [in_color_conv_channels, *n_color_filters]\n",
    "        self.conv_color_blocks = [conv_block(in_channels, out_channels, kernel_size=3, activation=activations[activation], padding=1) for in_channels, out_channels in zip(self.conv_color_space_dim, self.conv_color_space_dim[1:])]\n",
    "        self.color_encoder = nn.Sequential(*self.conv_color_blocks)\n",
    "\n",
    "        # number conv branch\n",
    "        in_number_conv_channels = in_channels if not n_common_filters else n_common_filters[-1]\n",
    "        self.conv_number_space_dim = [in_number_conv_channels, *n_number_filters]\n",
    "        self.conv_number_blocks = [conv_block(in_channels, out_channels, kernel_size=3, activation=activations[activation], padding=1) for in_channels, out_channels in zip(self.conv_number_space_dim, self.conv_number_space_dim[1:])]\n",
    "        self.number_encoder = nn.Sequential(*self.conv_number_blocks)\n",
    "\n",
    "        # Common fc\n",
    "        in_fc_features = self.conv_common_space_dim[-1]*in_dim if not self.conv_color_space_dim else self.conv_color_space_dim[-1]*in_dim\n",
    "        self.linear_common_space_dim = [in_fc_features, *n_common_neurons]\n",
    "        self.linear_common_blocks = [linear_block(in_features, out_features, activations[activation]) for in_features, out_features in zip(self.linear_common_space_dim, self.linear_common_space_dim[1:])]\n",
    "        self.common_fully_connected = nn.Sequential(*self.linear_common_blocks)\n",
    "        self.final_color_layer = nn.Linear(self.linear_common_space_dim[-1], out_dim[0])\n",
    "        self.final_number_layer = nn.Linear(self.linear_common_space_dim[-1], out_dim[1])\n",
    "\n",
    "        # Color fc\n",
    "        in_fc_color_features = self.conv_common_space_dim[-1]*in_dim if not n_common_neurons else n_common_neurons[-1]\n",
    "        self.linear_color_space_dim = [in_fc_color_features, *n_color_neurons]\n",
    "        self.linear_color_blocks = [linear_block(in_features, out_features, activations[activation]) for in_features, out_features in zip(self.linear_color_space_dim, self.linear_color_space_dim[1:])]\n",
    "        self.color_fully_connected = nn.Sequential(*self.linear_color_blocks, nn.Linear(self.linear_color_space_dim[-1], out_dim[1]))\n",
    "\n",
    "        # Number fc\n",
    "        in_fc_number_features = self.conv_common_space_dim[-1]*in_dim if not n_common_neurons else n_common_neurons[-1]\n",
    "        self.linear_number_space_dim = [in_fc_number_features, *n_number_neurons] \n",
    "        self.linear_number_blocks = [linear_block(in_features, out_features, activations[activation]) for in_features, out_features in zip(self.linear_number_space_dim, self.linear_number_space_dim[1:])]\n",
    "        self.number_fully_connected = nn.Sequential(*self.linear_number_blocks, nn.Linear(self.linear_number_space_dim[-1], out_dim[0]))\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        #outputs = F.softmax(self.encoder(inputs), dim=1)# Use softmax as the activation function for the last layer\n",
    "        common_encoding = self.common_encoder(inputs)\n",
    "\n",
    "        color_encoding = self.color_encoder(common_encoding) if self.conv_common_blocks else common_encoding\n",
    "        number_encoding = self.number_encoder(common_encoding) if self.conv_common_blocks else common_encoding\n",
    "\n",
    "        color_encoding = color_encoding.view(color_encoding.size(0), -1) # Flatten\n",
    "        number_encoding = number_encoding.view(number_encoding.size(0), -1) # Flatten\n",
    "\n",
    "        color_encoding = self.common_fully_connected(color_encoding)\n",
    "        number_encoding = self.common_fully_connected(number_encoding)\n",
    "\n",
    "        color_encoding = self.color_fully_connected(color_encoding) if self.linear_color_blocks else self.final_color_layer(color_encoding)\n",
    "        number_encoding = self.number_fully_connected(number_encoding) if self.linear_number_blocks else self.final_number_layer(number_encoding)\n",
    "    \n",
    "        if not self.logits: output_numbers, output_colors = F.softmax(number_encoding, dim=1), F.softmax(color_encoding, dim=1)\n",
    "        else: output_numbers, output_colors = number_encoding, color_encoding\n",
    "\n",
    "        return output_numbers, output_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.0551\n",
      "Epoch [2/3], Loss: 0.0738\n",
      "Epoch [3/3], Loss: 0.0652\n",
      "Accuracy of the model for numbers : 77.28 %\n",
      "Accuracy of the model for colors : 82.91 %\n",
      "Accuracy of the model for both : 64.02 %\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "batch_size = 10\n",
    "\n",
    "model = ConvModel(\"relu\", n_common_filters=[16, 16], n_color_filters=[], n_number_filters=[], n_common_neurons=[], n_color_neurons=[10], n_number_neurons=[10])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "train_error = train(num_epochs, batch_size, criterion, optimizer, model, train_set)\n",
    "\n",
    "acc_num, acc_col, acc = accuracy(val_set, model, model_type=\"conv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Impact of the optimizer\n",
    "Retrain the model by using different parameters of the optimizer; you can change its parameters in the cell initializing it, after the definition of your model.\n",
    "\n",
    "* Use different batch sizes, from 10 to 1 000 for instance\n",
    "* Try different values of the learning rate (between 0.001 and 10), and see how these impact the training process. Do all network architectures react the same way to different learning rates?\n",
    "* Change the duration of the training by increasing the number of epochs\n",
    "* Try other optimizers, such as [Adam](https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam) or [RMSprop](https://pytorch.org/docs/stable/optim.html?highlight=rmsprop#torch.optim.RMSprop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Impact of the loss function\n",
    "The MSE error is rarely used in this case. The cross entropy loss can be a better choice for multi-classification problems. In pytorch, the cross entropy loss is defined by [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#crossentropyloss). Replace the MSE loss by this one to observe its impact.\n",
    "\n",
    "**Note:** In order to use nn.CrossEntropyLoss correctly, don't add an activation function to the last layer of your network. And one-hot encoding is no longer needed to calculate the loss, delete the encoding procedures in function `train`.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Prediction on test set\n",
    "\n",
    "Once you have a model that seems satisfying on the validation dataset, you SHOULD evaluate it on a test dataset that has never been used before, to obtain a final accuracy value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading MNIST test set from torchvision.dataset\n",
    "test_set = torchvision.datasets.MNIST(root='data/',\n",
    "                                         train=False,\n",
    "                                         transform=transforms.ToTensor(),\n",
    "                                         download=False)\n",
    "test_set = colorize_dataset(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(test_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
