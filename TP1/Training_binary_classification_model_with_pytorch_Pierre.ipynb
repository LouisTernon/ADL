{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We study first a binary classification problem, performed by a neural network. Each input has two real features, and the output can be only 0 or 1. The training set contains 4000 examples, and the validation set, 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "# Display figures on jupyter notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate the dataset, in the form of two interlaced spirals\n",
    "def spiral(phi):\n",
    "    x = (phi+1)*torch.cos(phi)\n",
    "    y = phi*torch.sin(phi)\n",
    "    return torch.cat((x, y), dim=1)\n",
    "\n",
    "def generate_data(num_data):\n",
    "    angles = torch.empty((num_data, 1)).uniform_(0, 10)\n",
    "    data = spiral(angles)\n",
    "    # add some noise to the data\n",
    "    data += torch.empty((num_data, 2)).normal_(0.0, 0.3)\n",
    "    labels = torch.zeros((num_data,), dtype=torch.int)\n",
    "    # flip half of the points to create two classes\n",
    "    data[num_data//2:,:] *= -1\n",
    "    labels[num_data//2:] = 1\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the training set with 4000 examples by function generate_data\n",
    "\n",
    "X_train, y_train = generate_data(4000)\n",
    "X_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vis_data function to visualize the dataset\n",
    "def vis_data(X, y):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot(X[y==1, 0], X[y==1, 1], 'r+') #Examples are represented as red plusses for label 1\n",
    "    plt.plot(X[y==0, 0], X[y==0, 1], 'b+') #Examples are represented as blue plusses for label 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now invoke the `vis_data` function on the dataset previously generated to see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_data(X_train, y_train) # visualize training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `TensorDataset` wrapper from pytorch, so that the framework can easily understand our tensors as a proper dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "training_set = TensorDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training the model with a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a skeleton of a neural network with a single layer (thus: a linear classifier). This is the model you'll work on to improve it during this exercise.\n",
    "\n",
    "Look at the code and run it to see the structure, then follow the questions below to iteratively improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the first step, we define a neural network with just one layer. A useful tutorial for constructing model can be found [here](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic network structure with a single layer\n",
    "\n",
    "def linear_block(in_features, out_features, activation, *args, **kwargs):\n",
    "    block = nn.Sequential(nn.Linear(in_features, out_features), activation)\n",
    "    return block\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, activation:str, n_neurons:list, in_dim=2, out_dim=1, logits=False):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        activations = nn.ModuleDict([[\"relu\", nn.ReLU()], [\"lrelu\", nn.LeakyReLU()], [\"sigmoid\", nn.Sigmoid()], [\"tanh\", nn.Tanh()]])\n",
    "        \n",
    "        self.logits = logits\n",
    "        self.neurons = n_neurons   \n",
    "        if self.neurons: \n",
    "            in_neurons, out_neurons = [in_dim] + self.neurons, self.neurons + [out_dim]\n",
    "            self.linear_blocks = [linear_block(in_f, out_f, activations[activation]) for in_f, out_f in list(zip(in_neurons, out_neurons))[:-1]]\n",
    "            self.encoder = nn.Sequential(*self.linear_blocks, nn.Linear(self.neurons[-1], out_dim))\n",
    "        else:\n",
    "            self.encoder = nn.Linear(in_dim, out_dim)\n",
    "        \n",
    "    def forward(self, inputs, logits=True):\n",
    "        # We want the model to predict 0 for one class and 1 for the other class\n",
    "        # A Sigmoid activation function seems appropriate\n",
    "        \n",
    "        outputs = self.encoder(inputs)\n",
    "        if not self.logits: outputs = torch.sigmoid(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model: \n",
    "model = Model(activation=\"tanh\", n_neurons=[10, 10, 10, 10, 10])\n",
    "\n",
    "# Choose the hyperparameters for training: \n",
    "num_epochs = 1000\n",
    "batch_size = 10\n",
    "\n",
    "# Training criterion. This one is a mean squared error (MSE) loss between the output\n",
    "# of the network and the target label\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Use SGD optimizer with a learning rate of 0.01\n",
    "# It is initialized on our model\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the defined model\n",
    "More information can be found [here](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "\n",
    "    \n",
    "    def __init__(self, patience=7, eps=5e-4):\n",
    "\n",
    "        self.patience = patience\n",
    "        self.eps = eps\n",
    "        self.counter = 0\n",
    "        self.past_loss = np.inf\n",
    "\n",
    "    def __call__(self, curr_loss):\n",
    "        if np.abs(curr_loss - self.past_loss) < self.eps:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        else:\n",
    "            self.counter = 0\n",
    "            self.past_loss = curr_loss\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for training\n",
    "def train(num_epochs, batch_size, criterion, optimizer, model, dataset):\n",
    "    ES = EarlyStopping()\n",
    "    train_error = []\n",
    "    train_loader = DataLoader(dataset, batch_size, shuffle=True)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_average_loss = 0.0\n",
    "        for (X_batch, y_real) in train_loader:\n",
    "            y_pre = model(X_batch).view(-1)\n",
    "            loss = criterion(y_pre, y_real.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_average_loss += loss.item() * batch_size / len(dataset)\n",
    "        train_error.append(epoch_average_loss)\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, epoch_average_loss))\n",
    "        \n",
    "        if ES(epoch_average_loss):\n",
    "            print(f\"No improvement for {ES.patience} epochs, stopping\")\n",
    "            break\n",
    "    return train_error, epoch+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 1000 validation data:\n",
    "X_val, y_val = generate_data(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict labels for validation set\n",
    "model.eval() # set the model to test mode\n",
    "with torch.no_grad():\n",
    "    y_pre = model(X_val).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy on validation set to evaluate the model by the function accuracy\n",
    "def accuracy(y_real, y_pre):\n",
    "    y_pre[y_pre<0.5] = 0\n",
    "    y_pre[y_pre>=0.5] = 1\n",
    "\n",
    "    acc = 1 - torch.sum(torch.abs(y_pre - y_real))/len(y_pre)\n",
    "    print('Accuracy of the network on the 1000 validation data: {:.2f} %'.format(acc.item()*100))\n",
    "    return acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the prediction with real labels\n",
    "\n",
    "def compare_pred(X, y_real, y_pre):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.plot(X[y_real==1, 0], X[y_real==1, 1], 'r+') #Examples are represented as a red plusses for label 1\n",
    "    plt.plot(X[y_real==0, 0], X[y_real==0, 1], 'b+') #Examples are represented as a blue plusses for label 0\n",
    "    plt.title(\"real data\")\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(X[y_pre==1, 0], X[y_pre==1, 1], 'r+')\n",
    "    plt.plot(X[y_pre==0, 0], X[y_pre==0, 1], 'b+')\n",
    "    plt.title(\"prediciton results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_pred(X_val, y_val, y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1: Impact of the architecture of the model\n",
    "\n",
    "The class `Model` is the definition of your model. You can now modify it to try out different architectures and\n",
    "see the impact of the following factors:\n",
    "\n",
    "* Try to add more layers (1, 2, 3, more ?)\n",
    "* Try to different activation functions ([sigmoid](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.sigmoid), [tanh](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.tanh), [relu](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.relu), etc.)\n",
    "* Try to change the number of neurons for each layer (5, 10, 20, more ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = [\"relu\", \"lrelu\", \"sigmoid\", \"tanh\"]\n",
    "depth_interval = [1, 5]\n",
    "neurons_numbers = [5, 10, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Training model with depth : 1, activation : relu, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2444\n",
      "Epoch [2/1000], Loss: 0.2420\n",
      "Epoch [3/1000], Loss: 0.2415\n",
      "Epoch [4/1000], Loss: 0.2411\n",
      "Epoch [5/1000], Loss: 0.2409\n",
      "Epoch [6/1000], Loss: 0.2407\n",
      "Epoch [7/1000], Loss: 0.2404\n",
      "Epoch [8/1000], Loss: 0.2400\n",
      "Epoch [9/1000], Loss: 0.2397\n",
      "Epoch [10/1000], Loss: 0.2393\n",
      "Epoch [11/1000], Loss: 0.2388\n",
      "Epoch [12/1000], Loss: 0.2384\n",
      "Epoch [13/1000], Loss: 0.2380\n",
      "Epoch [14/1000], Loss: 0.2377\n",
      "Epoch [15/1000], Loss: 0.2373\n",
      "Epoch [16/1000], Loss: 0.2369\n",
      "Epoch [17/1000], Loss: 0.2366\n",
      "Epoch [18/1000], Loss: 0.2363\n",
      "Epoch [19/1000], Loss: 0.2361\n",
      "Epoch [20/1000], Loss: 0.2359\n",
      "Epoch [21/1000], Loss: 0.2356\n",
      "Epoch [22/1000], Loss: 0.2354\n",
      "Epoch [23/1000], Loss: 0.2352\n",
      "Epoch [24/1000], Loss: 0.2351\n",
      "Epoch [25/1000], Loss: 0.2349\n",
      "Epoch [26/1000], Loss: 0.2348\n",
      "Epoch [27/1000], Loss: 0.2347\n",
      "Epoch [28/1000], Loss: 0.2345\n",
      "Epoch [29/1000], Loss: 0.2346\n",
      "Epoch [30/1000], Loss: 0.2345\n",
      "Epoch [31/1000], Loss: 0.2343\n",
      "Epoch [32/1000], Loss: 0.2342\n",
      "Epoch [33/1000], Loss: 0.2342\n",
      "Epoch [34/1000], Loss: 0.2340\n",
      "Epoch [35/1000], Loss: 0.2340\n",
      "Epoch [36/1000], Loss: 0.2338\n",
      "Epoch [37/1000], Loss: 0.2337\n",
      "Epoch [38/1000], Loss: 0.2335\n",
      "Epoch [39/1000], Loss: 0.2335\n",
      "Epoch [40/1000], Loss: 0.2334\n",
      "Epoch [41/1000], Loss: 0.2333\n",
      "Epoch [42/1000], Loss: 0.2332\n",
      "Epoch [43/1000], Loss: 0.2331\n",
      "Epoch [44/1000], Loss: 0.2329\n",
      "Epoch [45/1000], Loss: 0.2329\n",
      "Epoch [46/1000], Loss: 0.2327\n",
      "Epoch [47/1000], Loss: 0.2325\n",
      "Epoch [48/1000], Loss: 0.2323\n",
      "Epoch [49/1000], Loss: 0.2323\n",
      "Epoch [50/1000], Loss: 0.2321\n",
      "Epoch [51/1000], Loss: 0.2319\n",
      "Epoch [52/1000], Loss: 0.2317\n",
      "Epoch [53/1000], Loss: 0.2316\n",
      "Epoch [54/1000], Loss: 0.2312\n",
      "Epoch [55/1000], Loss: 0.2313\n",
      "Epoch [56/1000], Loss: 0.2310\n",
      "Epoch [57/1000], Loss: 0.2308\n",
      "Epoch [58/1000], Loss: 0.2307\n",
      "Epoch [59/1000], Loss: 0.2305\n",
      "Epoch [60/1000], Loss: 0.2302\n",
      "Epoch [61/1000], Loss: 0.2301\n",
      "Epoch [62/1000], Loss: 0.2299\n",
      "Epoch [63/1000], Loss: 0.2296\n",
      "Epoch [64/1000], Loss: 0.2294\n",
      "Epoch [65/1000], Loss: 0.2293\n",
      "Epoch [66/1000], Loss: 0.2290\n",
      "Epoch [67/1000], Loss: 0.2287\n",
      "Epoch [68/1000], Loss: 0.2283\n",
      "Epoch [69/1000], Loss: 0.2281\n",
      "Epoch [70/1000], Loss: 0.2280\n",
      "Epoch [71/1000], Loss: 0.2278\n",
      "Epoch [72/1000], Loss: 0.2275\n",
      "Epoch [73/1000], Loss: 0.2274\n",
      "Epoch [74/1000], Loss: 0.2270\n",
      "Epoch [75/1000], Loss: 0.2268\n",
      "Epoch [76/1000], Loss: 0.2264\n",
      "Epoch [77/1000], Loss: 0.2262\n",
      "Epoch [78/1000], Loss: 0.2260\n",
      "Epoch [79/1000], Loss: 0.2258\n",
      "Epoch [80/1000], Loss: 0.2255\n",
      "Epoch [81/1000], Loss: 0.2252\n",
      "Epoch [82/1000], Loss: 0.2248\n",
      "Epoch [83/1000], Loss: 0.2246\n",
      "Epoch [84/1000], Loss: 0.2243\n",
      "Epoch [85/1000], Loss: 0.2243\n",
      "Epoch [86/1000], Loss: 0.2238\n",
      "Epoch [87/1000], Loss: 0.2236\n",
      "Epoch [88/1000], Loss: 0.2234\n",
      "Epoch [89/1000], Loss: 0.2232\n",
      "Epoch [90/1000], Loss: 0.2228\n",
      "Epoch [91/1000], Loss: 0.2226\n",
      "Epoch [92/1000], Loss: 0.2223\n",
      "Epoch [93/1000], Loss: 0.2222\n",
      "Epoch [94/1000], Loss: 0.2218\n",
      "Epoch [95/1000], Loss: 0.2216\n",
      "Epoch [96/1000], Loss: 0.2214\n",
      "Epoch [97/1000], Loss: 0.2210\n",
      "Epoch [98/1000], Loss: 0.2207\n",
      "Epoch [99/1000], Loss: 0.2205\n",
      "Epoch [100/1000], Loss: 0.2202\n",
      "Epoch [101/1000], Loss: 0.2202\n",
      "Epoch [102/1000], Loss: 0.2200\n",
      "Epoch [103/1000], Loss: 0.2195\n",
      "Epoch [104/1000], Loss: 0.2193\n",
      "Epoch [105/1000], Loss: 0.2190\n",
      "Epoch [106/1000], Loss: 0.2188\n",
      "Epoch [107/1000], Loss: 0.2187\n",
      "Epoch [108/1000], Loss: 0.2185\n",
      "Epoch [109/1000], Loss: 0.2184\n",
      "Epoch [110/1000], Loss: 0.2179\n",
      "Epoch [111/1000], Loss: 0.2179\n",
      "Epoch [112/1000], Loss: 0.2176\n",
      "Epoch [113/1000], Loss: 0.2173\n",
      "Epoch [114/1000], Loss: 0.2171\n",
      "Epoch [115/1000], Loss: 0.2169\n",
      "Epoch [116/1000], Loss: 0.2169\n",
      "Epoch [117/1000], Loss: 0.2167\n",
      "Epoch [118/1000], Loss: 0.2167\n",
      "Epoch [119/1000], Loss: 0.2163\n",
      "Epoch [120/1000], Loss: 0.2160\n",
      "Epoch [121/1000], Loss: 0.2158\n",
      "Epoch [122/1000], Loss: 0.2158\n",
      "Epoch [123/1000], Loss: 0.2156\n",
      "Epoch [124/1000], Loss: 0.2154\n",
      "Epoch [125/1000], Loss: 0.2152\n",
      "Epoch [126/1000], Loss: 0.2152\n",
      "Epoch [127/1000], Loss: 0.2148\n",
      "Epoch [128/1000], Loss: 0.2150\n",
      "Epoch [129/1000], Loss: 0.2145\n",
      "Epoch [130/1000], Loss: 0.2146\n",
      "Epoch [131/1000], Loss: 0.2141\n",
      "Epoch [132/1000], Loss: 0.2140\n",
      "Epoch [133/1000], Loss: 0.2140\n",
      "Epoch [134/1000], Loss: 0.2139\n",
      "Epoch [135/1000], Loss: 0.2139\n",
      "Epoch [136/1000], Loss: 0.2136\n",
      "Epoch [137/1000], Loss: 0.2136\n",
      "Epoch [138/1000], Loss: 0.2135\n",
      "Epoch [139/1000], Loss: 0.2134\n",
      "Epoch [140/1000], Loss: 0.2134\n",
      "Epoch [141/1000], Loss: 0.2131\n",
      "Epoch [142/1000], Loss: 0.2128\n",
      "Epoch [143/1000], Loss: 0.2129\n",
      "Epoch [144/1000], Loss: 0.2129\n",
      "Epoch [145/1000], Loss: 0.2126\n",
      "Epoch [146/1000], Loss: 0.2127\n",
      "Epoch [147/1000], Loss: 0.2125\n",
      "Epoch [148/1000], Loss: 0.2123\n",
      "Epoch [149/1000], Loss: 0.2120\n",
      "Epoch [150/1000], Loss: 0.2120\n",
      "Epoch [151/1000], Loss: 0.2121\n",
      "Epoch [152/1000], Loss: 0.2116\n",
      "Epoch [153/1000], Loss: 0.2114\n",
      "Epoch [154/1000], Loss: 0.2117\n",
      "Epoch [155/1000], Loss: 0.2114\n",
      "Epoch [156/1000], Loss: 0.2116\n",
      "Epoch [157/1000], Loss: 0.2109\n",
      "Epoch [158/1000], Loss: 0.2111\n",
      "Epoch [159/1000], Loss: 0.2109\n",
      "Epoch [160/1000], Loss: 0.2107\n",
      "Epoch [161/1000], Loss: 0.2104\n",
      "Epoch [162/1000], Loss: 0.2104\n",
      "Epoch [163/1000], Loss: 0.2104\n",
      "Epoch [164/1000], Loss: 0.2103\n",
      "Epoch [165/1000], Loss: 0.2101\n",
      "Epoch [166/1000], Loss: 0.2097\n",
      "Epoch [167/1000], Loss: 0.2095\n",
      "Epoch [168/1000], Loss: 0.2092\n",
      "Epoch [169/1000], Loss: 0.2087\n",
      "Epoch [170/1000], Loss: 0.2087\n",
      "Epoch [171/1000], Loss: 0.2086\n",
      "Epoch [172/1000], Loss: 0.2085\n",
      "Epoch [173/1000], Loss: 0.2083\n",
      "Epoch [174/1000], Loss: 0.2081\n",
      "Epoch [175/1000], Loss: 0.2080\n",
      "Epoch [176/1000], Loss: 0.2076\n",
      "Epoch [177/1000], Loss: 0.2071\n",
      "Epoch [178/1000], Loss: 0.2071\n",
      "Epoch [179/1000], Loss: 0.2072\n",
      "Epoch [180/1000], Loss: 0.2067\n",
      "Epoch [181/1000], Loss: 0.2069\n",
      "Epoch [182/1000], Loss: 0.2065\n",
      "Epoch [183/1000], Loss: 0.2068\n",
      "Epoch [184/1000], Loss: 0.2063\n",
      "Epoch [185/1000], Loss: 0.2062\n",
      "Epoch [186/1000], Loss: 0.2059\n",
      "Epoch [187/1000], Loss: 0.2056\n",
      "Epoch [188/1000], Loss: 0.2058\n",
      "Epoch [189/1000], Loss: 0.2054\n",
      "Epoch [190/1000], Loss: 0.2052\n",
      "Epoch [191/1000], Loss: 0.2053\n",
      "Epoch [192/1000], Loss: 0.2047\n",
      "Epoch [193/1000], Loss: 0.2048\n",
      "Epoch [194/1000], Loss: 0.2046\n",
      "Epoch [195/1000], Loss: 0.2045\n",
      "Epoch [196/1000], Loss: 0.2040\n",
      "Epoch [197/1000], Loss: 0.2040\n",
      "Epoch [198/1000], Loss: 0.2036\n",
      "Epoch [199/1000], Loss: 0.2031\n",
      "Epoch [200/1000], Loss: 0.2032\n",
      "Epoch [201/1000], Loss: 0.2033\n",
      "Epoch [202/1000], Loss: 0.2025\n",
      "Epoch [203/1000], Loss: 0.2031\n",
      "Epoch [204/1000], Loss: 0.2021\n",
      "Epoch [205/1000], Loss: 0.2019\n",
      "Epoch [206/1000], Loss: 0.2021\n",
      "Epoch [207/1000], Loss: 0.2021\n",
      "Epoch [208/1000], Loss: 0.2019\n",
      "Epoch [209/1000], Loss: 0.2015\n",
      "Epoch [210/1000], Loss: 0.2015\n",
      "Epoch [211/1000], Loss: 0.2011\n",
      "Epoch [212/1000], Loss: 0.2007\n",
      "Epoch [213/1000], Loss: 0.2007\n",
      "Epoch [214/1000], Loss: 0.2003\n",
      "Epoch [215/1000], Loss: 0.1999\n",
      "Epoch [216/1000], Loss: 0.1998\n",
      "Epoch [217/1000], Loss: 0.1996\n",
      "Epoch [218/1000], Loss: 0.1991\n",
      "Epoch [219/1000], Loss: 0.1996\n",
      "Epoch [220/1000], Loss: 0.1994\n",
      "Epoch [221/1000], Loss: 0.1993\n",
      "Epoch [222/1000], Loss: 0.1989\n",
      "Epoch [223/1000], Loss: 0.1993\n",
      "Epoch [224/1000], Loss: 0.1983\n",
      "Epoch [225/1000], Loss: 0.1985\n",
      "Epoch [226/1000], Loss: 0.1982\n",
      "Epoch [227/1000], Loss: 0.1977\n",
      "Epoch [228/1000], Loss: 0.1983\n",
      "Epoch [229/1000], Loss: 0.1972\n",
      "Epoch [230/1000], Loss: 0.1976\n",
      "Epoch [231/1000], Loss: 0.1970\n",
      "Epoch [232/1000], Loss: 0.1972\n",
      "Epoch [233/1000], Loss: 0.1971\n",
      "Epoch [234/1000], Loss: 0.1966\n",
      "Epoch [235/1000], Loss: 0.1962\n",
      "Epoch [236/1000], Loss: 0.1964\n",
      "Epoch [237/1000], Loss: 0.1959\n",
      "Epoch [238/1000], Loss: 0.1961\n",
      "Epoch [239/1000], Loss: 0.1957\n",
      "Epoch [240/1000], Loss: 0.1958\n",
      "Epoch [241/1000], Loss: 0.1957\n",
      "Epoch [242/1000], Loss: 0.1952\n",
      "Epoch [243/1000], Loss: 0.1949\n",
      "Epoch [244/1000], Loss: 0.1949\n",
      "Epoch [245/1000], Loss: 0.1947\n",
      "Epoch [246/1000], Loss: 0.1943\n",
      "Epoch [247/1000], Loss: 0.1943\n",
      "Epoch [248/1000], Loss: 0.1942\n",
      "Epoch [249/1000], Loss: 0.1933\n",
      "Epoch [250/1000], Loss: 0.1936\n",
      "Epoch [251/1000], Loss: 0.1930\n",
      "Epoch [252/1000], Loss: 0.1936\n",
      "Epoch [253/1000], Loss: 0.1923\n",
      "Epoch [254/1000], Loss: 0.1935\n",
      "Epoch [255/1000], Loss: 0.1934\n",
      "Epoch [256/1000], Loss: 0.1923\n",
      "Epoch [257/1000], Loss: 0.1927\n",
      "Epoch [258/1000], Loss: 0.1926\n",
      "Epoch [259/1000], Loss: 0.1924\n",
      "Epoch [260/1000], Loss: 0.1925\n",
      "Epoch [261/1000], Loss: 0.1922\n",
      "Epoch [262/1000], Loss: 0.1915\n",
      "Epoch [263/1000], Loss: 0.1916\n",
      "Epoch [264/1000], Loss: 0.1912\n",
      "Epoch [265/1000], Loss: 0.1916\n",
      "Epoch [266/1000], Loss: 0.1912\n",
      "Epoch [267/1000], Loss: 0.1910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [268/1000], Loss: 0.1908\n",
      "Epoch [269/1000], Loss: 0.1908\n",
      "Epoch [270/1000], Loss: 0.1906\n",
      "Epoch [271/1000], Loss: 0.1900\n",
      "Epoch [272/1000], Loss: 0.1910\n",
      "Epoch [273/1000], Loss: 0.1903\n",
      "Epoch [274/1000], Loss: 0.1901\n",
      "Epoch [275/1000], Loss: 0.1896\n",
      "Epoch [276/1000], Loss: 0.1898\n",
      "Epoch [277/1000], Loss: 0.1902\n",
      "Epoch [278/1000], Loss: 0.1900\n",
      "Epoch [279/1000], Loss: 0.1891\n",
      "Epoch [280/1000], Loss: 0.1896\n",
      "Epoch [281/1000], Loss: 0.1894\n",
      "Epoch [282/1000], Loss: 0.1892\n",
      "Epoch [283/1000], Loss: 0.1888\n",
      "Epoch [284/1000], Loss: 0.1890\n",
      "Epoch [285/1000], Loss: 0.1882\n",
      "Epoch [286/1000], Loss: 0.1887\n",
      "Epoch [287/1000], Loss: 0.1879\n",
      "Epoch [288/1000], Loss: 0.1889\n",
      "Epoch [289/1000], Loss: 0.1881\n",
      "Epoch [290/1000], Loss: 0.1879\n",
      "Epoch [291/1000], Loss: 0.1874\n",
      "Epoch [292/1000], Loss: 0.1882\n",
      "Epoch [293/1000], Loss: 0.1876\n",
      "Epoch [294/1000], Loss: 0.1877\n",
      "Epoch [295/1000], Loss: 0.1877\n",
      "Epoch [296/1000], Loss: 0.1879\n",
      "Epoch [297/1000], Loss: 0.1874\n",
      "Epoch [298/1000], Loss: 0.1870\n",
      "Epoch [299/1000], Loss: 0.1868\n",
      "Epoch [300/1000], Loss: 0.1875\n",
      "Epoch [301/1000], Loss: 0.1867\n",
      "Epoch [302/1000], Loss: 0.1868\n",
      "Epoch [303/1000], Loss: 0.1873\n",
      "Epoch [304/1000], Loss: 0.1868\n",
      "Epoch [305/1000], Loss: 0.1867\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 1, activation : relu, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2443\n",
      "Epoch [2/1000], Loss: 0.2388\n",
      "Epoch [3/1000], Loss: 0.2379\n",
      "Epoch [4/1000], Loss: 0.2376\n",
      "Epoch [5/1000], Loss: 0.2369\n",
      "Epoch [6/1000], Loss: 0.2370\n",
      "Epoch [7/1000], Loss: 0.2366\n",
      "Epoch [8/1000], Loss: 0.2361\n",
      "Epoch [9/1000], Loss: 0.2360\n",
      "Epoch [10/1000], Loss: 0.2357\n",
      "Epoch [11/1000], Loss: 0.2352\n",
      "Epoch [12/1000], Loss: 0.2351\n",
      "Epoch [13/1000], Loss: 0.2348\n",
      "Epoch [14/1000], Loss: 0.2347\n",
      "Epoch [15/1000], Loss: 0.2345\n",
      "Epoch [16/1000], Loss: 0.2343\n",
      "Epoch [17/1000], Loss: 0.2341\n",
      "Epoch [18/1000], Loss: 0.2341\n",
      "Epoch [19/1000], Loss: 0.2339\n",
      "Epoch [20/1000], Loss: 0.2337\n",
      "Epoch [21/1000], Loss: 0.2334\n",
      "Epoch [22/1000], Loss: 0.2331\n",
      "Epoch [23/1000], Loss: 0.2333\n",
      "Epoch [24/1000], Loss: 0.2330\n",
      "Epoch [25/1000], Loss: 0.2329\n",
      "Epoch [26/1000], Loss: 0.2327\n",
      "Epoch [27/1000], Loss: 0.2326\n",
      "Epoch [28/1000], Loss: 0.2325\n",
      "Epoch [29/1000], Loss: 0.2322\n",
      "Epoch [30/1000], Loss: 0.2320\n",
      "Epoch [31/1000], Loss: 0.2320\n",
      "Epoch [32/1000], Loss: 0.2319\n",
      "Epoch [33/1000], Loss: 0.2317\n",
      "Epoch [34/1000], Loss: 0.2312\n",
      "Epoch [35/1000], Loss: 0.2314\n",
      "Epoch [36/1000], Loss: 0.2312\n",
      "Epoch [37/1000], Loss: 0.2309\n",
      "Epoch [38/1000], Loss: 0.2307\n",
      "Epoch [39/1000], Loss: 0.2305\n",
      "Epoch [40/1000], Loss: 0.2305\n",
      "Epoch [41/1000], Loss: 0.2301\n",
      "Epoch [42/1000], Loss: 0.2301\n",
      "Epoch [43/1000], Loss: 0.2300\n",
      "Epoch [44/1000], Loss: 0.2298\n",
      "Epoch [45/1000], Loss: 0.2295\n",
      "Epoch [46/1000], Loss: 0.2293\n",
      "Epoch [47/1000], Loss: 0.2293\n",
      "Epoch [48/1000], Loss: 0.2291\n",
      "Epoch [49/1000], Loss: 0.2289\n",
      "Epoch [50/1000], Loss: 0.2286\n",
      "Epoch [51/1000], Loss: 0.2285\n",
      "Epoch [52/1000], Loss: 0.2282\n",
      "Epoch [53/1000], Loss: 0.2283\n",
      "Epoch [54/1000], Loss: 0.2278\n",
      "Epoch [55/1000], Loss: 0.2279\n",
      "Epoch [56/1000], Loss: 0.2276\n",
      "Epoch [57/1000], Loss: 0.2274\n",
      "Epoch [58/1000], Loss: 0.2273\n",
      "Epoch [59/1000], Loss: 0.2269\n",
      "Epoch [60/1000], Loss: 0.2269\n",
      "Epoch [61/1000], Loss: 0.2266\n",
      "Epoch [62/1000], Loss: 0.2263\n",
      "Epoch [63/1000], Loss: 0.2262\n",
      "Epoch [64/1000], Loss: 0.2261\n",
      "Epoch [65/1000], Loss: 0.2259\n",
      "Epoch [66/1000], Loss: 0.2254\n",
      "Epoch [67/1000], Loss: 0.2257\n",
      "Epoch [68/1000], Loss: 0.2250\n",
      "Epoch [69/1000], Loss: 0.2249\n",
      "Epoch [70/1000], Loss: 0.2244\n",
      "Epoch [71/1000], Loss: 0.2243\n",
      "Epoch [72/1000], Loss: 0.2237\n",
      "Epoch [73/1000], Loss: 0.2241\n",
      "Epoch [74/1000], Loss: 0.2236\n",
      "Epoch [75/1000], Loss: 0.2231\n",
      "Epoch [76/1000], Loss: 0.2227\n",
      "Epoch [77/1000], Loss: 0.2230\n",
      "Epoch [78/1000], Loss: 0.2224\n",
      "Epoch [79/1000], Loss: 0.2224\n",
      "Epoch [80/1000], Loss: 0.2221\n",
      "Epoch [81/1000], Loss: 0.2217\n",
      "Epoch [82/1000], Loss: 0.2215\n",
      "Epoch [83/1000], Loss: 0.2211\n",
      "Epoch [84/1000], Loss: 0.2207\n",
      "Epoch [85/1000], Loss: 0.2204\n",
      "Epoch [86/1000], Loss: 0.2199\n",
      "Epoch [87/1000], Loss: 0.2198\n",
      "Epoch [88/1000], Loss: 0.2196\n",
      "Epoch [89/1000], Loss: 0.2191\n",
      "Epoch [90/1000], Loss: 0.2188\n",
      "Epoch [91/1000], Loss: 0.2185\n",
      "Epoch [92/1000], Loss: 0.2181\n",
      "Epoch [93/1000], Loss: 0.2178\n",
      "Epoch [94/1000], Loss: 0.2178\n",
      "Epoch [95/1000], Loss: 0.2173\n",
      "Epoch [96/1000], Loss: 0.2167\n",
      "Epoch [97/1000], Loss: 0.2167\n",
      "Epoch [98/1000], Loss: 0.2159\n",
      "Epoch [99/1000], Loss: 0.2160\n",
      "Epoch [100/1000], Loss: 0.2154\n",
      "Epoch [101/1000], Loss: 0.2151\n",
      "Epoch [102/1000], Loss: 0.2150\n",
      "Epoch [103/1000], Loss: 0.2146\n",
      "Epoch [104/1000], Loss: 0.2140\n",
      "Epoch [105/1000], Loss: 0.2141\n",
      "Epoch [106/1000], Loss: 0.2135\n",
      "Epoch [107/1000], Loss: 0.2129\n",
      "Epoch [108/1000], Loss: 0.2131\n",
      "Epoch [109/1000], Loss: 0.2125\n",
      "Epoch [110/1000], Loss: 0.2122\n",
      "Epoch [111/1000], Loss: 0.2120\n",
      "Epoch [112/1000], Loss: 0.2119\n",
      "Epoch [113/1000], Loss: 0.2114\n",
      "Epoch [114/1000], Loss: 0.2110\n",
      "Epoch [115/1000], Loss: 0.2110\n",
      "Epoch [116/1000], Loss: 0.2103\n",
      "Epoch [117/1000], Loss: 0.2099\n",
      "Epoch [118/1000], Loss: 0.2100\n",
      "Epoch [119/1000], Loss: 0.2096\n",
      "Epoch [120/1000], Loss: 0.2093\n",
      "Epoch [121/1000], Loss: 0.2094\n",
      "Epoch [122/1000], Loss: 0.2090\n",
      "Epoch [123/1000], Loss: 0.2084\n",
      "Epoch [124/1000], Loss: 0.2081\n",
      "Epoch [125/1000], Loss: 0.2080\n",
      "Epoch [126/1000], Loss: 0.2078\n",
      "Epoch [127/1000], Loss: 0.2071\n",
      "Epoch [128/1000], Loss: 0.2075\n",
      "Epoch [129/1000], Loss: 0.2071\n",
      "Epoch [130/1000], Loss: 0.2066\n",
      "Epoch [131/1000], Loss: 0.2061\n",
      "Epoch [132/1000], Loss: 0.2066\n",
      "Epoch [133/1000], Loss: 0.2065\n",
      "Epoch [134/1000], Loss: 0.2059\n",
      "Epoch [135/1000], Loss: 0.2056\n",
      "Epoch [136/1000], Loss: 0.2051\n",
      "Epoch [137/1000], Loss: 0.2050\n",
      "Epoch [138/1000], Loss: 0.2049\n",
      "Epoch [139/1000], Loss: 0.2049\n",
      "Epoch [140/1000], Loss: 0.2042\n",
      "Epoch [141/1000], Loss: 0.2045\n",
      "Epoch [142/1000], Loss: 0.2042\n",
      "Epoch [143/1000], Loss: 0.2039\n",
      "Epoch [144/1000], Loss: 0.2041\n",
      "Epoch [145/1000], Loss: 0.2037\n",
      "Epoch [146/1000], Loss: 0.2028\n",
      "Epoch [147/1000], Loss: 0.2031\n",
      "Epoch [148/1000], Loss: 0.2027\n",
      "Epoch [149/1000], Loss: 0.2028\n",
      "Epoch [150/1000], Loss: 0.2028\n",
      "Epoch [151/1000], Loss: 0.2028\n",
      "Epoch [152/1000], Loss: 0.2026\n",
      "Epoch [153/1000], Loss: 0.2020\n",
      "Epoch [154/1000], Loss: 0.2019\n",
      "Epoch [155/1000], Loss: 0.2024\n",
      "Epoch [156/1000], Loss: 0.2018\n",
      "Epoch [157/1000], Loss: 0.2019\n",
      "Epoch [158/1000], Loss: 0.2013\n",
      "Epoch [159/1000], Loss: 0.2017\n",
      "Epoch [160/1000], Loss: 0.2010\n",
      "Epoch [161/1000], Loss: 0.2014\n",
      "Epoch [162/1000], Loss: 0.2014\n",
      "Epoch [163/1000], Loss: 0.2009\n",
      "Epoch [164/1000], Loss: 0.2011\n",
      "Epoch [165/1000], Loss: 0.2004\n",
      "Epoch [166/1000], Loss: 0.2003\n",
      "Epoch [167/1000], Loss: 0.2005\n",
      "Epoch [168/1000], Loss: 0.2003\n",
      "Epoch [169/1000], Loss: 0.1998\n",
      "Epoch [170/1000], Loss: 0.2001\n",
      "Epoch [171/1000], Loss: 0.1994\n",
      "Epoch [172/1000], Loss: 0.1997\n",
      "Epoch [173/1000], Loss: 0.2001\n",
      "Epoch [174/1000], Loss: 0.1997\n",
      "Epoch [175/1000], Loss: 0.1994\n",
      "Epoch [176/1000], Loss: 0.1996\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 1, activation : relu, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2435\n",
      "Epoch [2/1000], Loss: 0.2394\n",
      "Epoch [3/1000], Loss: 0.2385\n",
      "Epoch [4/1000], Loss: 0.2383\n",
      "Epoch [5/1000], Loss: 0.2377\n",
      "Epoch [6/1000], Loss: 0.2372\n",
      "Epoch [7/1000], Loss: 0.2369\n",
      "Epoch [8/1000], Loss: 0.2364\n",
      "Epoch [9/1000], Loss: 0.2365\n",
      "Epoch [10/1000], Loss: 0.2362\n",
      "Epoch [11/1000], Loss: 0.2357\n",
      "Epoch [12/1000], Loss: 0.2357\n",
      "Epoch [13/1000], Loss: 0.2354\n",
      "Epoch [14/1000], Loss: 0.2355\n",
      "Epoch [15/1000], Loss: 0.2353\n",
      "Epoch [16/1000], Loss: 0.2350\n",
      "Epoch [17/1000], Loss: 0.2350\n",
      "Epoch [18/1000], Loss: 0.2348\n",
      "Epoch [19/1000], Loss: 0.2348\n",
      "Epoch [20/1000], Loss: 0.2349\n",
      "Epoch [21/1000], Loss: 0.2344\n",
      "Epoch [22/1000], Loss: 0.2343\n",
      "Epoch [23/1000], Loss: 0.2341\n",
      "Epoch [24/1000], Loss: 0.2340\n",
      "Epoch [25/1000], Loss: 0.2343\n",
      "Epoch [26/1000], Loss: 0.2342\n",
      "Epoch [27/1000], Loss: 0.2341\n",
      "Epoch [28/1000], Loss: 0.2341\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 1, activation : lrelu, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2440\n",
      "Epoch [2/1000], Loss: 0.2387\n",
      "Epoch [3/1000], Loss: 0.2380\n",
      "Epoch [4/1000], Loss: 0.2376\n",
      "Epoch [5/1000], Loss: 0.2373\n",
      "Epoch [6/1000], Loss: 0.2371\n",
      "Epoch [7/1000], Loss: 0.2372\n",
      "Epoch [8/1000], Loss: 0.2371\n",
      "Epoch [9/1000], Loss: 0.2369\n",
      "Epoch [10/1000], Loss: 0.2369\n",
      "Epoch [11/1000], Loss: 0.2368\n",
      "Epoch [12/1000], Loss: 0.2369\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 1, activation : lrelu, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2421\n",
      "Epoch [2/1000], Loss: 0.2384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/1000], Loss: 0.2376\n",
      "Epoch [4/1000], Loss: 0.2371\n",
      "Epoch [5/1000], Loss: 0.2367\n",
      "Epoch [6/1000], Loss: 0.2361\n",
      "Epoch [7/1000], Loss: 0.2357\n",
      "Epoch [8/1000], Loss: 0.2355\n",
      "Epoch [9/1000], Loss: 0.2352\n",
      "Epoch [10/1000], Loss: 0.2345\n",
      "Epoch [11/1000], Loss: 0.2346\n",
      "Epoch [12/1000], Loss: 0.2343\n",
      "Epoch [13/1000], Loss: 0.2342\n",
      "Epoch [14/1000], Loss: 0.2340\n",
      "Epoch [15/1000], Loss: 0.2337\n",
      "Epoch [16/1000], Loss: 0.2336\n",
      "Epoch [17/1000], Loss: 0.2333\n",
      "Epoch [18/1000], Loss: 0.2334\n",
      "Epoch [19/1000], Loss: 0.2331\n",
      "Epoch [20/1000], Loss: 0.2330\n",
      "Epoch [21/1000], Loss: 0.2329\n",
      "Epoch [22/1000], Loss: 0.2324\n",
      "Epoch [23/1000], Loss: 0.2326\n",
      "Epoch [24/1000], Loss: 0.2324\n",
      "Epoch [25/1000], Loss: 0.2322\n",
      "Epoch [26/1000], Loss: 0.2318\n",
      "Epoch [27/1000], Loss: 0.2318\n",
      "Epoch [28/1000], Loss: 0.2315\n",
      "Epoch [29/1000], Loss: 0.2314\n",
      "Epoch [30/1000], Loss: 0.2310\n",
      "Epoch [31/1000], Loss: 0.2310\n",
      "Epoch [32/1000], Loss: 0.2309\n",
      "Epoch [33/1000], Loss: 0.2309\n",
      "Epoch [34/1000], Loss: 0.2309\n",
      "Epoch [35/1000], Loss: 0.2306\n",
      "Epoch [36/1000], Loss: 0.2302\n",
      "Epoch [37/1000], Loss: 0.2301\n",
      "Epoch [38/1000], Loss: 0.2298\n",
      "Epoch [39/1000], Loss: 0.2298\n",
      "Epoch [40/1000], Loss: 0.2294\n",
      "Epoch [41/1000], Loss: 0.2295\n",
      "Epoch [42/1000], Loss: 0.2292\n",
      "Epoch [43/1000], Loss: 0.2290\n",
      "Epoch [44/1000], Loss: 0.2286\n",
      "Epoch [45/1000], Loss: 0.2285\n",
      "Epoch [46/1000], Loss: 0.2284\n",
      "Epoch [47/1000], Loss: 0.2283\n",
      "Epoch [48/1000], Loss: 0.2278\n",
      "Epoch [49/1000], Loss: 0.2279\n",
      "Epoch [50/1000], Loss: 0.2271\n",
      "Epoch [51/1000], Loss: 0.2275\n",
      "Epoch [52/1000], Loss: 0.2270\n",
      "Epoch [53/1000], Loss: 0.2271\n",
      "Epoch [54/1000], Loss: 0.2267\n",
      "Epoch [55/1000], Loss: 0.2264\n",
      "Epoch [56/1000], Loss: 0.2264\n",
      "Epoch [57/1000], Loss: 0.2262\n",
      "Epoch [58/1000], Loss: 0.2260\n",
      "Epoch [59/1000], Loss: 0.2255\n",
      "Epoch [60/1000], Loss: 0.2252\n",
      "Epoch [61/1000], Loss: 0.2251\n",
      "Epoch [62/1000], Loss: 0.2248\n",
      "Epoch [63/1000], Loss: 0.2244\n",
      "Epoch [64/1000], Loss: 0.2244\n",
      "Epoch [65/1000], Loss: 0.2241\n",
      "Epoch [66/1000], Loss: 0.2236\n",
      "Epoch [67/1000], Loss: 0.2238\n",
      "Epoch [68/1000], Loss: 0.2233\n",
      "Epoch [69/1000], Loss: 0.2232\n",
      "Epoch [70/1000], Loss: 0.2229\n",
      "Epoch [71/1000], Loss: 0.2226\n",
      "Epoch [72/1000], Loss: 0.2219\n",
      "Epoch [73/1000], Loss: 0.2218\n",
      "Epoch [74/1000], Loss: 0.2215\n",
      "Epoch [75/1000], Loss: 0.2210\n",
      "Epoch [76/1000], Loss: 0.2206\n",
      "Epoch [77/1000], Loss: 0.2205\n",
      "Epoch [78/1000], Loss: 0.2202\n",
      "Epoch [79/1000], Loss: 0.2199\n",
      "Epoch [80/1000], Loss: 0.2196\n",
      "Epoch [81/1000], Loss: 0.2192\n",
      "Epoch [82/1000], Loss: 0.2186\n",
      "Epoch [83/1000], Loss: 0.2185\n",
      "Epoch [84/1000], Loss: 0.2184\n",
      "Epoch [85/1000], Loss: 0.2178\n",
      "Epoch [86/1000], Loss: 0.2176\n",
      "Epoch [87/1000], Loss: 0.2171\n",
      "Epoch [88/1000], Loss: 0.2169\n",
      "Epoch [89/1000], Loss: 0.2167\n",
      "Epoch [90/1000], Loss: 0.2163\n",
      "Epoch [91/1000], Loss: 0.2160\n",
      "Epoch [92/1000], Loss: 0.2159\n",
      "Epoch [93/1000], Loss: 0.2156\n",
      "Epoch [94/1000], Loss: 0.2155\n",
      "Epoch [95/1000], Loss: 0.2148\n",
      "Epoch [96/1000], Loss: 0.2147\n",
      "Epoch [97/1000], Loss: 0.2142\n",
      "Epoch [98/1000], Loss: 0.2142\n",
      "Epoch [99/1000], Loss: 0.2137\n",
      "Epoch [100/1000], Loss: 0.2138\n",
      "Epoch [101/1000], Loss: 0.2132\n",
      "Epoch [102/1000], Loss: 0.2135\n",
      "Epoch [103/1000], Loss: 0.2131\n",
      "Epoch [104/1000], Loss: 0.2131\n",
      "Epoch [105/1000], Loss: 0.2125\n",
      "Epoch [106/1000], Loss: 0.2126\n",
      "Epoch [107/1000], Loss: 0.2126\n",
      "Epoch [108/1000], Loss: 0.2116\n",
      "Epoch [109/1000], Loss: 0.2118\n",
      "Epoch [110/1000], Loss: 0.2116\n",
      "Epoch [111/1000], Loss: 0.2114\n",
      "Epoch [112/1000], Loss: 0.2111\n",
      "Epoch [113/1000], Loss: 0.2106\n",
      "Epoch [114/1000], Loss: 0.2106\n",
      "Epoch [115/1000], Loss: 0.2105\n",
      "Epoch [116/1000], Loss: 0.2102\n",
      "Epoch [117/1000], Loss: 0.2099\n",
      "Epoch [118/1000], Loss: 0.2099\n",
      "Epoch [119/1000], Loss: 0.2093\n",
      "Epoch [120/1000], Loss: 0.2091\n",
      "Epoch [121/1000], Loss: 0.2094\n",
      "Epoch [122/1000], Loss: 0.2090\n",
      "Epoch [123/1000], Loss: 0.2085\n",
      "Epoch [124/1000], Loss: 0.2086\n",
      "Epoch [125/1000], Loss: 0.2080\n",
      "Epoch [126/1000], Loss: 0.2076\n",
      "Epoch [127/1000], Loss: 0.2074\n",
      "Epoch [128/1000], Loss: 0.2073\n",
      "Epoch [129/1000], Loss: 0.2071\n",
      "Epoch [130/1000], Loss: 0.2068\n",
      "Epoch [131/1000], Loss: 0.2066\n",
      "Epoch [132/1000], Loss: 0.2061\n",
      "Epoch [133/1000], Loss: 0.2060\n",
      "Epoch [134/1000], Loss: 0.2056\n",
      "Epoch [135/1000], Loss: 0.2057\n",
      "Epoch [136/1000], Loss: 0.2052\n",
      "Epoch [137/1000], Loss: 0.2052\n",
      "Epoch [138/1000], Loss: 0.2050\n",
      "Epoch [139/1000], Loss: 0.2051\n",
      "Epoch [140/1000], Loss: 0.2048\n",
      "Epoch [141/1000], Loss: 0.2046\n",
      "Epoch [142/1000], Loss: 0.2043\n",
      "Epoch [143/1000], Loss: 0.2036\n",
      "Epoch [144/1000], Loss: 0.2043\n",
      "Epoch [145/1000], Loss: 0.2045\n",
      "Epoch [146/1000], Loss: 0.2037\n",
      "Epoch [147/1000], Loss: 0.2037\n",
      "Epoch [148/1000], Loss: 0.2038\n",
      "Epoch [149/1000], Loss: 0.2033\n",
      "Epoch [150/1000], Loss: 0.2031\n",
      "Epoch [151/1000], Loss: 0.2031\n",
      "Epoch [152/1000], Loss: 0.2027\n",
      "Epoch [153/1000], Loss: 0.2025\n",
      "Epoch [154/1000], Loss: 0.2028\n",
      "Epoch [155/1000], Loss: 0.2026\n",
      "Epoch [156/1000], Loss: 0.2021\n",
      "Epoch [157/1000], Loss: 0.2019\n",
      "Epoch [158/1000], Loss: 0.2021\n",
      "Epoch [159/1000], Loss: 0.2016\n",
      "Epoch [160/1000], Loss: 0.2015\n",
      "Epoch [161/1000], Loss: 0.2019\n",
      "Epoch [162/1000], Loss: 0.2013\n",
      "Epoch [163/1000], Loss: 0.2014\n",
      "Epoch [164/1000], Loss: 0.2010\n",
      "Epoch [165/1000], Loss: 0.2012\n",
      "Epoch [166/1000], Loss: 0.2013\n",
      "Epoch [167/1000], Loss: 0.2007\n",
      "Epoch [168/1000], Loss: 0.2006\n",
      "Epoch [169/1000], Loss: 0.2007\n",
      "Epoch [170/1000], Loss: 0.2004\n",
      "Epoch [171/1000], Loss: 0.2002\n",
      "Epoch [172/1000], Loss: 0.1999\n",
      "Epoch [173/1000], Loss: 0.1999\n",
      "Epoch [174/1000], Loss: 0.2001\n",
      "Epoch [175/1000], Loss: 0.1999\n",
      "Epoch [176/1000], Loss: 0.2001\n",
      "Epoch [177/1000], Loss: 0.1993\n",
      "Epoch [178/1000], Loss: 0.1995\n",
      "Epoch [179/1000], Loss: 0.1989\n",
      "Epoch [180/1000], Loss: 0.1991\n",
      "Epoch [181/1000], Loss: 0.1992\n",
      "Epoch [182/1000], Loss: 0.1992\n",
      "Epoch [183/1000], Loss: 0.1988\n",
      "Epoch [184/1000], Loss: 0.1989\n",
      "Epoch [185/1000], Loss: 0.1984\n",
      "Epoch [186/1000], Loss: 0.1985\n",
      "Epoch [187/1000], Loss: 0.1976\n",
      "Epoch [188/1000], Loss: 0.1984\n",
      "Epoch [189/1000], Loss: 0.1981\n",
      "Epoch [190/1000], Loss: 0.1979\n",
      "Epoch [191/1000], Loss: 0.1975\n",
      "Epoch [192/1000], Loss: 0.1977\n",
      "Epoch [193/1000], Loss: 0.1979\n",
      "Epoch [194/1000], Loss: 0.1975\n",
      "Epoch [195/1000], Loss: 0.1974\n",
      "Epoch [196/1000], Loss: 0.1974\n",
      "Epoch [197/1000], Loss: 0.1977\n",
      "Epoch [198/1000], Loss: 0.1968\n",
      "Epoch [199/1000], Loss: 0.1973\n",
      "Epoch [200/1000], Loss: 0.1973\n",
      "Epoch [201/1000], Loss: 0.1964\n",
      "Epoch [202/1000], Loss: 0.1971\n",
      "Epoch [203/1000], Loss: 0.1969\n",
      "Epoch [204/1000], Loss: 0.1965\n",
      "Epoch [205/1000], Loss: 0.1964\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 1, activation : lrelu, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2438\n",
      "Epoch [2/1000], Loss: 0.2376\n",
      "Epoch [3/1000], Loss: 0.2370\n",
      "Epoch [4/1000], Loss: 0.2367\n",
      "Epoch [5/1000], Loss: 0.2362\n",
      "Epoch [6/1000], Loss: 0.2362\n",
      "Epoch [7/1000], Loss: 0.2358\n",
      "Epoch [8/1000], Loss: 0.2354\n",
      "Epoch [9/1000], Loss: 0.2353\n",
      "Epoch [10/1000], Loss: 0.2351\n",
      "Epoch [11/1000], Loss: 0.2350\n",
      "Epoch [12/1000], Loss: 0.2350\n",
      "Epoch [13/1000], Loss: 0.2345\n",
      "Epoch [14/1000], Loss: 0.2345\n",
      "Epoch [15/1000], Loss: 0.2339\n",
      "Epoch [16/1000], Loss: 0.2342\n",
      "Epoch [17/1000], Loss: 0.2337\n",
      "Epoch [18/1000], Loss: 0.2339\n",
      "Epoch [19/1000], Loss: 0.2335\n",
      "Epoch [20/1000], Loss: 0.2333\n",
      "Epoch [21/1000], Loss: 0.2331\n",
      "Epoch [22/1000], Loss: 0.2330\n",
      "Epoch [23/1000], Loss: 0.2329\n",
      "Epoch [24/1000], Loss: 0.2327\n",
      "Epoch [25/1000], Loss: 0.2324\n",
      "Epoch [26/1000], Loss: 0.2321\n",
      "Epoch [27/1000], Loss: 0.2320\n",
      "Epoch [28/1000], Loss: 0.2316\n",
      "Epoch [29/1000], Loss: 0.2310\n",
      "Epoch [30/1000], Loss: 0.2315\n",
      "Epoch [31/1000], Loss: 0.2312\n",
      "Epoch [32/1000], Loss: 0.2309\n",
      "Epoch [33/1000], Loss: 0.2311\n",
      "Epoch [34/1000], Loss: 0.2308\n",
      "Epoch [35/1000], Loss: 0.2306\n",
      "Epoch [36/1000], Loss: 0.2305\n",
      "Epoch [37/1000], Loss: 0.2304\n",
      "Epoch [38/1000], Loss: 0.2297\n",
      "Epoch [39/1000], Loss: 0.2297\n",
      "Epoch [40/1000], Loss: 0.2296\n",
      "Epoch [41/1000], Loss: 0.2293\n",
      "Epoch [42/1000], Loss: 0.2291\n",
      "Epoch [43/1000], Loss: 0.2285\n",
      "Epoch [44/1000], Loss: 0.2284\n",
      "Epoch [45/1000], Loss: 0.2280\n",
      "Epoch [46/1000], Loss: 0.2273\n",
      "Epoch [47/1000], Loss: 0.2270\n",
      "Epoch [48/1000], Loss: 0.2266\n",
      "Epoch [49/1000], Loss: 0.2263\n",
      "Epoch [50/1000], Loss: 0.2261\n",
      "Epoch [51/1000], Loss: 0.2254\n",
      "Epoch [52/1000], Loss: 0.2251\n",
      "Epoch [53/1000], Loss: 0.2246\n",
      "Epoch [54/1000], Loss: 0.2246\n",
      "Epoch [55/1000], Loss: 0.2237\n",
      "Epoch [56/1000], Loss: 0.2235\n",
      "Epoch [57/1000], Loss: 0.2224\n",
      "Epoch [58/1000], Loss: 0.2227\n",
      "Epoch [59/1000], Loss: 0.2220\n",
      "Epoch [60/1000], Loss: 0.2216\n",
      "Epoch [61/1000], Loss: 0.2214\n",
      "Epoch [62/1000], Loss: 0.2206\n",
      "Epoch [63/1000], Loss: 0.2201\n",
      "Epoch [64/1000], Loss: 0.2198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/1000], Loss: 0.2192\n",
      "Epoch [66/1000], Loss: 0.2187\n",
      "Epoch [67/1000], Loss: 0.2183\n",
      "Epoch [68/1000], Loss: 0.2174\n",
      "Epoch [69/1000], Loss: 0.2172\n",
      "Epoch [70/1000], Loss: 0.2166\n",
      "Epoch [71/1000], Loss: 0.2159\n",
      "Epoch [72/1000], Loss: 0.2150\n",
      "Epoch [73/1000], Loss: 0.2148\n",
      "Epoch [74/1000], Loss: 0.2143\n",
      "Epoch [75/1000], Loss: 0.2132\n",
      "Epoch [76/1000], Loss: 0.2129\n",
      "Epoch [77/1000], Loss: 0.2124\n",
      "Epoch [78/1000], Loss: 0.2117\n",
      "Epoch [79/1000], Loss: 0.2109\n",
      "Epoch [80/1000], Loss: 0.2101\n",
      "Epoch [81/1000], Loss: 0.2096\n",
      "Epoch [82/1000], Loss: 0.2085\n",
      "Epoch [83/1000], Loss: 0.2078\n",
      "Epoch [84/1000], Loss: 0.2075\n",
      "Epoch [85/1000], Loss: 0.2064\n",
      "Epoch [86/1000], Loss: 0.2058\n",
      "Epoch [87/1000], Loss: 0.2047\n",
      "Epoch [88/1000], Loss: 0.2041\n",
      "Epoch [89/1000], Loss: 0.2032\n",
      "Epoch [90/1000], Loss: 0.2028\n",
      "Epoch [91/1000], Loss: 0.2017\n",
      "Epoch [92/1000], Loss: 0.2009\n",
      "Epoch [93/1000], Loss: 0.1996\n",
      "Epoch [94/1000], Loss: 0.1992\n",
      "Epoch [95/1000], Loss: 0.1983\n",
      "Epoch [96/1000], Loss: 0.1964\n",
      "Epoch [97/1000], Loss: 0.1968\n",
      "Epoch [98/1000], Loss: 0.1956\n",
      "Epoch [99/1000], Loss: 0.1945\n",
      "Epoch [100/1000], Loss: 0.1940\n",
      "Epoch [101/1000], Loss: 0.1927\n",
      "Epoch [102/1000], Loss: 0.1917\n",
      "Epoch [103/1000], Loss: 0.1910\n",
      "Epoch [104/1000], Loss: 0.1897\n",
      "Epoch [105/1000], Loss: 0.1892\n",
      "Epoch [106/1000], Loss: 0.1882\n",
      "Epoch [107/1000], Loss: 0.1876\n",
      "Epoch [108/1000], Loss: 0.1864\n",
      "Epoch [109/1000], Loss: 0.1857\n",
      "Epoch [110/1000], Loss: 0.1849\n",
      "Epoch [111/1000], Loss: 0.1840\n",
      "Epoch [112/1000], Loss: 0.1828\n",
      "Epoch [113/1000], Loss: 0.1821\n",
      "Epoch [114/1000], Loss: 0.1817\n",
      "Epoch [115/1000], Loss: 0.1806\n",
      "Epoch [116/1000], Loss: 0.1796\n",
      "Epoch [117/1000], Loss: 0.1789\n",
      "Epoch [118/1000], Loss: 0.1781\n",
      "Epoch [119/1000], Loss: 0.1771\n",
      "Epoch [120/1000], Loss: 0.1766\n",
      "Epoch [121/1000], Loss: 0.1757\n",
      "Epoch [122/1000], Loss: 0.1750\n",
      "Epoch [123/1000], Loss: 0.1742\n",
      "Epoch [124/1000], Loss: 0.1734\n",
      "Epoch [125/1000], Loss: 0.1726\n",
      "Epoch [126/1000], Loss: 0.1714\n",
      "Epoch [127/1000], Loss: 0.1710\n",
      "Epoch [128/1000], Loss: 0.1702\n",
      "Epoch [129/1000], Loss: 0.1701\n",
      "Epoch [130/1000], Loss: 0.1694\n",
      "Epoch [131/1000], Loss: 0.1683\n",
      "Epoch [132/1000], Loss: 0.1675\n",
      "Epoch [133/1000], Loss: 0.1671\n",
      "Epoch [134/1000], Loss: 0.1662\n",
      "Epoch [135/1000], Loss: 0.1657\n",
      "Epoch [136/1000], Loss: 0.1652\n",
      "Epoch [137/1000], Loss: 0.1641\n",
      "Epoch [138/1000], Loss: 0.1645\n",
      "Epoch [139/1000], Loss: 0.1632\n",
      "Epoch [140/1000], Loss: 0.1631\n",
      "Epoch [141/1000], Loss: 0.1618\n",
      "Epoch [142/1000], Loss: 0.1611\n",
      "Epoch [143/1000], Loss: 0.1613\n",
      "Epoch [144/1000], Loss: 0.1606\n",
      "Epoch [145/1000], Loss: 0.1597\n",
      "Epoch [146/1000], Loss: 0.1592\n",
      "Epoch [147/1000], Loss: 0.1584\n",
      "Epoch [148/1000], Loss: 0.1580\n",
      "Epoch [149/1000], Loss: 0.1570\n",
      "Epoch [150/1000], Loss: 0.1570\n",
      "Epoch [151/1000], Loss: 0.1566\n",
      "Epoch [152/1000], Loss: 0.1555\n",
      "Epoch [153/1000], Loss: 0.1555\n",
      "Epoch [154/1000], Loss: 0.1547\n",
      "Epoch [155/1000], Loss: 0.1546\n",
      "Epoch [156/1000], Loss: 0.1535\n",
      "Epoch [157/1000], Loss: 0.1522\n",
      "Epoch [158/1000], Loss: 0.1517\n",
      "Epoch [159/1000], Loss: 0.1518\n",
      "Epoch [160/1000], Loss: 0.1512\n",
      "Epoch [161/1000], Loss: 0.1507\n",
      "Epoch [162/1000], Loss: 0.1496\n",
      "Epoch [163/1000], Loss: 0.1488\n",
      "Epoch [164/1000], Loss: 0.1480\n",
      "Epoch [165/1000], Loss: 0.1481\n",
      "Epoch [166/1000], Loss: 0.1467\n",
      "Epoch [167/1000], Loss: 0.1461\n",
      "Epoch [168/1000], Loss: 0.1457\n",
      "Epoch [169/1000], Loss: 0.1459\n",
      "Epoch [170/1000], Loss: 0.1449\n",
      "Epoch [171/1000], Loss: 0.1446\n",
      "Epoch [172/1000], Loss: 0.1443\n",
      "Epoch [173/1000], Loss: 0.1438\n",
      "Epoch [174/1000], Loss: 0.1429\n",
      "Epoch [175/1000], Loss: 0.1428\n",
      "Epoch [176/1000], Loss: 0.1420\n",
      "Epoch [177/1000], Loss: 0.1417\n",
      "Epoch [178/1000], Loss: 0.1409\n",
      "Epoch [179/1000], Loss: 0.1409\n",
      "Epoch [180/1000], Loss: 0.1408\n",
      "Epoch [181/1000], Loss: 0.1396\n",
      "Epoch [182/1000], Loss: 0.1392\n",
      "Epoch [183/1000], Loss: 0.1384\n",
      "Epoch [184/1000], Loss: 0.1390\n",
      "Epoch [185/1000], Loss: 0.1382\n",
      "Epoch [186/1000], Loss: 0.1383\n",
      "Epoch [187/1000], Loss: 0.1370\n",
      "Epoch [188/1000], Loss: 0.1379\n",
      "Epoch [189/1000], Loss: 0.1365\n",
      "Epoch [190/1000], Loss: 0.1366\n",
      "Epoch [191/1000], Loss: 0.1360\n",
      "Epoch [192/1000], Loss: 0.1356\n",
      "Epoch [193/1000], Loss: 0.1353\n",
      "Epoch [194/1000], Loss: 0.1351\n",
      "Epoch [195/1000], Loss: 0.1347\n",
      "Epoch [196/1000], Loss: 0.1335\n",
      "Epoch [197/1000], Loss: 0.1338\n",
      "Epoch [198/1000], Loss: 0.1330\n",
      "Epoch [199/1000], Loss: 0.1327\n",
      "Epoch [200/1000], Loss: 0.1331\n",
      "Epoch [201/1000], Loss: 0.1327\n",
      "Epoch [202/1000], Loss: 0.1328\n",
      "Epoch [203/1000], Loss: 0.1311\n",
      "Epoch [204/1000], Loss: 0.1320\n",
      "Epoch [205/1000], Loss: 0.1306\n",
      "Epoch [206/1000], Loss: 0.1306\n",
      "Epoch [207/1000], Loss: 0.1296\n",
      "Epoch [208/1000], Loss: 0.1297\n",
      "Epoch [209/1000], Loss: 0.1301\n",
      "Epoch [210/1000], Loss: 0.1289\n",
      "Epoch [211/1000], Loss: 0.1274\n",
      "Epoch [212/1000], Loss: 0.1277\n",
      "Epoch [213/1000], Loss: 0.1275\n",
      "Epoch [214/1000], Loss: 0.1274\n",
      "Epoch [215/1000], Loss: 0.1265\n",
      "Epoch [216/1000], Loss: 0.1270\n",
      "Epoch [217/1000], Loss: 0.1259\n",
      "Epoch [218/1000], Loss: 0.1261\n",
      "Epoch [219/1000], Loss: 0.1258\n",
      "Epoch [220/1000], Loss: 0.1251\n",
      "Epoch [221/1000], Loss: 0.1252\n",
      "Epoch [222/1000], Loss: 0.1245\n",
      "Epoch [223/1000], Loss: 0.1240\n",
      "Epoch [224/1000], Loss: 0.1247\n",
      "Epoch [225/1000], Loss: 0.1230\n",
      "Epoch [226/1000], Loss: 0.1230\n",
      "Epoch [227/1000], Loss: 0.1223\n",
      "Epoch [228/1000], Loss: 0.1213\n",
      "Epoch [229/1000], Loss: 0.1222\n",
      "Epoch [230/1000], Loss: 0.1213\n",
      "Epoch [231/1000], Loss: 0.1207\n",
      "Epoch [232/1000], Loss: 0.1209\n",
      "Epoch [233/1000], Loss: 0.1208\n",
      "Epoch [234/1000], Loss: 0.1200\n",
      "Epoch [235/1000], Loss: 0.1204\n",
      "Epoch [236/1000], Loss: 0.1192\n",
      "Epoch [237/1000], Loss: 0.1187\n",
      "Epoch [238/1000], Loss: 0.1186\n",
      "Epoch [239/1000], Loss: 0.1187\n",
      "Epoch [240/1000], Loss: 0.1181\n",
      "Epoch [241/1000], Loss: 0.1174\n",
      "Epoch [242/1000], Loss: 0.1172\n",
      "Epoch [243/1000], Loss: 0.1169\n",
      "Epoch [244/1000], Loss: 0.1169\n",
      "Epoch [245/1000], Loss: 0.1169\n",
      "Epoch [246/1000], Loss: 0.1164\n",
      "Epoch [247/1000], Loss: 0.1153\n",
      "Epoch [248/1000], Loss: 0.1165\n",
      "Epoch [249/1000], Loss: 0.1152\n",
      "Epoch [250/1000], Loss: 0.1149\n",
      "Epoch [251/1000], Loss: 0.1141\n",
      "Epoch [252/1000], Loss: 0.1148\n",
      "Epoch [253/1000], Loss: 0.1144\n",
      "Epoch [254/1000], Loss: 0.1137\n",
      "Epoch [255/1000], Loss: 0.1134\n",
      "Epoch [256/1000], Loss: 0.1124\n",
      "Epoch [257/1000], Loss: 0.1116\n",
      "Epoch [258/1000], Loss: 0.1097\n",
      "Epoch [259/1000], Loss: 0.1102\n",
      "Epoch [260/1000], Loss: 0.1084\n",
      "Epoch [261/1000], Loss: 0.1077\n",
      "Epoch [262/1000], Loss: 0.1075\n",
      "Epoch [263/1000], Loss: 0.1063\n",
      "Epoch [264/1000], Loss: 0.1049\n",
      "Epoch [265/1000], Loss: 0.1035\n",
      "Epoch [266/1000], Loss: 0.1021\n",
      "Epoch [267/1000], Loss: 0.1014\n",
      "Epoch [268/1000], Loss: 0.1010\n",
      "Epoch [269/1000], Loss: 0.0996\n",
      "Epoch [270/1000], Loss: 0.0989\n",
      "Epoch [271/1000], Loss: 0.0976\n",
      "Epoch [272/1000], Loss: 0.0974\n",
      "Epoch [273/1000], Loss: 0.0967\n",
      "Epoch [274/1000], Loss: 0.0954\n",
      "Epoch [275/1000], Loss: 0.0951\n",
      "Epoch [276/1000], Loss: 0.0953\n",
      "Epoch [277/1000], Loss: 0.0941\n",
      "Epoch [278/1000], Loss: 0.0941\n",
      "Epoch [279/1000], Loss: 0.0939\n",
      "Epoch [280/1000], Loss: 0.0936\n",
      "Epoch [281/1000], Loss: 0.0923\n",
      "Epoch [282/1000], Loss: 0.0915\n",
      "Epoch [283/1000], Loss: 0.0914\n",
      "Epoch [284/1000], Loss: 0.0913\n",
      "Epoch [285/1000], Loss: 0.0906\n",
      "Epoch [286/1000], Loss: 0.0907\n",
      "Epoch [287/1000], Loss: 0.0896\n",
      "Epoch [288/1000], Loss: 0.0887\n",
      "Epoch [289/1000], Loss: 0.0896\n",
      "Epoch [290/1000], Loss: 0.0885\n",
      "Epoch [291/1000], Loss: 0.0883\n",
      "Epoch [292/1000], Loss: 0.0879\n",
      "Epoch [293/1000], Loss: 0.0873\n",
      "Epoch [294/1000], Loss: 0.0868\n",
      "Epoch [295/1000], Loss: 0.0861\n",
      "Epoch [296/1000], Loss: 0.0855\n",
      "Epoch [297/1000], Loss: 0.0849\n",
      "Epoch [298/1000], Loss: 0.0843\n",
      "Epoch [299/1000], Loss: 0.0836\n",
      "Epoch [300/1000], Loss: 0.0827\n",
      "Epoch [301/1000], Loss: 0.0824\n",
      "Epoch [302/1000], Loss: 0.0817\n",
      "Epoch [303/1000], Loss: 0.0814\n",
      "Epoch [304/1000], Loss: 0.0804\n",
      "Epoch [305/1000], Loss: 0.0803\n",
      "Epoch [306/1000], Loss: 0.0797\n",
      "Epoch [307/1000], Loss: 0.0791\n",
      "Epoch [308/1000], Loss: 0.0785\n",
      "Epoch [309/1000], Loss: 0.0782\n",
      "Epoch [310/1000], Loss: 0.0779\n",
      "Epoch [311/1000], Loss: 0.0769\n",
      "Epoch [312/1000], Loss: 0.0766\n",
      "Epoch [313/1000], Loss: 0.0763\n",
      "Epoch [314/1000], Loss: 0.0756\n",
      "Epoch [315/1000], Loss: 0.0741\n",
      "Epoch [316/1000], Loss: 0.0744\n",
      "Epoch [317/1000], Loss: 0.0739\n",
      "Epoch [318/1000], Loss: 0.0734\n",
      "Epoch [319/1000], Loss: 0.0729\n",
      "Epoch [320/1000], Loss: 0.0723\n",
      "Epoch [321/1000], Loss: 0.0723\n",
      "Epoch [322/1000], Loss: 0.0717\n",
      "Epoch [323/1000], Loss: 0.0714\n",
      "Epoch [324/1000], Loss: 0.0706\n",
      "Epoch [325/1000], Loss: 0.0704\n",
      "Epoch [326/1000], Loss: 0.0694\n",
      "Epoch [327/1000], Loss: 0.0698\n",
      "Epoch [328/1000], Loss: 0.0696\n",
      "Epoch [329/1000], Loss: 0.0686\n",
      "Epoch [330/1000], Loss: 0.0691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [331/1000], Loss: 0.0681\n",
      "Epoch [332/1000], Loss: 0.0682\n",
      "Epoch [333/1000], Loss: 0.0680\n",
      "Epoch [334/1000], Loss: 0.0672\n",
      "Epoch [335/1000], Loss: 0.0670\n",
      "Epoch [336/1000], Loss: 0.0665\n",
      "Epoch [337/1000], Loss: 0.0662\n",
      "Epoch [338/1000], Loss: 0.0661\n",
      "Epoch [339/1000], Loss: 0.0650\n",
      "Epoch [340/1000], Loss: 0.0655\n",
      "Epoch [341/1000], Loss: 0.0649\n",
      "Epoch [342/1000], Loss: 0.0649\n",
      "Epoch [343/1000], Loss: 0.0646\n",
      "Epoch [344/1000], Loss: 0.0639\n",
      "Epoch [345/1000], Loss: 0.0639\n",
      "Epoch [346/1000], Loss: 0.0641\n",
      "Epoch [347/1000], Loss: 0.0633\n",
      "Epoch [348/1000], Loss: 0.0632\n",
      "Epoch [349/1000], Loss: 0.0629\n",
      "Epoch [350/1000], Loss: 0.0622\n",
      "Epoch [351/1000], Loss: 0.0623\n",
      "Epoch [352/1000], Loss: 0.0620\n",
      "Epoch [353/1000], Loss: 0.0619\n",
      "Epoch [354/1000], Loss: 0.0618\n",
      "Epoch [355/1000], Loss: 0.0617\n",
      "Epoch [356/1000], Loss: 0.0613\n",
      "Epoch [357/1000], Loss: 0.0605\n",
      "Epoch [358/1000], Loss: 0.0608\n",
      "Epoch [359/1000], Loss: 0.0607\n",
      "Epoch [360/1000], Loss: 0.0601\n",
      "Epoch [361/1000], Loss: 0.0603\n",
      "Epoch [362/1000], Loss: 0.0597\n",
      "Epoch [363/1000], Loss: 0.0594\n",
      "Epoch [364/1000], Loss: 0.0596\n",
      "Epoch [365/1000], Loss: 0.0592\n",
      "Epoch [366/1000], Loss: 0.0589\n",
      "Epoch [367/1000], Loss: 0.0588\n",
      "Epoch [368/1000], Loss: 0.0589\n",
      "Epoch [369/1000], Loss: 0.0587\n",
      "Epoch [370/1000], Loss: 0.0587\n",
      "Epoch [371/1000], Loss: 0.0580\n",
      "Epoch [372/1000], Loss: 0.0583\n",
      "Epoch [373/1000], Loss: 0.0573\n",
      "Epoch [374/1000], Loss: 0.0578\n",
      "Epoch [375/1000], Loss: 0.0576\n",
      "Epoch [376/1000], Loss: 0.0569\n",
      "Epoch [377/1000], Loss: 0.0576\n",
      "Epoch [378/1000], Loss: 0.0568\n",
      "Epoch [379/1000], Loss: 0.0568\n",
      "Epoch [380/1000], Loss: 0.0566\n",
      "Epoch [381/1000], Loss: 0.0566\n",
      "Epoch [382/1000], Loss: 0.0564\n",
      "Epoch [383/1000], Loss: 0.0566\n",
      "Epoch [384/1000], Loss: 0.0555\n",
      "Epoch [385/1000], Loss: 0.0560\n",
      "Epoch [386/1000], Loss: 0.0559\n",
      "Epoch [387/1000], Loss: 0.0557\n",
      "Epoch [388/1000], Loss: 0.0552\n",
      "Epoch [389/1000], Loss: 0.0549\n",
      "Epoch [390/1000], Loss: 0.0548\n",
      "Epoch [391/1000], Loss: 0.0549\n",
      "Epoch [392/1000], Loss: 0.0542\n",
      "Epoch [393/1000], Loss: 0.0545\n",
      "Epoch [394/1000], Loss: 0.0555\n",
      "Epoch [395/1000], Loss: 0.0544\n",
      "Epoch [396/1000], Loss: 0.0550\n",
      "Epoch [397/1000], Loss: 0.0542\n",
      "Epoch [398/1000], Loss: 0.0540\n",
      "Epoch [399/1000], Loss: 0.0535\n",
      "Epoch [400/1000], Loss: 0.0530\n",
      "Epoch [401/1000], Loss: 0.0537\n",
      "Epoch [402/1000], Loss: 0.0536\n",
      "Epoch [403/1000], Loss: 0.0532\n",
      "Epoch [404/1000], Loss: 0.0534\n",
      "Epoch [405/1000], Loss: 0.0532\n",
      "Epoch [406/1000], Loss: 0.0530\n",
      "Epoch [407/1000], Loss: 0.0530\n",
      "Epoch [408/1000], Loss: 0.0524\n",
      "Epoch [409/1000], Loss: 0.0523\n",
      "Epoch [410/1000], Loss: 0.0522\n",
      "Epoch [411/1000], Loss: 0.0521\n",
      "Epoch [412/1000], Loss: 0.0521\n",
      "Epoch [413/1000], Loss: 0.0518\n",
      "Epoch [414/1000], Loss: 0.0522\n",
      "Epoch [415/1000], Loss: 0.0517\n",
      "Epoch [416/1000], Loss: 0.0517\n",
      "Epoch [417/1000], Loss: 0.0515\n",
      "Epoch [418/1000], Loss: 0.0514\n",
      "Epoch [419/1000], Loss: 0.0513\n",
      "Epoch [420/1000], Loss: 0.0512\n",
      "Epoch [421/1000], Loss: 0.0513\n",
      "Epoch [422/1000], Loss: 0.0512\n",
      "Epoch [423/1000], Loss: 0.0507\n",
      "Epoch [424/1000], Loss: 0.0511\n",
      "Epoch [425/1000], Loss: 0.0507\n",
      "Epoch [426/1000], Loss: 0.0503\n",
      "Epoch [427/1000], Loss: 0.0502\n",
      "Epoch [428/1000], Loss: 0.0506\n",
      "Epoch [429/1000], Loss: 0.0505\n",
      "Epoch [430/1000], Loss: 0.0499\n",
      "Epoch [431/1000], Loss: 0.0497\n",
      "Epoch [432/1000], Loss: 0.0496\n",
      "Epoch [433/1000], Loss: 0.0496\n",
      "Epoch [434/1000], Loss: 0.0495\n",
      "Epoch [435/1000], Loss: 0.0499\n",
      "Epoch [436/1000], Loss: 0.0501\n",
      "Epoch [437/1000], Loss: 0.0495\n",
      "Epoch [438/1000], Loss: 0.0493\n",
      "Epoch [439/1000], Loss: 0.0487\n",
      "Epoch [440/1000], Loss: 0.0495\n",
      "Epoch [441/1000], Loss: 0.0491\n",
      "Epoch [442/1000], Loss: 0.0487\n",
      "Epoch [443/1000], Loss: 0.0487\n",
      "Epoch [444/1000], Loss: 0.0486\n",
      "Epoch [445/1000], Loss: 0.0484\n",
      "Epoch [446/1000], Loss: 0.0487\n",
      "Epoch [447/1000], Loss: 0.0485\n",
      "Epoch [448/1000], Loss: 0.0484\n",
      "Epoch [449/1000], Loss: 0.0486\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 1, activation : sigmoid, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2549\n",
      "Epoch [2/1000], Loss: 0.2512\n",
      "Epoch [3/1000], Loss: 0.2492\n",
      "Epoch [4/1000], Loss: 0.2478\n",
      "Epoch [5/1000], Loss: 0.2467\n",
      "Epoch [6/1000], Loss: 0.2457\n",
      "Epoch [7/1000], Loss: 0.2449\n",
      "Epoch [8/1000], Loss: 0.2443\n",
      "Epoch [9/1000], Loss: 0.2437\n",
      "Epoch [10/1000], Loss: 0.2432\n",
      "Epoch [11/1000], Loss: 0.2428\n",
      "Epoch [12/1000], Loss: 0.2424\n",
      "Epoch [13/1000], Loss: 0.2420\n",
      "Epoch [14/1000], Loss: 0.2418\n",
      "Epoch [15/1000], Loss: 0.2415\n",
      "Epoch [16/1000], Loss: 0.2413\n",
      "Epoch [17/1000], Loss: 0.2412\n",
      "Epoch [18/1000], Loss: 0.2410\n",
      "Epoch [19/1000], Loss: 0.2409\n",
      "Epoch [20/1000], Loss: 0.2407\n",
      "Epoch [21/1000], Loss: 0.2406\n",
      "Epoch [22/1000], Loss: 0.2405\n",
      "Epoch [23/1000], Loss: 0.2404\n",
      "Epoch [24/1000], Loss: 0.2404\n",
      "Epoch [25/1000], Loss: 0.2403\n",
      "Epoch [26/1000], Loss: 0.2402\n",
      "Epoch [27/1000], Loss: 0.2402\n",
      "Epoch [28/1000], Loss: 0.2401\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 1, activation : sigmoid, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2513\n",
      "Epoch [2/1000], Loss: 0.2448\n",
      "Epoch [3/1000], Loss: 0.2437\n",
      "Epoch [4/1000], Loss: 0.2429\n",
      "Epoch [5/1000], Loss: 0.2423\n",
      "Epoch [6/1000], Loss: 0.2419\n",
      "Epoch [7/1000], Loss: 0.2415\n",
      "Epoch [8/1000], Loss: 0.2413\n",
      "Epoch [9/1000], Loss: 0.2411\n",
      "Epoch [10/1000], Loss: 0.2409\n",
      "Epoch [11/1000], Loss: 0.2407\n",
      "Epoch [12/1000], Loss: 0.2406\n",
      "Epoch [13/1000], Loss: 0.2404\n",
      "Epoch [14/1000], Loss: 0.2404\n",
      "Epoch [15/1000], Loss: 0.2403\n",
      "Epoch [16/1000], Loss: 0.2402\n",
      "Epoch [17/1000], Loss: 0.2401\n",
      "Epoch [18/1000], Loss: 0.2400\n",
      "Epoch [19/1000], Loss: 0.2399\n",
      "Epoch [20/1000], Loss: 0.2398\n",
      "Epoch [21/1000], Loss: 0.2398\n",
      "Epoch [22/1000], Loss: 0.2397\n",
      "Epoch [23/1000], Loss: 0.2396\n",
      "Epoch [24/1000], Loss: 0.2395\n",
      "Epoch [25/1000], Loss: 0.2394\n",
      "Epoch [26/1000], Loss: 0.2393\n",
      "Epoch [27/1000], Loss: 0.2393\n",
      "Epoch [28/1000], Loss: 0.2392\n",
      "Epoch [29/1000], Loss: 0.2391\n",
      "Epoch [30/1000], Loss: 0.2391\n",
      "Epoch [31/1000], Loss: 0.2390\n",
      "Epoch [32/1000], Loss: 0.2389\n",
      "Epoch [33/1000], Loss: 0.2388\n",
      "Epoch [34/1000], Loss: 0.2387\n",
      "Epoch [35/1000], Loss: 0.2387\n",
      "Epoch [36/1000], Loss: 0.2387\n",
      "Epoch [37/1000], Loss: 0.2386\n",
      "Epoch [38/1000], Loss: 0.2385\n",
      "Epoch [39/1000], Loss: 0.2385\n",
      "Epoch [40/1000], Loss: 0.2384\n",
      "Epoch [41/1000], Loss: 0.2383\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 1, activation : sigmoid, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2482\n",
      "Epoch [2/1000], Loss: 0.2426\n",
      "Epoch [3/1000], Loss: 0.2412\n",
      "Epoch [4/1000], Loss: 0.2407\n",
      "Epoch [5/1000], Loss: 0.2405\n",
      "Epoch [6/1000], Loss: 0.2403\n",
      "Epoch [7/1000], Loss: 0.2403\n",
      "Epoch [8/1000], Loss: 0.2402\n",
      "Epoch [9/1000], Loss: 0.2401\n",
      "Epoch [10/1000], Loss: 0.2400\n",
      "Epoch [11/1000], Loss: 0.2399\n",
      "Epoch [12/1000], Loss: 0.2399\n",
      "Epoch [13/1000], Loss: 0.2397\n",
      "Epoch [14/1000], Loss: 0.2397\n",
      "Epoch [15/1000], Loss: 0.2396\n",
      "Epoch [16/1000], Loss: 0.2395\n",
      "Epoch [17/1000], Loss: 0.2395\n",
      "Epoch [18/1000], Loss: 0.2393\n",
      "Epoch [19/1000], Loss: 0.2393\n",
      "Epoch [20/1000], Loss: 0.2393\n",
      "Epoch [21/1000], Loss: 0.2392\n",
      "Epoch [22/1000], Loss: 0.2392\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 1, activation : tanh, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2488\n",
      "Epoch [2/1000], Loss: 0.2439\n",
      "Epoch [3/1000], Loss: 0.2421\n",
      "Epoch [4/1000], Loss: 0.2412\n",
      "Epoch [5/1000], Loss: 0.2406\n",
      "Epoch [6/1000], Loss: 0.2400\n",
      "Epoch [7/1000], Loss: 0.2394\n",
      "Epoch [8/1000], Loss: 0.2388\n",
      "Epoch [9/1000], Loss: 0.2382\n",
      "Epoch [10/1000], Loss: 0.2377\n",
      "Epoch [11/1000], Loss: 0.2373\n",
      "Epoch [12/1000], Loss: 0.2369\n",
      "Epoch [13/1000], Loss: 0.2365\n",
      "Epoch [14/1000], Loss: 0.2363\n",
      "Epoch [15/1000], Loss: 0.2360\n",
      "Epoch [16/1000], Loss: 0.2358\n",
      "Epoch [17/1000], Loss: 0.2356\n",
      "Epoch [18/1000], Loss: 0.2354\n",
      "Epoch [19/1000], Loss: 0.2351\n",
      "Epoch [20/1000], Loss: 0.2349\n",
      "Epoch [21/1000], Loss: 0.2348\n",
      "Epoch [22/1000], Loss: 0.2345\n",
      "Epoch [23/1000], Loss: 0.2343\n",
      "Epoch [24/1000], Loss: 0.2342\n",
      "Epoch [25/1000], Loss: 0.2340\n",
      "Epoch [26/1000], Loss: 0.2338\n",
      "Epoch [27/1000], Loss: 0.2336\n",
      "Epoch [28/1000], Loss: 0.2334\n",
      "Epoch [29/1000], Loss: 0.2332\n",
      "Epoch [30/1000], Loss: 0.2330\n",
      "Epoch [31/1000], Loss: 0.2328\n",
      "Epoch [32/1000], Loss: 0.2326\n",
      "Epoch [33/1000], Loss: 0.2324\n",
      "Epoch [34/1000], Loss: 0.2322\n",
      "Epoch [35/1000], Loss: 0.2321\n",
      "Epoch [36/1000], Loss: 0.2319\n",
      "Epoch [37/1000], Loss: 0.2317\n",
      "Epoch [38/1000], Loss: 0.2316\n",
      "Epoch [39/1000], Loss: 0.2314\n",
      "Epoch [40/1000], Loss: 0.2312\n",
      "Epoch [41/1000], Loss: 0.2311\n",
      "Epoch [42/1000], Loss: 0.2309\n",
      "Epoch [43/1000], Loss: 0.2307\n",
      "Epoch [44/1000], Loss: 0.2306\n",
      "Epoch [45/1000], Loss: 0.2304\n",
      "Epoch [46/1000], Loss: 0.2302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/1000], Loss: 0.2301\n",
      "Epoch [48/1000], Loss: 0.2299\n",
      "Epoch [49/1000], Loss: 0.2297\n",
      "Epoch [50/1000], Loss: 0.2296\n",
      "Epoch [51/1000], Loss: 0.2294\n",
      "Epoch [52/1000], Loss: 0.2292\n",
      "Epoch [53/1000], Loss: 0.2291\n",
      "Epoch [54/1000], Loss: 0.2289\n",
      "Epoch [55/1000], Loss: 0.2288\n",
      "Epoch [56/1000], Loss: 0.2286\n",
      "Epoch [57/1000], Loss: 0.2285\n",
      "Epoch [58/1000], Loss: 0.2283\n",
      "Epoch [59/1000], Loss: 0.2282\n",
      "Epoch [60/1000], Loss: 0.2280\n",
      "Epoch [61/1000], Loss: 0.2278\n",
      "Epoch [62/1000], Loss: 0.2277\n",
      "Epoch [63/1000], Loss: 0.2275\n",
      "Epoch [64/1000], Loss: 0.2273\n",
      "Epoch [65/1000], Loss: 0.2272\n",
      "Epoch [66/1000], Loss: 0.2271\n",
      "Epoch [67/1000], Loss: 0.2269\n",
      "Epoch [68/1000], Loss: 0.2267\n",
      "Epoch [69/1000], Loss: 0.2266\n",
      "Epoch [70/1000], Loss: 0.2264\n",
      "Epoch [71/1000], Loss: 0.2262\n",
      "Epoch [72/1000], Loss: 0.2261\n",
      "Epoch [73/1000], Loss: 0.2258\n",
      "Epoch [74/1000], Loss: 0.2258\n",
      "Epoch [75/1000], Loss: 0.2256\n",
      "Epoch [76/1000], Loss: 0.2253\n",
      "Epoch [77/1000], Loss: 0.2252\n",
      "Epoch [78/1000], Loss: 0.2251\n",
      "Epoch [79/1000], Loss: 0.2249\n",
      "Epoch [80/1000], Loss: 0.2247\n",
      "Epoch [81/1000], Loss: 0.2246\n",
      "Epoch [82/1000], Loss: 0.2244\n",
      "Epoch [83/1000], Loss: 0.2241\n",
      "Epoch [84/1000], Loss: 0.2241\n",
      "Epoch [85/1000], Loss: 0.2239\n",
      "Epoch [86/1000], Loss: 0.2237\n",
      "Epoch [87/1000], Loss: 0.2236\n",
      "Epoch [88/1000], Loss: 0.2234\n",
      "Epoch [89/1000], Loss: 0.2233\n",
      "Epoch [90/1000], Loss: 0.2231\n",
      "Epoch [91/1000], Loss: 0.2229\n",
      "Epoch [92/1000], Loss: 0.2228\n",
      "Epoch [93/1000], Loss: 0.2226\n",
      "Epoch [94/1000], Loss: 0.2224\n",
      "Epoch [95/1000], Loss: 0.2224\n",
      "Epoch [96/1000], Loss: 0.2222\n",
      "Epoch [97/1000], Loss: 0.2220\n",
      "Epoch [98/1000], Loss: 0.2219\n",
      "Epoch [99/1000], Loss: 0.2218\n",
      "Epoch [100/1000], Loss: 0.2216\n",
      "Epoch [101/1000], Loss: 0.2214\n",
      "Epoch [102/1000], Loss: 0.2214\n",
      "Epoch [103/1000], Loss: 0.2212\n",
      "Epoch [104/1000], Loss: 0.2212\n",
      "Epoch [105/1000], Loss: 0.2210\n",
      "Epoch [106/1000], Loss: 0.2208\n",
      "Epoch [107/1000], Loss: 0.2208\n",
      "Epoch [108/1000], Loss: 0.2206\n",
      "Epoch [109/1000], Loss: 0.2206\n",
      "Epoch [110/1000], Loss: 0.2204\n",
      "Epoch [111/1000], Loss: 0.2204\n",
      "Epoch [112/1000], Loss: 0.2203\n",
      "Epoch [113/1000], Loss: 0.2201\n",
      "Epoch [114/1000], Loss: 0.2200\n",
      "Epoch [115/1000], Loss: 0.2200\n",
      "Epoch [116/1000], Loss: 0.2199\n",
      "Epoch [117/1000], Loss: 0.2198\n",
      "Epoch [118/1000], Loss: 0.2196\n",
      "Epoch [119/1000], Loss: 0.2195\n",
      "Epoch [120/1000], Loss: 0.2195\n",
      "Epoch [121/1000], Loss: 0.2195\n",
      "Epoch [122/1000], Loss: 0.2193\n",
      "Epoch [123/1000], Loss: 0.2194\n",
      "Epoch [124/1000], Loss: 0.2193\n",
      "Epoch [125/1000], Loss: 0.2190\n",
      "Epoch [126/1000], Loss: 0.2191\n",
      "Epoch [127/1000], Loss: 0.2190\n",
      "Epoch [128/1000], Loss: 0.2190\n",
      "Epoch [129/1000], Loss: 0.2189\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 1, activation : tanh, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2613\n",
      "Epoch [2/1000], Loss: 0.2411\n",
      "Epoch [3/1000], Loss: 0.2384\n",
      "Epoch [4/1000], Loss: 0.2380\n",
      "Epoch [5/1000], Loss: 0.2377\n",
      "Epoch [6/1000], Loss: 0.2376\n",
      "Epoch [7/1000], Loss: 0.2374\n",
      "Epoch [8/1000], Loss: 0.2373\n",
      "Epoch [9/1000], Loss: 0.2371\n",
      "Epoch [10/1000], Loss: 0.2370\n",
      "Epoch [11/1000], Loss: 0.2369\n",
      "Epoch [12/1000], Loss: 0.2366\n",
      "Epoch [13/1000], Loss: 0.2366\n",
      "Epoch [14/1000], Loss: 0.2365\n",
      "Epoch [15/1000], Loss: 0.2363\n",
      "Epoch [16/1000], Loss: 0.2361\n",
      "Epoch [17/1000], Loss: 0.2361\n",
      "Epoch [18/1000], Loss: 0.2359\n",
      "Epoch [19/1000], Loss: 0.2357\n",
      "Epoch [20/1000], Loss: 0.2356\n",
      "Epoch [21/1000], Loss: 0.2354\n",
      "Epoch [22/1000], Loss: 0.2352\n",
      "Epoch [23/1000], Loss: 0.2350\n",
      "Epoch [24/1000], Loss: 0.2348\n",
      "Epoch [25/1000], Loss: 0.2347\n",
      "Epoch [26/1000], Loss: 0.2344\n",
      "Epoch [27/1000], Loss: 0.2342\n",
      "Epoch [28/1000], Loss: 0.2340\n",
      "Epoch [29/1000], Loss: 0.2338\n",
      "Epoch [30/1000], Loss: 0.2335\n",
      "Epoch [31/1000], Loss: 0.2332\n",
      "Epoch [32/1000], Loss: 0.2329\n",
      "Epoch [33/1000], Loss: 0.2327\n",
      "Epoch [34/1000], Loss: 0.2324\n",
      "Epoch [35/1000], Loss: 0.2321\n",
      "Epoch [36/1000], Loss: 0.2319\n",
      "Epoch [37/1000], Loss: 0.2316\n",
      "Epoch [38/1000], Loss: 0.2313\n",
      "Epoch [39/1000], Loss: 0.2310\n",
      "Epoch [40/1000], Loss: 0.2307\n",
      "Epoch [41/1000], Loss: 0.2304\n",
      "Epoch [42/1000], Loss: 0.2301\n",
      "Epoch [43/1000], Loss: 0.2298\n",
      "Epoch [44/1000], Loss: 0.2295\n",
      "Epoch [45/1000], Loss: 0.2292\n",
      "Epoch [46/1000], Loss: 0.2290\n",
      "Epoch [47/1000], Loss: 0.2287\n",
      "Epoch [48/1000], Loss: 0.2284\n",
      "Epoch [49/1000], Loss: 0.2281\n",
      "Epoch [50/1000], Loss: 0.2278\n",
      "Epoch [51/1000], Loss: 0.2275\n",
      "Epoch [52/1000], Loss: 0.2272\n",
      "Epoch [53/1000], Loss: 0.2270\n",
      "Epoch [54/1000], Loss: 0.2268\n",
      "Epoch [55/1000], Loss: 0.2264\n",
      "Epoch [56/1000], Loss: 0.2262\n",
      "Epoch [57/1000], Loss: 0.2259\n",
      "Epoch [58/1000], Loss: 0.2255\n",
      "Epoch [59/1000], Loss: 0.2253\n",
      "Epoch [60/1000], Loss: 0.2251\n",
      "Epoch [61/1000], Loss: 0.2248\n",
      "Epoch [62/1000], Loss: 0.2245\n",
      "Epoch [63/1000], Loss: 0.2242\n",
      "Epoch [64/1000], Loss: 0.2240\n",
      "Epoch [65/1000], Loss: 0.2236\n",
      "Epoch [66/1000], Loss: 0.2234\n",
      "Epoch [67/1000], Loss: 0.2231\n",
      "Epoch [68/1000], Loss: 0.2228\n",
      "Epoch [69/1000], Loss: 0.2225\n",
      "Epoch [70/1000], Loss: 0.2222\n",
      "Epoch [71/1000], Loss: 0.2218\n",
      "Epoch [72/1000], Loss: 0.2216\n",
      "Epoch [73/1000], Loss: 0.2213\n",
      "Epoch [74/1000], Loss: 0.2210\n",
      "Epoch [75/1000], Loss: 0.2206\n",
      "Epoch [76/1000], Loss: 0.2203\n",
      "Epoch [77/1000], Loss: 0.2200\n",
      "Epoch [78/1000], Loss: 0.2197\n",
      "Epoch [79/1000], Loss: 0.2194\n",
      "Epoch [80/1000], Loss: 0.2190\n",
      "Epoch [81/1000], Loss: 0.2186\n",
      "Epoch [82/1000], Loss: 0.2183\n",
      "Epoch [83/1000], Loss: 0.2179\n",
      "Epoch [84/1000], Loss: 0.2177\n",
      "Epoch [85/1000], Loss: 0.2172\n",
      "Epoch [86/1000], Loss: 0.2170\n",
      "Epoch [87/1000], Loss: 0.2168\n",
      "Epoch [88/1000], Loss: 0.2164\n",
      "Epoch [89/1000], Loss: 0.2163\n",
      "Epoch [90/1000], Loss: 0.2160\n",
      "Epoch [91/1000], Loss: 0.2157\n",
      "Epoch [92/1000], Loss: 0.2155\n",
      "Epoch [93/1000], Loss: 0.2152\n",
      "Epoch [94/1000], Loss: 0.2150\n",
      "Epoch [95/1000], Loss: 0.2147\n",
      "Epoch [96/1000], Loss: 0.2145\n",
      "Epoch [97/1000], Loss: 0.2143\n",
      "Epoch [98/1000], Loss: 0.2139\n",
      "Epoch [99/1000], Loss: 0.2138\n",
      "Epoch [100/1000], Loss: 0.2136\n",
      "Epoch [101/1000], Loss: 0.2134\n",
      "Epoch [102/1000], Loss: 0.2132\n",
      "Epoch [103/1000], Loss: 0.2129\n",
      "Epoch [104/1000], Loss: 0.2127\n",
      "Epoch [105/1000], Loss: 0.2124\n",
      "Epoch [106/1000], Loss: 0.2123\n",
      "Epoch [107/1000], Loss: 0.2119\n",
      "Epoch [108/1000], Loss: 0.2118\n",
      "Epoch [109/1000], Loss: 0.2116\n",
      "Epoch [110/1000], Loss: 0.2114\n",
      "Epoch [111/1000], Loss: 0.2112\n",
      "Epoch [112/1000], Loss: 0.2109\n",
      "Epoch [113/1000], Loss: 0.2107\n",
      "Epoch [114/1000], Loss: 0.2106\n",
      "Epoch [115/1000], Loss: 0.2101\n",
      "Epoch [116/1000], Loss: 0.2100\n",
      "Epoch [117/1000], Loss: 0.2097\n",
      "Epoch [118/1000], Loss: 0.2097\n",
      "Epoch [119/1000], Loss: 0.2094\n",
      "Epoch [120/1000], Loss: 0.2092\n",
      "Epoch [121/1000], Loss: 0.2090\n",
      "Epoch [122/1000], Loss: 0.2088\n",
      "Epoch [123/1000], Loss: 0.2088\n",
      "Epoch [124/1000], Loss: 0.2081\n",
      "Epoch [125/1000], Loss: 0.2084\n",
      "Epoch [126/1000], Loss: 0.2081\n",
      "Epoch [127/1000], Loss: 0.2079\n",
      "Epoch [128/1000], Loss: 0.2076\n",
      "Epoch [129/1000], Loss: 0.2072\n",
      "Epoch [130/1000], Loss: 0.2074\n",
      "Epoch [131/1000], Loss: 0.2071\n",
      "Epoch [132/1000], Loss: 0.2069\n",
      "Epoch [133/1000], Loss: 0.2067\n",
      "Epoch [134/1000], Loss: 0.2066\n",
      "Epoch [135/1000], Loss: 0.2063\n",
      "Epoch [136/1000], Loss: 0.2060\n",
      "Epoch [137/1000], Loss: 0.2060\n",
      "Epoch [138/1000], Loss: 0.2058\n",
      "Epoch [139/1000], Loss: 0.2055\n",
      "Epoch [140/1000], Loss: 0.2054\n",
      "Epoch [141/1000], Loss: 0.2052\n",
      "Epoch [142/1000], Loss: 0.2051\n",
      "Epoch [143/1000], Loss: 0.2048\n",
      "Epoch [144/1000], Loss: 0.2049\n",
      "Epoch [145/1000], Loss: 0.2046\n",
      "Epoch [146/1000], Loss: 0.2044\n",
      "Epoch [147/1000], Loss: 0.2042\n",
      "Epoch [148/1000], Loss: 0.2042\n",
      "Epoch [149/1000], Loss: 0.2040\n",
      "Epoch [150/1000], Loss: 0.2035\n",
      "Epoch [151/1000], Loss: 0.2039\n",
      "Epoch [152/1000], Loss: 0.2032\n",
      "Epoch [153/1000], Loss: 0.2033\n",
      "Epoch [154/1000], Loss: 0.2032\n",
      "Epoch [155/1000], Loss: 0.2030\n",
      "Epoch [156/1000], Loss: 0.2028\n",
      "Epoch [157/1000], Loss: 0.2026\n",
      "Epoch [158/1000], Loss: 0.2025\n",
      "Epoch [159/1000], Loss: 0.2026\n",
      "Epoch [160/1000], Loss: 0.2020\n",
      "Epoch [161/1000], Loss: 0.2019\n",
      "Epoch [162/1000], Loss: 0.2017\n",
      "Epoch [163/1000], Loss: 0.2014\n",
      "Epoch [164/1000], Loss: 0.2012\n",
      "Epoch [165/1000], Loss: 0.2013\n",
      "Epoch [166/1000], Loss: 0.2010\n",
      "Epoch [167/1000], Loss: 0.2010\n",
      "Epoch [168/1000], Loss: 0.2005\n",
      "Epoch [169/1000], Loss: 0.2001\n",
      "Epoch [170/1000], Loss: 0.2005\n",
      "Epoch [171/1000], Loss: 0.2002\n",
      "Epoch [172/1000], Loss: 0.2003\n",
      "Epoch [173/1000], Loss: 0.2001\n",
      "Epoch [174/1000], Loss: 0.1997\n",
      "Epoch [175/1000], Loss: 0.1999\n",
      "Epoch [176/1000], Loss: 0.1990\n",
      "Epoch [177/1000], Loss: 0.1994\n",
      "Epoch [178/1000], Loss: 0.1995\n",
      "Epoch [179/1000], Loss: 0.1994\n",
      "Epoch [180/1000], Loss: 0.1990\n",
      "Epoch [181/1000], Loss: 0.1988\n",
      "Epoch [182/1000], Loss: 0.1988\n",
      "Epoch [183/1000], Loss: 0.1989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [184/1000], Loss: 0.1983\n",
      "Epoch [185/1000], Loss: 0.1983\n",
      "Epoch [186/1000], Loss: 0.1978\n",
      "Epoch [187/1000], Loss: 0.1979\n",
      "Epoch [188/1000], Loss: 0.1979\n",
      "Epoch [189/1000], Loss: 0.1976\n",
      "Epoch [190/1000], Loss: 0.1973\n",
      "Epoch [191/1000], Loss: 0.1977\n",
      "Epoch [192/1000], Loss: 0.1969\n",
      "Epoch [193/1000], Loss: 0.1971\n",
      "Epoch [194/1000], Loss: 0.1971\n",
      "Epoch [195/1000], Loss: 0.1967\n",
      "Epoch [196/1000], Loss: 0.1968\n",
      "Epoch [197/1000], Loss: 0.1960\n",
      "Epoch [198/1000], Loss: 0.1963\n",
      "Epoch [199/1000], Loss: 0.1960\n",
      "Epoch [200/1000], Loss: 0.1963\n",
      "Epoch [201/1000], Loss: 0.1962\n",
      "Epoch [202/1000], Loss: 0.1960\n",
      "Epoch [203/1000], Loss: 0.1959\n",
      "Epoch [204/1000], Loss: 0.1956\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 1, activation : tanh, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2511\n",
      "Epoch [2/1000], Loss: 0.2401\n",
      "Epoch [3/1000], Loss: 0.2389\n",
      "Epoch [4/1000], Loss: 0.2380\n",
      "Epoch [5/1000], Loss: 0.2377\n",
      "Epoch [6/1000], Loss: 0.2372\n",
      "Epoch [7/1000], Loss: 0.2367\n",
      "Epoch [8/1000], Loss: 0.2363\n",
      "Epoch [9/1000], Loss: 0.2360\n",
      "Epoch [10/1000], Loss: 0.2355\n",
      "Epoch [11/1000], Loss: 0.2350\n",
      "Epoch [12/1000], Loss: 0.2346\n",
      "Epoch [13/1000], Loss: 0.2343\n",
      "Epoch [14/1000], Loss: 0.2337\n",
      "Epoch [15/1000], Loss: 0.2333\n",
      "Epoch [16/1000], Loss: 0.2328\n",
      "Epoch [17/1000], Loss: 0.2323\n",
      "Epoch [18/1000], Loss: 0.2318\n",
      "Epoch [19/1000], Loss: 0.2314\n",
      "Epoch [20/1000], Loss: 0.2309\n",
      "Epoch [21/1000], Loss: 0.2302\n",
      "Epoch [22/1000], Loss: 0.2297\n",
      "Epoch [23/1000], Loss: 0.2291\n",
      "Epoch [24/1000], Loss: 0.2287\n",
      "Epoch [25/1000], Loss: 0.2281\n",
      "Epoch [26/1000], Loss: 0.2276\n",
      "Epoch [27/1000], Loss: 0.2271\n",
      "Epoch [28/1000], Loss: 0.2264\n",
      "Epoch [29/1000], Loss: 0.2258\n",
      "Epoch [30/1000], Loss: 0.2252\n",
      "Epoch [31/1000], Loss: 0.2247\n",
      "Epoch [32/1000], Loss: 0.2240\n",
      "Epoch [33/1000], Loss: 0.2235\n",
      "Epoch [34/1000], Loss: 0.2228\n",
      "Epoch [35/1000], Loss: 0.2221\n",
      "Epoch [36/1000], Loss: 0.2216\n",
      "Epoch [37/1000], Loss: 0.2211\n",
      "Epoch [38/1000], Loss: 0.2205\n",
      "Epoch [39/1000], Loss: 0.2200\n",
      "Epoch [40/1000], Loss: 0.2192\n",
      "Epoch [41/1000], Loss: 0.2187\n",
      "Epoch [42/1000], Loss: 0.2181\n",
      "Epoch [43/1000], Loss: 0.2177\n",
      "Epoch [44/1000], Loss: 0.2170\n",
      "Epoch [45/1000], Loss: 0.2165\n",
      "Epoch [46/1000], Loss: 0.2159\n",
      "Epoch [47/1000], Loss: 0.2155\n",
      "Epoch [48/1000], Loss: 0.2148\n",
      "Epoch [49/1000], Loss: 0.2143\n",
      "Epoch [50/1000], Loss: 0.2140\n",
      "Epoch [51/1000], Loss: 0.2134\n",
      "Epoch [52/1000], Loss: 0.2127\n",
      "Epoch [53/1000], Loss: 0.2124\n",
      "Epoch [54/1000], Loss: 0.2118\n",
      "Epoch [55/1000], Loss: 0.2114\n",
      "Epoch [56/1000], Loss: 0.2108\n",
      "Epoch [57/1000], Loss: 0.2105\n",
      "Epoch [58/1000], Loss: 0.2098\n",
      "Epoch [59/1000], Loss: 0.2096\n",
      "Epoch [60/1000], Loss: 0.2089\n",
      "Epoch [61/1000], Loss: 0.2084\n",
      "Epoch [62/1000], Loss: 0.2081\n",
      "Epoch [63/1000], Loss: 0.2077\n",
      "Epoch [64/1000], Loss: 0.2071\n",
      "Epoch [65/1000], Loss: 0.2067\n",
      "Epoch [66/1000], Loss: 0.2061\n",
      "Epoch [67/1000], Loss: 0.2057\n",
      "Epoch [68/1000], Loss: 0.2057\n",
      "Epoch [69/1000], Loss: 0.2047\n",
      "Epoch [70/1000], Loss: 0.2042\n",
      "Epoch [71/1000], Loss: 0.2040\n",
      "Epoch [72/1000], Loss: 0.2036\n",
      "Epoch [73/1000], Loss: 0.2032\n",
      "Epoch [74/1000], Loss: 0.2026\n",
      "Epoch [75/1000], Loss: 0.2021\n",
      "Epoch [76/1000], Loss: 0.2020\n",
      "Epoch [77/1000], Loss: 0.2016\n",
      "Epoch [78/1000], Loss: 0.2009\n",
      "Epoch [79/1000], Loss: 0.2007\n",
      "Epoch [80/1000], Loss: 0.2001\n",
      "Epoch [81/1000], Loss: 0.1999\n",
      "Epoch [82/1000], Loss: 0.1992\n",
      "Epoch [83/1000], Loss: 0.1989\n",
      "Epoch [84/1000], Loss: 0.1987\n",
      "Epoch [85/1000], Loss: 0.1981\n",
      "Epoch [86/1000], Loss: 0.1975\n",
      "Epoch [87/1000], Loss: 0.1974\n",
      "Epoch [88/1000], Loss: 0.1970\n",
      "Epoch [89/1000], Loss: 0.1967\n",
      "Epoch [90/1000], Loss: 0.1962\n",
      "Epoch [91/1000], Loss: 0.1955\n",
      "Epoch [92/1000], Loss: 0.1953\n",
      "Epoch [93/1000], Loss: 0.1944\n",
      "Epoch [94/1000], Loss: 0.1941\n",
      "Epoch [95/1000], Loss: 0.1938\n",
      "Epoch [96/1000], Loss: 0.1927\n",
      "Epoch [97/1000], Loss: 0.1931\n",
      "Epoch [98/1000], Loss: 0.1925\n",
      "Epoch [99/1000], Loss: 0.1926\n",
      "Epoch [100/1000], Loss: 0.1921\n",
      "Epoch [101/1000], Loss: 0.1914\n",
      "Epoch [102/1000], Loss: 0.1912\n",
      "Epoch [103/1000], Loss: 0.1906\n",
      "Epoch [104/1000], Loss: 0.1898\n",
      "Epoch [105/1000], Loss: 0.1898\n",
      "Epoch [106/1000], Loss: 0.1895\n",
      "Epoch [107/1000], Loss: 0.1892\n",
      "Epoch [108/1000], Loss: 0.1886\n",
      "Epoch [109/1000], Loss: 0.1877\n",
      "Epoch [110/1000], Loss: 0.1870\n",
      "Epoch [111/1000], Loss: 0.1870\n",
      "Epoch [112/1000], Loss: 0.1860\n",
      "Epoch [113/1000], Loss: 0.1859\n",
      "Epoch [114/1000], Loss: 0.1853\n",
      "Epoch [115/1000], Loss: 0.1849\n",
      "Epoch [116/1000], Loss: 0.1845\n",
      "Epoch [117/1000], Loss: 0.1842\n",
      "Epoch [118/1000], Loss: 0.1838\n",
      "Epoch [119/1000], Loss: 0.1828\n",
      "Epoch [120/1000], Loss: 0.1826\n",
      "Epoch [121/1000], Loss: 0.1826\n",
      "Epoch [122/1000], Loss: 0.1823\n",
      "Epoch [123/1000], Loss: 0.1816\n",
      "Epoch [124/1000], Loss: 0.1810\n",
      "Epoch [125/1000], Loss: 0.1808\n",
      "Epoch [126/1000], Loss: 0.1799\n",
      "Epoch [127/1000], Loss: 0.1791\n",
      "Epoch [128/1000], Loss: 0.1792\n",
      "Epoch [129/1000], Loss: 0.1786\n",
      "Epoch [130/1000], Loss: 0.1776\n",
      "Epoch [131/1000], Loss: 0.1769\n",
      "Epoch [132/1000], Loss: 0.1774\n",
      "Epoch [133/1000], Loss: 0.1768\n",
      "Epoch [134/1000], Loss: 0.1763\n",
      "Epoch [135/1000], Loss: 0.1755\n",
      "Epoch [136/1000], Loss: 0.1745\n",
      "Epoch [137/1000], Loss: 0.1749\n",
      "Epoch [138/1000], Loss: 0.1739\n",
      "Epoch [139/1000], Loss: 0.1738\n",
      "Epoch [140/1000], Loss: 0.1729\n",
      "Epoch [141/1000], Loss: 0.1728\n",
      "Epoch [142/1000], Loss: 0.1721\n",
      "Epoch [143/1000], Loss: 0.1706\n",
      "Epoch [144/1000], Loss: 0.1702\n",
      "Epoch [145/1000], Loss: 0.1701\n",
      "Epoch [146/1000], Loss: 0.1701\n",
      "Epoch [147/1000], Loss: 0.1689\n",
      "Epoch [148/1000], Loss: 0.1680\n",
      "Epoch [149/1000], Loss: 0.1673\n",
      "Epoch [150/1000], Loss: 0.1668\n",
      "Epoch [151/1000], Loss: 0.1663\n",
      "Epoch [152/1000], Loss: 0.1657\n",
      "Epoch [153/1000], Loss: 0.1654\n",
      "Epoch [154/1000], Loss: 0.1643\n",
      "Epoch [155/1000], Loss: 0.1638\n",
      "Epoch [156/1000], Loss: 0.1632\n",
      "Epoch [157/1000], Loss: 0.1628\n",
      "Epoch [158/1000], Loss: 0.1620\n",
      "Epoch [159/1000], Loss: 0.1614\n",
      "Epoch [160/1000], Loss: 0.1602\n",
      "Epoch [161/1000], Loss: 0.1603\n",
      "Epoch [162/1000], Loss: 0.1591\n",
      "Epoch [163/1000], Loss: 0.1581\n",
      "Epoch [164/1000], Loss: 0.1580\n",
      "Epoch [165/1000], Loss: 0.1571\n",
      "Epoch [166/1000], Loss: 0.1564\n",
      "Epoch [167/1000], Loss: 0.1552\n",
      "Epoch [168/1000], Loss: 0.1547\n",
      "Epoch [169/1000], Loss: 0.1542\n",
      "Epoch [170/1000], Loss: 0.1535\n",
      "Epoch [171/1000], Loss: 0.1532\n",
      "Epoch [172/1000], Loss: 0.1521\n",
      "Epoch [173/1000], Loss: 0.1505\n",
      "Epoch [174/1000], Loss: 0.1508\n",
      "Epoch [175/1000], Loss: 0.1501\n",
      "Epoch [176/1000], Loss: 0.1491\n",
      "Epoch [177/1000], Loss: 0.1483\n",
      "Epoch [178/1000], Loss: 0.1482\n",
      "Epoch [179/1000], Loss: 0.1471\n",
      "Epoch [180/1000], Loss: 0.1461\n",
      "Epoch [181/1000], Loss: 0.1460\n",
      "Epoch [182/1000], Loss: 0.1455\n",
      "Epoch [183/1000], Loss: 0.1446\n",
      "Epoch [184/1000], Loss: 0.1437\n",
      "Epoch [185/1000], Loss: 0.1432\n",
      "Epoch [186/1000], Loss: 0.1432\n",
      "Epoch [187/1000], Loss: 0.1426\n",
      "Epoch [188/1000], Loss: 0.1415\n",
      "Epoch [189/1000], Loss: 0.1409\n",
      "Epoch [190/1000], Loss: 0.1401\n",
      "Epoch [191/1000], Loss: 0.1401\n",
      "Epoch [192/1000], Loss: 0.1392\n",
      "Epoch [193/1000], Loss: 0.1391\n",
      "Epoch [194/1000], Loss: 0.1378\n",
      "Epoch [195/1000], Loss: 0.1374\n",
      "Epoch [196/1000], Loss: 0.1369\n",
      "Epoch [197/1000], Loss: 0.1364\n",
      "Epoch [198/1000], Loss: 0.1357\n",
      "Epoch [199/1000], Loss: 0.1349\n",
      "Epoch [200/1000], Loss: 0.1352\n",
      "Epoch [201/1000], Loss: 0.1344\n",
      "Epoch [202/1000], Loss: 0.1326\n",
      "Epoch [203/1000], Loss: 0.1332\n",
      "Epoch [204/1000], Loss: 0.1328\n",
      "Epoch [205/1000], Loss: 0.1322\n",
      "Epoch [206/1000], Loss: 0.1310\n",
      "Epoch [207/1000], Loss: 0.1314\n",
      "Epoch [208/1000], Loss: 0.1309\n",
      "Epoch [209/1000], Loss: 0.1306\n",
      "Epoch [210/1000], Loss: 0.1288\n",
      "Epoch [211/1000], Loss: 0.1299\n",
      "Epoch [212/1000], Loss: 0.1289\n",
      "Epoch [213/1000], Loss: 0.1287\n",
      "Epoch [214/1000], Loss: 0.1281\n",
      "Epoch [215/1000], Loss: 0.1280\n",
      "Epoch [216/1000], Loss: 0.1274\n",
      "Epoch [217/1000], Loss: 0.1270\n",
      "Epoch [218/1000], Loss: 0.1266\n",
      "Epoch [219/1000], Loss: 0.1262\n",
      "Epoch [220/1000], Loss: 0.1253\n",
      "Epoch [221/1000], Loss: 0.1251\n",
      "Epoch [222/1000], Loss: 0.1249\n",
      "Epoch [223/1000], Loss: 0.1244\n",
      "Epoch [224/1000], Loss: 0.1244\n",
      "Epoch [225/1000], Loss: 0.1236\n",
      "Epoch [226/1000], Loss: 0.1234\n",
      "Epoch [227/1000], Loss: 0.1229\n",
      "Epoch [228/1000], Loss: 0.1224\n",
      "Epoch [229/1000], Loss: 0.1218\n",
      "Epoch [230/1000], Loss: 0.1210\n",
      "Epoch [231/1000], Loss: 0.1202\n",
      "Epoch [232/1000], Loss: 0.1199\n",
      "Epoch [233/1000], Loss: 0.1193\n",
      "Epoch [234/1000], Loss: 0.1187\n",
      "Epoch [235/1000], Loss: 0.1177\n",
      "Epoch [236/1000], Loss: 0.1169\n",
      "Epoch [237/1000], Loss: 0.1164\n",
      "Epoch [238/1000], Loss: 0.1150\n",
      "Epoch [239/1000], Loss: 0.1143\n",
      "Epoch [240/1000], Loss: 0.1137\n",
      "Epoch [241/1000], Loss: 0.1132\n",
      "Epoch [242/1000], Loss: 0.1124\n",
      "Epoch [243/1000], Loss: 0.1120\n",
      "Epoch [244/1000], Loss: 0.1113\n",
      "Epoch [245/1000], Loss: 0.1106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [246/1000], Loss: 0.1102\n",
      "Epoch [247/1000], Loss: 0.1093\n",
      "Epoch [248/1000], Loss: 0.1092\n",
      "Epoch [249/1000], Loss: 0.1082\n",
      "Epoch [250/1000], Loss: 0.1076\n",
      "Epoch [251/1000], Loss: 0.1074\n",
      "Epoch [252/1000], Loss: 0.1064\n",
      "Epoch [253/1000], Loss: 0.1063\n",
      "Epoch [254/1000], Loss: 0.1056\n",
      "Epoch [255/1000], Loss: 0.1048\n",
      "Epoch [256/1000], Loss: 0.1043\n",
      "Epoch [257/1000], Loss: 0.1038\n",
      "Epoch [258/1000], Loss: 0.1034\n",
      "Epoch [259/1000], Loss: 0.1032\n",
      "Epoch [260/1000], Loss: 0.1029\n",
      "Epoch [261/1000], Loss: 0.1024\n",
      "Epoch [262/1000], Loss: 0.1017\n",
      "Epoch [263/1000], Loss: 0.1012\n",
      "Epoch [264/1000], Loss: 0.1010\n",
      "Epoch [265/1000], Loss: 0.1008\n",
      "Epoch [266/1000], Loss: 0.1002\n",
      "Epoch [267/1000], Loss: 0.0998\n",
      "Epoch [268/1000], Loss: 0.0992\n",
      "Epoch [269/1000], Loss: 0.0985\n",
      "Epoch [270/1000], Loss: 0.0975\n",
      "Epoch [271/1000], Loss: 0.0969\n",
      "Epoch [272/1000], Loss: 0.0960\n",
      "Epoch [273/1000], Loss: 0.0952\n",
      "Epoch [274/1000], Loss: 0.0945\n",
      "Epoch [275/1000], Loss: 0.0934\n",
      "Epoch [276/1000], Loss: 0.0918\n",
      "Epoch [277/1000], Loss: 0.0894\n",
      "Epoch [278/1000], Loss: 0.0881\n",
      "Epoch [279/1000], Loss: 0.0868\n",
      "Epoch [280/1000], Loss: 0.0857\n",
      "Epoch [281/1000], Loss: 0.0850\n",
      "Epoch [282/1000], Loss: 0.0841\n",
      "Epoch [283/1000], Loss: 0.0834\n",
      "Epoch [284/1000], Loss: 0.0824\n",
      "Epoch [285/1000], Loss: 0.0819\n",
      "Epoch [286/1000], Loss: 0.0812\n",
      "Epoch [287/1000], Loss: 0.0804\n",
      "Epoch [288/1000], Loss: 0.0797\n",
      "Epoch [289/1000], Loss: 0.0791\n",
      "Epoch [290/1000], Loss: 0.0784\n",
      "Epoch [291/1000], Loss: 0.0777\n",
      "Epoch [292/1000], Loss: 0.0770\n",
      "Epoch [293/1000], Loss: 0.0766\n",
      "Epoch [294/1000], Loss: 0.0758\n",
      "Epoch [295/1000], Loss: 0.0750\n",
      "Epoch [296/1000], Loss: 0.0744\n",
      "Epoch [297/1000], Loss: 0.0740\n",
      "Epoch [298/1000], Loss: 0.0729\n",
      "Epoch [299/1000], Loss: 0.0723\n",
      "Epoch [300/1000], Loss: 0.0715\n",
      "Epoch [301/1000], Loss: 0.0707\n",
      "Epoch [302/1000], Loss: 0.0701\n",
      "Epoch [303/1000], Loss: 0.0693\n",
      "Epoch [304/1000], Loss: 0.0687\n",
      "Epoch [305/1000], Loss: 0.0678\n",
      "Epoch [306/1000], Loss: 0.0672\n",
      "Epoch [307/1000], Loss: 0.0665\n",
      "Epoch [308/1000], Loss: 0.0659\n",
      "Epoch [309/1000], Loss: 0.0649\n",
      "Epoch [310/1000], Loss: 0.0645\n",
      "Epoch [311/1000], Loss: 0.0640\n",
      "Epoch [312/1000], Loss: 0.0634\n",
      "Epoch [313/1000], Loss: 0.0625\n",
      "Epoch [314/1000], Loss: 0.0616\n",
      "Epoch [315/1000], Loss: 0.0617\n",
      "Epoch [316/1000], Loss: 0.0611\n",
      "Epoch [317/1000], Loss: 0.0604\n",
      "Epoch [318/1000], Loss: 0.0598\n",
      "Epoch [319/1000], Loss: 0.0594\n",
      "Epoch [320/1000], Loss: 0.0589\n",
      "Epoch [321/1000], Loss: 0.0584\n",
      "Epoch [322/1000], Loss: 0.0579\n",
      "Epoch [323/1000], Loss: 0.0573\n",
      "Epoch [324/1000], Loss: 0.0568\n",
      "Epoch [325/1000], Loss: 0.0564\n",
      "Epoch [326/1000], Loss: 0.0559\n",
      "Epoch [327/1000], Loss: 0.0555\n",
      "Epoch [328/1000], Loss: 0.0549\n",
      "Epoch [329/1000], Loss: 0.0544\n",
      "Epoch [330/1000], Loss: 0.0541\n",
      "Epoch [331/1000], Loss: 0.0536\n",
      "Epoch [332/1000], Loss: 0.0530\n",
      "Epoch [333/1000], Loss: 0.0526\n",
      "Epoch [334/1000], Loss: 0.0524\n",
      "Epoch [335/1000], Loss: 0.0518\n",
      "Epoch [336/1000], Loss: 0.0514\n",
      "Epoch [337/1000], Loss: 0.0512\n",
      "Epoch [338/1000], Loss: 0.0507\n",
      "Epoch [339/1000], Loss: 0.0503\n",
      "Epoch [340/1000], Loss: 0.0498\n",
      "Epoch [341/1000], Loss: 0.0497\n",
      "Epoch [342/1000], Loss: 0.0492\n",
      "Epoch [343/1000], Loss: 0.0488\n",
      "Epoch [344/1000], Loss: 0.0485\n",
      "Epoch [345/1000], Loss: 0.0481\n",
      "Epoch [346/1000], Loss: 0.0478\n",
      "Epoch [347/1000], Loss: 0.0474\n",
      "Epoch [348/1000], Loss: 0.0470\n",
      "Epoch [349/1000], Loss: 0.0467\n",
      "Epoch [350/1000], Loss: 0.0464\n",
      "Epoch [351/1000], Loss: 0.0461\n",
      "Epoch [352/1000], Loss: 0.0459\n",
      "Epoch [353/1000], Loss: 0.0454\n",
      "Epoch [354/1000], Loss: 0.0450\n",
      "Epoch [355/1000], Loss: 0.0450\n",
      "Epoch [356/1000], Loss: 0.0446\n",
      "Epoch [357/1000], Loss: 0.0443\n",
      "Epoch [358/1000], Loss: 0.0440\n",
      "Epoch [359/1000], Loss: 0.0437\n",
      "Epoch [360/1000], Loss: 0.0432\n",
      "Epoch [361/1000], Loss: 0.0430\n",
      "Epoch [362/1000], Loss: 0.0427\n",
      "Epoch [363/1000], Loss: 0.0425\n",
      "Epoch [364/1000], Loss: 0.0422\n",
      "Epoch [365/1000], Loss: 0.0420\n",
      "Epoch [366/1000], Loss: 0.0415\n",
      "Epoch [367/1000], Loss: 0.0414\n",
      "Epoch [368/1000], Loss: 0.0411\n",
      "Epoch [369/1000], Loss: 0.0407\n",
      "Epoch [370/1000], Loss: 0.0408\n",
      "Epoch [371/1000], Loss: 0.0401\n",
      "Epoch [372/1000], Loss: 0.0402\n",
      "Epoch [373/1000], Loss: 0.0399\n",
      "Epoch [374/1000], Loss: 0.0396\n",
      "Epoch [375/1000], Loss: 0.0395\n",
      "Epoch [376/1000], Loss: 0.0390\n",
      "Epoch [377/1000], Loss: 0.0390\n",
      "Epoch [378/1000], Loss: 0.0388\n",
      "Epoch [379/1000], Loss: 0.0384\n",
      "Epoch [380/1000], Loss: 0.0381\n",
      "Epoch [381/1000], Loss: 0.0380\n",
      "Epoch [382/1000], Loss: 0.0377\n",
      "Epoch [383/1000], Loss: 0.0376\n",
      "Epoch [384/1000], Loss: 0.0372\n",
      "Epoch [385/1000], Loss: 0.0371\n",
      "Epoch [386/1000], Loss: 0.0369\n",
      "Epoch [387/1000], Loss: 0.0367\n",
      "Epoch [388/1000], Loss: 0.0364\n",
      "Epoch [389/1000], Loss: 0.0361\n",
      "Epoch [390/1000], Loss: 0.0359\n",
      "Epoch [391/1000], Loss: 0.0359\n",
      "Epoch [392/1000], Loss: 0.0355\n",
      "Epoch [393/1000], Loss: 0.0355\n",
      "Epoch [394/1000], Loss: 0.0352\n",
      "Epoch [395/1000], Loss: 0.0350\n",
      "Epoch [396/1000], Loss: 0.0349\n",
      "Epoch [397/1000], Loss: 0.0346\n",
      "Epoch [398/1000], Loss: 0.0344\n",
      "Epoch [399/1000], Loss: 0.0343\n",
      "Epoch [400/1000], Loss: 0.0341\n",
      "Epoch [401/1000], Loss: 0.0339\n",
      "Epoch [402/1000], Loss: 0.0337\n",
      "Epoch [403/1000], Loss: 0.0335\n",
      "Epoch [404/1000], Loss: 0.0333\n",
      "Epoch [405/1000], Loss: 0.0332\n",
      "Epoch [406/1000], Loss: 0.0331\n",
      "Epoch [407/1000], Loss: 0.0329\n",
      "Epoch [408/1000], Loss: 0.0326\n",
      "Epoch [409/1000], Loss: 0.0326\n",
      "Epoch [410/1000], Loss: 0.0323\n",
      "Epoch [411/1000], Loss: 0.0321\n",
      "Epoch [412/1000], Loss: 0.0320\n",
      "Epoch [413/1000], Loss: 0.0318\n",
      "Epoch [414/1000], Loss: 0.0317\n",
      "Epoch [415/1000], Loss: 0.0315\n",
      "Epoch [416/1000], Loss: 0.0314\n",
      "Epoch [417/1000], Loss: 0.0311\n",
      "Epoch [418/1000], Loss: 0.0311\n",
      "Epoch [419/1000], Loss: 0.0309\n",
      "Epoch [420/1000], Loss: 0.0308\n",
      "Epoch [421/1000], Loss: 0.0305\n",
      "Epoch [422/1000], Loss: 0.0304\n",
      "Epoch [423/1000], Loss: 0.0302\n",
      "Epoch [424/1000], Loss: 0.0301\n",
      "Epoch [425/1000], Loss: 0.0300\n",
      "Epoch [426/1000], Loss: 0.0299\n",
      "Epoch [427/1000], Loss: 0.0297\n",
      "Epoch [428/1000], Loss: 0.0296\n",
      "Epoch [429/1000], Loss: 0.0294\n",
      "Epoch [430/1000], Loss: 0.0292\n",
      "Epoch [431/1000], Loss: 0.0292\n",
      "Epoch [432/1000], Loss: 0.0290\n",
      "Epoch [433/1000], Loss: 0.0289\n",
      "Epoch [434/1000], Loss: 0.0286\n",
      "Epoch [435/1000], Loss: 0.0286\n",
      "Epoch [436/1000], Loss: 0.0284\n",
      "Epoch [437/1000], Loss: 0.0284\n",
      "Epoch [438/1000], Loss: 0.0282\n",
      "Epoch [439/1000], Loss: 0.0280\n",
      "Epoch [440/1000], Loss: 0.0280\n",
      "Epoch [441/1000], Loss: 0.0278\n",
      "Epoch [442/1000], Loss: 0.0278\n",
      "Epoch [443/1000], Loss: 0.0277\n",
      "Epoch [444/1000], Loss: 0.0275\n",
      "Epoch [445/1000], Loss: 0.0274\n",
      "Epoch [446/1000], Loss: 0.0272\n",
      "Epoch [447/1000], Loss: 0.0271\n",
      "Epoch [448/1000], Loss: 0.0271\n",
      "Epoch [449/1000], Loss: 0.0269\n",
      "Epoch [450/1000], Loss: 0.0267\n",
      "Epoch [451/1000], Loss: 0.0265\n",
      "Epoch [452/1000], Loss: 0.0266\n",
      "Epoch [453/1000], Loss: 0.0264\n",
      "Epoch [454/1000], Loss: 0.0263\n",
      "Epoch [455/1000], Loss: 0.0262\n",
      "Epoch [456/1000], Loss: 0.0260\n",
      "Epoch [457/1000], Loss: 0.0260\n",
      "Epoch [458/1000], Loss: 0.0258\n",
      "Epoch [459/1000], Loss: 0.0258\n",
      "Epoch [460/1000], Loss: 0.0257\n",
      "Epoch [461/1000], Loss: 0.0255\n",
      "Epoch [462/1000], Loss: 0.0254\n",
      "Epoch [463/1000], Loss: 0.0253\n",
      "Epoch [464/1000], Loss: 0.0252\n",
      "Epoch [465/1000], Loss: 0.0251\n",
      "Epoch [466/1000], Loss: 0.0250\n",
      "Epoch [467/1000], Loss: 0.0249\n",
      "Epoch [468/1000], Loss: 0.0248\n",
      "Epoch [469/1000], Loss: 0.0247\n",
      "Epoch [470/1000], Loss: 0.0245\n",
      "Epoch [471/1000], Loss: 0.0246\n",
      "Epoch [472/1000], Loss: 0.0244\n",
      "Epoch [473/1000], Loss: 0.0243\n",
      "Epoch [474/1000], Loss: 0.0243\n",
      "Epoch [475/1000], Loss: 0.0241\n",
      "Epoch [476/1000], Loss: 0.0241\n",
      "Epoch [477/1000], Loss: 0.0240\n",
      "Epoch [478/1000], Loss: 0.0239\n",
      "Epoch [479/1000], Loss: 0.0237\n",
      "Epoch [480/1000], Loss: 0.0237\n",
      "Epoch [481/1000], Loss: 0.0236\n",
      "Epoch [482/1000], Loss: 0.0235\n",
      "Epoch [483/1000], Loss: 0.0233\n",
      "Epoch [484/1000], Loss: 0.0233\n",
      "Epoch [485/1000], Loss: 0.0231\n",
      "Epoch [486/1000], Loss: 0.0232\n",
      "Epoch [487/1000], Loss: 0.0231\n",
      "Epoch [488/1000], Loss: 0.0229\n",
      "Epoch [489/1000], Loss: 0.0229\n",
      "Epoch [490/1000], Loss: 0.0228\n",
      "Epoch [491/1000], Loss: 0.0228\n",
      "Epoch [492/1000], Loss: 0.0227\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 2, activation : relu, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2603\n",
      "Epoch [2/1000], Loss: 0.2502\n",
      "Epoch [3/1000], Loss: 0.2472\n",
      "Epoch [4/1000], Loss: 0.2443\n",
      "Epoch [5/1000], Loss: 0.2417\n",
      "Epoch [6/1000], Loss: 0.2397\n",
      "Epoch [7/1000], Loss: 0.2382\n",
      "Epoch [8/1000], Loss: 0.2371\n",
      "Epoch [9/1000], Loss: 0.2365\n",
      "Epoch [10/1000], Loss: 0.2361\n",
      "Epoch [11/1000], Loss: 0.2357\n",
      "Epoch [12/1000], Loss: 0.2355\n",
      "Epoch [13/1000], Loss: 0.2352\n",
      "Epoch [14/1000], Loss: 0.2348\n",
      "Epoch [15/1000], Loss: 0.2345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/1000], Loss: 0.2342\n",
      "Epoch [17/1000], Loss: 0.2339\n",
      "Epoch [18/1000], Loss: 0.2336\n",
      "Epoch [19/1000], Loss: 0.2333\n",
      "Epoch [20/1000], Loss: 0.2330\n",
      "Epoch [21/1000], Loss: 0.2327\n",
      "Epoch [22/1000], Loss: 0.2324\n",
      "Epoch [23/1000], Loss: 0.2321\n",
      "Epoch [24/1000], Loss: 0.2317\n",
      "Epoch [25/1000], Loss: 0.2314\n",
      "Epoch [26/1000], Loss: 0.2311\n",
      "Epoch [27/1000], Loss: 0.2307\n",
      "Epoch [28/1000], Loss: 0.2304\n",
      "Epoch [29/1000], Loss: 0.2300\n",
      "Epoch [30/1000], Loss: 0.2296\n",
      "Epoch [31/1000], Loss: 0.2293\n",
      "Epoch [32/1000], Loss: 0.2289\n",
      "Epoch [33/1000], Loss: 0.2284\n",
      "Epoch [34/1000], Loss: 0.2280\n",
      "Epoch [35/1000], Loss: 0.2275\n",
      "Epoch [36/1000], Loss: 0.2271\n",
      "Epoch [37/1000], Loss: 0.2265\n",
      "Epoch [38/1000], Loss: 0.2260\n",
      "Epoch [39/1000], Loss: 0.2255\n",
      "Epoch [40/1000], Loss: 0.2249\n",
      "Epoch [41/1000], Loss: 0.2243\n",
      "Epoch [42/1000], Loss: 0.2237\n",
      "Epoch [43/1000], Loss: 0.2230\n",
      "Epoch [44/1000], Loss: 0.2223\n",
      "Epoch [45/1000], Loss: 0.2216\n",
      "Epoch [46/1000], Loss: 0.2209\n",
      "Epoch [47/1000], Loss: 0.2201\n",
      "Epoch [48/1000], Loss: 0.2193\n",
      "Epoch [49/1000], Loss: 0.2185\n",
      "Epoch [50/1000], Loss: 0.2176\n",
      "Epoch [51/1000], Loss: 0.2166\n",
      "Epoch [52/1000], Loss: 0.2156\n",
      "Epoch [53/1000], Loss: 0.2146\n",
      "Epoch [54/1000], Loss: 0.2135\n",
      "Epoch [55/1000], Loss: 0.2125\n",
      "Epoch [56/1000], Loss: 0.2113\n",
      "Epoch [57/1000], Loss: 0.2101\n",
      "Epoch [58/1000], Loss: 0.2087\n",
      "Epoch [59/1000], Loss: 0.2055\n",
      "Epoch [60/1000], Loss: 0.2019\n",
      "Epoch [61/1000], Loss: 0.2001\n",
      "Epoch [62/1000], Loss: 0.1983\n",
      "Epoch [63/1000], Loss: 0.1963\n",
      "Epoch [64/1000], Loss: 0.1941\n",
      "Epoch [65/1000], Loss: 0.1923\n",
      "Epoch [66/1000], Loss: 0.1900\n",
      "Epoch [67/1000], Loss: 0.1885\n",
      "Epoch [68/1000], Loss: 0.1868\n",
      "Epoch [69/1000], Loss: 0.1847\n",
      "Epoch [70/1000], Loss: 0.1828\n",
      "Epoch [71/1000], Loss: 0.1810\n",
      "Epoch [72/1000], Loss: 0.1789\n",
      "Epoch [73/1000], Loss: 0.1769\n",
      "Epoch [74/1000], Loss: 0.1749\n",
      "Epoch [75/1000], Loss: 0.1729\n",
      "Epoch [76/1000], Loss: 0.1710\n",
      "Epoch [77/1000], Loss: 0.1695\n",
      "Epoch [78/1000], Loss: 0.1678\n",
      "Epoch [79/1000], Loss: 0.1663\n",
      "Epoch [80/1000], Loss: 0.1649\n",
      "Epoch [81/1000], Loss: 0.1636\n",
      "Epoch [82/1000], Loss: 0.1622\n",
      "Epoch [83/1000], Loss: 0.1610\n",
      "Epoch [84/1000], Loss: 0.1598\n",
      "Epoch [85/1000], Loss: 0.1586\n",
      "Epoch [86/1000], Loss: 0.1574\n",
      "Epoch [87/1000], Loss: 0.1563\n",
      "Epoch [88/1000], Loss: 0.1551\n",
      "Epoch [89/1000], Loss: 0.1529\n",
      "Epoch [90/1000], Loss: 0.1513\n",
      "Epoch [91/1000], Loss: 0.1498\n",
      "Epoch [92/1000], Loss: 0.1484\n",
      "Epoch [93/1000], Loss: 0.1469\n",
      "Epoch [94/1000], Loss: 0.1456\n",
      "Epoch [95/1000], Loss: 0.1441\n",
      "Epoch [96/1000], Loss: 0.1432\n",
      "Epoch [97/1000], Loss: 0.1419\n",
      "Epoch [98/1000], Loss: 0.1406\n",
      "Epoch [99/1000], Loss: 0.1394\n",
      "Epoch [100/1000], Loss: 0.1383\n",
      "Epoch [101/1000], Loss: 0.1371\n",
      "Epoch [102/1000], Loss: 0.1360\n",
      "Epoch [103/1000], Loss: 0.1347\n",
      "Epoch [104/1000], Loss: 0.1335\n",
      "Epoch [105/1000], Loss: 0.1322\n",
      "Epoch [106/1000], Loss: 0.1311\n",
      "Epoch [107/1000], Loss: 0.1296\n",
      "Epoch [108/1000], Loss: 0.1285\n",
      "Epoch [109/1000], Loss: 0.1269\n",
      "Epoch [110/1000], Loss: 0.1258\n",
      "Epoch [111/1000], Loss: 0.1239\n",
      "Epoch [112/1000], Loss: 0.1224\n",
      "Epoch [113/1000], Loss: 0.1210\n",
      "Epoch [114/1000], Loss: 0.1187\n",
      "Epoch [115/1000], Loss: 0.1172\n",
      "Epoch [116/1000], Loss: 0.1155\n",
      "Epoch [117/1000], Loss: 0.1137\n",
      "Epoch [118/1000], Loss: 0.1121\n",
      "Epoch [119/1000], Loss: 0.1108\n",
      "Epoch [120/1000], Loss: 0.1089\n",
      "Epoch [121/1000], Loss: 0.1077\n",
      "Epoch [122/1000], Loss: 0.1066\n",
      "Epoch [123/1000], Loss: 0.1045\n",
      "Epoch [124/1000], Loss: 0.1029\n",
      "Epoch [125/1000], Loss: 0.1012\n",
      "Epoch [126/1000], Loss: 0.0993\n",
      "Epoch [127/1000], Loss: 0.0977\n",
      "Epoch [128/1000], Loss: 0.0961\n",
      "Epoch [129/1000], Loss: 0.0943\n",
      "Epoch [130/1000], Loss: 0.0928\n",
      "Epoch [131/1000], Loss: 0.0910\n",
      "Epoch [132/1000], Loss: 0.0886\n",
      "Epoch [133/1000], Loss: 0.0860\n",
      "Epoch [134/1000], Loss: 0.0833\n",
      "Epoch [135/1000], Loss: 0.0805\n",
      "Epoch [136/1000], Loss: 0.0776\n",
      "Epoch [137/1000], Loss: 0.0754\n",
      "Epoch [138/1000], Loss: 0.0736\n",
      "Epoch [139/1000], Loss: 0.0719\n",
      "Epoch [140/1000], Loss: 0.0702\n",
      "Epoch [141/1000], Loss: 0.0688\n",
      "Epoch [142/1000], Loss: 0.0672\n",
      "Epoch [143/1000], Loss: 0.0659\n",
      "Epoch [144/1000], Loss: 0.0644\n",
      "Epoch [145/1000], Loss: 0.0631\n",
      "Epoch [146/1000], Loss: 0.0617\n",
      "Epoch [147/1000], Loss: 0.0601\n",
      "Epoch [148/1000], Loss: 0.0589\n",
      "Epoch [149/1000], Loss: 0.0574\n",
      "Epoch [150/1000], Loss: 0.0560\n",
      "Epoch [151/1000], Loss: 0.0547\n",
      "Epoch [152/1000], Loss: 0.0532\n",
      "Epoch [153/1000], Loss: 0.0519\n",
      "Epoch [154/1000], Loss: 0.0507\n",
      "Epoch [155/1000], Loss: 0.0493\n",
      "Epoch [156/1000], Loss: 0.0482\n",
      "Epoch [157/1000], Loss: 0.0468\n",
      "Epoch [158/1000], Loss: 0.0455\n",
      "Epoch [159/1000], Loss: 0.0445\n",
      "Epoch [160/1000], Loss: 0.0430\n",
      "Epoch [161/1000], Loss: 0.0422\n",
      "Epoch [162/1000], Loss: 0.0408\n",
      "Epoch [163/1000], Loss: 0.0399\n",
      "Epoch [164/1000], Loss: 0.0387\n",
      "Epoch [165/1000], Loss: 0.0376\n",
      "Epoch [166/1000], Loss: 0.0367\n",
      "Epoch [167/1000], Loss: 0.0358\n",
      "Epoch [168/1000], Loss: 0.0350\n",
      "Epoch [169/1000], Loss: 0.0340\n",
      "Epoch [170/1000], Loss: 0.0333\n",
      "Epoch [171/1000], Loss: 0.0322\n",
      "Epoch [172/1000], Loss: 0.0315\n",
      "Epoch [173/1000], Loss: 0.0309\n",
      "Epoch [174/1000], Loss: 0.0302\n",
      "Epoch [175/1000], Loss: 0.0295\n",
      "Epoch [176/1000], Loss: 0.0289\n",
      "Epoch [177/1000], Loss: 0.0283\n",
      "Epoch [178/1000], Loss: 0.0276\n",
      "Epoch [179/1000], Loss: 0.0272\n",
      "Epoch [180/1000], Loss: 0.0265\n",
      "Epoch [181/1000], Loss: 0.0261\n",
      "Epoch [182/1000], Loss: 0.0257\n",
      "Epoch [183/1000], Loss: 0.0250\n",
      "Epoch [184/1000], Loss: 0.0247\n",
      "Epoch [185/1000], Loss: 0.0241\n",
      "Epoch [186/1000], Loss: 0.0240\n",
      "Epoch [187/1000], Loss: 0.0234\n",
      "Epoch [188/1000], Loss: 0.0228\n",
      "Epoch [189/1000], Loss: 0.0224\n",
      "Epoch [190/1000], Loss: 0.0221\n",
      "Epoch [191/1000], Loss: 0.0217\n",
      "Epoch [192/1000], Loss: 0.0213\n",
      "Epoch [193/1000], Loss: 0.0207\n",
      "Epoch [194/1000], Loss: 0.0204\n",
      "Epoch [195/1000], Loss: 0.0202\n",
      "Epoch [196/1000], Loss: 0.0197\n",
      "Epoch [197/1000], Loss: 0.0193\n",
      "Epoch [198/1000], Loss: 0.0189\n",
      "Epoch [199/1000], Loss: 0.0185\n",
      "Epoch [200/1000], Loss: 0.0182\n",
      "Epoch [201/1000], Loss: 0.0181\n",
      "Epoch [202/1000], Loss: 0.0177\n",
      "Epoch [203/1000], Loss: 0.0173\n",
      "Epoch [204/1000], Loss: 0.0173\n",
      "Epoch [205/1000], Loss: 0.0168\n",
      "Epoch [206/1000], Loss: 0.0166\n",
      "Epoch [207/1000], Loss: 0.0163\n",
      "Epoch [208/1000], Loss: 0.0161\n",
      "Epoch [209/1000], Loss: 0.0157\n",
      "Epoch [210/1000], Loss: 0.0156\n",
      "Epoch [211/1000], Loss: 0.0152\n",
      "Epoch [212/1000], Loss: 0.0153\n",
      "Epoch [213/1000], Loss: 0.0149\n",
      "Epoch [214/1000], Loss: 0.0147\n",
      "Epoch [215/1000], Loss: 0.0146\n",
      "Epoch [216/1000], Loss: 0.0144\n",
      "Epoch [217/1000], Loss: 0.0140\n",
      "Epoch [218/1000], Loss: 0.0140\n",
      "Epoch [219/1000], Loss: 0.0139\n",
      "Epoch [220/1000], Loss: 0.0137\n",
      "Epoch [221/1000], Loss: 0.0135\n",
      "Epoch [222/1000], Loss: 0.0130\n",
      "Epoch [223/1000], Loss: 0.0129\n",
      "Epoch [224/1000], Loss: 0.0130\n",
      "Epoch [225/1000], Loss: 0.0127\n",
      "Epoch [226/1000], Loss: 0.0126\n",
      "Epoch [227/1000], Loss: 0.0124\n",
      "Epoch [228/1000], Loss: 0.0123\n",
      "Epoch [229/1000], Loss: 0.0122\n",
      "Epoch [230/1000], Loss: 0.0120\n",
      "Epoch [231/1000], Loss: 0.0119\n",
      "Epoch [232/1000], Loss: 0.0118\n",
      "Epoch [233/1000], Loss: 0.0116\n",
      "Epoch [234/1000], Loss: 0.0115\n",
      "Epoch [235/1000], Loss: 0.0114\n",
      "Epoch [236/1000], Loss: 0.0111\n",
      "Epoch [237/1000], Loss: 0.0111\n",
      "Epoch [238/1000], Loss: 0.0108\n",
      "Epoch [239/1000], Loss: 0.0107\n",
      "Epoch [240/1000], Loss: 0.0108\n",
      "Epoch [241/1000], Loss: 0.0106\n",
      "Epoch [242/1000], Loss: 0.0105\n",
      "Epoch [243/1000], Loss: 0.0103\n",
      "Epoch [244/1000], Loss: 0.0102\n",
      "Epoch [245/1000], Loss: 0.0101\n",
      "Epoch [246/1000], Loss: 0.0101\n",
      "Epoch [247/1000], Loss: 0.0100\n",
      "Epoch [248/1000], Loss: 0.0100\n",
      "Epoch [249/1000], Loss: 0.0098\n",
      "Epoch [250/1000], Loss: 0.0098\n",
      "Epoch [251/1000], Loss: 0.0096\n",
      "Epoch [252/1000], Loss: 0.0096\n",
      "Epoch [253/1000], Loss: 0.0093\n",
      "Epoch [254/1000], Loss: 0.0093\n",
      "Epoch [255/1000], Loss: 0.0093\n",
      "Epoch [256/1000], Loss: 0.0092\n",
      "Epoch [257/1000], Loss: 0.0091\n",
      "Epoch [258/1000], Loss: 0.0089\n",
      "Epoch [259/1000], Loss: 0.0089\n",
      "Epoch [260/1000], Loss: 0.0089\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 2, activation : relu, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2427\n",
      "Epoch [2/1000], Loss: 0.2405\n",
      "Epoch [3/1000], Loss: 0.2394\n",
      "Epoch [4/1000], Loss: 0.2386\n",
      "Epoch [5/1000], Loss: 0.2380\n",
      "Epoch [6/1000], Loss: 0.2375\n",
      "Epoch [7/1000], Loss: 0.2370\n",
      "Epoch [8/1000], Loss: 0.2365\n",
      "Epoch [9/1000], Loss: 0.2360\n",
      "Epoch [10/1000], Loss: 0.2356\n",
      "Epoch [11/1000], Loss: 0.2351\n",
      "Epoch [12/1000], Loss: 0.2346\n",
      "Epoch [13/1000], Loss: 0.2342\n",
      "Epoch [14/1000], Loss: 0.2337\n",
      "Epoch [15/1000], Loss: 0.2333\n",
      "Epoch [16/1000], Loss: 0.2328\n",
      "Epoch [17/1000], Loss: 0.2323\n",
      "Epoch [18/1000], Loss: 0.2318\n",
      "Epoch [19/1000], Loss: 0.2313\n",
      "Epoch [20/1000], Loss: 0.2307\n",
      "Epoch [21/1000], Loss: 0.2303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/1000], Loss: 0.2300\n",
      "Epoch [23/1000], Loss: 0.2296\n",
      "Epoch [24/1000], Loss: 0.2291\n",
      "Epoch [25/1000], Loss: 0.2287\n",
      "Epoch [26/1000], Loss: 0.2283\n",
      "Epoch [27/1000], Loss: 0.2278\n",
      "Epoch [28/1000], Loss: 0.2271\n",
      "Epoch [29/1000], Loss: 0.2270\n",
      "Epoch [30/1000], Loss: 0.2264\n",
      "Epoch [31/1000], Loss: 0.2258\n",
      "Epoch [32/1000], Loss: 0.2252\n",
      "Epoch [33/1000], Loss: 0.2245\n",
      "Epoch [34/1000], Loss: 0.2238\n",
      "Epoch [35/1000], Loss: 0.2232\n",
      "Epoch [36/1000], Loss: 0.2221\n",
      "Epoch [37/1000], Loss: 0.2216\n",
      "Epoch [38/1000], Loss: 0.2206\n",
      "Epoch [39/1000], Loss: 0.2197\n",
      "Epoch [40/1000], Loss: 0.2187\n",
      "Epoch [41/1000], Loss: 0.2177\n",
      "Epoch [42/1000], Loss: 0.2167\n",
      "Epoch [43/1000], Loss: 0.2152\n",
      "Epoch [44/1000], Loss: 0.2140\n",
      "Epoch [45/1000], Loss: 0.2124\n",
      "Epoch [46/1000], Loss: 0.2110\n",
      "Epoch [47/1000], Loss: 0.2092\n",
      "Epoch [48/1000], Loss: 0.2066\n",
      "Epoch [49/1000], Loss: 0.2045\n",
      "Epoch [50/1000], Loss: 0.2027\n",
      "Epoch [51/1000], Loss: 0.2005\n",
      "Epoch [52/1000], Loss: 0.1981\n",
      "Epoch [53/1000], Loss: 0.1957\n",
      "Epoch [54/1000], Loss: 0.1926\n",
      "Epoch [55/1000], Loss: 0.1895\n",
      "Epoch [56/1000], Loss: 0.1863\n",
      "Epoch [57/1000], Loss: 0.1834\n",
      "Epoch [58/1000], Loss: 0.1808\n",
      "Epoch [59/1000], Loss: 0.1780\n",
      "Epoch [60/1000], Loss: 0.1753\n",
      "Epoch [61/1000], Loss: 0.1723\n",
      "Epoch [62/1000], Loss: 0.1691\n",
      "Epoch [63/1000], Loss: 0.1655\n",
      "Epoch [64/1000], Loss: 0.1628\n",
      "Epoch [65/1000], Loss: 0.1587\n",
      "Epoch [66/1000], Loss: 0.1551\n",
      "Epoch [67/1000], Loss: 0.1515\n",
      "Epoch [68/1000], Loss: 0.1471\n",
      "Epoch [69/1000], Loss: 0.1430\n",
      "Epoch [70/1000], Loss: 0.1384\n",
      "Epoch [71/1000], Loss: 0.1337\n",
      "Epoch [72/1000], Loss: 0.1287\n",
      "Epoch [73/1000], Loss: 0.1241\n",
      "Epoch [74/1000], Loss: 0.1191\n",
      "Epoch [75/1000], Loss: 0.1143\n",
      "Epoch [76/1000], Loss: 0.1098\n",
      "Epoch [77/1000], Loss: 0.1055\n",
      "Epoch [78/1000], Loss: 0.1011\n",
      "Epoch [79/1000], Loss: 0.0967\n",
      "Epoch [80/1000], Loss: 0.0925\n",
      "Epoch [81/1000], Loss: 0.0888\n",
      "Epoch [82/1000], Loss: 0.0852\n",
      "Epoch [83/1000], Loss: 0.0818\n",
      "Epoch [84/1000], Loss: 0.0786\n",
      "Epoch [85/1000], Loss: 0.0758\n",
      "Epoch [86/1000], Loss: 0.0732\n",
      "Epoch [87/1000], Loss: 0.0707\n",
      "Epoch [88/1000], Loss: 0.0685\n",
      "Epoch [89/1000], Loss: 0.0664\n",
      "Epoch [90/1000], Loss: 0.0642\n",
      "Epoch [91/1000], Loss: 0.0626\n",
      "Epoch [92/1000], Loss: 0.0610\n",
      "Epoch [93/1000], Loss: 0.0590\n",
      "Epoch [94/1000], Loss: 0.0579\n",
      "Epoch [95/1000], Loss: 0.0561\n",
      "Epoch [96/1000], Loss: 0.0552\n",
      "Epoch [97/1000], Loss: 0.0537\n",
      "Epoch [98/1000], Loss: 0.0524\n",
      "Epoch [99/1000], Loss: 0.0513\n",
      "Epoch [100/1000], Loss: 0.0502\n",
      "Epoch [101/1000], Loss: 0.0492\n",
      "Epoch [102/1000], Loss: 0.0485\n",
      "Epoch [103/1000], Loss: 0.0475\n",
      "Epoch [104/1000], Loss: 0.0466\n",
      "Epoch [105/1000], Loss: 0.0453\n",
      "Epoch [106/1000], Loss: 0.0445\n",
      "Epoch [107/1000], Loss: 0.0439\n",
      "Epoch [108/1000], Loss: 0.0427\n",
      "Epoch [109/1000], Loss: 0.0422\n",
      "Epoch [110/1000], Loss: 0.0415\n",
      "Epoch [111/1000], Loss: 0.0408\n",
      "Epoch [112/1000], Loss: 0.0402\n",
      "Epoch [113/1000], Loss: 0.0390\n",
      "Epoch [114/1000], Loss: 0.0388\n",
      "Epoch [115/1000], Loss: 0.0383\n",
      "Epoch [116/1000], Loss: 0.0377\n",
      "Epoch [117/1000], Loss: 0.0371\n",
      "Epoch [118/1000], Loss: 0.0364\n",
      "Epoch [119/1000], Loss: 0.0358\n",
      "Epoch [120/1000], Loss: 0.0352\n",
      "Epoch [121/1000], Loss: 0.0348\n",
      "Epoch [122/1000], Loss: 0.0339\n",
      "Epoch [123/1000], Loss: 0.0335\n",
      "Epoch [124/1000], Loss: 0.0328\n",
      "Epoch [125/1000], Loss: 0.0324\n",
      "Epoch [126/1000], Loss: 0.0318\n",
      "Epoch [127/1000], Loss: 0.0312\n",
      "Epoch [128/1000], Loss: 0.0303\n",
      "Epoch [129/1000], Loss: 0.0298\n",
      "Epoch [130/1000], Loss: 0.0293\n",
      "Epoch [131/1000], Loss: 0.0286\n",
      "Epoch [132/1000], Loss: 0.0280\n",
      "Epoch [133/1000], Loss: 0.0269\n",
      "Epoch [134/1000], Loss: 0.0266\n",
      "Epoch [135/1000], Loss: 0.0260\n",
      "Epoch [136/1000], Loss: 0.0251\n",
      "Epoch [137/1000], Loss: 0.0246\n",
      "Epoch [138/1000], Loss: 0.0238\n",
      "Epoch [139/1000], Loss: 0.0231\n",
      "Epoch [140/1000], Loss: 0.0224\n",
      "Epoch [141/1000], Loss: 0.0216\n",
      "Epoch [142/1000], Loss: 0.0209\n",
      "Epoch [143/1000], Loss: 0.0200\n",
      "Epoch [144/1000], Loss: 0.0198\n",
      "Epoch [145/1000], Loss: 0.0192\n",
      "Epoch [146/1000], Loss: 0.0186\n",
      "Epoch [147/1000], Loss: 0.0178\n",
      "Epoch [148/1000], Loss: 0.0174\n",
      "Epoch [149/1000], Loss: 0.0170\n",
      "Epoch [150/1000], Loss: 0.0164\n",
      "Epoch [151/1000], Loss: 0.0156\n",
      "Epoch [152/1000], Loss: 0.0150\n",
      "Epoch [153/1000], Loss: 0.0144\n",
      "Epoch [154/1000], Loss: 0.0139\n",
      "Epoch [155/1000], Loss: 0.0140\n",
      "Epoch [156/1000], Loss: 0.0132\n",
      "Epoch [157/1000], Loss: 0.0130\n",
      "Epoch [158/1000], Loss: 0.0128\n",
      "Epoch [159/1000], Loss: 0.0121\n",
      "Epoch [160/1000], Loss: 0.0121\n",
      "Epoch [161/1000], Loss: 0.0118\n",
      "Epoch [162/1000], Loss: 0.0113\n",
      "Epoch [163/1000], Loss: 0.0112\n",
      "Epoch [164/1000], Loss: 0.0110\n",
      "Epoch [165/1000], Loss: 0.0106\n",
      "Epoch [166/1000], Loss: 0.0105\n",
      "Epoch [167/1000], Loss: 0.0104\n",
      "Epoch [168/1000], Loss: 0.0099\n",
      "Epoch [169/1000], Loss: 0.0099\n",
      "Epoch [170/1000], Loss: 0.0094\n",
      "Epoch [171/1000], Loss: 0.0093\n",
      "Epoch [172/1000], Loss: 0.0092\n",
      "Epoch [173/1000], Loss: 0.0090\n",
      "Epoch [174/1000], Loss: 0.0088\n",
      "Epoch [175/1000], Loss: 0.0086\n",
      "Epoch [176/1000], Loss: 0.0084\n",
      "Epoch [177/1000], Loss: 0.0081\n",
      "Epoch [178/1000], Loss: 0.0080\n",
      "Epoch [179/1000], Loss: 0.0080\n",
      "Epoch [180/1000], Loss: 0.0077\n",
      "Epoch [181/1000], Loss: 0.0074\n",
      "Epoch [182/1000], Loss: 0.0075\n",
      "Epoch [183/1000], Loss: 0.0071\n",
      "Epoch [184/1000], Loss: 0.0071\n",
      "Epoch [185/1000], Loss: 0.0070\n",
      "Epoch [186/1000], Loss: 0.0068\n",
      "Epoch [187/1000], Loss: 0.0068\n",
      "Epoch [188/1000], Loss: 0.0067\n",
      "Epoch [189/1000], Loss: 0.0064\n",
      "Epoch [190/1000], Loss: 0.0062\n",
      "Epoch [191/1000], Loss: 0.0060\n",
      "Epoch [192/1000], Loss: 0.0061\n",
      "Epoch [193/1000], Loss: 0.0059\n",
      "Epoch [194/1000], Loss: 0.0057\n",
      "Epoch [195/1000], Loss: 0.0056\n",
      "Epoch [196/1000], Loss: 0.0055\n",
      "Epoch [197/1000], Loss: 0.0053\n",
      "Epoch [198/1000], Loss: 0.0053\n",
      "Epoch [199/1000], Loss: 0.0052\n",
      "Epoch [200/1000], Loss: 0.0050\n",
      "Epoch [201/1000], Loss: 0.0050\n",
      "Epoch [202/1000], Loss: 0.0048\n",
      "Epoch [203/1000], Loss: 0.0047\n",
      "Epoch [204/1000], Loss: 0.0047\n",
      "Epoch [205/1000], Loss: 0.0045\n",
      "Epoch [206/1000], Loss: 0.0045\n",
      "Epoch [207/1000], Loss: 0.0045\n",
      "Epoch [208/1000], Loss: 0.0042\n",
      "Epoch [209/1000], Loss: 0.0042\n",
      "Epoch [210/1000], Loss: 0.0042\n",
      "Epoch [211/1000], Loss: 0.0041\n",
      "Epoch [212/1000], Loss: 0.0041\n",
      "Epoch [213/1000], Loss: 0.0039\n",
      "Epoch [214/1000], Loss: 0.0039\n",
      "Epoch [215/1000], Loss: 0.0038\n",
      "Epoch [216/1000], Loss: 0.0038\n",
      "Epoch [217/1000], Loss: 0.0037\n",
      "Epoch [218/1000], Loss: 0.0036\n",
      "Epoch [219/1000], Loss: 0.0036\n",
      "Epoch [220/1000], Loss: 0.0036\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 2, activation : relu, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2375\n",
      "Epoch [2/1000], Loss: 0.2365\n",
      "Epoch [3/1000], Loss: 0.2360\n",
      "Epoch [4/1000], Loss: 0.2354\n",
      "Epoch [5/1000], Loss: 0.2350\n",
      "Epoch [6/1000], Loss: 0.2345\n",
      "Epoch [7/1000], Loss: 0.2344\n",
      "Epoch [8/1000], Loss: 0.2335\n",
      "Epoch [9/1000], Loss: 0.2337\n",
      "Epoch [10/1000], Loss: 0.2333\n",
      "Epoch [11/1000], Loss: 0.2330\n",
      "Epoch [12/1000], Loss: 0.2325\n",
      "Epoch [13/1000], Loss: 0.2323\n",
      "Epoch [14/1000], Loss: 0.2318\n",
      "Epoch [15/1000], Loss: 0.2314\n",
      "Epoch [16/1000], Loss: 0.2308\n",
      "Epoch [17/1000], Loss: 0.2310\n",
      "Epoch [18/1000], Loss: 0.2304\n",
      "Epoch [19/1000], Loss: 0.2298\n",
      "Epoch [20/1000], Loss: 0.2293\n",
      "Epoch [21/1000], Loss: 0.2287\n",
      "Epoch [22/1000], Loss: 0.2281\n",
      "Epoch [23/1000], Loss: 0.2275\n",
      "Epoch [24/1000], Loss: 0.2266\n",
      "Epoch [25/1000], Loss: 0.2262\n",
      "Epoch [26/1000], Loss: 0.2253\n",
      "Epoch [27/1000], Loss: 0.2244\n",
      "Epoch [28/1000], Loss: 0.2237\n",
      "Epoch [29/1000], Loss: 0.2223\n",
      "Epoch [30/1000], Loss: 0.2209\n",
      "Epoch [31/1000], Loss: 0.2197\n",
      "Epoch [32/1000], Loss: 0.2181\n",
      "Epoch [33/1000], Loss: 0.2161\n",
      "Epoch [34/1000], Loss: 0.2142\n",
      "Epoch [35/1000], Loss: 0.2121\n",
      "Epoch [36/1000], Loss: 0.2095\n",
      "Epoch [37/1000], Loss: 0.2072\n",
      "Epoch [38/1000], Loss: 0.2048\n",
      "Epoch [39/1000], Loss: 0.2016\n",
      "Epoch [40/1000], Loss: 0.1985\n",
      "Epoch [41/1000], Loss: 0.1951\n",
      "Epoch [42/1000], Loss: 0.1914\n",
      "Epoch [43/1000], Loss: 0.1875\n",
      "Epoch [44/1000], Loss: 0.1835\n",
      "Epoch [45/1000], Loss: 0.1789\n",
      "Epoch [46/1000], Loss: 0.1738\n",
      "Epoch [47/1000], Loss: 0.1691\n",
      "Epoch [48/1000], Loss: 0.1643\n",
      "Epoch [49/1000], Loss: 0.1585\n",
      "Epoch [50/1000], Loss: 0.1526\n",
      "Epoch [51/1000], Loss: 0.1468\n",
      "Epoch [52/1000], Loss: 0.1396\n",
      "Epoch [53/1000], Loss: 0.1327\n",
      "Epoch [54/1000], Loss: 0.1267\n",
      "Epoch [55/1000], Loss: 0.1198\n",
      "Epoch [56/1000], Loss: 0.1132\n",
      "Epoch [57/1000], Loss: 0.1058\n",
      "Epoch [58/1000], Loss: 0.0992\n",
      "Epoch [59/1000], Loss: 0.0920\n",
      "Epoch [60/1000], Loss: 0.0859\n",
      "Epoch [61/1000], Loss: 0.0795\n",
      "Epoch [62/1000], Loss: 0.0740\n",
      "Epoch [63/1000], Loss: 0.0685\n",
      "Epoch [64/1000], Loss: 0.0634\n",
      "Epoch [65/1000], Loss: 0.0586\n",
      "Epoch [66/1000], Loss: 0.0540\n",
      "Epoch [67/1000], Loss: 0.0494\n",
      "Epoch [68/1000], Loss: 0.0453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/1000], Loss: 0.0402\n",
      "Epoch [70/1000], Loss: 0.0361\n",
      "Epoch [71/1000], Loss: 0.0327\n",
      "Epoch [72/1000], Loss: 0.0297\n",
      "Epoch [73/1000], Loss: 0.0274\n",
      "Epoch [74/1000], Loss: 0.0251\n",
      "Epoch [75/1000], Loss: 0.0232\n",
      "Epoch [76/1000], Loss: 0.0213\n",
      "Epoch [77/1000], Loss: 0.0197\n",
      "Epoch [78/1000], Loss: 0.0183\n",
      "Epoch [79/1000], Loss: 0.0170\n",
      "Epoch [80/1000], Loss: 0.0158\n",
      "Epoch [81/1000], Loss: 0.0149\n",
      "Epoch [82/1000], Loss: 0.0140\n",
      "Epoch [83/1000], Loss: 0.0130\n",
      "Epoch [84/1000], Loss: 0.0123\n",
      "Epoch [85/1000], Loss: 0.0117\n",
      "Epoch [86/1000], Loss: 0.0110\n",
      "Epoch [87/1000], Loss: 0.0104\n",
      "Epoch [88/1000], Loss: 0.0099\n",
      "Epoch [89/1000], Loss: 0.0095\n",
      "Epoch [90/1000], Loss: 0.0090\n",
      "Epoch [91/1000], Loss: 0.0086\n",
      "Epoch [92/1000], Loss: 0.0082\n",
      "Epoch [93/1000], Loss: 0.0080\n",
      "Epoch [94/1000], Loss: 0.0076\n",
      "Epoch [95/1000], Loss: 0.0073\n",
      "Epoch [96/1000], Loss: 0.0070\n",
      "Epoch [97/1000], Loss: 0.0067\n",
      "Epoch [98/1000], Loss: 0.0064\n",
      "Epoch [99/1000], Loss: 0.0062\n",
      "Epoch [100/1000], Loss: 0.0060\n",
      "Epoch [101/1000], Loss: 0.0058\n",
      "Epoch [102/1000], Loss: 0.0056\n",
      "Epoch [103/1000], Loss: 0.0054\n",
      "Epoch [104/1000], Loss: 0.0053\n",
      "Epoch [105/1000], Loss: 0.0051\n",
      "Epoch [106/1000], Loss: 0.0050\n",
      "Epoch [107/1000], Loss: 0.0048\n",
      "Epoch [108/1000], Loss: 0.0047\n",
      "Epoch [109/1000], Loss: 0.0045\n",
      "Epoch [110/1000], Loss: 0.0044\n",
      "Epoch [111/1000], Loss: 0.0043\n",
      "Epoch [112/1000], Loss: 0.0042\n",
      "Epoch [113/1000], Loss: 0.0041\n",
      "Epoch [114/1000], Loss: 0.0040\n",
      "Epoch [115/1000], Loss: 0.0039\n",
      "Epoch [116/1000], Loss: 0.0038\n",
      "Epoch [117/1000], Loss: 0.0037\n",
      "Epoch [118/1000], Loss: 0.0036\n",
      "Epoch [119/1000], Loss: 0.0035\n",
      "Epoch [120/1000], Loss: 0.0035\n",
      "Epoch [121/1000], Loss: 0.0034\n",
      "Epoch [122/1000], Loss: 0.0033\n",
      "Epoch [123/1000], Loss: 0.0032\n",
      "Epoch [124/1000], Loss: 0.0032\n",
      "Epoch [125/1000], Loss: 0.0031\n",
      "Epoch [126/1000], Loss: 0.0031\n",
      "Epoch [127/1000], Loss: 0.0030\n",
      "Epoch [128/1000], Loss: 0.0029\n",
      "Epoch [129/1000], Loss: 0.0029\n",
      "Epoch [130/1000], Loss: 0.0028\n",
      "Epoch [131/1000], Loss: 0.0028\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 2, activation : lrelu, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2636\n",
      "Epoch [2/1000], Loss: 0.2514\n",
      "Epoch [3/1000], Loss: 0.2477\n",
      "Epoch [4/1000], Loss: 0.2454\n",
      "Epoch [5/1000], Loss: 0.2437\n",
      "Epoch [6/1000], Loss: 0.2423\n",
      "Epoch [7/1000], Loss: 0.2411\n",
      "Epoch [8/1000], Loss: 0.2401\n",
      "Epoch [9/1000], Loss: 0.2393\n",
      "Epoch [10/1000], Loss: 0.2386\n",
      "Epoch [11/1000], Loss: 0.2380\n",
      "Epoch [12/1000], Loss: 0.2374\n",
      "Epoch [13/1000], Loss: 0.2369\n",
      "Epoch [14/1000], Loss: 0.2363\n",
      "Epoch [15/1000], Loss: 0.2359\n",
      "Epoch [16/1000], Loss: 0.2355\n",
      "Epoch [17/1000], Loss: 0.2350\n",
      "Epoch [18/1000], Loss: 0.2345\n",
      "Epoch [19/1000], Loss: 0.2341\n",
      "Epoch [20/1000], Loss: 0.2337\n",
      "Epoch [21/1000], Loss: 0.2333\n",
      "Epoch [22/1000], Loss: 0.2328\n",
      "Epoch [23/1000], Loss: 0.2324\n",
      "Epoch [24/1000], Loss: 0.2319\n",
      "Epoch [25/1000], Loss: 0.2314\n",
      "Epoch [26/1000], Loss: 0.2309\n",
      "Epoch [27/1000], Loss: 0.2303\n",
      "Epoch [28/1000], Loss: 0.2298\n",
      "Epoch [29/1000], Loss: 0.2292\n",
      "Epoch [30/1000], Loss: 0.2286\n",
      "Epoch [31/1000], Loss: 0.2280\n",
      "Epoch [32/1000], Loss: 0.2272\n",
      "Epoch [33/1000], Loss: 0.2265\n",
      "Epoch [34/1000], Loss: 0.2257\n",
      "Epoch [35/1000], Loss: 0.2250\n",
      "Epoch [36/1000], Loss: 0.2241\n",
      "Epoch [37/1000], Loss: 0.2230\n",
      "Epoch [38/1000], Loss: 0.2219\n",
      "Epoch [39/1000], Loss: 0.2208\n",
      "Epoch [40/1000], Loss: 0.2194\n",
      "Epoch [41/1000], Loss: 0.2181\n",
      "Epoch [42/1000], Loss: 0.2168\n",
      "Epoch [43/1000], Loss: 0.2157\n",
      "Epoch [44/1000], Loss: 0.2145\n",
      "Epoch [45/1000], Loss: 0.2132\n",
      "Epoch [46/1000], Loss: 0.2118\n",
      "Epoch [47/1000], Loss: 0.2103\n",
      "Epoch [48/1000], Loss: 0.2085\n",
      "Epoch [49/1000], Loss: 0.2065\n",
      "Epoch [50/1000], Loss: 0.2037\n",
      "Epoch [51/1000], Loss: 0.2013\n",
      "Epoch [52/1000], Loss: 0.1994\n",
      "Epoch [53/1000], Loss: 0.1976\n",
      "Epoch [54/1000], Loss: 0.1957\n",
      "Epoch [55/1000], Loss: 0.1938\n",
      "Epoch [56/1000], Loss: 0.1923\n",
      "Epoch [57/1000], Loss: 0.1904\n",
      "Epoch [58/1000], Loss: 0.1887\n",
      "Epoch [59/1000], Loss: 0.1868\n",
      "Epoch [60/1000], Loss: 0.1850\n",
      "Epoch [61/1000], Loss: 0.1833\n",
      "Epoch [62/1000], Loss: 0.1815\n",
      "Epoch [63/1000], Loss: 0.1798\n",
      "Epoch [64/1000], Loss: 0.1783\n",
      "Epoch [65/1000], Loss: 0.1765\n",
      "Epoch [66/1000], Loss: 0.1753\n",
      "Epoch [67/1000], Loss: 0.1739\n",
      "Epoch [68/1000], Loss: 0.1726\n",
      "Epoch [69/1000], Loss: 0.1712\n",
      "Epoch [70/1000], Loss: 0.1701\n",
      "Epoch [71/1000], Loss: 0.1689\n",
      "Epoch [72/1000], Loss: 0.1676\n",
      "Epoch [73/1000], Loss: 0.1666\n",
      "Epoch [74/1000], Loss: 0.1658\n",
      "Epoch [75/1000], Loss: 0.1648\n",
      "Epoch [76/1000], Loss: 0.1639\n",
      "Epoch [77/1000], Loss: 0.1631\n",
      "Epoch [78/1000], Loss: 0.1622\n",
      "Epoch [79/1000], Loss: 0.1612\n",
      "Epoch [80/1000], Loss: 0.1603\n",
      "Epoch [81/1000], Loss: 0.1596\n",
      "Epoch [82/1000], Loss: 0.1586\n",
      "Epoch [83/1000], Loss: 0.1577\n",
      "Epoch [84/1000], Loss: 0.1571\n",
      "Epoch [85/1000], Loss: 0.1564\n",
      "Epoch [86/1000], Loss: 0.1556\n",
      "Epoch [87/1000], Loss: 0.1552\n",
      "Epoch [88/1000], Loss: 0.1543\n",
      "Epoch [89/1000], Loss: 0.1537\n",
      "Epoch [90/1000], Loss: 0.1532\n",
      "Epoch [91/1000], Loss: 0.1527\n",
      "Epoch [92/1000], Loss: 0.1520\n",
      "Epoch [93/1000], Loss: 0.1513\n",
      "Epoch [94/1000], Loss: 0.1509\n",
      "Epoch [95/1000], Loss: 0.1501\n",
      "Epoch [96/1000], Loss: 0.1500\n",
      "Epoch [97/1000], Loss: 0.1494\n",
      "Epoch [98/1000], Loss: 0.1489\n",
      "Epoch [99/1000], Loss: 0.1485\n",
      "Epoch [100/1000], Loss: 0.1480\n",
      "Epoch [101/1000], Loss: 0.1475\n",
      "Epoch [102/1000], Loss: 0.1471\n",
      "Epoch [103/1000], Loss: 0.1468\n",
      "Epoch [104/1000], Loss: 0.1462\n",
      "Epoch [105/1000], Loss: 0.1456\n",
      "Epoch [106/1000], Loss: 0.1454\n",
      "Epoch [107/1000], Loss: 0.1450\n",
      "Epoch [108/1000], Loss: 0.1444\n",
      "Epoch [109/1000], Loss: 0.1443\n",
      "Epoch [110/1000], Loss: 0.1438\n",
      "Epoch [111/1000], Loss: 0.1434\n",
      "Epoch [112/1000], Loss: 0.1432\n",
      "Epoch [113/1000], Loss: 0.1429\n",
      "Epoch [114/1000], Loss: 0.1426\n",
      "Epoch [115/1000], Loss: 0.1421\n",
      "Epoch [116/1000], Loss: 0.1418\n",
      "Epoch [117/1000], Loss: 0.1412\n",
      "Epoch [118/1000], Loss: 0.1409\n",
      "Epoch [119/1000], Loss: 0.1404\n",
      "Epoch [120/1000], Loss: 0.1402\n",
      "Epoch [121/1000], Loss: 0.1396\n",
      "Epoch [122/1000], Loss: 0.1396\n",
      "Epoch [123/1000], Loss: 0.1393\n",
      "Epoch [124/1000], Loss: 0.1389\n",
      "Epoch [125/1000], Loss: 0.1386\n",
      "Epoch [126/1000], Loss: 0.1385\n",
      "Epoch [127/1000], Loss: 0.1384\n",
      "Epoch [128/1000], Loss: 0.1378\n",
      "Epoch [129/1000], Loss: 0.1375\n",
      "Epoch [130/1000], Loss: 0.1373\n",
      "Epoch [131/1000], Loss: 0.1371\n",
      "Epoch [132/1000], Loss: 0.1368\n",
      "Epoch [133/1000], Loss: 0.1367\n",
      "Epoch [134/1000], Loss: 0.1363\n",
      "Epoch [135/1000], Loss: 0.1359\n",
      "Epoch [136/1000], Loss: 0.1356\n",
      "Epoch [137/1000], Loss: 0.1356\n",
      "Epoch [138/1000], Loss: 0.1353\n",
      "Epoch [139/1000], Loss: 0.1349\n",
      "Epoch [140/1000], Loss: 0.1351\n",
      "Epoch [141/1000], Loss: 0.1349\n",
      "Epoch [142/1000], Loss: 0.1347\n",
      "Epoch [143/1000], Loss: 0.1342\n",
      "Epoch [144/1000], Loss: 0.1343\n",
      "Epoch [145/1000], Loss: 0.1337\n",
      "Epoch [146/1000], Loss: 0.1343\n",
      "Epoch [147/1000], Loss: 0.1338\n",
      "Epoch [148/1000], Loss: 0.1337\n",
      "Epoch [149/1000], Loss: 0.1334\n",
      "Epoch [150/1000], Loss: 0.1334\n",
      "Epoch [151/1000], Loss: 0.1333\n",
      "Epoch [152/1000], Loss: 0.1330\n",
      "Epoch [153/1000], Loss: 0.1326\n",
      "Epoch [154/1000], Loss: 0.1331\n",
      "Epoch [155/1000], Loss: 0.1327\n",
      "Epoch [156/1000], Loss: 0.1327\n",
      "Epoch [157/1000], Loss: 0.1326\n",
      "Epoch [158/1000], Loss: 0.1323\n",
      "Epoch [159/1000], Loss: 0.1326\n",
      "Epoch [160/1000], Loss: 0.1320\n",
      "Epoch [161/1000], Loss: 0.1322\n",
      "Epoch [162/1000], Loss: 0.1319\n",
      "Epoch [163/1000], Loss: 0.1316\n",
      "Epoch [164/1000], Loss: 0.1316\n",
      "Epoch [165/1000], Loss: 0.1314\n",
      "Epoch [166/1000], Loss: 0.1311\n",
      "Epoch [167/1000], Loss: 0.1316\n",
      "Epoch [168/1000], Loss: 0.1313\n",
      "Epoch [169/1000], Loss: 0.1313\n",
      "Epoch [170/1000], Loss: 0.1305\n",
      "Epoch [171/1000], Loss: 0.1307\n",
      "Epoch [172/1000], Loss: 0.1307\n",
      "Epoch [173/1000], Loss: 0.1309\n",
      "Epoch [174/1000], Loss: 0.1306\n",
      "Epoch [175/1000], Loss: 0.1304\n",
      "Epoch [176/1000], Loss: 0.1303\n",
      "Epoch [177/1000], Loss: 0.1304\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 2, activation : lrelu, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2530\n",
      "Epoch [2/1000], Loss: 0.2479\n",
      "Epoch [3/1000], Loss: 0.2458\n",
      "Epoch [4/1000], Loss: 0.2444\n",
      "Epoch [5/1000], Loss: 0.2434\n",
      "Epoch [6/1000], Loss: 0.2426\n",
      "Epoch [7/1000], Loss: 0.2417\n",
      "Epoch [8/1000], Loss: 0.2408\n",
      "Epoch [9/1000], Loss: 0.2401\n",
      "Epoch [10/1000], Loss: 0.2396\n",
      "Epoch [11/1000], Loss: 0.2390\n",
      "Epoch [12/1000], Loss: 0.2385\n",
      "Epoch [13/1000], Loss: 0.2381\n",
      "Epoch [14/1000], Loss: 0.2377\n",
      "Epoch [15/1000], Loss: 0.2374\n",
      "Epoch [16/1000], Loss: 0.2370\n",
      "Epoch [17/1000], Loss: 0.2369\n",
      "Epoch [18/1000], Loss: 0.2367\n",
      "Epoch [19/1000], Loss: 0.2366\n",
      "Epoch [20/1000], Loss: 0.2364\n",
      "Epoch [21/1000], Loss: 0.2363\n",
      "Epoch [22/1000], Loss: 0.2361\n",
      "Epoch [23/1000], Loss: 0.2359\n",
      "Epoch [24/1000], Loss: 0.2358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/1000], Loss: 0.2357\n",
      "Epoch [26/1000], Loss: 0.2356\n",
      "Epoch [27/1000], Loss: 0.2354\n",
      "Epoch [28/1000], Loss: 0.2352\n",
      "Epoch [29/1000], Loss: 0.2352\n",
      "Epoch [30/1000], Loss: 0.2350\n",
      "Epoch [31/1000], Loss: 0.2349\n",
      "Epoch [32/1000], Loss: 0.2348\n",
      "Epoch [33/1000], Loss: 0.2346\n",
      "Epoch [34/1000], Loss: 0.2345\n",
      "Epoch [35/1000], Loss: 0.2344\n",
      "Epoch [36/1000], Loss: 0.2342\n",
      "Epoch [37/1000], Loss: 0.2341\n",
      "Epoch [38/1000], Loss: 0.2340\n",
      "Epoch [39/1000], Loss: 0.2339\n",
      "Epoch [40/1000], Loss: 0.2337\n",
      "Epoch [41/1000], Loss: 0.2335\n",
      "Epoch [42/1000], Loss: 0.2334\n",
      "Epoch [43/1000], Loss: 0.2333\n",
      "Epoch [44/1000], Loss: 0.2331\n",
      "Epoch [45/1000], Loss: 0.2330\n",
      "Epoch [46/1000], Loss: 0.2328\n",
      "Epoch [47/1000], Loss: 0.2327\n",
      "Epoch [48/1000], Loss: 0.2326\n",
      "Epoch [49/1000], Loss: 0.2324\n",
      "Epoch [50/1000], Loss: 0.2322\n",
      "Epoch [51/1000], Loss: 0.2320\n",
      "Epoch [52/1000], Loss: 0.2318\n",
      "Epoch [53/1000], Loss: 0.2316\n",
      "Epoch [54/1000], Loss: 0.2314\n",
      "Epoch [55/1000], Loss: 0.2311\n",
      "Epoch [56/1000], Loss: 0.2307\n",
      "Epoch [57/1000], Loss: 0.2304\n",
      "Epoch [58/1000], Loss: 0.2301\n",
      "Epoch [59/1000], Loss: 0.2299\n",
      "Epoch [60/1000], Loss: 0.2295\n",
      "Epoch [61/1000], Loss: 0.2292\n",
      "Epoch [62/1000], Loss: 0.2287\n",
      "Epoch [63/1000], Loss: 0.2283\n",
      "Epoch [64/1000], Loss: 0.2278\n",
      "Epoch [65/1000], Loss: 0.2276\n",
      "Epoch [66/1000], Loss: 0.2272\n",
      "Epoch [67/1000], Loss: 0.2266\n",
      "Epoch [68/1000], Loss: 0.2262\n",
      "Epoch [69/1000], Loss: 0.2256\n",
      "Epoch [70/1000], Loss: 0.2251\n",
      "Epoch [71/1000], Loss: 0.2243\n",
      "Epoch [72/1000], Loss: 0.2238\n",
      "Epoch [73/1000], Loss: 0.2231\n",
      "Epoch [74/1000], Loss: 0.2223\n",
      "Epoch [75/1000], Loss: 0.2216\n",
      "Epoch [76/1000], Loss: 0.2207\n",
      "Epoch [77/1000], Loss: 0.2196\n",
      "Epoch [78/1000], Loss: 0.2186\n",
      "Epoch [79/1000], Loss: 0.2177\n",
      "Epoch [80/1000], Loss: 0.2165\n",
      "Epoch [81/1000], Loss: 0.2155\n",
      "Epoch [82/1000], Loss: 0.2140\n",
      "Epoch [83/1000], Loss: 0.2128\n",
      "Epoch [84/1000], Loss: 0.2114\n",
      "Epoch [85/1000], Loss: 0.2097\n",
      "Epoch [86/1000], Loss: 0.2082\n",
      "Epoch [87/1000], Loss: 0.2064\n",
      "Epoch [88/1000], Loss: 0.2047\n",
      "Epoch [89/1000], Loss: 0.2030\n",
      "Epoch [90/1000], Loss: 0.2010\n",
      "Epoch [91/1000], Loss: 0.1989\n",
      "Epoch [92/1000], Loss: 0.1965\n",
      "Epoch [93/1000], Loss: 0.1943\n",
      "Epoch [94/1000], Loss: 0.1917\n",
      "Epoch [95/1000], Loss: 0.1890\n",
      "Epoch [96/1000], Loss: 0.1860\n",
      "Epoch [97/1000], Loss: 0.1833\n",
      "Epoch [98/1000], Loss: 0.1801\n",
      "Epoch [99/1000], Loss: 0.1767\n",
      "Epoch [100/1000], Loss: 0.1729\n",
      "Epoch [101/1000], Loss: 0.1698\n",
      "Epoch [102/1000], Loss: 0.1661\n",
      "Epoch [103/1000], Loss: 0.1628\n",
      "Epoch [104/1000], Loss: 0.1589\n",
      "Epoch [105/1000], Loss: 0.1554\n",
      "Epoch [106/1000], Loss: 0.1514\n",
      "Epoch [107/1000], Loss: 0.1474\n",
      "Epoch [108/1000], Loss: 0.1433\n",
      "Epoch [109/1000], Loss: 0.1389\n",
      "Epoch [110/1000], Loss: 0.1349\n",
      "Epoch [111/1000], Loss: 0.1300\n",
      "Epoch [112/1000], Loss: 0.1248\n",
      "Epoch [113/1000], Loss: 0.1203\n",
      "Epoch [114/1000], Loss: 0.1155\n",
      "Epoch [115/1000], Loss: 0.1104\n",
      "Epoch [116/1000], Loss: 0.1050\n",
      "Epoch [117/1000], Loss: 0.0998\n",
      "Epoch [118/1000], Loss: 0.0943\n",
      "Epoch [119/1000], Loss: 0.0883\n",
      "Epoch [120/1000], Loss: 0.0829\n",
      "Epoch [121/1000], Loss: 0.0774\n",
      "Epoch [122/1000], Loss: 0.0719\n",
      "Epoch [123/1000], Loss: 0.0668\n",
      "Epoch [124/1000], Loss: 0.0621\n",
      "Epoch [125/1000], Loss: 0.0576\n",
      "Epoch [126/1000], Loss: 0.0535\n",
      "Epoch [127/1000], Loss: 0.0496\n",
      "Epoch [128/1000], Loss: 0.0462\n",
      "Epoch [129/1000], Loss: 0.0430\n",
      "Epoch [130/1000], Loss: 0.0395\n",
      "Epoch [131/1000], Loss: 0.0369\n",
      "Epoch [132/1000], Loss: 0.0343\n",
      "Epoch [133/1000], Loss: 0.0315\n",
      "Epoch [134/1000], Loss: 0.0298\n",
      "Epoch [135/1000], Loss: 0.0275\n",
      "Epoch [136/1000], Loss: 0.0256\n",
      "Epoch [137/1000], Loss: 0.0244\n",
      "Epoch [138/1000], Loss: 0.0228\n",
      "Epoch [139/1000], Loss: 0.0214\n",
      "Epoch [140/1000], Loss: 0.0205\n",
      "Epoch [141/1000], Loss: 0.0191\n",
      "Epoch [142/1000], Loss: 0.0179\n",
      "Epoch [143/1000], Loss: 0.0168\n",
      "Epoch [144/1000], Loss: 0.0162\n",
      "Epoch [145/1000], Loss: 0.0155\n",
      "Epoch [146/1000], Loss: 0.0147\n",
      "Epoch [147/1000], Loss: 0.0139\n",
      "Epoch [148/1000], Loss: 0.0134\n",
      "Epoch [149/1000], Loss: 0.0127\n",
      "Epoch [150/1000], Loss: 0.0121\n",
      "Epoch [151/1000], Loss: 0.0119\n",
      "Epoch [152/1000], Loss: 0.0113\n",
      "Epoch [153/1000], Loss: 0.0106\n",
      "Epoch [154/1000], Loss: 0.0102\n",
      "Epoch [155/1000], Loss: 0.0099\n",
      "Epoch [156/1000], Loss: 0.0096\n",
      "Epoch [157/1000], Loss: 0.0092\n",
      "Epoch [158/1000], Loss: 0.0088\n",
      "Epoch [159/1000], Loss: 0.0084\n",
      "Epoch [160/1000], Loss: 0.0089\n",
      "Epoch [161/1000], Loss: 0.0079\n",
      "Epoch [162/1000], Loss: 0.0076\n",
      "Epoch [163/1000], Loss: 0.0075\n",
      "Epoch [164/1000], Loss: 0.0073\n",
      "Epoch [165/1000], Loss: 0.0070\n",
      "Epoch [166/1000], Loss: 0.0068\n",
      "Epoch [167/1000], Loss: 0.0067\n",
      "Epoch [168/1000], Loss: 0.0064\n",
      "Epoch [169/1000], Loss: 0.0063\n",
      "Epoch [170/1000], Loss: 0.0060\n",
      "Epoch [171/1000], Loss: 0.0059\n",
      "Epoch [172/1000], Loss: 0.0058\n",
      "Epoch [173/1000], Loss: 0.0056\n",
      "Epoch [174/1000], Loss: 0.0054\n",
      "Epoch [175/1000], Loss: 0.0054\n",
      "Epoch [176/1000], Loss: 0.0052\n",
      "Epoch [177/1000], Loss: 0.0051\n",
      "Epoch [178/1000], Loss: 0.0050\n",
      "Epoch [179/1000], Loss: 0.0050\n",
      "Epoch [180/1000], Loss: 0.0048\n",
      "Epoch [181/1000], Loss: 0.0047\n",
      "Epoch [182/1000], Loss: 0.0046\n",
      "Epoch [183/1000], Loss: 0.0045\n",
      "Epoch [184/1000], Loss: 0.0044\n",
      "Epoch [185/1000], Loss: 0.0044\n",
      "Epoch [186/1000], Loss: 0.0043\n",
      "Epoch [187/1000], Loss: 0.0043\n",
      "Epoch [188/1000], Loss: 0.0041\n",
      "Epoch [189/1000], Loss: 0.0041\n",
      "Epoch [190/1000], Loss: 0.0039\n",
      "Epoch [191/1000], Loss: 0.0039\n",
      "Epoch [192/1000], Loss: 0.0038\n",
      "Epoch [193/1000], Loss: 0.0039\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 2, activation : lrelu, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2405\n",
      "Epoch [2/1000], Loss: 0.2375\n",
      "Epoch [3/1000], Loss: 0.2367\n",
      "Epoch [4/1000], Loss: 0.2361\n",
      "Epoch [5/1000], Loss: 0.2357\n",
      "Epoch [6/1000], Loss: 0.2352\n",
      "Epoch [7/1000], Loss: 0.2346\n",
      "Epoch [8/1000], Loss: 0.2342\n",
      "Epoch [9/1000], Loss: 0.2335\n",
      "Epoch [10/1000], Loss: 0.2330\n",
      "Epoch [11/1000], Loss: 0.2327\n",
      "Epoch [12/1000], Loss: 0.2322\n",
      "Epoch [13/1000], Loss: 0.2318\n",
      "Epoch [14/1000], Loss: 0.2313\n",
      "Epoch [15/1000], Loss: 0.2308\n",
      "Epoch [16/1000], Loss: 0.2302\n",
      "Epoch [17/1000], Loss: 0.2295\n",
      "Epoch [18/1000], Loss: 0.2290\n",
      "Epoch [19/1000], Loss: 0.2282\n",
      "Epoch [20/1000], Loss: 0.2275\n",
      "Epoch [21/1000], Loss: 0.2268\n",
      "Epoch [22/1000], Loss: 0.2262\n",
      "Epoch [23/1000], Loss: 0.2255\n",
      "Epoch [24/1000], Loss: 0.2245\n",
      "Epoch [25/1000], Loss: 0.2232\n",
      "Epoch [26/1000], Loss: 0.2228\n",
      "Epoch [27/1000], Loss: 0.2219\n",
      "Epoch [28/1000], Loss: 0.2206\n",
      "Epoch [29/1000], Loss: 0.2197\n",
      "Epoch [30/1000], Loss: 0.2183\n",
      "Epoch [31/1000], Loss: 0.2170\n",
      "Epoch [32/1000], Loss: 0.2156\n",
      "Epoch [33/1000], Loss: 0.2131\n",
      "Epoch [34/1000], Loss: 0.2118\n",
      "Epoch [35/1000], Loss: 0.2089\n",
      "Epoch [36/1000], Loss: 0.2066\n",
      "Epoch [37/1000], Loss: 0.2040\n",
      "Epoch [38/1000], Loss: 0.1996\n",
      "Epoch [39/1000], Loss: 0.1974\n",
      "Epoch [40/1000], Loss: 0.1930\n",
      "Epoch [41/1000], Loss: 0.1885\n",
      "Epoch [42/1000], Loss: 0.1835\n",
      "Epoch [43/1000], Loss: 0.1786\n",
      "Epoch [44/1000], Loss: 0.1725\n",
      "Epoch [45/1000], Loss: 0.1672\n",
      "Epoch [46/1000], Loss: 0.1612\n",
      "Epoch [47/1000], Loss: 0.1544\n",
      "Epoch [48/1000], Loss: 0.1481\n",
      "Epoch [49/1000], Loss: 0.1416\n",
      "Epoch [50/1000], Loss: 0.1349\n",
      "Epoch [51/1000], Loss: 0.1282\n",
      "Epoch [52/1000], Loss: 0.1220\n",
      "Epoch [53/1000], Loss: 0.1157\n",
      "Epoch [54/1000], Loss: 0.1083\n",
      "Epoch [55/1000], Loss: 0.1030\n",
      "Epoch [56/1000], Loss: 0.0956\n",
      "Epoch [57/1000], Loss: 0.0918\n",
      "Epoch [58/1000], Loss: 0.0859\n",
      "Epoch [59/1000], Loss: 0.0799\n",
      "Epoch [60/1000], Loss: 0.0751\n",
      "Epoch [61/1000], Loss: 0.0692\n",
      "Epoch [62/1000], Loss: 0.0663\n",
      "Epoch [63/1000], Loss: 0.0599\n",
      "Epoch [64/1000], Loss: 0.0559\n",
      "Epoch [65/1000], Loss: 0.0528\n",
      "Epoch [66/1000], Loss: 0.0484\n",
      "Epoch [67/1000], Loss: 0.0448\n",
      "Epoch [68/1000], Loss: 0.0421\n",
      "Epoch [69/1000], Loss: 0.0391\n",
      "Epoch [70/1000], Loss: 0.0366\n",
      "Epoch [71/1000], Loss: 0.0347\n",
      "Epoch [72/1000], Loss: 0.0313\n",
      "Epoch [73/1000], Loss: 0.0292\n",
      "Epoch [74/1000], Loss: 0.0276\n",
      "Epoch [75/1000], Loss: 0.0259\n",
      "Epoch [76/1000], Loss: 0.0240\n",
      "Epoch [77/1000], Loss: 0.0227\n",
      "Epoch [78/1000], Loss: 0.0217\n",
      "Epoch [79/1000], Loss: 0.0202\n",
      "Epoch [80/1000], Loss: 0.0194\n",
      "Epoch [81/1000], Loss: 0.0181\n",
      "Epoch [82/1000], Loss: 0.0174\n",
      "Epoch [83/1000], Loss: 0.0159\n",
      "Epoch [84/1000], Loss: 0.0161\n",
      "Epoch [85/1000], Loss: 0.0144\n",
      "Epoch [86/1000], Loss: 0.0136\n",
      "Epoch [87/1000], Loss: 0.0131\n",
      "Epoch [88/1000], Loss: 0.0125\n",
      "Epoch [89/1000], Loss: 0.0119\n",
      "Epoch [90/1000], Loss: 0.0113\n",
      "Epoch [91/1000], Loss: 0.0109\n",
      "Epoch [92/1000], Loss: 0.0104\n",
      "Epoch [93/1000], Loss: 0.0101\n",
      "Epoch [94/1000], Loss: 0.0094\n",
      "Epoch [95/1000], Loss: 0.0093\n",
      "Epoch [96/1000], Loss: 0.0088\n",
      "Epoch [97/1000], Loss: 0.0087\n",
      "Epoch [98/1000], Loss: 0.0084\n",
      "Epoch [99/1000], Loss: 0.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0077\n",
      "Epoch [101/1000], Loss: 0.0076\n",
      "Epoch [102/1000], Loss: 0.0073\n",
      "Epoch [103/1000], Loss: 0.0071\n",
      "Epoch [104/1000], Loss: 0.0068\n",
      "Epoch [105/1000], Loss: 0.0067\n",
      "Epoch [106/1000], Loss: 0.0065\n",
      "Epoch [107/1000], Loss: 0.0064\n",
      "Epoch [108/1000], Loss: 0.0061\n",
      "Epoch [109/1000], Loss: 0.0060\n",
      "Epoch [110/1000], Loss: 0.0061\n",
      "Epoch [111/1000], Loss: 0.0056\n",
      "Epoch [112/1000], Loss: 0.0055\n",
      "Epoch [113/1000], Loss: 0.0053\n",
      "Epoch [114/1000], Loss: 0.0052\n",
      "Epoch [115/1000], Loss: 0.0051\n",
      "Epoch [116/1000], Loss: 0.0049\n",
      "Epoch [117/1000], Loss: 0.0049\n",
      "Epoch [118/1000], Loss: 0.0047\n",
      "Epoch [119/1000], Loss: 0.0046\n",
      "Epoch [120/1000], Loss: 0.0045\n",
      "Epoch [121/1000], Loss: 0.0044\n",
      "Epoch [122/1000], Loss: 0.0044\n",
      "Epoch [123/1000], Loss: 0.0043\n",
      "Epoch [124/1000], Loss: 0.0041\n",
      "Epoch [125/1000], Loss: 0.0041\n",
      "Epoch [126/1000], Loss: 0.0040\n",
      "Epoch [127/1000], Loss: 0.0039\n",
      "Epoch [128/1000], Loss: 0.0039\n",
      "Epoch [129/1000], Loss: 0.0037\n",
      "Epoch [130/1000], Loss: 0.0037\n",
      "Epoch [131/1000], Loss: 0.0037\n",
      "Epoch [132/1000], Loss: 0.0035\n",
      "Epoch [133/1000], Loss: 0.0035\n",
      "Epoch [134/1000], Loss: 0.0034\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 2, activation : sigmoid, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2516\n",
      "Epoch [2/1000], Loss: 0.2499\n",
      "Epoch [3/1000], Loss: 0.2496\n",
      "Epoch [4/1000], Loss: 0.2495\n",
      "Epoch [5/1000], Loss: 0.2493\n",
      "Epoch [6/1000], Loss: 0.2491\n",
      "Epoch [7/1000], Loss: 0.2490\n",
      "Epoch [8/1000], Loss: 0.2488\n",
      "Epoch [9/1000], Loss: 0.2486\n",
      "Epoch [10/1000], Loss: 0.2484\n",
      "Epoch [11/1000], Loss: 0.2483\n",
      "Epoch [12/1000], Loss: 0.2481\n",
      "Epoch [13/1000], Loss: 0.2479\n",
      "Epoch [14/1000], Loss: 0.2477\n",
      "Epoch [15/1000], Loss: 0.2476\n",
      "Epoch [16/1000], Loss: 0.2474\n",
      "Epoch [17/1000], Loss: 0.2472\n",
      "Epoch [18/1000], Loss: 0.2470\n",
      "Epoch [19/1000], Loss: 0.2468\n",
      "Epoch [20/1000], Loss: 0.2466\n",
      "Epoch [21/1000], Loss: 0.2464\n",
      "Epoch [22/1000], Loss: 0.2462\n",
      "Epoch [23/1000], Loss: 0.2460\n",
      "Epoch [24/1000], Loss: 0.2458\n",
      "Epoch [25/1000], Loss: 0.2456\n",
      "Epoch [26/1000], Loss: 0.2454\n",
      "Epoch [27/1000], Loss: 0.2452\n",
      "Epoch [28/1000], Loss: 0.2450\n",
      "Epoch [29/1000], Loss: 0.2447\n",
      "Epoch [30/1000], Loss: 0.2446\n",
      "Epoch [31/1000], Loss: 0.2444\n",
      "Epoch [32/1000], Loss: 0.2441\n",
      "Epoch [33/1000], Loss: 0.2439\n",
      "Epoch [34/1000], Loss: 0.2437\n",
      "Epoch [35/1000], Loss: 0.2435\n",
      "Epoch [36/1000], Loss: 0.2433\n",
      "Epoch [37/1000], Loss: 0.2431\n",
      "Epoch [38/1000], Loss: 0.2429\n",
      "Epoch [39/1000], Loss: 0.2427\n",
      "Epoch [40/1000], Loss: 0.2425\n",
      "Epoch [41/1000], Loss: 0.2423\n",
      "Epoch [42/1000], Loss: 0.2421\n",
      "Epoch [43/1000], Loss: 0.2419\n",
      "Epoch [44/1000], Loss: 0.2418\n",
      "Epoch [45/1000], Loss: 0.2416\n",
      "Epoch [46/1000], Loss: 0.2414\n",
      "Epoch [47/1000], Loss: 0.2413\n",
      "Epoch [48/1000], Loss: 0.2411\n",
      "Epoch [49/1000], Loss: 0.2410\n",
      "Epoch [50/1000], Loss: 0.2409\n",
      "Epoch [51/1000], Loss: 0.2407\n",
      "Epoch [52/1000], Loss: 0.2406\n",
      "Epoch [53/1000], Loss: 0.2405\n",
      "Epoch [54/1000], Loss: 0.2404\n",
      "Epoch [55/1000], Loss: 0.2403\n",
      "Epoch [56/1000], Loss: 0.2402\n",
      "Epoch [57/1000], Loss: 0.2401\n",
      "Epoch [58/1000], Loss: 0.2400\n",
      "Epoch [59/1000], Loss: 0.2399\n",
      "Epoch [60/1000], Loss: 0.2398\n",
      "Epoch [61/1000], Loss: 0.2398\n",
      "Epoch [62/1000], Loss: 0.2397\n",
      "Epoch [63/1000], Loss: 0.2396\n",
      "Epoch [64/1000], Loss: 0.2396\n",
      "Epoch [65/1000], Loss: 0.2395\n",
      "Epoch [66/1000], Loss: 0.2395\n",
      "Epoch [67/1000], Loss: 0.2394\n",
      "Epoch [68/1000], Loss: 0.2394\n",
      "Epoch [69/1000], Loss: 0.2393\n",
      "Epoch [70/1000], Loss: 0.2393\n",
      "Epoch [71/1000], Loss: 0.2393\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 2, activation : sigmoid, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2513\n",
      "Epoch [2/1000], Loss: 0.2508\n",
      "Epoch [3/1000], Loss: 0.2506\n",
      "Epoch [4/1000], Loss: 0.2505\n",
      "Epoch [5/1000], Loss: 0.2503\n",
      "Epoch [6/1000], Loss: 0.2503\n",
      "Epoch [7/1000], Loss: 0.2501\n",
      "Epoch [8/1000], Loss: 0.2500\n",
      "Epoch [9/1000], Loss: 0.2499\n",
      "Epoch [10/1000], Loss: 0.2498\n",
      "Epoch [11/1000], Loss: 0.2497\n",
      "Epoch [12/1000], Loss: 0.2496\n",
      "Epoch [13/1000], Loss: 0.2495\n",
      "Epoch [14/1000], Loss: 0.2493\n",
      "Epoch [15/1000], Loss: 0.2492\n",
      "Epoch [16/1000], Loss: 0.2491\n",
      "Epoch [17/1000], Loss: 0.2490\n",
      "Epoch [18/1000], Loss: 0.2488\n",
      "Epoch [19/1000], Loss: 0.2487\n",
      "Epoch [20/1000], Loss: 0.2486\n",
      "Epoch [21/1000], Loss: 0.2485\n",
      "Epoch [22/1000], Loss: 0.2483\n",
      "Epoch [23/1000], Loss: 0.2481\n",
      "Epoch [24/1000], Loss: 0.2480\n",
      "Epoch [25/1000], Loss: 0.2478\n",
      "Epoch [26/1000], Loss: 0.2477\n",
      "Epoch [27/1000], Loss: 0.2475\n",
      "Epoch [28/1000], Loss: 0.2473\n",
      "Epoch [29/1000], Loss: 0.2471\n",
      "Epoch [30/1000], Loss: 0.2469\n",
      "Epoch [31/1000], Loss: 0.2468\n",
      "Epoch [32/1000], Loss: 0.2466\n",
      "Epoch [33/1000], Loss: 0.2464\n",
      "Epoch [34/1000], Loss: 0.2462\n",
      "Epoch [35/1000], Loss: 0.2459\n",
      "Epoch [36/1000], Loss: 0.2458\n",
      "Epoch [37/1000], Loss: 0.2456\n",
      "Epoch [38/1000], Loss: 0.2453\n",
      "Epoch [39/1000], Loss: 0.2451\n",
      "Epoch [40/1000], Loss: 0.2449\n",
      "Epoch [41/1000], Loss: 0.2447\n",
      "Epoch [42/1000], Loss: 0.2445\n",
      "Epoch [43/1000], Loss: 0.2443\n",
      "Epoch [44/1000], Loss: 0.2440\n",
      "Epoch [45/1000], Loss: 0.2438\n",
      "Epoch [46/1000], Loss: 0.2436\n",
      "Epoch [47/1000], Loss: 0.2434\n",
      "Epoch [48/1000], Loss: 0.2432\n",
      "Epoch [49/1000], Loss: 0.2430\n",
      "Epoch [50/1000], Loss: 0.2428\n",
      "Epoch [51/1000], Loss: 0.2427\n",
      "Epoch [52/1000], Loss: 0.2424\n",
      "Epoch [53/1000], Loss: 0.2423\n",
      "Epoch [54/1000], Loss: 0.2421\n",
      "Epoch [55/1000], Loss: 0.2420\n",
      "Epoch [56/1000], Loss: 0.2418\n",
      "Epoch [57/1000], Loss: 0.2416\n",
      "Epoch [58/1000], Loss: 0.2415\n",
      "Epoch [59/1000], Loss: 0.2415\n",
      "Epoch [60/1000], Loss: 0.2413\n",
      "Epoch [61/1000], Loss: 0.2412\n",
      "Epoch [62/1000], Loss: 0.2411\n",
      "Epoch [63/1000], Loss: 0.2410\n",
      "Epoch [64/1000], Loss: 0.2409\n",
      "Epoch [65/1000], Loss: 0.2408\n",
      "Epoch [66/1000], Loss: 0.2407\n",
      "Epoch [67/1000], Loss: 0.2407\n",
      "Epoch [68/1000], Loss: 0.2406\n",
      "Epoch [69/1000], Loss: 0.2406\n",
      "Epoch [70/1000], Loss: 0.2405\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 2, activation : sigmoid, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2505\n",
      "Epoch [2/1000], Loss: 0.2502\n",
      "Epoch [3/1000], Loss: 0.2500\n",
      "Epoch [4/1000], Loss: 0.2499\n",
      "Epoch [5/1000], Loss: 0.2497\n",
      "Epoch [6/1000], Loss: 0.2495\n",
      "Epoch [7/1000], Loss: 0.2493\n",
      "Epoch [8/1000], Loss: 0.2490\n",
      "Epoch [9/1000], Loss: 0.2490\n",
      "Epoch [10/1000], Loss: 0.2487\n",
      "Epoch [11/1000], Loss: 0.2486\n",
      "Epoch [12/1000], Loss: 0.2483\n",
      "Epoch [13/1000], Loss: 0.2482\n",
      "Epoch [14/1000], Loss: 0.2480\n",
      "Epoch [15/1000], Loss: 0.2478\n",
      "Epoch [16/1000], Loss: 0.2476\n",
      "Epoch [17/1000], Loss: 0.2473\n",
      "Epoch [18/1000], Loss: 0.2470\n",
      "Epoch [19/1000], Loss: 0.2470\n",
      "Epoch [20/1000], Loss: 0.2467\n",
      "Epoch [21/1000], Loss: 0.2464\n",
      "Epoch [22/1000], Loss: 0.2462\n",
      "Epoch [23/1000], Loss: 0.2460\n",
      "Epoch [24/1000], Loss: 0.2457\n",
      "Epoch [25/1000], Loss: 0.2455\n",
      "Epoch [26/1000], Loss: 0.2452\n",
      "Epoch [27/1000], Loss: 0.2449\n",
      "Epoch [28/1000], Loss: 0.2448\n",
      "Epoch [29/1000], Loss: 0.2444\n",
      "Epoch [30/1000], Loss: 0.2441\n",
      "Epoch [31/1000], Loss: 0.2440\n",
      "Epoch [32/1000], Loss: 0.2438\n",
      "Epoch [33/1000], Loss: 0.2435\n",
      "Epoch [34/1000], Loss: 0.2433\n",
      "Epoch [35/1000], Loss: 0.2431\n",
      "Epoch [36/1000], Loss: 0.2429\n",
      "Epoch [37/1000], Loss: 0.2427\n",
      "Epoch [38/1000], Loss: 0.2425\n",
      "Epoch [39/1000], Loss: 0.2423\n",
      "Epoch [40/1000], Loss: 0.2422\n",
      "Epoch [41/1000], Loss: 0.2420\n",
      "Epoch [42/1000], Loss: 0.2419\n",
      "Epoch [43/1000], Loss: 0.2418\n",
      "Epoch [44/1000], Loss: 0.2416\n",
      "Epoch [45/1000], Loss: 0.2416\n",
      "Epoch [46/1000], Loss: 0.2414\n",
      "Epoch [47/1000], Loss: 0.2413\n",
      "Epoch [48/1000], Loss: 0.2412\n",
      "Epoch [49/1000], Loss: 0.2411\n",
      "Epoch [50/1000], Loss: 0.2411\n",
      "Epoch [51/1000], Loss: 0.2409\n",
      "Epoch [52/1000], Loss: 0.2409\n",
      "Epoch [53/1000], Loss: 0.2408\n",
      "Epoch [54/1000], Loss: 0.2408\n",
      "Epoch [55/1000], Loss: 0.2406\n",
      "Epoch [56/1000], Loss: 0.2406\n",
      "Epoch [57/1000], Loss: 0.2405\n",
      "Epoch [58/1000], Loss: 0.2405\n",
      "Epoch [59/1000], Loss: 0.2404\n",
      "Epoch [60/1000], Loss: 0.2403\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 2, activation : tanh, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2504\n",
      "Epoch [2/1000], Loss: 0.2438\n",
      "Epoch [3/1000], Loss: 0.2407\n",
      "Epoch [4/1000], Loss: 0.2393\n",
      "Epoch [5/1000], Loss: 0.2386\n",
      "Epoch [6/1000], Loss: 0.2382\n",
      "Epoch [7/1000], Loss: 0.2379\n",
      "Epoch [8/1000], Loss: 0.2377\n",
      "Epoch [9/1000], Loss: 0.2375\n",
      "Epoch [10/1000], Loss: 0.2374\n",
      "Epoch [11/1000], Loss: 0.2372\n",
      "Epoch [12/1000], Loss: 0.2371\n",
      "Epoch [13/1000], Loss: 0.2370\n",
      "Epoch [14/1000], Loss: 0.2369\n",
      "Epoch [15/1000], Loss: 0.2368\n",
      "Epoch [16/1000], Loss: 0.2367\n",
      "Epoch [17/1000], Loss: 0.2367\n",
      "Epoch [18/1000], Loss: 0.2366\n",
      "Epoch [19/1000], Loss: 0.2365\n",
      "Epoch [20/1000], Loss: 0.2364\n",
      "Epoch [21/1000], Loss: 0.2363\n",
      "Epoch [22/1000], Loss: 0.2362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/1000], Loss: 0.2361\n",
      "Epoch [24/1000], Loss: 0.2360\n",
      "Epoch [25/1000], Loss: 0.2359\n",
      "Epoch [26/1000], Loss: 0.2358\n",
      "Epoch [27/1000], Loss: 0.2357\n",
      "Epoch [28/1000], Loss: 0.2355\n",
      "Epoch [29/1000], Loss: 0.2355\n",
      "Epoch [30/1000], Loss: 0.2353\n",
      "Epoch [31/1000], Loss: 0.2352\n",
      "Epoch [32/1000], Loss: 0.2351\n",
      "Epoch [33/1000], Loss: 0.2350\n",
      "Epoch [34/1000], Loss: 0.2349\n",
      "Epoch [35/1000], Loss: 0.2347\n",
      "Epoch [36/1000], Loss: 0.2346\n",
      "Epoch [37/1000], Loss: 0.2344\n",
      "Epoch [38/1000], Loss: 0.2343\n",
      "Epoch [39/1000], Loss: 0.2341\n",
      "Epoch [40/1000], Loss: 0.2340\n",
      "Epoch [41/1000], Loss: 0.2338\n",
      "Epoch [42/1000], Loss: 0.2337\n",
      "Epoch [43/1000], Loss: 0.2335\n",
      "Epoch [44/1000], Loss: 0.2333\n",
      "Epoch [45/1000], Loss: 0.2331\n",
      "Epoch [46/1000], Loss: 0.2329\n",
      "Epoch [47/1000], Loss: 0.2328\n",
      "Epoch [48/1000], Loss: 0.2326\n",
      "Epoch [49/1000], Loss: 0.2323\n",
      "Epoch [50/1000], Loss: 0.2321\n",
      "Epoch [51/1000], Loss: 0.2319\n",
      "Epoch [52/1000], Loss: 0.2316\n",
      "Epoch [53/1000], Loss: 0.2312\n",
      "Epoch [54/1000], Loss: 0.2308\n",
      "Epoch [55/1000], Loss: 0.2303\n",
      "Epoch [56/1000], Loss: 0.2298\n",
      "Epoch [57/1000], Loss: 0.2292\n",
      "Epoch [58/1000], Loss: 0.2286\n",
      "Epoch [59/1000], Loss: 0.2281\n",
      "Epoch [60/1000], Loss: 0.2277\n",
      "Epoch [61/1000], Loss: 0.2273\n",
      "Epoch [62/1000], Loss: 0.2268\n",
      "Epoch [63/1000], Loss: 0.2265\n",
      "Epoch [64/1000], Loss: 0.2261\n",
      "Epoch [65/1000], Loss: 0.2257\n",
      "Epoch [66/1000], Loss: 0.2253\n",
      "Epoch [67/1000], Loss: 0.2250\n",
      "Epoch [68/1000], Loss: 0.2245\n",
      "Epoch [69/1000], Loss: 0.2242\n",
      "Epoch [70/1000], Loss: 0.2238\n",
      "Epoch [71/1000], Loss: 0.2235\n",
      "Epoch [72/1000], Loss: 0.2231\n",
      "Epoch [73/1000], Loss: 0.2228\n",
      "Epoch [74/1000], Loss: 0.2224\n",
      "Epoch [75/1000], Loss: 0.2221\n",
      "Epoch [76/1000], Loss: 0.2218\n",
      "Epoch [77/1000], Loss: 0.2214\n",
      "Epoch [78/1000], Loss: 0.2211\n",
      "Epoch [79/1000], Loss: 0.2207\n",
      "Epoch [80/1000], Loss: 0.2204\n",
      "Epoch [81/1000], Loss: 0.2201\n",
      "Epoch [82/1000], Loss: 0.2198\n",
      "Epoch [83/1000], Loss: 0.2195\n",
      "Epoch [84/1000], Loss: 0.2192\n",
      "Epoch [85/1000], Loss: 0.2189\n",
      "Epoch [86/1000], Loss: 0.2187\n",
      "Epoch [87/1000], Loss: 0.2184\n",
      "Epoch [88/1000], Loss: 0.2181\n",
      "Epoch [89/1000], Loss: 0.2178\n",
      "Epoch [90/1000], Loss: 0.2176\n",
      "Epoch [91/1000], Loss: 0.2173\n",
      "Epoch [92/1000], Loss: 0.2171\n",
      "Epoch [93/1000], Loss: 0.2169\n",
      "Epoch [94/1000], Loss: 0.2165\n",
      "Epoch [95/1000], Loss: 0.2164\n",
      "Epoch [96/1000], Loss: 0.2162\n",
      "Epoch [97/1000], Loss: 0.2159\n",
      "Epoch [98/1000], Loss: 0.2157\n",
      "Epoch [99/1000], Loss: 0.2155\n",
      "Epoch [100/1000], Loss: 0.2153\n",
      "Epoch [101/1000], Loss: 0.2150\n",
      "Epoch [102/1000], Loss: 0.2149\n",
      "Epoch [103/1000], Loss: 0.2147\n",
      "Epoch [104/1000], Loss: 0.2144\n",
      "Epoch [105/1000], Loss: 0.2143\n",
      "Epoch [106/1000], Loss: 0.2141\n",
      "Epoch [107/1000], Loss: 0.2139\n",
      "Epoch [108/1000], Loss: 0.2137\n",
      "Epoch [109/1000], Loss: 0.2135\n",
      "Epoch [110/1000], Loss: 0.2134\n",
      "Epoch [111/1000], Loss: 0.2132\n",
      "Epoch [112/1000], Loss: 0.2130\n",
      "Epoch [113/1000], Loss: 0.2128\n",
      "Epoch [114/1000], Loss: 0.2126\n",
      "Epoch [115/1000], Loss: 0.2124\n",
      "Epoch [116/1000], Loss: 0.2122\n",
      "Epoch [117/1000], Loss: 0.2120\n",
      "Epoch [118/1000], Loss: 0.2119\n",
      "Epoch [119/1000], Loss: 0.2116\n",
      "Epoch [120/1000], Loss: 0.2116\n",
      "Epoch [121/1000], Loss: 0.2114\n",
      "Epoch [122/1000], Loss: 0.2111\n",
      "Epoch [123/1000], Loss: 0.2108\n",
      "Epoch [124/1000], Loss: 0.2109\n",
      "Epoch [125/1000], Loss: 0.2107\n",
      "Epoch [126/1000], Loss: 0.2105\n",
      "Epoch [127/1000], Loss: 0.2104\n",
      "Epoch [128/1000], Loss: 0.2101\n",
      "Epoch [129/1000], Loss: 0.2100\n",
      "Epoch [130/1000], Loss: 0.2098\n",
      "Epoch [131/1000], Loss: 0.2097\n",
      "Epoch [132/1000], Loss: 0.2095\n",
      "Epoch [133/1000], Loss: 0.2093\n",
      "Epoch [134/1000], Loss: 0.2091\n",
      "Epoch [135/1000], Loss: 0.2089\n",
      "Epoch [136/1000], Loss: 0.2087\n",
      "Epoch [137/1000], Loss: 0.2085\n",
      "Epoch [138/1000], Loss: 0.2084\n",
      "Epoch [139/1000], Loss: 0.2080\n",
      "Epoch [140/1000], Loss: 0.2079\n",
      "Epoch [141/1000], Loss: 0.2077\n",
      "Epoch [142/1000], Loss: 0.2075\n",
      "Epoch [143/1000], Loss: 0.2074\n",
      "Epoch [144/1000], Loss: 0.2071\n",
      "Epoch [145/1000], Loss: 0.2069\n",
      "Epoch [146/1000], Loss: 0.2066\n",
      "Epoch [147/1000], Loss: 0.2066\n",
      "Epoch [148/1000], Loss: 0.2063\n",
      "Epoch [149/1000], Loss: 0.2061\n",
      "Epoch [150/1000], Loss: 0.2058\n",
      "Epoch [151/1000], Loss: 0.2057\n",
      "Epoch [152/1000], Loss: 0.2055\n",
      "Epoch [153/1000], Loss: 0.2053\n",
      "Epoch [154/1000], Loss: 0.2050\n",
      "Epoch [155/1000], Loss: 0.2050\n",
      "Epoch [156/1000], Loss: 0.2047\n",
      "Epoch [157/1000], Loss: 0.2046\n",
      "Epoch [158/1000], Loss: 0.2044\n",
      "Epoch [159/1000], Loss: 0.2042\n",
      "Epoch [160/1000], Loss: 0.2040\n",
      "Epoch [161/1000], Loss: 0.2039\n",
      "Epoch [162/1000], Loss: 0.2036\n",
      "Epoch [163/1000], Loss: 0.2036\n",
      "Epoch [164/1000], Loss: 0.2033\n",
      "Epoch [165/1000], Loss: 0.2032\n",
      "Epoch [166/1000], Loss: 0.2029\n",
      "Epoch [167/1000], Loss: 0.2028\n",
      "Epoch [168/1000], Loss: 0.2025\n",
      "Epoch [169/1000], Loss: 0.2024\n",
      "Epoch [170/1000], Loss: 0.2023\n",
      "Epoch [171/1000], Loss: 0.2019\n",
      "Epoch [172/1000], Loss: 0.2019\n",
      "Epoch [173/1000], Loss: 0.2018\n",
      "Epoch [174/1000], Loss: 0.2013\n",
      "Epoch [175/1000], Loss: 0.2015\n",
      "Epoch [176/1000], Loss: 0.2011\n",
      "Epoch [177/1000], Loss: 0.2009\n",
      "Epoch [178/1000], Loss: 0.2008\n",
      "Epoch [179/1000], Loss: 0.2006\n",
      "Epoch [180/1000], Loss: 0.2003\n",
      "Epoch [181/1000], Loss: 0.2001\n",
      "Epoch [182/1000], Loss: 0.1998\n",
      "Epoch [183/1000], Loss: 0.1997\n",
      "Epoch [184/1000], Loss: 0.1995\n",
      "Epoch [185/1000], Loss: 0.1992\n",
      "Epoch [186/1000], Loss: 0.1991\n",
      "Epoch [187/1000], Loss: 0.1988\n",
      "Epoch [188/1000], Loss: 0.1985\n",
      "Epoch [189/1000], Loss: 0.1982\n",
      "Epoch [190/1000], Loss: 0.1982\n",
      "Epoch [191/1000], Loss: 0.1978\n",
      "Epoch [192/1000], Loss: 0.1975\n",
      "Epoch [193/1000], Loss: 0.1973\n",
      "Epoch [194/1000], Loss: 0.1971\n",
      "Epoch [195/1000], Loss: 0.1968\n",
      "Epoch [196/1000], Loss: 0.1967\n",
      "Epoch [197/1000], Loss: 0.1965\n",
      "Epoch [198/1000], Loss: 0.1962\n",
      "Epoch [199/1000], Loss: 0.1959\n",
      "Epoch [200/1000], Loss: 0.1957\n",
      "Epoch [201/1000], Loss: 0.1955\n",
      "Epoch [202/1000], Loss: 0.1952\n",
      "Epoch [203/1000], Loss: 0.1949\n",
      "Epoch [204/1000], Loss: 0.1947\n",
      "Epoch [205/1000], Loss: 0.1946\n",
      "Epoch [206/1000], Loss: 0.1942\n",
      "Epoch [207/1000], Loss: 0.1943\n",
      "Epoch [208/1000], Loss: 0.1938\n",
      "Epoch [209/1000], Loss: 0.1936\n",
      "Epoch [210/1000], Loss: 0.1935\n",
      "Epoch [211/1000], Loss: 0.1931\n",
      "Epoch [212/1000], Loss: 0.1932\n",
      "Epoch [213/1000], Loss: 0.1929\n",
      "Epoch [214/1000], Loss: 0.1926\n",
      "Epoch [215/1000], Loss: 0.1925\n",
      "Epoch [216/1000], Loss: 0.1921\n",
      "Epoch [217/1000], Loss: 0.1920\n",
      "Epoch [218/1000], Loss: 0.1918\n",
      "Epoch [219/1000], Loss: 0.1915\n",
      "Epoch [220/1000], Loss: 0.1915\n",
      "Epoch [221/1000], Loss: 0.1912\n",
      "Epoch [222/1000], Loss: 0.1909\n",
      "Epoch [223/1000], Loss: 0.1909\n",
      "Epoch [224/1000], Loss: 0.1906\n",
      "Epoch [225/1000], Loss: 0.1905\n",
      "Epoch [226/1000], Loss: 0.1901\n",
      "Epoch [227/1000], Loss: 0.1900\n",
      "Epoch [228/1000], Loss: 0.1900\n",
      "Epoch [229/1000], Loss: 0.1898\n",
      "Epoch [230/1000], Loss: 0.1893\n",
      "Epoch [231/1000], Loss: 0.1894\n",
      "Epoch [232/1000], Loss: 0.1891\n",
      "Epoch [233/1000], Loss: 0.1889\n",
      "Epoch [234/1000], Loss: 0.1889\n",
      "Epoch [235/1000], Loss: 0.1886\n",
      "Epoch [236/1000], Loss: 0.1885\n",
      "Epoch [237/1000], Loss: 0.1883\n",
      "Epoch [238/1000], Loss: 0.1881\n",
      "Epoch [239/1000], Loss: 0.1880\n",
      "Epoch [240/1000], Loss: 0.1878\n",
      "Epoch [241/1000], Loss: 0.1877\n",
      "Epoch [242/1000], Loss: 0.1875\n",
      "Epoch [243/1000], Loss: 0.1873\n",
      "Epoch [244/1000], Loss: 0.1872\n",
      "Epoch [245/1000], Loss: 0.1869\n",
      "Epoch [246/1000], Loss: 0.1869\n",
      "Epoch [247/1000], Loss: 0.1864\n",
      "Epoch [248/1000], Loss: 0.1866\n",
      "Epoch [249/1000], Loss: 0.1863\n",
      "Epoch [250/1000], Loss: 0.1862\n",
      "Epoch [251/1000], Loss: 0.1859\n",
      "Epoch [252/1000], Loss: 0.1857\n",
      "Epoch [253/1000], Loss: 0.1856\n",
      "Epoch [254/1000], Loss: 0.1852\n",
      "Epoch [255/1000], Loss: 0.1854\n",
      "Epoch [256/1000], Loss: 0.1851\n",
      "Epoch [257/1000], Loss: 0.1849\n",
      "Epoch [258/1000], Loss: 0.1847\n",
      "Epoch [259/1000], Loss: 0.1846\n",
      "Epoch [260/1000], Loss: 0.1844\n",
      "Epoch [261/1000], Loss: 0.1843\n",
      "Epoch [262/1000], Loss: 0.1839\n",
      "Epoch [263/1000], Loss: 0.1839\n",
      "Epoch [264/1000], Loss: 0.1837\n",
      "Epoch [265/1000], Loss: 0.1835\n",
      "Epoch [266/1000], Loss: 0.1832\n",
      "Epoch [267/1000], Loss: 0.1832\n",
      "Epoch [268/1000], Loss: 0.1830\n",
      "Epoch [269/1000], Loss: 0.1826\n",
      "Epoch [270/1000], Loss: 0.1825\n",
      "Epoch [271/1000], Loss: 0.1822\n",
      "Epoch [272/1000], Loss: 0.1822\n",
      "Epoch [273/1000], Loss: 0.1819\n",
      "Epoch [274/1000], Loss: 0.1818\n",
      "Epoch [275/1000], Loss: 0.1815\n",
      "Epoch [276/1000], Loss: 0.1814\n",
      "Epoch [277/1000], Loss: 0.1812\n",
      "Epoch [278/1000], Loss: 0.1811\n",
      "Epoch [279/1000], Loss: 0.1809\n",
      "Epoch [280/1000], Loss: 0.1806\n",
      "Epoch [281/1000], Loss: 0.1805\n",
      "Epoch [282/1000], Loss: 0.1803\n",
      "Epoch [283/1000], Loss: 0.1800\n",
      "Epoch [284/1000], Loss: 0.1800\n",
      "Epoch [285/1000], Loss: 0.1797\n",
      "Epoch [286/1000], Loss: 0.1796\n",
      "Epoch [287/1000], Loss: 0.1793\n",
      "Epoch [288/1000], Loss: 0.1791\n",
      "Epoch [289/1000], Loss: 0.1791\n",
      "Epoch [290/1000], Loss: 0.1788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [291/1000], Loss: 0.1786\n",
      "Epoch [292/1000], Loss: 0.1784\n",
      "Epoch [293/1000], Loss: 0.1782\n",
      "Epoch [294/1000], Loss: 0.1779\n",
      "Epoch [295/1000], Loss: 0.1778\n",
      "Epoch [296/1000], Loss: 0.1777\n",
      "Epoch [297/1000], Loss: 0.1775\n",
      "Epoch [298/1000], Loss: 0.1773\n",
      "Epoch [299/1000], Loss: 0.1772\n",
      "Epoch [300/1000], Loss: 0.1770\n",
      "Epoch [301/1000], Loss: 0.1769\n",
      "Epoch [302/1000], Loss: 0.1766\n",
      "Epoch [303/1000], Loss: 0.1764\n",
      "Epoch [304/1000], Loss: 0.1764\n",
      "Epoch [305/1000], Loss: 0.1761\n",
      "Epoch [306/1000], Loss: 0.1759\n",
      "Epoch [307/1000], Loss: 0.1757\n",
      "Epoch [308/1000], Loss: 0.1757\n",
      "Epoch [309/1000], Loss: 0.1755\n",
      "Epoch [310/1000], Loss: 0.1754\n",
      "Epoch [311/1000], Loss: 0.1751\n",
      "Epoch [312/1000], Loss: 0.1750\n",
      "Epoch [313/1000], Loss: 0.1749\n",
      "Epoch [314/1000], Loss: 0.1746\n",
      "Epoch [315/1000], Loss: 0.1746\n",
      "Epoch [316/1000], Loss: 0.1745\n",
      "Epoch [317/1000], Loss: 0.1742\n",
      "Epoch [318/1000], Loss: 0.1741\n",
      "Epoch [319/1000], Loss: 0.1740\n",
      "Epoch [320/1000], Loss: 0.1737\n",
      "Epoch [321/1000], Loss: 0.1736\n",
      "Epoch [322/1000], Loss: 0.1736\n",
      "Epoch [323/1000], Loss: 0.1733\n",
      "Epoch [324/1000], Loss: 0.1732\n",
      "Epoch [325/1000], Loss: 0.1731\n",
      "Epoch [326/1000], Loss: 0.1729\n",
      "Epoch [327/1000], Loss: 0.1728\n",
      "Epoch [328/1000], Loss: 0.1728\n",
      "Epoch [329/1000], Loss: 0.1726\n",
      "Epoch [330/1000], Loss: 0.1724\n",
      "Epoch [331/1000], Loss: 0.1723\n",
      "Epoch [332/1000], Loss: 0.1723\n",
      "Epoch [333/1000], Loss: 0.1719\n",
      "Epoch [334/1000], Loss: 0.1720\n",
      "Epoch [335/1000], Loss: 0.1718\n",
      "Epoch [336/1000], Loss: 0.1717\n",
      "Epoch [337/1000], Loss: 0.1714\n",
      "Epoch [338/1000], Loss: 0.1715\n",
      "Epoch [339/1000], Loss: 0.1713\n",
      "Epoch [340/1000], Loss: 0.1712\n",
      "Epoch [341/1000], Loss: 0.1711\n",
      "Epoch [342/1000], Loss: 0.1710\n",
      "Epoch [343/1000], Loss: 0.1709\n",
      "Epoch [344/1000], Loss: 0.1707\n",
      "Epoch [345/1000], Loss: 0.1706\n",
      "Epoch [346/1000], Loss: 0.1705\n",
      "Epoch [347/1000], Loss: 0.1703\n",
      "Epoch [348/1000], Loss: 0.1703\n",
      "Epoch [349/1000], Loss: 0.1701\n",
      "Epoch [350/1000], Loss: 0.1699\n",
      "Epoch [351/1000], Loss: 0.1699\n",
      "Epoch [352/1000], Loss: 0.1697\n",
      "Epoch [353/1000], Loss: 0.1697\n",
      "Epoch [354/1000], Loss: 0.1696\n",
      "Epoch [355/1000], Loss: 0.1695\n",
      "Epoch [356/1000], Loss: 0.1693\n",
      "Epoch [357/1000], Loss: 0.1693\n",
      "Epoch [358/1000], Loss: 0.1691\n",
      "Epoch [359/1000], Loss: 0.1690\n",
      "Epoch [360/1000], Loss: 0.1689\n",
      "Epoch [361/1000], Loss: 0.1686\n",
      "Epoch [362/1000], Loss: 0.1686\n",
      "Epoch [363/1000], Loss: 0.1686\n",
      "Epoch [364/1000], Loss: 0.1683\n",
      "Epoch [365/1000], Loss: 0.1682\n",
      "Epoch [366/1000], Loss: 0.1681\n",
      "Epoch [367/1000], Loss: 0.1680\n",
      "Epoch [368/1000], Loss: 0.1679\n",
      "Epoch [369/1000], Loss: 0.1678\n",
      "Epoch [370/1000], Loss: 0.1675\n",
      "Epoch [371/1000], Loss: 0.1676\n",
      "Epoch [372/1000], Loss: 0.1674\n",
      "Epoch [373/1000], Loss: 0.1674\n",
      "Epoch [374/1000], Loss: 0.1671\n",
      "Epoch [375/1000], Loss: 0.1671\n",
      "Epoch [376/1000], Loss: 0.1669\n",
      "Epoch [377/1000], Loss: 0.1668\n",
      "Epoch [378/1000], Loss: 0.1667\n",
      "Epoch [379/1000], Loss: 0.1665\n",
      "Epoch [380/1000], Loss: 0.1664\n",
      "Epoch [381/1000], Loss: 0.1662\n",
      "Epoch [382/1000], Loss: 0.1661\n",
      "Epoch [383/1000], Loss: 0.1660\n",
      "Epoch [384/1000], Loss: 0.1657\n",
      "Epoch [385/1000], Loss: 0.1657\n",
      "Epoch [386/1000], Loss: 0.1653\n",
      "Epoch [387/1000], Loss: 0.1653\n",
      "Epoch [388/1000], Loss: 0.1651\n",
      "Epoch [389/1000], Loss: 0.1649\n",
      "Epoch [390/1000], Loss: 0.1649\n",
      "Epoch [391/1000], Loss: 0.1646\n",
      "Epoch [392/1000], Loss: 0.1645\n",
      "Epoch [393/1000], Loss: 0.1643\n",
      "Epoch [394/1000], Loss: 0.1641\n",
      "Epoch [395/1000], Loss: 0.1637\n",
      "Epoch [396/1000], Loss: 0.1638\n",
      "Epoch [397/1000], Loss: 0.1636\n",
      "Epoch [398/1000], Loss: 0.1633\n",
      "Epoch [399/1000], Loss: 0.1631\n",
      "Epoch [400/1000], Loss: 0.1627\n",
      "Epoch [401/1000], Loss: 0.1622\n",
      "Epoch [402/1000], Loss: 0.1618\n",
      "Epoch [403/1000], Loss: 0.1608\n",
      "Epoch [404/1000], Loss: 0.1589\n",
      "Epoch [405/1000], Loss: 0.1560\n",
      "Epoch [406/1000], Loss: 0.1518\n",
      "Epoch [407/1000], Loss: 0.1477\n",
      "Epoch [408/1000], Loss: 0.1450\n",
      "Epoch [409/1000], Loss: 0.1432\n",
      "Epoch [410/1000], Loss: 0.1417\n",
      "Epoch [411/1000], Loss: 0.1403\n",
      "Epoch [412/1000], Loss: 0.1393\n",
      "Epoch [413/1000], Loss: 0.1384\n",
      "Epoch [414/1000], Loss: 0.1376\n",
      "Epoch [415/1000], Loss: 0.1368\n",
      "Epoch [416/1000], Loss: 0.1360\n",
      "Epoch [417/1000], Loss: 0.1356\n",
      "Epoch [418/1000], Loss: 0.1349\n",
      "Epoch [419/1000], Loss: 0.1344\n",
      "Epoch [420/1000], Loss: 0.1338\n",
      "Epoch [421/1000], Loss: 0.1332\n",
      "Epoch [422/1000], Loss: 0.1327\n",
      "Epoch [423/1000], Loss: 0.1324\n",
      "Epoch [424/1000], Loss: 0.1320\n",
      "Epoch [425/1000], Loss: 0.1317\n",
      "Epoch [426/1000], Loss: 0.1310\n",
      "Epoch [427/1000], Loss: 0.1310\n",
      "Epoch [428/1000], Loss: 0.1305\n",
      "Epoch [429/1000], Loss: 0.1302\n",
      "Epoch [430/1000], Loss: 0.1298\n",
      "Epoch [431/1000], Loss: 0.1297\n",
      "Epoch [432/1000], Loss: 0.1293\n",
      "Epoch [433/1000], Loss: 0.1290\n",
      "Epoch [434/1000], Loss: 0.1288\n",
      "Epoch [435/1000], Loss: 0.1285\n",
      "Epoch [436/1000], Loss: 0.1281\n",
      "Epoch [437/1000], Loss: 0.1276\n",
      "Epoch [438/1000], Loss: 0.1275\n",
      "Epoch [439/1000], Loss: 0.1273\n",
      "Epoch [440/1000], Loss: 0.1271\n",
      "Epoch [441/1000], Loss: 0.1268\n",
      "Epoch [442/1000], Loss: 0.1268\n",
      "Epoch [443/1000], Loss: 0.1265\n",
      "Epoch [444/1000], Loss: 0.1261\n",
      "Epoch [445/1000], Loss: 0.1261\n",
      "Epoch [446/1000], Loss: 0.1260\n",
      "Epoch [447/1000], Loss: 0.1257\n",
      "Epoch [448/1000], Loss: 0.1255\n",
      "Epoch [449/1000], Loss: 0.1254\n",
      "Epoch [450/1000], Loss: 0.1250\n",
      "Epoch [451/1000], Loss: 0.1246\n",
      "Epoch [452/1000], Loss: 0.1247\n",
      "Epoch [453/1000], Loss: 0.1244\n",
      "Epoch [454/1000], Loss: 0.1242\n",
      "Epoch [455/1000], Loss: 0.1241\n",
      "Epoch [456/1000], Loss: 0.1239\n",
      "Epoch [457/1000], Loss: 0.1236\n",
      "Epoch [458/1000], Loss: 0.1233\n",
      "Epoch [459/1000], Loss: 0.1234\n",
      "Epoch [460/1000], Loss: 0.1230\n",
      "Epoch [461/1000], Loss: 0.1227\n",
      "Epoch [462/1000], Loss: 0.1227\n",
      "Epoch [463/1000], Loss: 0.1227\n",
      "Epoch [464/1000], Loss: 0.1224\n",
      "Epoch [465/1000], Loss: 0.1221\n",
      "Epoch [466/1000], Loss: 0.1219\n",
      "Epoch [467/1000], Loss: 0.1219\n",
      "Epoch [468/1000], Loss: 0.1217\n",
      "Epoch [469/1000], Loss: 0.1215\n",
      "Epoch [470/1000], Loss: 0.1214\n",
      "Epoch [471/1000], Loss: 0.1212\n",
      "Epoch [472/1000], Loss: 0.1211\n",
      "Epoch [473/1000], Loss: 0.1208\n",
      "Epoch [474/1000], Loss: 0.1206\n",
      "Epoch [475/1000], Loss: 0.1205\n",
      "Epoch [476/1000], Loss: 0.1203\n",
      "Epoch [477/1000], Loss: 0.1203\n",
      "Epoch [478/1000], Loss: 0.1198\n",
      "Epoch [479/1000], Loss: 0.1198\n",
      "Epoch [480/1000], Loss: 0.1198\n",
      "Epoch [481/1000], Loss: 0.1196\n",
      "Epoch [482/1000], Loss: 0.1194\n",
      "Epoch [483/1000], Loss: 0.1194\n",
      "Epoch [484/1000], Loss: 0.1191\n",
      "Epoch [485/1000], Loss: 0.1189\n",
      "Epoch [486/1000], Loss: 0.1189\n",
      "Epoch [487/1000], Loss: 0.1188\n",
      "Epoch [488/1000], Loss: 0.1187\n",
      "Epoch [489/1000], Loss: 0.1185\n",
      "Epoch [490/1000], Loss: 0.1183\n",
      "Epoch [491/1000], Loss: 0.1183\n",
      "Epoch [492/1000], Loss: 0.1182\n",
      "Epoch [493/1000], Loss: 0.1182\n",
      "Epoch [494/1000], Loss: 0.1179\n",
      "Epoch [495/1000], Loss: 0.1178\n",
      "Epoch [496/1000], Loss: 0.1175\n",
      "Epoch [497/1000], Loss: 0.1177\n",
      "Epoch [498/1000], Loss: 0.1174\n",
      "Epoch [499/1000], Loss: 0.1174\n",
      "Epoch [500/1000], Loss: 0.1173\n",
      "Epoch [501/1000], Loss: 0.1171\n",
      "Epoch [502/1000], Loss: 0.1170\n",
      "Epoch [503/1000], Loss: 0.1170\n",
      "Epoch [504/1000], Loss: 0.1167\n",
      "Epoch [505/1000], Loss: 0.1165\n",
      "Epoch [506/1000], Loss: 0.1166\n",
      "Epoch [507/1000], Loss: 0.1164\n",
      "Epoch [508/1000], Loss: 0.1160\n",
      "Epoch [509/1000], Loss: 0.1161\n",
      "Epoch [510/1000], Loss: 0.1160\n",
      "Epoch [511/1000], Loss: 0.1158\n",
      "Epoch [512/1000], Loss: 0.1155\n",
      "Epoch [513/1000], Loss: 0.1155\n",
      "Epoch [514/1000], Loss: 0.1154\n",
      "Epoch [515/1000], Loss: 0.1151\n",
      "Epoch [516/1000], Loss: 0.1149\n",
      "Epoch [517/1000], Loss: 0.1144\n",
      "Epoch [518/1000], Loss: 0.1143\n",
      "Epoch [519/1000], Loss: 0.1139\n",
      "Epoch [520/1000], Loss: 0.1136\n",
      "Epoch [521/1000], Loss: 0.1134\n",
      "Epoch [522/1000], Loss: 0.1133\n",
      "Epoch [523/1000], Loss: 0.1131\n",
      "Epoch [524/1000], Loss: 0.1128\n",
      "Epoch [525/1000], Loss: 0.1128\n",
      "Epoch [526/1000], Loss: 0.1125\n",
      "Epoch [527/1000], Loss: 0.1125\n",
      "Epoch [528/1000], Loss: 0.1124\n",
      "Epoch [529/1000], Loss: 0.1122\n",
      "Epoch [530/1000], Loss: 0.1120\n",
      "Epoch [531/1000], Loss: 0.1117\n",
      "Epoch [532/1000], Loss: 0.1118\n",
      "Epoch [533/1000], Loss: 0.1111\n",
      "Epoch [534/1000], Loss: 0.1114\n",
      "Epoch [535/1000], Loss: 0.1111\n",
      "Epoch [536/1000], Loss: 0.1109\n",
      "Epoch [537/1000], Loss: 0.1108\n",
      "Epoch [538/1000], Loss: 0.1107\n",
      "Epoch [539/1000], Loss: 0.1106\n",
      "Epoch [540/1000], Loss: 0.1105\n",
      "Epoch [541/1000], Loss: 0.1103\n",
      "Epoch [542/1000], Loss: 0.1103\n",
      "Epoch [543/1000], Loss: 0.1102\n",
      "Epoch [544/1000], Loss: 0.1103\n",
      "Epoch [545/1000], Loss: 0.1099\n",
      "Epoch [546/1000], Loss: 0.1100\n",
      "Epoch [547/1000], Loss: 0.1098\n",
      "Epoch [548/1000], Loss: 0.1098\n",
      "Epoch [549/1000], Loss: 0.1099\n",
      "Epoch [550/1000], Loss: 0.1095\n",
      "Epoch [551/1000], Loss: 0.1096\n",
      "Epoch [552/1000], Loss: 0.1094\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 2, activation : tanh, and neurons: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 0.2577\n",
      "Epoch [2/1000], Loss: 0.2444\n",
      "Epoch [3/1000], Loss: 0.2408\n",
      "Epoch [4/1000], Loss: 0.2395\n",
      "Epoch [5/1000], Loss: 0.2390\n",
      "Epoch [6/1000], Loss: 0.2386\n",
      "Epoch [7/1000], Loss: 0.2382\n",
      "Epoch [8/1000], Loss: 0.2379\n",
      "Epoch [9/1000], Loss: 0.2376\n",
      "Epoch [10/1000], Loss: 0.2372\n",
      "Epoch [11/1000], Loss: 0.2369\n",
      "Epoch [12/1000], Loss: 0.2366\n",
      "Epoch [13/1000], Loss: 0.2362\n",
      "Epoch [14/1000], Loss: 0.2359\n",
      "Epoch [15/1000], Loss: 0.2355\n",
      "Epoch [16/1000], Loss: 0.2352\n",
      "Epoch [17/1000], Loss: 0.2348\n",
      "Epoch [18/1000], Loss: 0.2344\n",
      "Epoch [19/1000], Loss: 0.2340\n",
      "Epoch [20/1000], Loss: 0.2336\n",
      "Epoch [21/1000], Loss: 0.2332\n",
      "Epoch [22/1000], Loss: 0.2327\n",
      "Epoch [23/1000], Loss: 0.2323\n",
      "Epoch [24/1000], Loss: 0.2319\n",
      "Epoch [25/1000], Loss: 0.2314\n",
      "Epoch [26/1000], Loss: 0.2309\n",
      "Epoch [27/1000], Loss: 0.2304\n",
      "Epoch [28/1000], Loss: 0.2299\n",
      "Epoch [29/1000], Loss: 0.2294\n",
      "Epoch [30/1000], Loss: 0.2289\n",
      "Epoch [31/1000], Loss: 0.2283\n",
      "Epoch [32/1000], Loss: 0.2278\n",
      "Epoch [33/1000], Loss: 0.2272\n",
      "Epoch [34/1000], Loss: 0.2266\n",
      "Epoch [35/1000], Loss: 0.2260\n",
      "Epoch [36/1000], Loss: 0.2255\n",
      "Epoch [37/1000], Loss: 0.2249\n",
      "Epoch [38/1000], Loss: 0.2242\n",
      "Epoch [39/1000], Loss: 0.2237\n",
      "Epoch [40/1000], Loss: 0.2231\n",
      "Epoch [41/1000], Loss: 0.2225\n",
      "Epoch [42/1000], Loss: 0.2219\n",
      "Epoch [43/1000], Loss: 0.2213\n",
      "Epoch [44/1000], Loss: 0.2206\n",
      "Epoch [45/1000], Loss: 0.2201\n",
      "Epoch [46/1000], Loss: 0.2195\n",
      "Epoch [47/1000], Loss: 0.2188\n",
      "Epoch [48/1000], Loss: 0.2182\n",
      "Epoch [49/1000], Loss: 0.2176\n",
      "Epoch [50/1000], Loss: 0.2169\n",
      "Epoch [51/1000], Loss: 0.2164\n",
      "Epoch [52/1000], Loss: 0.2156\n",
      "Epoch [53/1000], Loss: 0.2152\n",
      "Epoch [54/1000], Loss: 0.2144\n",
      "Epoch [55/1000], Loss: 0.2138\n",
      "Epoch [56/1000], Loss: 0.2133\n",
      "Epoch [57/1000], Loss: 0.2126\n",
      "Epoch [58/1000], Loss: 0.2119\n",
      "Epoch [59/1000], Loss: 0.2114\n",
      "Epoch [60/1000], Loss: 0.2105\n",
      "Epoch [61/1000], Loss: 0.2102\n",
      "Epoch [62/1000], Loss: 0.2095\n",
      "Epoch [63/1000], Loss: 0.2088\n",
      "Epoch [64/1000], Loss: 0.2079\n",
      "Epoch [65/1000], Loss: 0.2074\n",
      "Epoch [66/1000], Loss: 0.2067\n",
      "Epoch [67/1000], Loss: 0.2060\n",
      "Epoch [68/1000], Loss: 0.2051\n",
      "Epoch [69/1000], Loss: 0.2045\n",
      "Epoch [70/1000], Loss: 0.2036\n",
      "Epoch [71/1000], Loss: 0.2029\n",
      "Epoch [72/1000], Loss: 0.2020\n",
      "Epoch [73/1000], Loss: 0.2008\n",
      "Epoch [74/1000], Loss: 0.2000\n",
      "Epoch [75/1000], Loss: 0.1991\n",
      "Epoch [76/1000], Loss: 0.1983\n",
      "Epoch [77/1000], Loss: 0.1972\n",
      "Epoch [78/1000], Loss: 0.1962\n",
      "Epoch [79/1000], Loss: 0.1953\n",
      "Epoch [80/1000], Loss: 0.1941\n",
      "Epoch [81/1000], Loss: 0.1930\n",
      "Epoch [82/1000], Loss: 0.1918\n",
      "Epoch [83/1000], Loss: 0.1904\n",
      "Epoch [84/1000], Loss: 0.1892\n",
      "Epoch [85/1000], Loss: 0.1879\n",
      "Epoch [86/1000], Loss: 0.1863\n",
      "Epoch [87/1000], Loss: 0.1854\n",
      "Epoch [88/1000], Loss: 0.1836\n",
      "Epoch [89/1000], Loss: 0.1824\n",
      "Epoch [90/1000], Loss: 0.1807\n",
      "Epoch [91/1000], Loss: 0.1797\n",
      "Epoch [92/1000], Loss: 0.1782\n",
      "Epoch [93/1000], Loss: 0.1766\n",
      "Epoch [94/1000], Loss: 0.1756\n",
      "Epoch [95/1000], Loss: 0.1736\n",
      "Epoch [96/1000], Loss: 0.1723\n",
      "Epoch [97/1000], Loss: 0.1711\n",
      "Epoch [98/1000], Loss: 0.1693\n",
      "Epoch [99/1000], Loss: 0.1681\n",
      "Epoch [100/1000], Loss: 0.1664\n",
      "Epoch [101/1000], Loss: 0.1655\n",
      "Epoch [102/1000], Loss: 0.1638\n",
      "Epoch [103/1000], Loss: 0.1623\n",
      "Epoch [104/1000], Loss: 0.1614\n",
      "Epoch [105/1000], Loss: 0.1599\n",
      "Epoch [106/1000], Loss: 0.1586\n",
      "Epoch [107/1000], Loss: 0.1574\n",
      "Epoch [108/1000], Loss: 0.1555\n",
      "Epoch [109/1000], Loss: 0.1540\n",
      "Epoch [110/1000], Loss: 0.1525\n",
      "Epoch [111/1000], Loss: 0.1515\n",
      "Epoch [112/1000], Loss: 0.1498\n",
      "Epoch [113/1000], Loss: 0.1485\n",
      "Epoch [114/1000], Loss: 0.1471\n",
      "Epoch [115/1000], Loss: 0.1457\n",
      "Epoch [116/1000], Loss: 0.1437\n",
      "Epoch [117/1000], Loss: 0.1429\n",
      "Epoch [118/1000], Loss: 0.1416\n",
      "Epoch [119/1000], Loss: 0.1401\n",
      "Epoch [120/1000], Loss: 0.1389\n",
      "Epoch [121/1000], Loss: 0.1376\n",
      "Epoch [122/1000], Loss: 0.1365\n",
      "Epoch [123/1000], Loss: 0.1349\n",
      "Epoch [124/1000], Loss: 0.1336\n",
      "Epoch [125/1000], Loss: 0.1328\n",
      "Epoch [126/1000], Loss: 0.1316\n",
      "Epoch [127/1000], Loss: 0.1305\n",
      "Epoch [128/1000], Loss: 0.1295\n",
      "Epoch [129/1000], Loss: 0.1284\n",
      "Epoch [130/1000], Loss: 0.1273\n",
      "Epoch [131/1000], Loss: 0.1264\n",
      "Epoch [132/1000], Loss: 0.1247\n",
      "Epoch [133/1000], Loss: 0.1246\n",
      "Epoch [134/1000], Loss: 0.1237\n",
      "Epoch [135/1000], Loss: 0.1229\n",
      "Epoch [136/1000], Loss: 0.1217\n",
      "Epoch [137/1000], Loss: 0.1207\n",
      "Epoch [138/1000], Loss: 0.1201\n",
      "Epoch [139/1000], Loss: 0.1195\n",
      "Epoch [140/1000], Loss: 0.1185\n",
      "Epoch [141/1000], Loss: 0.1179\n",
      "Epoch [142/1000], Loss: 0.1170\n",
      "Epoch [143/1000], Loss: 0.1164\n",
      "Epoch [144/1000], Loss: 0.1153\n",
      "Epoch [145/1000], Loss: 0.1148\n",
      "Epoch [146/1000], Loss: 0.1141\n",
      "Epoch [147/1000], Loss: 0.1134\n",
      "Epoch [148/1000], Loss: 0.1125\n",
      "Epoch [149/1000], Loss: 0.1121\n",
      "Epoch [150/1000], Loss: 0.1111\n",
      "Epoch [151/1000], Loss: 0.1107\n",
      "Epoch [152/1000], Loss: 0.1096\n",
      "Epoch [153/1000], Loss: 0.1089\n",
      "Epoch [154/1000], Loss: 0.1085\n",
      "Epoch [155/1000], Loss: 0.1074\n",
      "Epoch [156/1000], Loss: 0.1071\n",
      "Epoch [157/1000], Loss: 0.1065\n",
      "Epoch [158/1000], Loss: 0.1060\n",
      "Epoch [159/1000], Loss: 0.1054\n",
      "Epoch [160/1000], Loss: 0.1043\n",
      "Epoch [161/1000], Loss: 0.1040\n",
      "Epoch [162/1000], Loss: 0.1038\n",
      "Epoch [163/1000], Loss: 0.1030\n",
      "Epoch [164/1000], Loss: 0.1025\n",
      "Epoch [165/1000], Loss: 0.1019\n",
      "Epoch [166/1000], Loss: 0.1014\n",
      "Epoch [167/1000], Loss: 0.1007\n",
      "Epoch [168/1000], Loss: 0.1005\n",
      "Epoch [169/1000], Loss: 0.0997\n",
      "Epoch [170/1000], Loss: 0.0991\n",
      "Epoch [171/1000], Loss: 0.0985\n",
      "Epoch [172/1000], Loss: 0.0976\n",
      "Epoch [173/1000], Loss: 0.0971\n",
      "Epoch [174/1000], Loss: 0.0962\n",
      "Epoch [175/1000], Loss: 0.0954\n",
      "Epoch [176/1000], Loss: 0.0944\n",
      "Epoch [177/1000], Loss: 0.0934\n",
      "Epoch [178/1000], Loss: 0.0920\n",
      "Epoch [179/1000], Loss: 0.0909\n",
      "Epoch [180/1000], Loss: 0.0894\n",
      "Epoch [181/1000], Loss: 0.0882\n",
      "Epoch [182/1000], Loss: 0.0876\n",
      "Epoch [183/1000], Loss: 0.0859\n",
      "Epoch [184/1000], Loss: 0.0849\n",
      "Epoch [185/1000], Loss: 0.0848\n",
      "Epoch [186/1000], Loss: 0.0843\n",
      "Epoch [187/1000], Loss: 0.0832\n",
      "Epoch [188/1000], Loss: 0.0824\n",
      "Epoch [189/1000], Loss: 0.0816\n",
      "Epoch [190/1000], Loss: 0.0810\n",
      "Epoch [191/1000], Loss: 0.0808\n",
      "Epoch [192/1000], Loss: 0.0802\n",
      "Epoch [193/1000], Loss: 0.0798\n",
      "Epoch [194/1000], Loss: 0.0792\n",
      "Epoch [195/1000], Loss: 0.0783\n",
      "Epoch [196/1000], Loss: 0.0786\n",
      "Epoch [197/1000], Loss: 0.0773\n",
      "Epoch [198/1000], Loss: 0.0772\n",
      "Epoch [199/1000], Loss: 0.0771\n",
      "Epoch [200/1000], Loss: 0.0757\n",
      "Epoch [201/1000], Loss: 0.0761\n",
      "Epoch [202/1000], Loss: 0.0754\n",
      "Epoch [203/1000], Loss: 0.0748\n",
      "Epoch [204/1000], Loss: 0.0743\n",
      "Epoch [205/1000], Loss: 0.0737\n",
      "Epoch [206/1000], Loss: 0.0736\n",
      "Epoch [207/1000], Loss: 0.0722\n",
      "Epoch [208/1000], Loss: 0.0722\n",
      "Epoch [209/1000], Loss: 0.0722\n",
      "Epoch [210/1000], Loss: 0.0711\n",
      "Epoch [211/1000], Loss: 0.0707\n",
      "Epoch [212/1000], Loss: 0.0696\n",
      "Epoch [213/1000], Loss: 0.0702\n",
      "Epoch [214/1000], Loss: 0.0685\n",
      "Epoch [215/1000], Loss: 0.0683\n",
      "Epoch [216/1000], Loss: 0.0681\n",
      "Epoch [217/1000], Loss: 0.0672\n",
      "Epoch [218/1000], Loss: 0.0666\n",
      "Epoch [219/1000], Loss: 0.0665\n",
      "Epoch [220/1000], Loss: 0.0657\n",
      "Epoch [221/1000], Loss: 0.0648\n",
      "Epoch [222/1000], Loss: 0.0645\n",
      "Epoch [223/1000], Loss: 0.0645\n",
      "Epoch [224/1000], Loss: 0.0637\n",
      "Epoch [225/1000], Loss: 0.0634\n",
      "Epoch [226/1000], Loss: 0.0627\n",
      "Epoch [227/1000], Loss: 0.0619\n",
      "Epoch [228/1000], Loss: 0.0618\n",
      "Epoch [229/1000], Loss: 0.0608\n",
      "Epoch [230/1000], Loss: 0.0608\n",
      "Epoch [231/1000], Loss: 0.0602\n",
      "Epoch [232/1000], Loss: 0.0590\n",
      "Epoch [233/1000], Loss: 0.0587\n",
      "Epoch [234/1000], Loss: 0.0580\n",
      "Epoch [235/1000], Loss: 0.0582\n",
      "Epoch [236/1000], Loss: 0.0573\n",
      "Epoch [237/1000], Loss: 0.0566\n",
      "Epoch [238/1000], Loss: 0.0564\n",
      "Epoch [239/1000], Loss: 0.0560\n",
      "Epoch [240/1000], Loss: 0.0555\n",
      "Epoch [241/1000], Loss: 0.0554\n",
      "Epoch [242/1000], Loss: 0.0545\n",
      "Epoch [243/1000], Loss: 0.0531\n",
      "Epoch [244/1000], Loss: 0.0531\n",
      "Epoch [245/1000], Loss: 0.0523\n",
      "Epoch [246/1000], Loss: 0.0510\n",
      "Epoch [247/1000], Loss: 0.0507\n",
      "Epoch [248/1000], Loss: 0.0507\n",
      "Epoch [249/1000], Loss: 0.0504\n",
      "Epoch [250/1000], Loss: 0.0492\n",
      "Epoch [251/1000], Loss: 0.0489\n",
      "Epoch [252/1000], Loss: 0.0476\n",
      "Epoch [253/1000], Loss: 0.0476\n",
      "Epoch [254/1000], Loss: 0.0467\n",
      "Epoch [255/1000], Loss: 0.0459\n",
      "Epoch [256/1000], Loss: 0.0459\n",
      "Epoch [257/1000], Loss: 0.0456\n",
      "Epoch [258/1000], Loss: 0.0438\n",
      "Epoch [259/1000], Loss: 0.0440\n",
      "Epoch [260/1000], Loss: 0.0447\n",
      "Epoch [261/1000], Loss: 0.0435\n",
      "Epoch [262/1000], Loss: 0.0426\n",
      "Epoch [263/1000], Loss: 0.0433\n",
      "Epoch [264/1000], Loss: 0.0423\n",
      "Epoch [265/1000], Loss: 0.0420\n",
      "Epoch [266/1000], Loss: 0.0414\n",
      "Epoch [267/1000], Loss: 0.0396\n",
      "Epoch [268/1000], Loss: 0.0395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [269/1000], Loss: 0.0392\n",
      "Epoch [270/1000], Loss: 0.0394\n",
      "Epoch [271/1000], Loss: 0.0382\n",
      "Epoch [272/1000], Loss: 0.0389\n",
      "Epoch [273/1000], Loss: 0.0378\n",
      "Epoch [274/1000], Loss: 0.0376\n",
      "Epoch [275/1000], Loss: 0.0374\n",
      "Epoch [276/1000], Loss: 0.0383\n",
      "Epoch [277/1000], Loss: 0.0354\n",
      "Epoch [278/1000], Loss: 0.0364\n",
      "Epoch [279/1000], Loss: 0.0342\n",
      "Epoch [280/1000], Loss: 0.0337\n",
      "Epoch [281/1000], Loss: 0.0324\n",
      "Epoch [282/1000], Loss: 0.0295\n",
      "Epoch [283/1000], Loss: 0.0291\n",
      "Epoch [284/1000], Loss: 0.0281\n",
      "Epoch [285/1000], Loss: 0.0254\n",
      "Epoch [286/1000], Loss: 0.0256\n",
      "Epoch [287/1000], Loss: 0.0237\n",
      "Epoch [288/1000], Loss: 0.0226\n",
      "Epoch [289/1000], Loss: 0.0223\n",
      "Epoch [290/1000], Loss: 0.0209\n",
      "Epoch [291/1000], Loss: 0.0197\n",
      "Epoch [292/1000], Loss: 0.0196\n",
      "Epoch [293/1000], Loss: 0.0184\n",
      "Epoch [294/1000], Loss: 0.0187\n",
      "Epoch [295/1000], Loss: 0.0175\n",
      "Epoch [296/1000], Loss: 0.0173\n",
      "Epoch [297/1000], Loss: 0.0163\n",
      "Epoch [298/1000], Loss: 0.0164\n",
      "Epoch [299/1000], Loss: 0.0158\n",
      "Epoch [300/1000], Loss: 0.0151\n",
      "Epoch [301/1000], Loss: 0.0151\n",
      "Epoch [302/1000], Loss: 0.0151\n",
      "Epoch [303/1000], Loss: 0.0140\n",
      "Epoch [304/1000], Loss: 0.0139\n",
      "Epoch [305/1000], Loss: 0.0135\n",
      "Epoch [306/1000], Loss: 0.0134\n",
      "Epoch [307/1000], Loss: 0.0132\n",
      "Epoch [308/1000], Loss: 0.0128\n",
      "Epoch [309/1000], Loss: 0.0127\n",
      "Epoch [310/1000], Loss: 0.0121\n",
      "Epoch [311/1000], Loss: 0.0125\n",
      "Epoch [312/1000], Loss: 0.0120\n",
      "Epoch [313/1000], Loss: 0.0116\n",
      "Epoch [314/1000], Loss: 0.0116\n",
      "Epoch [315/1000], Loss: 0.0113\n",
      "Epoch [316/1000], Loss: 0.0111\n",
      "Epoch [317/1000], Loss: 0.0108\n",
      "Epoch [318/1000], Loss: 0.0106\n",
      "Epoch [319/1000], Loss: 0.0105\n",
      "Epoch [320/1000], Loss: 0.0102\n",
      "Epoch [321/1000], Loss: 0.0103\n",
      "Epoch [322/1000], Loss: 0.0102\n",
      "Epoch [323/1000], Loss: 0.0098\n",
      "Epoch [324/1000], Loss: 0.0100\n",
      "Epoch [325/1000], Loss: 0.0098\n",
      "Epoch [326/1000], Loss: 0.0092\n",
      "Epoch [327/1000], Loss: 0.0095\n",
      "Epoch [328/1000], Loss: 0.0092\n",
      "Epoch [329/1000], Loss: 0.0090\n",
      "Epoch [330/1000], Loss: 0.0092\n",
      "Epoch [331/1000], Loss: 0.0087\n",
      "Epoch [332/1000], Loss: 0.0087\n",
      "Epoch [333/1000], Loss: 0.0088\n",
      "Epoch [334/1000], Loss: 0.0085\n",
      "Epoch [335/1000], Loss: 0.0084\n",
      "Epoch [336/1000], Loss: 0.0082\n",
      "Epoch [337/1000], Loss: 0.0083\n",
      "Epoch [338/1000], Loss: 0.0080\n",
      "Epoch [339/1000], Loss: 0.0080\n",
      "Epoch [340/1000], Loss: 0.0078\n",
      "Epoch [341/1000], Loss: 0.0076\n",
      "Epoch [342/1000], Loss: 0.0076\n",
      "Epoch [343/1000], Loss: 0.0075\n",
      "Epoch [344/1000], Loss: 0.0075\n",
      "Epoch [345/1000], Loss: 0.0074\n",
      "Epoch [346/1000], Loss: 0.0074\n",
      "Epoch [347/1000], Loss: 0.0072\n",
      "Epoch [348/1000], Loss: 0.0072\n",
      "Epoch [349/1000], Loss: 0.0071\n",
      "Epoch [350/1000], Loss: 0.0070\n",
      "Epoch [351/1000], Loss: 0.0069\n",
      "Epoch [352/1000], Loss: 0.0068\n",
      "Epoch [353/1000], Loss: 0.0067\n",
      "Epoch [354/1000], Loss: 0.0070\n",
      "Epoch [355/1000], Loss: 0.0065\n",
      "Epoch [356/1000], Loss: 0.0067\n",
      "Epoch [357/1000], Loss: 0.0065\n",
      "Epoch [358/1000], Loss: 0.0064\n",
      "Epoch [359/1000], Loss: 0.0065\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 2, activation : tanh, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2437\n",
      "Epoch [2/1000], Loss: 0.2390\n",
      "Epoch [3/1000], Loss: 0.2385\n",
      "Epoch [4/1000], Loss: 0.2382\n",
      "Epoch [5/1000], Loss: 0.2380\n",
      "Epoch [6/1000], Loss: 0.2376\n",
      "Epoch [7/1000], Loss: 0.2374\n",
      "Epoch [8/1000], Loss: 0.2371\n",
      "Epoch [9/1000], Loss: 0.2368\n",
      "Epoch [10/1000], Loss: 0.2365\n",
      "Epoch [11/1000], Loss: 0.2363\n",
      "Epoch [12/1000], Loss: 0.2359\n",
      "Epoch [13/1000], Loss: 0.2357\n",
      "Epoch [14/1000], Loss: 0.2354\n",
      "Epoch [15/1000], Loss: 0.2350\n",
      "Epoch [16/1000], Loss: 0.2347\n",
      "Epoch [17/1000], Loss: 0.2342\n",
      "Epoch [18/1000], Loss: 0.2339\n",
      "Epoch [19/1000], Loss: 0.2335\n",
      "Epoch [20/1000], Loss: 0.2330\n",
      "Epoch [21/1000], Loss: 0.2325\n",
      "Epoch [22/1000], Loss: 0.2319\n",
      "Epoch [23/1000], Loss: 0.2314\n",
      "Epoch [24/1000], Loss: 0.2306\n",
      "Epoch [25/1000], Loss: 0.2300\n",
      "Epoch [26/1000], Loss: 0.2292\n",
      "Epoch [27/1000], Loss: 0.2284\n",
      "Epoch [28/1000], Loss: 0.2275\n",
      "Epoch [29/1000], Loss: 0.2266\n",
      "Epoch [30/1000], Loss: 0.2256\n",
      "Epoch [31/1000], Loss: 0.2246\n",
      "Epoch [32/1000], Loss: 0.2236\n",
      "Epoch [33/1000], Loss: 0.2224\n",
      "Epoch [34/1000], Loss: 0.2213\n",
      "Epoch [35/1000], Loss: 0.2203\n",
      "Epoch [36/1000], Loss: 0.2192\n",
      "Epoch [37/1000], Loss: 0.2178\n",
      "Epoch [38/1000], Loss: 0.2167\n",
      "Epoch [39/1000], Loss: 0.2155\n",
      "Epoch [40/1000], Loss: 0.2145\n",
      "Epoch [41/1000], Loss: 0.2133\n",
      "Epoch [42/1000], Loss: 0.2120\n",
      "Epoch [43/1000], Loss: 0.2109\n",
      "Epoch [44/1000], Loss: 0.2099\n",
      "Epoch [45/1000], Loss: 0.2087\n",
      "Epoch [46/1000], Loss: 0.2074\n",
      "Epoch [47/1000], Loss: 0.2065\n",
      "Epoch [48/1000], Loss: 0.2054\n",
      "Epoch [49/1000], Loss: 0.2044\n",
      "Epoch [50/1000], Loss: 0.2032\n",
      "Epoch [51/1000], Loss: 0.2020\n",
      "Epoch [52/1000], Loss: 0.2010\n",
      "Epoch [53/1000], Loss: 0.1996\n",
      "Epoch [54/1000], Loss: 0.1986\n",
      "Epoch [55/1000], Loss: 0.1975\n",
      "Epoch [56/1000], Loss: 0.1962\n",
      "Epoch [57/1000], Loss: 0.1951\n",
      "Epoch [58/1000], Loss: 0.1940\n",
      "Epoch [59/1000], Loss: 0.1926\n",
      "Epoch [60/1000], Loss: 0.1914\n",
      "Epoch [61/1000], Loss: 0.1904\n",
      "Epoch [62/1000], Loss: 0.1886\n",
      "Epoch [63/1000], Loss: 0.1875\n",
      "Epoch [64/1000], Loss: 0.1862\n",
      "Epoch [65/1000], Loss: 0.1852\n",
      "Epoch [66/1000], Loss: 0.1836\n",
      "Epoch [67/1000], Loss: 0.1823\n",
      "Epoch [68/1000], Loss: 0.1807\n",
      "Epoch [69/1000], Loss: 0.1793\n",
      "Epoch [70/1000], Loss: 0.1780\n",
      "Epoch [71/1000], Loss: 0.1764\n",
      "Epoch [72/1000], Loss: 0.1749\n",
      "Epoch [73/1000], Loss: 0.1730\n",
      "Epoch [74/1000], Loss: 0.1717\n",
      "Epoch [75/1000], Loss: 0.1706\n",
      "Epoch [76/1000], Loss: 0.1687\n",
      "Epoch [77/1000], Loss: 0.1667\n",
      "Epoch [78/1000], Loss: 0.1656\n",
      "Epoch [79/1000], Loss: 0.1635\n",
      "Epoch [80/1000], Loss: 0.1617\n",
      "Epoch [81/1000], Loss: 0.1597\n",
      "Epoch [82/1000], Loss: 0.1587\n",
      "Epoch [83/1000], Loss: 0.1561\n",
      "Epoch [84/1000], Loss: 0.1551\n",
      "Epoch [85/1000], Loss: 0.1524\n",
      "Epoch [86/1000], Loss: 0.1505\n",
      "Epoch [87/1000], Loss: 0.1486\n",
      "Epoch [88/1000], Loss: 0.1477\n",
      "Epoch [89/1000], Loss: 0.1452\n",
      "Epoch [90/1000], Loss: 0.1432\n",
      "Epoch [91/1000], Loss: 0.1420\n",
      "Epoch [92/1000], Loss: 0.1398\n",
      "Epoch [93/1000], Loss: 0.1381\n",
      "Epoch [94/1000], Loss: 0.1357\n",
      "Epoch [95/1000], Loss: 0.1350\n",
      "Epoch [96/1000], Loss: 0.1316\n",
      "Epoch [97/1000], Loss: 0.1301\n",
      "Epoch [98/1000], Loss: 0.1280\n",
      "Epoch [99/1000], Loss: 0.1260\n",
      "Epoch [100/1000], Loss: 0.1235\n",
      "Epoch [101/1000], Loss: 0.1221\n",
      "Epoch [102/1000], Loss: 0.1199\n",
      "Epoch [103/1000], Loss: 0.1180\n",
      "Epoch [104/1000], Loss: 0.1162\n",
      "Epoch [105/1000], Loss: 0.1136\n",
      "Epoch [106/1000], Loss: 0.1115\n",
      "Epoch [107/1000], Loss: 0.1098\n",
      "Epoch [108/1000], Loss: 0.1077\n",
      "Epoch [109/1000], Loss: 0.1059\n",
      "Epoch [110/1000], Loss: 0.1039\n",
      "Epoch [111/1000], Loss: 0.1022\n",
      "Epoch [112/1000], Loss: 0.1005\n",
      "Epoch [113/1000], Loss: 0.0983\n",
      "Epoch [114/1000], Loss: 0.0970\n",
      "Epoch [115/1000], Loss: 0.0956\n",
      "Epoch [116/1000], Loss: 0.0943\n",
      "Epoch [117/1000], Loss: 0.0930\n",
      "Epoch [118/1000], Loss: 0.0918\n",
      "Epoch [119/1000], Loss: 0.0895\n",
      "Epoch [120/1000], Loss: 0.0880\n",
      "Epoch [121/1000], Loss: 0.0869\n",
      "Epoch [122/1000], Loss: 0.0853\n",
      "Epoch [123/1000], Loss: 0.0843\n",
      "Epoch [124/1000], Loss: 0.0828\n",
      "Epoch [125/1000], Loss: 0.0817\n",
      "Epoch [126/1000], Loss: 0.0803\n",
      "Epoch [127/1000], Loss: 0.0788\n",
      "Epoch [128/1000], Loss: 0.0778\n",
      "Epoch [129/1000], Loss: 0.0764\n",
      "Epoch [130/1000], Loss: 0.0747\n",
      "Epoch [131/1000], Loss: 0.0740\n",
      "Epoch [132/1000], Loss: 0.0725\n",
      "Epoch [133/1000], Loss: 0.0706\n",
      "Epoch [134/1000], Loss: 0.0694\n",
      "Epoch [135/1000], Loss: 0.0681\n",
      "Epoch [136/1000], Loss: 0.0661\n",
      "Epoch [137/1000], Loss: 0.0648\n",
      "Epoch [138/1000], Loss: 0.0635\n",
      "Epoch [139/1000], Loss: 0.0621\n",
      "Epoch [140/1000], Loss: 0.0604\n",
      "Epoch [141/1000], Loss: 0.0588\n",
      "Epoch [142/1000], Loss: 0.0580\n",
      "Epoch [143/1000], Loss: 0.0561\n",
      "Epoch [144/1000], Loss: 0.0550\n",
      "Epoch [145/1000], Loss: 0.0537\n",
      "Epoch [146/1000], Loss: 0.0529\n",
      "Epoch [147/1000], Loss: 0.0518\n",
      "Epoch [148/1000], Loss: 0.0500\n",
      "Epoch [149/1000], Loss: 0.0491\n",
      "Epoch [150/1000], Loss: 0.0478\n",
      "Epoch [151/1000], Loss: 0.0464\n",
      "Epoch [152/1000], Loss: 0.0453\n",
      "Epoch [153/1000], Loss: 0.0440\n",
      "Epoch [154/1000], Loss: 0.0430\n",
      "Epoch [155/1000], Loss: 0.0421\n",
      "Epoch [156/1000], Loss: 0.0406\n",
      "Epoch [157/1000], Loss: 0.0395\n",
      "Epoch [158/1000], Loss: 0.0386\n",
      "Epoch [159/1000], Loss: 0.0371\n",
      "Epoch [160/1000], Loss: 0.0365\n",
      "Epoch [161/1000], Loss: 0.0352\n",
      "Epoch [162/1000], Loss: 0.0340\n",
      "Epoch [163/1000], Loss: 0.0334\n",
      "Epoch [164/1000], Loss: 0.0320\n",
      "Epoch [165/1000], Loss: 0.0310\n",
      "Epoch [166/1000], Loss: 0.0301\n",
      "Epoch [167/1000], Loss: 0.0293\n",
      "Epoch [168/1000], Loss: 0.0284\n",
      "Epoch [169/1000], Loss: 0.0276\n",
      "Epoch [170/1000], Loss: 0.0268\n",
      "Epoch [171/1000], Loss: 0.0261\n",
      "Epoch [172/1000], Loss: 0.0250\n",
      "Epoch [173/1000], Loss: 0.0244\n",
      "Epoch [174/1000], Loss: 0.0237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [175/1000], Loss: 0.0231\n",
      "Epoch [176/1000], Loss: 0.0222\n",
      "Epoch [177/1000], Loss: 0.0216\n",
      "Epoch [178/1000], Loss: 0.0209\n",
      "Epoch [179/1000], Loss: 0.0201\n",
      "Epoch [180/1000], Loss: 0.0200\n",
      "Epoch [181/1000], Loss: 0.0189\n",
      "Epoch [182/1000], Loss: 0.0184\n",
      "Epoch [183/1000], Loss: 0.0179\n",
      "Epoch [184/1000], Loss: 0.0175\n",
      "Epoch [185/1000], Loss: 0.0168\n",
      "Epoch [186/1000], Loss: 0.0165\n",
      "Epoch [187/1000], Loss: 0.0158\n",
      "Epoch [188/1000], Loss: 0.0154\n",
      "Epoch [189/1000], Loss: 0.0150\n",
      "Epoch [190/1000], Loss: 0.0146\n",
      "Epoch [191/1000], Loss: 0.0140\n",
      "Epoch [192/1000], Loss: 0.0139\n",
      "Epoch [193/1000], Loss: 0.0135\n",
      "Epoch [194/1000], Loss: 0.0127\n",
      "Epoch [195/1000], Loss: 0.0125\n",
      "Epoch [196/1000], Loss: 0.0122\n",
      "Epoch [197/1000], Loss: 0.0119\n",
      "Epoch [198/1000], Loss: 0.0115\n",
      "Epoch [199/1000], Loss: 0.0114\n",
      "Epoch [200/1000], Loss: 0.0110\n",
      "Epoch [201/1000], Loss: 0.0107\n",
      "Epoch [202/1000], Loss: 0.0105\n",
      "Epoch [203/1000], Loss: 0.0102\n",
      "Epoch [204/1000], Loss: 0.0100\n",
      "Epoch [205/1000], Loss: 0.0096\n",
      "Epoch [206/1000], Loss: 0.0095\n",
      "Epoch [207/1000], Loss: 0.0093\n",
      "Epoch [208/1000], Loss: 0.0090\n",
      "Epoch [209/1000], Loss: 0.0087\n",
      "Epoch [210/1000], Loss: 0.0086\n",
      "Epoch [211/1000], Loss: 0.0084\n",
      "Epoch [212/1000], Loss: 0.0081\n",
      "Epoch [213/1000], Loss: 0.0080\n",
      "Epoch [214/1000], Loss: 0.0080\n",
      "Epoch [215/1000], Loss: 0.0076\n",
      "Epoch [216/1000], Loss: 0.0076\n",
      "Epoch [217/1000], Loss: 0.0073\n",
      "Epoch [218/1000], Loss: 0.0071\n",
      "Epoch [219/1000], Loss: 0.0070\n",
      "Epoch [220/1000], Loss: 0.0068\n",
      "Epoch [221/1000], Loss: 0.0067\n",
      "Epoch [222/1000], Loss: 0.0066\n",
      "Epoch [223/1000], Loss: 0.0064\n",
      "Epoch [224/1000], Loss: 0.0063\n",
      "Epoch [225/1000], Loss: 0.0062\n",
      "Epoch [226/1000], Loss: 0.0061\n",
      "Epoch [227/1000], Loss: 0.0059\n",
      "Epoch [228/1000], Loss: 0.0059\n",
      "Epoch [229/1000], Loss: 0.0057\n",
      "Epoch [230/1000], Loss: 0.0056\n",
      "Epoch [231/1000], Loss: 0.0054\n",
      "Epoch [232/1000], Loss: 0.0056\n",
      "Epoch [233/1000], Loss: 0.0054\n",
      "Epoch [234/1000], Loss: 0.0053\n",
      "Epoch [235/1000], Loss: 0.0052\n",
      "Epoch [236/1000], Loss: 0.0051\n",
      "Epoch [237/1000], Loss: 0.0050\n",
      "Epoch [238/1000], Loss: 0.0050\n",
      "Epoch [239/1000], Loss: 0.0048\n",
      "Epoch [240/1000], Loss: 0.0047\n",
      "Epoch [241/1000], Loss: 0.0047\n",
      "Epoch [242/1000], Loss: 0.0046\n",
      "Epoch [243/1000], Loss: 0.0045\n",
      "Epoch [244/1000], Loss: 0.0045\n",
      "Epoch [245/1000], Loss: 0.0044\n",
      "Epoch [246/1000], Loss: 0.0043\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 3, activation : relu, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2537\n",
      "Epoch [2/1000], Loss: 0.2510\n",
      "Epoch [3/1000], Loss: 0.2492\n",
      "Epoch [4/1000], Loss: 0.2478\n",
      "Epoch [5/1000], Loss: 0.2462\n",
      "Epoch [6/1000], Loss: 0.2445\n",
      "Epoch [7/1000], Loss: 0.2427\n",
      "Epoch [8/1000], Loss: 0.2412\n",
      "Epoch [9/1000], Loss: 0.2401\n",
      "Epoch [10/1000], Loss: 0.2394\n",
      "Epoch [11/1000], Loss: 0.2390\n",
      "Epoch [12/1000], Loss: 0.2387\n",
      "Epoch [13/1000], Loss: 0.2384\n",
      "Epoch [14/1000], Loss: 0.2382\n",
      "Epoch [15/1000], Loss: 0.2380\n",
      "Epoch [16/1000], Loss: 0.2377\n",
      "Epoch [17/1000], Loss: 0.2376\n",
      "Epoch [18/1000], Loss: 0.2374\n",
      "Epoch [19/1000], Loss: 0.2372\n",
      "Epoch [20/1000], Loss: 0.2371\n",
      "Epoch [21/1000], Loss: 0.2369\n",
      "Epoch [22/1000], Loss: 0.2367\n",
      "Epoch [23/1000], Loss: 0.2365\n",
      "Epoch [24/1000], Loss: 0.2362\n",
      "Epoch [25/1000], Loss: 0.2357\n",
      "Epoch [26/1000], Loss: 0.2353\n",
      "Epoch [27/1000], Loss: 0.2351\n",
      "Epoch [28/1000], Loss: 0.2349\n",
      "Epoch [29/1000], Loss: 0.2348\n",
      "Epoch [30/1000], Loss: 0.2346\n",
      "Epoch [31/1000], Loss: 0.2345\n",
      "Epoch [32/1000], Loss: 0.2343\n",
      "Epoch [33/1000], Loss: 0.2341\n",
      "Epoch [34/1000], Loss: 0.2340\n",
      "Epoch [35/1000], Loss: 0.2338\n",
      "Epoch [36/1000], Loss: 0.2337\n",
      "Epoch [37/1000], Loss: 0.2335\n",
      "Epoch [38/1000], Loss: 0.2333\n",
      "Epoch [39/1000], Loss: 0.2331\n",
      "Epoch [40/1000], Loss: 0.2330\n",
      "Epoch [41/1000], Loss: 0.2327\n",
      "Epoch [42/1000], Loss: 0.2325\n",
      "Epoch [43/1000], Loss: 0.2322\n",
      "Epoch [44/1000], Loss: 0.2320\n",
      "Epoch [45/1000], Loss: 0.2317\n",
      "Epoch [46/1000], Loss: 0.2314\n",
      "Epoch [47/1000], Loss: 0.2311\n",
      "Epoch [48/1000], Loss: 0.2307\n",
      "Epoch [49/1000], Loss: 0.2303\n",
      "Epoch [50/1000], Loss: 0.2300\n",
      "Epoch [51/1000], Loss: 0.2294\n",
      "Epoch [52/1000], Loss: 0.2291\n",
      "Epoch [53/1000], Loss: 0.2287\n",
      "Epoch [54/1000], Loss: 0.2279\n",
      "Epoch [55/1000], Loss: 0.2273\n",
      "Epoch [56/1000], Loss: 0.2264\n",
      "Epoch [57/1000], Loss: 0.2261\n",
      "Epoch [58/1000], Loss: 0.2252\n",
      "Epoch [59/1000], Loss: 0.2245\n",
      "Epoch [60/1000], Loss: 0.2236\n",
      "Epoch [61/1000], Loss: 0.2223\n",
      "Epoch [62/1000], Loss: 0.2216\n",
      "Epoch [63/1000], Loss: 0.2206\n",
      "Epoch [64/1000], Loss: 0.2198\n",
      "Epoch [65/1000], Loss: 0.2187\n",
      "Epoch [66/1000], Loss: 0.2169\n",
      "Epoch [67/1000], Loss: 0.2158\n",
      "Epoch [68/1000], Loss: 0.2140\n",
      "Epoch [69/1000], Loss: 0.2121\n",
      "Epoch [70/1000], Loss: 0.2099\n",
      "Epoch [71/1000], Loss: 0.2084\n",
      "Epoch [72/1000], Loss: 0.2061\n",
      "Epoch [73/1000], Loss: 0.2037\n",
      "Epoch [74/1000], Loss: 0.2018\n",
      "Epoch [75/1000], Loss: 0.1999\n",
      "Epoch [76/1000], Loss: 0.1978\n",
      "Epoch [77/1000], Loss: 0.1960\n",
      "Epoch [78/1000], Loss: 0.1940\n",
      "Epoch [79/1000], Loss: 0.1926\n",
      "Epoch [80/1000], Loss: 0.1906\n",
      "Epoch [81/1000], Loss: 0.1884\n",
      "Epoch [82/1000], Loss: 0.1750\n",
      "Epoch [83/1000], Loss: 0.1567\n",
      "Epoch [84/1000], Loss: 0.1480\n",
      "Epoch [85/1000], Loss: 0.1412\n",
      "Epoch [86/1000], Loss: 0.1340\n",
      "Epoch [87/1000], Loss: 0.1283\n",
      "Epoch [88/1000], Loss: 0.1236\n",
      "Epoch [89/1000], Loss: 0.1203\n",
      "Epoch [90/1000], Loss: 0.1169\n",
      "Epoch [91/1000], Loss: 0.1138\n",
      "Epoch [92/1000], Loss: 0.1119\n",
      "Epoch [93/1000], Loss: 0.1094\n",
      "Epoch [94/1000], Loss: 0.1081\n",
      "Epoch [95/1000], Loss: 0.1066\n",
      "Epoch [96/1000], Loss: 0.1048\n",
      "Epoch [97/1000], Loss: 0.1035\n",
      "Epoch [98/1000], Loss: 0.1027\n",
      "Epoch [99/1000], Loss: 0.1015\n",
      "Epoch [100/1000], Loss: 0.1010\n",
      "Epoch [101/1000], Loss: 0.1013\n",
      "Epoch [102/1000], Loss: 0.0989\n",
      "Epoch [103/1000], Loss: 0.0988\n",
      "Epoch [104/1000], Loss: 0.0980\n",
      "Epoch [105/1000], Loss: 0.0975\n",
      "Epoch [106/1000], Loss: 0.0972\n",
      "Epoch [107/1000], Loss: 0.0965\n",
      "Epoch [108/1000], Loss: 0.0967\n",
      "Epoch [109/1000], Loss: 0.0960\n",
      "Epoch [110/1000], Loss: 0.0958\n",
      "Epoch [111/1000], Loss: 0.0971\n",
      "Epoch [112/1000], Loss: 0.0946\n",
      "Epoch [113/1000], Loss: 0.0951\n",
      "Epoch [114/1000], Loss: 0.0944\n",
      "Epoch [115/1000], Loss: 0.0943\n",
      "Epoch [116/1000], Loss: 0.0943\n",
      "Epoch [117/1000], Loss: 0.0934\n",
      "Epoch [118/1000], Loss: 0.0935\n",
      "Epoch [119/1000], Loss: 0.0932\n",
      "Epoch [120/1000], Loss: 0.0932\n",
      "Epoch [121/1000], Loss: 0.0942\n",
      "Epoch [122/1000], Loss: 0.0935\n",
      "Epoch [123/1000], Loss: 0.0929\n",
      "Epoch [124/1000], Loss: 0.0928\n",
      "Epoch [125/1000], Loss: 0.0927\n",
      "Epoch [126/1000], Loss: 0.0927\n",
      "Epoch [127/1000], Loss: 0.0931\n",
      "Epoch [128/1000], Loss: 0.0923\n",
      "Epoch [129/1000], Loss: 0.0919\n",
      "Epoch [130/1000], Loss: 0.0919\n",
      "Epoch [131/1000], Loss: 0.0917\n",
      "Epoch [132/1000], Loss: 0.0918\n",
      "Epoch [133/1000], Loss: 0.0915\n",
      "Epoch [134/1000], Loss: 0.0915\n",
      "Epoch [135/1000], Loss: 0.0924\n",
      "Epoch [136/1000], Loss: 0.0915\n",
      "Epoch [137/1000], Loss: 0.0914\n",
      "Epoch [138/1000], Loss: 0.0913\n",
      "Epoch [139/1000], Loss: 0.0924\n",
      "Epoch [140/1000], Loss: 0.0925\n",
      "Epoch [141/1000], Loss: 0.0907\n",
      "Epoch [142/1000], Loss: 0.0915\n",
      "Epoch [143/1000], Loss: 0.0906\n",
      "Epoch [144/1000], Loss: 0.0902\n",
      "Epoch [145/1000], Loss: 0.0907\n",
      "Epoch [146/1000], Loss: 0.0900\n",
      "Epoch [147/1000], Loss: 0.1045\n",
      "Epoch [148/1000], Loss: 0.0908\n",
      "Epoch [149/1000], Loss: 0.0909\n",
      "Epoch [150/1000], Loss: 0.0901\n",
      "Epoch [151/1000], Loss: 0.0903\n",
      "Epoch [152/1000], Loss: 0.0903\n",
      "Epoch [153/1000], Loss: 0.0902\n",
      "Epoch [154/1000], Loss: 0.0904\n",
      "Epoch [155/1000], Loss: 0.0900\n",
      "Epoch [156/1000], Loss: 0.0902\n",
      "Epoch [157/1000], Loss: 0.0897\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 3, activation : relu, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2517\n",
      "Epoch [2/1000], Loss: 0.2457\n",
      "Epoch [3/1000], Loss: 0.2417\n",
      "Epoch [4/1000], Loss: 0.2387\n",
      "Epoch [5/1000], Loss: 0.2372\n",
      "Epoch [6/1000], Loss: 0.2366\n",
      "Epoch [7/1000], Loss: 0.2362\n",
      "Epoch [8/1000], Loss: 0.2360\n",
      "Epoch [9/1000], Loss: 0.2358\n",
      "Epoch [10/1000], Loss: 0.2356\n",
      "Epoch [11/1000], Loss: 0.2354\n",
      "Epoch [12/1000], Loss: 0.2352\n",
      "Epoch [13/1000], Loss: 0.2350\n",
      "Epoch [14/1000], Loss: 0.2348\n",
      "Epoch [15/1000], Loss: 0.2346\n",
      "Epoch [16/1000], Loss: 0.2345\n",
      "Epoch [17/1000], Loss: 0.2343\n",
      "Epoch [18/1000], Loss: 0.2342\n",
      "Epoch [19/1000], Loss: 0.2340\n",
      "Epoch [20/1000], Loss: 0.2338\n",
      "Epoch [21/1000], Loss: 0.2336\n",
      "Epoch [22/1000], Loss: 0.2334\n",
      "Epoch [23/1000], Loss: 0.2331\n",
      "Epoch [24/1000], Loss: 0.2329\n",
      "Epoch [25/1000], Loss: 0.2326\n",
      "Epoch [26/1000], Loss: 0.2323\n",
      "Epoch [27/1000], Loss: 0.2319\n",
      "Epoch [28/1000], Loss: 0.2315\n",
      "Epoch [29/1000], Loss: 0.2310\n",
      "Epoch [30/1000], Loss: 0.2306\n",
      "Epoch [31/1000], Loss: 0.2301\n",
      "Epoch [32/1000], Loss: 0.2294\n",
      "Epoch [33/1000], Loss: 0.2288\n",
      "Epoch [34/1000], Loss: 0.2281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/1000], Loss: 0.2272\n",
      "Epoch [36/1000], Loss: 0.2263\n",
      "Epoch [37/1000], Loss: 0.2253\n",
      "Epoch [38/1000], Loss: 0.2242\n",
      "Epoch [39/1000], Loss: 0.2230\n",
      "Epoch [40/1000], Loss: 0.2216\n",
      "Epoch [41/1000], Loss: 0.2202\n",
      "Epoch [42/1000], Loss: 0.2188\n",
      "Epoch [43/1000], Loss: 0.2169\n",
      "Epoch [44/1000], Loss: 0.2147\n",
      "Epoch [45/1000], Loss: 0.2123\n",
      "Epoch [46/1000], Loss: 0.2093\n",
      "Epoch [47/1000], Loss: 0.2062\n",
      "Epoch [48/1000], Loss: 0.2028\n",
      "Epoch [49/1000], Loss: 0.1986\n",
      "Epoch [50/1000], Loss: 0.1931\n",
      "Epoch [51/1000], Loss: 0.1863\n",
      "Epoch [52/1000], Loss: 0.1787\n",
      "Epoch [53/1000], Loss: 0.1711\n",
      "Epoch [54/1000], Loss: 0.1622\n",
      "Epoch [55/1000], Loss: 0.1532\n",
      "Epoch [56/1000], Loss: 0.1432\n",
      "Epoch [57/1000], Loss: 0.1322\n",
      "Epoch [58/1000], Loss: 0.1219\n",
      "Epoch [59/1000], Loss: 0.1127\n",
      "Epoch [60/1000], Loss: 0.1048\n",
      "Epoch [61/1000], Loss: 0.0968\n",
      "Epoch [62/1000], Loss: 0.0887\n",
      "Epoch [63/1000], Loss: 0.0817\n",
      "Epoch [64/1000], Loss: 0.0742\n",
      "Epoch [65/1000], Loss: 0.0677\n",
      "Epoch [66/1000], Loss: 0.0606\n",
      "Epoch [67/1000], Loss: 0.0548\n",
      "Epoch [68/1000], Loss: 0.0491\n",
      "Epoch [69/1000], Loss: 0.0437\n",
      "Epoch [70/1000], Loss: 0.0384\n",
      "Epoch [71/1000], Loss: 0.0341\n",
      "Epoch [72/1000], Loss: 0.0300\n",
      "Epoch [73/1000], Loss: 0.0256\n",
      "Epoch [74/1000], Loss: 0.0240\n",
      "Epoch [75/1000], Loss: 0.0212\n",
      "Epoch [76/1000], Loss: 0.0182\n",
      "Epoch [77/1000], Loss: 0.0166\n",
      "Epoch [78/1000], Loss: 0.0149\n",
      "Epoch [79/1000], Loss: 0.0134\n",
      "Epoch [80/1000], Loss: 0.0124\n",
      "Epoch [81/1000], Loss: 0.0114\n",
      "Epoch [82/1000], Loss: 0.0102\n",
      "Epoch [83/1000], Loss: 0.0092\n",
      "Epoch [84/1000], Loss: 0.0087\n",
      "Epoch [85/1000], Loss: 0.0080\n",
      "Epoch [86/1000], Loss: 0.0074\n",
      "Epoch [87/1000], Loss: 0.0070\n",
      "Epoch [88/1000], Loss: 0.0064\n",
      "Epoch [89/1000], Loss: 0.0062\n",
      "Epoch [90/1000], Loss: 0.0059\n",
      "Epoch [91/1000], Loss: 0.0054\n",
      "Epoch [92/1000], Loss: 0.0051\n",
      "Epoch [93/1000], Loss: 0.0048\n",
      "Epoch [94/1000], Loss: 0.0045\n",
      "Epoch [95/1000], Loss: 0.0045\n",
      "Epoch [96/1000], Loss: 0.0043\n",
      "Epoch [97/1000], Loss: 0.0039\n",
      "Epoch [98/1000], Loss: 0.0039\n",
      "Epoch [99/1000], Loss: 0.0036\n",
      "Epoch [100/1000], Loss: 0.0035\n",
      "Epoch [101/1000], Loss: 0.0035\n",
      "Epoch [102/1000], Loss: 0.0032\n",
      "Epoch [103/1000], Loss: 0.0030\n",
      "Epoch [104/1000], Loss: 0.0029\n",
      "Epoch [105/1000], Loss: 0.0028\n",
      "Epoch [106/1000], Loss: 0.0027\n",
      "Epoch [107/1000], Loss: 0.0027\n",
      "Epoch [108/1000], Loss: 0.0027\n",
      "Epoch [109/1000], Loss: 0.0025\n",
      "Epoch [110/1000], Loss: 0.0024\n",
      "Epoch [111/1000], Loss: 0.0023\n",
      "Epoch [112/1000], Loss: 0.0022\n",
      "Epoch [113/1000], Loss: 0.0021\n",
      "Epoch [114/1000], Loss: 0.0021\n",
      "Epoch [115/1000], Loss: 0.0022\n",
      "Epoch [116/1000], Loss: 0.0020\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 3, activation : relu, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2500\n",
      "Epoch [2/1000], Loss: 0.2456\n",
      "Epoch [3/1000], Loss: 0.2428\n",
      "Epoch [4/1000], Loss: 0.2407\n",
      "Epoch [5/1000], Loss: 0.2389\n",
      "Epoch [6/1000], Loss: 0.2375\n",
      "Epoch [7/1000], Loss: 0.2364\n",
      "Epoch [8/1000], Loss: 0.2355\n",
      "Epoch [9/1000], Loss: 0.2347\n",
      "Epoch [10/1000], Loss: 0.2341\n",
      "Epoch [11/1000], Loss: 0.2333\n",
      "Epoch [12/1000], Loss: 0.2326\n",
      "Epoch [13/1000], Loss: 0.2321\n",
      "Epoch [14/1000], Loss: 0.2313\n",
      "Epoch [15/1000], Loss: 0.2307\n",
      "Epoch [16/1000], Loss: 0.2300\n",
      "Epoch [17/1000], Loss: 0.2291\n",
      "Epoch [18/1000], Loss: 0.2284\n",
      "Epoch [19/1000], Loss: 0.2274\n",
      "Epoch [20/1000], Loss: 0.2264\n",
      "Epoch [21/1000], Loss: 0.2252\n",
      "Epoch [22/1000], Loss: 0.2241\n",
      "Epoch [23/1000], Loss: 0.2228\n",
      "Epoch [24/1000], Loss: 0.2212\n",
      "Epoch [25/1000], Loss: 0.2194\n",
      "Epoch [26/1000], Loss: 0.2175\n",
      "Epoch [27/1000], Loss: 0.2154\n",
      "Epoch [28/1000], Loss: 0.2132\n",
      "Epoch [29/1000], Loss: 0.2106\n",
      "Epoch [30/1000], Loss: 0.2081\n",
      "Epoch [31/1000], Loss: 0.2051\n",
      "Epoch [32/1000], Loss: 0.2019\n",
      "Epoch [33/1000], Loss: 0.1980\n",
      "Epoch [34/1000], Loss: 0.1944\n",
      "Epoch [35/1000], Loss: 0.1899\n",
      "Epoch [36/1000], Loss: 0.1850\n",
      "Epoch [37/1000], Loss: 0.1793\n",
      "Epoch [38/1000], Loss: 0.1725\n",
      "Epoch [39/1000], Loss: 0.1659\n",
      "Epoch [40/1000], Loss: 0.1573\n",
      "Epoch [41/1000], Loss: 0.1476\n",
      "Epoch [42/1000], Loss: 0.1379\n",
      "Epoch [43/1000], Loss: 0.1268\n",
      "Epoch [44/1000], Loss: 0.1140\n",
      "Epoch [45/1000], Loss: 0.1003\n",
      "Epoch [46/1000], Loss: 0.0867\n",
      "Epoch [47/1000], Loss: 0.0744\n",
      "Epoch [48/1000], Loss: 0.0626\n",
      "Epoch [49/1000], Loss: 0.0521\n",
      "Epoch [50/1000], Loss: 0.0440\n",
      "Epoch [51/1000], Loss: 0.0371\n",
      "Epoch [52/1000], Loss: 0.0321\n",
      "Epoch [53/1000], Loss: 0.0278\n",
      "Epoch [54/1000], Loss: 0.0241\n",
      "Epoch [55/1000], Loss: 0.0209\n",
      "Epoch [56/1000], Loss: 0.0184\n",
      "Epoch [57/1000], Loss: 0.0161\n",
      "Epoch [58/1000], Loss: 0.0144\n",
      "Epoch [59/1000], Loss: 0.0127\n",
      "Epoch [60/1000], Loss: 0.0113\n",
      "Epoch [61/1000], Loss: 0.0102\n",
      "Epoch [62/1000], Loss: 0.0092\n",
      "Epoch [63/1000], Loss: 0.0083\n",
      "Epoch [64/1000], Loss: 0.0075\n",
      "Epoch [65/1000], Loss: 0.0069\n",
      "Epoch [66/1000], Loss: 0.0063\n",
      "Epoch [67/1000], Loss: 0.0058\n",
      "Epoch [68/1000], Loss: 0.0054\n",
      "Epoch [69/1000], Loss: 0.0050\n",
      "Epoch [70/1000], Loss: 0.0046\n",
      "Epoch [71/1000], Loss: 0.0043\n",
      "Epoch [72/1000], Loss: 0.0040\n",
      "Epoch [73/1000], Loss: 0.0038\n",
      "Epoch [74/1000], Loss: 0.0035\n",
      "Epoch [75/1000], Loss: 0.0034\n",
      "Epoch [76/1000], Loss: 0.0031\n",
      "Epoch [77/1000], Loss: 0.0030\n",
      "Epoch [78/1000], Loss: 0.0028\n",
      "Epoch [79/1000], Loss: 0.0027\n",
      "Epoch [80/1000], Loss: 0.0026\n",
      "Epoch [81/1000], Loss: 0.0024\n",
      "Epoch [82/1000], Loss: 0.0023\n",
      "Epoch [83/1000], Loss: 0.0022\n",
      "Epoch [84/1000], Loss: 0.0021\n",
      "Epoch [85/1000], Loss: 0.0021\n",
      "Epoch [86/1000], Loss: 0.0019\n",
      "Epoch [87/1000], Loss: 0.0019\n",
      "Epoch [88/1000], Loss: 0.0018\n",
      "Epoch [89/1000], Loss: 0.0017\n",
      "Epoch [90/1000], Loss: 0.0017\n",
      "Epoch [91/1000], Loss: 0.0016\n",
      "Epoch [92/1000], Loss: 0.0016\n",
      "Epoch [93/1000], Loss: 0.0015\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 3, activation : lrelu, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2557\n",
      "Epoch [2/1000], Loss: 0.2476\n",
      "Epoch [3/1000], Loss: 0.2449\n",
      "Epoch [4/1000], Loss: 0.2435\n",
      "Epoch [5/1000], Loss: 0.2424\n",
      "Epoch [6/1000], Loss: 0.2414\n",
      "Epoch [7/1000], Loss: 0.2403\n",
      "Epoch [8/1000], Loss: 0.2394\n",
      "Epoch [9/1000], Loss: 0.2384\n",
      "Epoch [10/1000], Loss: 0.2375\n",
      "Epoch [11/1000], Loss: 0.2366\n",
      "Epoch [12/1000], Loss: 0.2357\n",
      "Epoch [13/1000], Loss: 0.2349\n",
      "Epoch [14/1000], Loss: 0.2341\n",
      "Epoch [15/1000], Loss: 0.2335\n",
      "Epoch [16/1000], Loss: 0.2329\n",
      "Epoch [17/1000], Loss: 0.2325\n",
      "Epoch [18/1000], Loss: 0.2320\n",
      "Epoch [19/1000], Loss: 0.2316\n",
      "Epoch [20/1000], Loss: 0.2312\n",
      "Epoch [21/1000], Loss: 0.2308\n",
      "Epoch [22/1000], Loss: 0.2305\n",
      "Epoch [23/1000], Loss: 0.2301\n",
      "Epoch [24/1000], Loss: 0.2297\n",
      "Epoch [25/1000], Loss: 0.2296\n",
      "Epoch [26/1000], Loss: 0.2292\n",
      "Epoch [27/1000], Loss: 0.2289\n",
      "Epoch [28/1000], Loss: 0.2286\n",
      "Epoch [29/1000], Loss: 0.2284\n",
      "Epoch [30/1000], Loss: 0.2280\n",
      "Epoch [31/1000], Loss: 0.2277\n",
      "Epoch [32/1000], Loss: 0.2275\n",
      "Epoch [33/1000], Loss: 0.2272\n",
      "Epoch [34/1000], Loss: 0.2267\n",
      "Epoch [35/1000], Loss: 0.2264\n",
      "Epoch [36/1000], Loss: 0.2260\n",
      "Epoch [37/1000], Loss: 0.2257\n",
      "Epoch [38/1000], Loss: 0.2252\n",
      "Epoch [39/1000], Loss: 0.2248\n",
      "Epoch [40/1000], Loss: 0.2243\n",
      "Epoch [41/1000], Loss: 0.2238\n",
      "Epoch [42/1000], Loss: 0.2233\n",
      "Epoch [43/1000], Loss: 0.2227\n",
      "Epoch [44/1000], Loss: 0.2220\n",
      "Epoch [45/1000], Loss: 0.2212\n",
      "Epoch [46/1000], Loss: 0.2205\n",
      "Epoch [47/1000], Loss: 0.2197\n",
      "Epoch [48/1000], Loss: 0.2186\n",
      "Epoch [49/1000], Loss: 0.2172\n",
      "Epoch [50/1000], Loss: 0.2158\n",
      "Epoch [51/1000], Loss: 0.2143\n",
      "Epoch [52/1000], Loss: 0.2128\n",
      "Epoch [53/1000], Loss: 0.2112\n",
      "Epoch [54/1000], Loss: 0.2095\n",
      "Epoch [55/1000], Loss: 0.2078\n",
      "Epoch [56/1000], Loss: 0.2058\n",
      "Epoch [57/1000], Loss: 0.2040\n",
      "Epoch [58/1000], Loss: 0.2019\n",
      "Epoch [59/1000], Loss: 0.1997\n",
      "Epoch [60/1000], Loss: 0.1975\n",
      "Epoch [61/1000], Loss: 0.1952\n",
      "Epoch [62/1000], Loss: 0.1924\n",
      "Epoch [63/1000], Loss: 0.1894\n",
      "Epoch [64/1000], Loss: 0.1864\n",
      "Epoch [65/1000], Loss: 0.1834\n",
      "Epoch [66/1000], Loss: 0.1798\n",
      "Epoch [67/1000], Loss: 0.1770\n",
      "Epoch [68/1000], Loss: 0.1731\n",
      "Epoch [69/1000], Loss: 0.1681\n",
      "Epoch [70/1000], Loss: 0.1630\n",
      "Epoch [71/1000], Loss: 0.1578\n",
      "Epoch [72/1000], Loss: 0.1534\n",
      "Epoch [73/1000], Loss: 0.1488\n",
      "Epoch [74/1000], Loss: 0.1432\n",
      "Epoch [75/1000], Loss: 0.1379\n",
      "Epoch [76/1000], Loss: 0.1306\n",
      "Epoch [77/1000], Loss: 0.1191\n",
      "Epoch [78/1000], Loss: 0.1110\n",
      "Epoch [79/1000], Loss: 0.1043\n",
      "Epoch [80/1000], Loss: 0.0986\n",
      "Epoch [81/1000], Loss: 0.0937\n",
      "Epoch [82/1000], Loss: 0.0889\n",
      "Epoch [83/1000], Loss: 0.0850\n",
      "Epoch [84/1000], Loss: 0.0815\n",
      "Epoch [85/1000], Loss: 0.0781\n",
      "Epoch [86/1000], Loss: 0.0751\n",
      "Epoch [87/1000], Loss: 0.0723\n",
      "Epoch [88/1000], Loss: 0.0704\n",
      "Epoch [89/1000], Loss: 0.0683\n",
      "Epoch [90/1000], Loss: 0.0657\n",
      "Epoch [91/1000], Loss: 0.0645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/1000], Loss: 0.0631\n",
      "Epoch [93/1000], Loss: 0.0619\n",
      "Epoch [94/1000], Loss: 0.0607\n",
      "Epoch [95/1000], Loss: 0.0591\n",
      "Epoch [96/1000], Loss: 0.0582\n",
      "Epoch [97/1000], Loss: 0.0566\n",
      "Epoch [98/1000], Loss: 0.0558\n",
      "Epoch [99/1000], Loss: 0.0550\n",
      "Epoch [100/1000], Loss: 0.0534\n",
      "Epoch [101/1000], Loss: 0.0536\n",
      "Epoch [102/1000], Loss: 0.0523\n",
      "Epoch [103/1000], Loss: 0.0515\n",
      "Epoch [104/1000], Loss: 0.0504\n",
      "Epoch [105/1000], Loss: 0.0490\n",
      "Epoch [106/1000], Loss: 0.0482\n",
      "Epoch [107/1000], Loss: 0.0477\n",
      "Epoch [108/1000], Loss: 0.0464\n",
      "Epoch [109/1000], Loss: 0.0458\n",
      "Epoch [110/1000], Loss: 0.0453\n",
      "Epoch [111/1000], Loss: 0.0448\n",
      "Epoch [112/1000], Loss: 0.0439\n",
      "Epoch [113/1000], Loss: 0.0434\n",
      "Epoch [114/1000], Loss: 0.0433\n",
      "Epoch [115/1000], Loss: 0.0426\n",
      "Epoch [116/1000], Loss: 0.0415\n",
      "Epoch [117/1000], Loss: 0.0410\n",
      "Epoch [118/1000], Loss: 0.0418\n",
      "Epoch [119/1000], Loss: 0.0408\n",
      "Epoch [120/1000], Loss: 0.0403\n",
      "Epoch [121/1000], Loss: 0.0395\n",
      "Epoch [122/1000], Loss: 0.0393\n",
      "Epoch [123/1000], Loss: 0.0381\n",
      "Epoch [124/1000], Loss: 0.0390\n",
      "Epoch [125/1000], Loss: 0.0375\n",
      "Epoch [126/1000], Loss: 0.0375\n",
      "Epoch [127/1000], Loss: 0.0370\n",
      "Epoch [128/1000], Loss: 0.0369\n",
      "Epoch [129/1000], Loss: 0.0369\n",
      "Epoch [130/1000], Loss: 0.0364\n",
      "Epoch [131/1000], Loss: 0.0362\n",
      "Epoch [132/1000], Loss: 0.0356\n",
      "Epoch [133/1000], Loss: 0.0351\n",
      "Epoch [134/1000], Loss: 0.0350\n",
      "Epoch [135/1000], Loss: 0.0341\n",
      "Epoch [136/1000], Loss: 0.0343\n",
      "Epoch [137/1000], Loss: 0.0341\n",
      "Epoch [138/1000], Loss: 0.0328\n",
      "Epoch [139/1000], Loss: 0.0329\n",
      "Epoch [140/1000], Loss: 0.0328\n",
      "Epoch [141/1000], Loss: 0.0328\n",
      "Epoch [142/1000], Loss: 0.0323\n",
      "Epoch [143/1000], Loss: 0.0316\n",
      "Epoch [144/1000], Loss: 0.0316\n",
      "Epoch [145/1000], Loss: 0.0313\n",
      "Epoch [146/1000], Loss: 0.0310\n",
      "Epoch [147/1000], Loss: 0.0306\n",
      "Epoch [148/1000], Loss: 0.0305\n",
      "Epoch [149/1000], Loss: 0.0308\n",
      "Epoch [150/1000], Loss: 0.0303\n",
      "Epoch [151/1000], Loss: 0.0296\n",
      "Epoch [152/1000], Loss: 0.0296\n",
      "Epoch [153/1000], Loss: 0.0288\n",
      "Epoch [154/1000], Loss: 0.0290\n",
      "Epoch [155/1000], Loss: 0.0284\n",
      "Epoch [156/1000], Loss: 0.0274\n",
      "Epoch [157/1000], Loss: 0.0274\n",
      "Epoch [158/1000], Loss: 0.0270\n",
      "Epoch [159/1000], Loss: 0.0267\n",
      "Epoch [160/1000], Loss: 0.0263\n",
      "Epoch [161/1000], Loss: 0.0253\n",
      "Epoch [162/1000], Loss: 0.0255\n",
      "Epoch [163/1000], Loss: 0.0251\n",
      "Epoch [164/1000], Loss: 0.0249\n",
      "Epoch [165/1000], Loss: 0.0248\n",
      "Epoch [166/1000], Loss: 0.0243\n",
      "Epoch [167/1000], Loss: 0.0241\n",
      "Epoch [168/1000], Loss: 0.0234\n",
      "Epoch [169/1000], Loss: 0.0238\n",
      "Epoch [170/1000], Loss: 0.0226\n",
      "Epoch [171/1000], Loss: 0.0226\n",
      "Epoch [172/1000], Loss: 0.0225\n",
      "Epoch [173/1000], Loss: 0.0217\n",
      "Epoch [174/1000], Loss: 0.0218\n",
      "Epoch [175/1000], Loss: 0.0215\n",
      "Epoch [176/1000], Loss: 0.0210\n",
      "Epoch [177/1000], Loss: 0.0206\n",
      "Epoch [178/1000], Loss: 0.0204\n",
      "Epoch [179/1000], Loss: 0.0202\n",
      "Epoch [180/1000], Loss: 0.0200\n",
      "Epoch [181/1000], Loss: 0.0193\n",
      "Epoch [182/1000], Loss: 0.0191\n",
      "Epoch [183/1000], Loss: 0.0188\n",
      "Epoch [184/1000], Loss: 0.0188\n",
      "Epoch [185/1000], Loss: 0.0183\n",
      "Epoch [186/1000], Loss: 0.0179\n",
      "Epoch [187/1000], Loss: 0.0179\n",
      "Epoch [188/1000], Loss: 0.0177\n",
      "Epoch [189/1000], Loss: 0.0171\n",
      "Epoch [190/1000], Loss: 0.0170\n",
      "Epoch [191/1000], Loss: 0.0167\n",
      "Epoch [192/1000], Loss: 0.0163\n",
      "Epoch [193/1000], Loss: 0.0162\n",
      "Epoch [194/1000], Loss: 0.0155\n",
      "Epoch [195/1000], Loss: 0.0154\n",
      "Epoch [196/1000], Loss: 0.0153\n",
      "Epoch [197/1000], Loss: 0.0150\n",
      "Epoch [198/1000], Loss: 0.0148\n",
      "Epoch [199/1000], Loss: 0.0147\n",
      "Epoch [200/1000], Loss: 0.0140\n",
      "Epoch [201/1000], Loss: 0.0141\n",
      "Epoch [202/1000], Loss: 0.0136\n",
      "Epoch [203/1000], Loss: 0.0136\n",
      "Epoch [204/1000], Loss: 0.0136\n",
      "Epoch [205/1000], Loss: 0.0129\n",
      "Epoch [206/1000], Loss: 0.0131\n",
      "Epoch [207/1000], Loss: 0.0127\n",
      "Epoch [208/1000], Loss: 0.0126\n",
      "Epoch [209/1000], Loss: 0.0123\n",
      "Epoch [210/1000], Loss: 0.0122\n",
      "Epoch [211/1000], Loss: 0.0118\n",
      "Epoch [212/1000], Loss: 0.0116\n",
      "Epoch [213/1000], Loss: 0.0117\n",
      "Epoch [214/1000], Loss: 0.0112\n",
      "Epoch [215/1000], Loss: 0.0111\n",
      "Epoch [216/1000], Loss: 0.0109\n",
      "Epoch [217/1000], Loss: 0.0108\n",
      "Epoch [218/1000], Loss: 0.0107\n",
      "Epoch [219/1000], Loss: 0.0104\n",
      "Epoch [220/1000], Loss: 0.0103\n",
      "Epoch [221/1000], Loss: 0.0102\n",
      "Epoch [222/1000], Loss: 0.0099\n",
      "Epoch [223/1000], Loss: 0.0096\n",
      "Epoch [224/1000], Loss: 0.0099\n",
      "Epoch [225/1000], Loss: 0.0094\n",
      "Epoch [226/1000], Loss: 0.0095\n",
      "Epoch [227/1000], Loss: 0.0093\n",
      "Epoch [228/1000], Loss: 0.0091\n",
      "Epoch [229/1000], Loss: 0.0090\n",
      "Epoch [230/1000], Loss: 0.0088\n",
      "Epoch [231/1000], Loss: 0.0088\n",
      "Epoch [232/1000], Loss: 0.0089\n",
      "Epoch [233/1000], Loss: 0.0085\n",
      "Epoch [234/1000], Loss: 0.0084\n",
      "Epoch [235/1000], Loss: 0.0083\n",
      "Epoch [236/1000], Loss: 0.0080\n",
      "Epoch [237/1000], Loss: 0.0080\n",
      "Epoch [238/1000], Loss: 0.0079\n",
      "Epoch [239/1000], Loss: 0.0078\n",
      "Epoch [240/1000], Loss: 0.0075\n",
      "Epoch [241/1000], Loss: 0.0077\n",
      "Epoch [242/1000], Loss: 0.0074\n",
      "Epoch [243/1000], Loss: 0.0072\n",
      "Epoch [244/1000], Loss: 0.0073\n",
      "Epoch [245/1000], Loss: 0.0070\n",
      "Epoch [246/1000], Loss: 0.0070\n",
      "Epoch [247/1000], Loss: 0.0068\n",
      "Epoch [248/1000], Loss: 0.0069\n",
      "Epoch [249/1000], Loss: 0.0068\n",
      "Epoch [250/1000], Loss: 0.0066\n",
      "Epoch [251/1000], Loss: 0.0065\n",
      "Epoch [252/1000], Loss: 0.0064\n",
      "Epoch [253/1000], Loss: 0.0064\n",
      "Epoch [254/1000], Loss: 0.0062\n",
      "Epoch [255/1000], Loss: 0.0060\n",
      "Epoch [256/1000], Loss: 0.0061\n",
      "Epoch [257/1000], Loss: 0.0060\n",
      "Epoch [258/1000], Loss: 0.0058\n",
      "Epoch [259/1000], Loss: 0.0058\n",
      "Epoch [260/1000], Loss: 0.0058\n",
      "Epoch [261/1000], Loss: 0.0057\n",
      "Epoch [262/1000], Loss: 0.0054\n",
      "Epoch [263/1000], Loss: 0.0055\n",
      "Epoch [264/1000], Loss: 0.0054\n",
      "Epoch [265/1000], Loss: 0.0054\n",
      "Epoch [266/1000], Loss: 0.0053\n",
      "Epoch [267/1000], Loss: 0.0051\n",
      "Epoch [268/1000], Loss: 0.0052\n",
      "Epoch [269/1000], Loss: 0.0051\n",
      "Epoch [270/1000], Loss: 0.0050\n",
      "Epoch [271/1000], Loss: 0.0050\n",
      "Epoch [272/1000], Loss: 0.0049\n",
      "Epoch [273/1000], Loss: 0.0049\n",
      "Epoch [274/1000], Loss: 0.0048\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 3, activation : lrelu, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2485\n",
      "Epoch [2/1000], Loss: 0.2437\n",
      "Epoch [3/1000], Loss: 0.2412\n",
      "Epoch [4/1000], Loss: 0.2396\n",
      "Epoch [5/1000], Loss: 0.2386\n",
      "Epoch [6/1000], Loss: 0.2377\n",
      "Epoch [7/1000], Loss: 0.2370\n",
      "Epoch [8/1000], Loss: 0.2364\n",
      "Epoch [9/1000], Loss: 0.2359\n",
      "Epoch [10/1000], Loss: 0.2355\n",
      "Epoch [11/1000], Loss: 0.2351\n",
      "Epoch [12/1000], Loss: 0.2347\n",
      "Epoch [13/1000], Loss: 0.2343\n",
      "Epoch [14/1000], Loss: 0.2339\n",
      "Epoch [15/1000], Loss: 0.2335\n",
      "Epoch [16/1000], Loss: 0.2330\n",
      "Epoch [17/1000], Loss: 0.2326\n",
      "Epoch [18/1000], Loss: 0.2321\n",
      "Epoch [19/1000], Loss: 0.2316\n",
      "Epoch [20/1000], Loss: 0.2311\n",
      "Epoch [21/1000], Loss: 0.2306\n",
      "Epoch [22/1000], Loss: 0.2300\n",
      "Epoch [23/1000], Loss: 0.2295\n",
      "Epoch [24/1000], Loss: 0.2289\n",
      "Epoch [25/1000], Loss: 0.2283\n",
      "Epoch [26/1000], Loss: 0.2277\n",
      "Epoch [27/1000], Loss: 0.2271\n",
      "Epoch [28/1000], Loss: 0.2264\n",
      "Epoch [29/1000], Loss: 0.2256\n",
      "Epoch [30/1000], Loss: 0.2248\n",
      "Epoch [31/1000], Loss: 0.2238\n",
      "Epoch [32/1000], Loss: 0.2231\n",
      "Epoch [33/1000], Loss: 0.2219\n",
      "Epoch [34/1000], Loss: 0.2207\n",
      "Epoch [35/1000], Loss: 0.2193\n",
      "Epoch [36/1000], Loss: 0.2182\n",
      "Epoch [37/1000], Loss: 0.2164\n",
      "Epoch [38/1000], Loss: 0.2145\n",
      "Epoch [39/1000], Loss: 0.2124\n",
      "Epoch [40/1000], Loss: 0.2095\n",
      "Epoch [41/1000], Loss: 0.2079\n",
      "Epoch [42/1000], Loss: 0.2050\n",
      "Epoch [43/1000], Loss: 0.2021\n",
      "Epoch [44/1000], Loss: 0.1986\n",
      "Epoch [45/1000], Loss: 0.1949\n",
      "Epoch [46/1000], Loss: 0.1910\n",
      "Epoch [47/1000], Loss: 0.1869\n",
      "Epoch [48/1000], Loss: 0.1823\n",
      "Epoch [49/1000], Loss: 0.1778\n",
      "Epoch [50/1000], Loss: 0.1725\n",
      "Epoch [51/1000], Loss: 0.1675\n",
      "Epoch [52/1000], Loss: 0.1625\n",
      "Epoch [53/1000], Loss: 0.1568\n",
      "Epoch [54/1000], Loss: 0.1525\n",
      "Epoch [55/1000], Loss: 0.1470\n",
      "Epoch [56/1000], Loss: 0.1414\n",
      "Epoch [57/1000], Loss: 0.1380\n",
      "Epoch [58/1000], Loss: 0.1329\n",
      "Epoch [59/1000], Loss: 0.1284\n",
      "Epoch [60/1000], Loss: 0.1243\n",
      "Epoch [61/1000], Loss: 0.1202\n",
      "Epoch [62/1000], Loss: 0.1150\n",
      "Epoch [63/1000], Loss: 0.1128\n",
      "Epoch [64/1000], Loss: 0.1084\n",
      "Epoch [65/1000], Loss: 0.1043\n",
      "Epoch [66/1000], Loss: 0.1009\n",
      "Epoch [67/1000], Loss: 0.0984\n",
      "Epoch [68/1000], Loss: 0.0954\n",
      "Epoch [69/1000], Loss: 0.0918\n",
      "Epoch [70/1000], Loss: 0.0866\n",
      "Epoch [71/1000], Loss: 0.0846\n",
      "Epoch [72/1000], Loss: 0.0774\n",
      "Epoch [73/1000], Loss: 0.0702\n",
      "Epoch [74/1000], Loss: 0.0662\n",
      "Epoch [75/1000], Loss: 0.0622\n",
      "Epoch [76/1000], Loss: 0.0595\n",
      "Epoch [77/1000], Loss: 0.0543\n",
      "Epoch [78/1000], Loss: 0.0509\n",
      "Epoch [79/1000], Loss: 0.0485\n",
      "Epoch [80/1000], Loss: 0.0447\n",
      "Epoch [81/1000], Loss: 0.0417\n",
      "Epoch [82/1000], Loss: 0.0376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/1000], Loss: 0.0362\n",
      "Epoch [84/1000], Loss: 0.0338\n",
      "Epoch [85/1000], Loss: 0.0331\n",
      "Epoch [86/1000], Loss: 0.0277\n",
      "Epoch [87/1000], Loss: 0.0226\n",
      "Epoch [88/1000], Loss: 0.0213\n",
      "Epoch [89/1000], Loss: 0.0188\n",
      "Epoch [90/1000], Loss: 0.0174\n",
      "Epoch [91/1000], Loss: 0.0154\n",
      "Epoch [92/1000], Loss: 0.0145\n",
      "Epoch [93/1000], Loss: 0.0133\n",
      "Epoch [94/1000], Loss: 0.0125\n",
      "Epoch [95/1000], Loss: 0.0110\n",
      "Epoch [96/1000], Loss: 0.0104\n",
      "Epoch [97/1000], Loss: 0.0100\n",
      "Epoch [98/1000], Loss: 0.0089\n",
      "Epoch [99/1000], Loss: 0.0090\n",
      "Epoch [100/1000], Loss: 0.0083\n",
      "Epoch [101/1000], Loss: 0.0076\n",
      "Epoch [102/1000], Loss: 0.0076\n",
      "Epoch [103/1000], Loss: 0.0070\n",
      "Epoch [104/1000], Loss: 0.0068\n",
      "Epoch [105/1000], Loss: 0.0061\n",
      "Epoch [106/1000], Loss: 0.0060\n",
      "Epoch [107/1000], Loss: 0.0058\n",
      "Epoch [108/1000], Loss: 0.0057\n",
      "Epoch [109/1000], Loss: 0.0053\n",
      "Epoch [110/1000], Loss: 0.0050\n",
      "Epoch [111/1000], Loss: 0.0045\n",
      "Epoch [112/1000], Loss: 0.0044\n",
      "Epoch [113/1000], Loss: 0.0045\n",
      "Epoch [114/1000], Loss: 0.0042\n",
      "Epoch [115/1000], Loss: 0.0042\n",
      "Epoch [116/1000], Loss: 0.0037\n",
      "Epoch [117/1000], Loss: 0.0039\n",
      "Epoch [118/1000], Loss: 0.0035\n",
      "Epoch [119/1000], Loss: 0.0034\n",
      "Epoch [120/1000], Loss: 0.0038\n",
      "Epoch [121/1000], Loss: 0.0032\n",
      "Epoch [122/1000], Loss: 0.0036\n",
      "Epoch [123/1000], Loss: 0.0030\n",
      "Epoch [124/1000], Loss: 0.0028\n",
      "Epoch [125/1000], Loss: 0.0027\n",
      "Epoch [126/1000], Loss: 0.0027\n",
      "Epoch [127/1000], Loss: 0.0026\n",
      "Epoch [128/1000], Loss: 0.0025\n",
      "Epoch [129/1000], Loss: 0.0025\n",
      "Epoch [130/1000], Loss: 0.0024\n",
      "Epoch [131/1000], Loss: 0.0023\n",
      "Epoch [132/1000], Loss: 0.0023\n",
      "Epoch [133/1000], Loss: 0.0022\n",
      "Epoch [134/1000], Loss: 0.0022\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 3, activation : lrelu, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2501\n",
      "Epoch [2/1000], Loss: 0.2438\n",
      "Epoch [3/1000], Loss: 0.2404\n",
      "Epoch [4/1000], Loss: 0.2383\n",
      "Epoch [5/1000], Loss: 0.2370\n",
      "Epoch [6/1000], Loss: 0.2362\n",
      "Epoch [7/1000], Loss: 0.2356\n",
      "Epoch [8/1000], Loss: 0.2352\n",
      "Epoch [9/1000], Loss: 0.2347\n",
      "Epoch [10/1000], Loss: 0.2344\n",
      "Epoch [11/1000], Loss: 0.2339\n",
      "Epoch [12/1000], Loss: 0.2337\n",
      "Epoch [13/1000], Loss: 0.2334\n",
      "Epoch [14/1000], Loss: 0.2331\n",
      "Epoch [15/1000], Loss: 0.2328\n",
      "Epoch [16/1000], Loss: 0.2325\n",
      "Epoch [17/1000], Loss: 0.2322\n",
      "Epoch [18/1000], Loss: 0.2319\n",
      "Epoch [19/1000], Loss: 0.2315\n",
      "Epoch [20/1000], Loss: 0.2311\n",
      "Epoch [21/1000], Loss: 0.2307\n",
      "Epoch [22/1000], Loss: 0.2303\n",
      "Epoch [23/1000], Loss: 0.2299\n",
      "Epoch [24/1000], Loss: 0.2293\n",
      "Epoch [25/1000], Loss: 0.2289\n",
      "Epoch [26/1000], Loss: 0.2281\n",
      "Epoch [27/1000], Loss: 0.2275\n",
      "Epoch [28/1000], Loss: 0.2269\n",
      "Epoch [29/1000], Loss: 0.2258\n",
      "Epoch [30/1000], Loss: 0.2248\n",
      "Epoch [31/1000], Loss: 0.2236\n",
      "Epoch [32/1000], Loss: 0.2224\n",
      "Epoch [33/1000], Loss: 0.2210\n",
      "Epoch [34/1000], Loss: 0.2192\n",
      "Epoch [35/1000], Loss: 0.2174\n",
      "Epoch [36/1000], Loss: 0.2151\n",
      "Epoch [37/1000], Loss: 0.2125\n",
      "Epoch [38/1000], Loss: 0.2093\n",
      "Epoch [39/1000], Loss: 0.2053\n",
      "Epoch [40/1000], Loss: 0.2004\n",
      "Epoch [41/1000], Loss: 0.1950\n",
      "Epoch [42/1000], Loss: 0.1888\n",
      "Epoch [43/1000], Loss: 0.1818\n",
      "Epoch [44/1000], Loss: 0.1738\n",
      "Epoch [45/1000], Loss: 0.1654\n",
      "Epoch [46/1000], Loss: 0.1564\n",
      "Epoch [47/1000], Loss: 0.1473\n",
      "Epoch [48/1000], Loss: 0.1370\n",
      "Epoch [49/1000], Loss: 0.1263\n",
      "Epoch [50/1000], Loss: 0.1160\n",
      "Epoch [51/1000], Loss: 0.1057\n",
      "Epoch [52/1000], Loss: 0.0950\n",
      "Epoch [53/1000], Loss: 0.0850\n",
      "Epoch [54/1000], Loss: 0.0752\n",
      "Epoch [55/1000], Loss: 0.0660\n",
      "Epoch [56/1000], Loss: 0.0575\n",
      "Epoch [57/1000], Loss: 0.0498\n",
      "Epoch [58/1000], Loss: 0.0426\n",
      "Epoch [59/1000], Loss: 0.0371\n",
      "Epoch [60/1000], Loss: 0.0319\n",
      "Epoch [61/1000], Loss: 0.0278\n",
      "Epoch [62/1000], Loss: 0.0242\n",
      "Epoch [63/1000], Loss: 0.0210\n",
      "Epoch [64/1000], Loss: 0.0186\n",
      "Epoch [65/1000], Loss: 0.0165\n",
      "Epoch [66/1000], Loss: 0.0144\n",
      "Epoch [67/1000], Loss: 0.0130\n",
      "Epoch [68/1000], Loss: 0.0114\n",
      "Epoch [69/1000], Loss: 0.0105\n",
      "Epoch [70/1000], Loss: 0.0091\n",
      "Epoch [71/1000], Loss: 0.0083\n",
      "Epoch [72/1000], Loss: 0.0074\n",
      "Epoch [73/1000], Loss: 0.0068\n",
      "Epoch [74/1000], Loss: 0.0061\n",
      "Epoch [75/1000], Loss: 0.0057\n",
      "Epoch [76/1000], Loss: 0.0053\n",
      "Epoch [77/1000], Loss: 0.0049\n",
      "Epoch [78/1000], Loss: 0.0045\n",
      "Epoch [79/1000], Loss: 0.0041\n",
      "Epoch [80/1000], Loss: 0.0039\n",
      "Epoch [81/1000], Loss: 0.0037\n",
      "Epoch [82/1000], Loss: 0.0035\n",
      "Epoch [83/1000], Loss: 0.0033\n",
      "Epoch [84/1000], Loss: 0.0031\n",
      "Epoch [85/1000], Loss: 0.0029\n",
      "Epoch [86/1000], Loss: 0.0028\n",
      "Epoch [87/1000], Loss: 0.0027\n",
      "Epoch [88/1000], Loss: 0.0025\n",
      "Epoch [89/1000], Loss: 0.0024\n",
      "Epoch [90/1000], Loss: 0.0023\n",
      "Epoch [91/1000], Loss: 0.0023\n",
      "Epoch [92/1000], Loss: 0.0021\n",
      "Epoch [93/1000], Loss: 0.0021\n",
      "Epoch [94/1000], Loss: 0.0020\n",
      "Epoch [95/1000], Loss: 0.0019\n",
      "Epoch [96/1000], Loss: 0.0018\n",
      "Epoch [97/1000], Loss: 0.0018\n",
      "Epoch [98/1000], Loss: 0.0017\n",
      "Epoch [99/1000], Loss: 0.0017\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 3, activation : sigmoid, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2527\n",
      "Epoch [2/1000], Loss: 0.2504\n",
      "Epoch [3/1000], Loss: 0.2501\n",
      "Epoch [4/1000], Loss: 0.2501\n",
      "Epoch [5/1000], Loss: 0.2500\n",
      "Epoch [6/1000], Loss: 0.2501\n",
      "Epoch [7/1000], Loss: 0.2500\n",
      "Epoch [8/1000], Loss: 0.2500\n",
      "Epoch [9/1000], Loss: 0.2500\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 3, activation : sigmoid, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2536\n",
      "Epoch [2/1000], Loss: 0.2502\n",
      "Epoch [3/1000], Loss: 0.2501\n",
      "Epoch [4/1000], Loss: 0.2501\n",
      "Epoch [5/1000], Loss: 0.2502\n",
      "Epoch [6/1000], Loss: 0.2501\n",
      "Epoch [7/1000], Loss: 0.2501\n",
      "Epoch [8/1000], Loss: 0.2501\n",
      "Epoch [9/1000], Loss: 0.2501\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 3, activation : sigmoid, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2502\n",
      "Epoch [2/1000], Loss: 0.2501\n",
      "Epoch [3/1000], Loss: 0.2501\n",
      "Epoch [4/1000], Loss: 0.2501\n",
      "Epoch [5/1000], Loss: 0.2501\n",
      "Epoch [6/1000], Loss: 0.2499\n",
      "Epoch [7/1000], Loss: 0.2500\n",
      "Epoch [8/1000], Loss: 0.2501\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 3, activation : tanh, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2492\n",
      "Epoch [2/1000], Loss: 0.2450\n",
      "Epoch [3/1000], Loss: 0.2427\n",
      "Epoch [4/1000], Loss: 0.2413\n",
      "Epoch [5/1000], Loss: 0.2403\n",
      "Epoch [6/1000], Loss: 0.2398\n",
      "Epoch [7/1000], Loss: 0.2394\n",
      "Epoch [8/1000], Loss: 0.2392\n",
      "Epoch [9/1000], Loss: 0.2390\n",
      "Epoch [10/1000], Loss: 0.2388\n",
      "Epoch [11/1000], Loss: 0.2387\n",
      "Epoch [12/1000], Loss: 0.2385\n",
      "Epoch [13/1000], Loss: 0.2384\n",
      "Epoch [14/1000], Loss: 0.2383\n",
      "Epoch [15/1000], Loss: 0.2382\n",
      "Epoch [16/1000], Loss: 0.2381\n",
      "Epoch [17/1000], Loss: 0.2380\n",
      "Epoch [18/1000], Loss: 0.2378\n",
      "Epoch [19/1000], Loss: 0.2377\n",
      "Epoch [20/1000], Loss: 0.2375\n",
      "Epoch [21/1000], Loss: 0.2374\n",
      "Epoch [22/1000], Loss: 0.2373\n",
      "Epoch [23/1000], Loss: 0.2372\n",
      "Epoch [24/1000], Loss: 0.2370\n",
      "Epoch [25/1000], Loss: 0.2369\n",
      "Epoch [26/1000], Loss: 0.2367\n",
      "Epoch [27/1000], Loss: 0.2365\n",
      "Epoch [28/1000], Loss: 0.2363\n",
      "Epoch [29/1000], Loss: 0.2361\n",
      "Epoch [30/1000], Loss: 0.2359\n",
      "Epoch [31/1000], Loss: 0.2356\n",
      "Epoch [32/1000], Loss: 0.2353\n",
      "Epoch [33/1000], Loss: 0.2350\n",
      "Epoch [34/1000], Loss: 0.2346\n",
      "Epoch [35/1000], Loss: 0.2343\n",
      "Epoch [36/1000], Loss: 0.2338\n",
      "Epoch [37/1000], Loss: 0.2333\n",
      "Epoch [38/1000], Loss: 0.2329\n",
      "Epoch [39/1000], Loss: 0.2323\n",
      "Epoch [40/1000], Loss: 0.2316\n",
      "Epoch [41/1000], Loss: 0.2309\n",
      "Epoch [42/1000], Loss: 0.2302\n",
      "Epoch [43/1000], Loss: 0.2294\n",
      "Epoch [44/1000], Loss: 0.2286\n",
      "Epoch [45/1000], Loss: 0.2276\n",
      "Epoch [46/1000], Loss: 0.2265\n",
      "Epoch [47/1000], Loss: 0.2255\n",
      "Epoch [48/1000], Loss: 0.2243\n",
      "Epoch [49/1000], Loss: 0.2232\n",
      "Epoch [50/1000], Loss: 0.2220\n",
      "Epoch [51/1000], Loss: 0.2207\n",
      "Epoch [52/1000], Loss: 0.2196\n",
      "Epoch [53/1000], Loss: 0.2181\n",
      "Epoch [54/1000], Loss: 0.2168\n",
      "Epoch [55/1000], Loss: 0.2154\n",
      "Epoch [56/1000], Loss: 0.2143\n",
      "Epoch [57/1000], Loss: 0.2123\n",
      "Epoch [58/1000], Loss: 0.2113\n",
      "Epoch [59/1000], Loss: 0.2096\n",
      "Epoch [60/1000], Loss: 0.2084\n",
      "Epoch [61/1000], Loss: 0.2069\n",
      "Epoch [62/1000], Loss: 0.2057\n",
      "Epoch [63/1000], Loss: 0.2046\n",
      "Epoch [64/1000], Loss: 0.2026\n",
      "Epoch [65/1000], Loss: 0.2014\n",
      "Epoch [66/1000], Loss: 0.2001\n",
      "Epoch [67/1000], Loss: 0.1992\n",
      "Epoch [68/1000], Loss: 0.1977\n",
      "Epoch [69/1000], Loss: 0.1964\n",
      "Epoch [70/1000], Loss: 0.1951\n",
      "Epoch [71/1000], Loss: 0.1936\n",
      "Epoch [72/1000], Loss: 0.1922\n",
      "Epoch [73/1000], Loss: 0.1909\n",
      "Epoch [74/1000], Loss: 0.1896\n",
      "Epoch [75/1000], Loss: 0.1879\n",
      "Epoch [76/1000], Loss: 0.1868\n",
      "Epoch [77/1000], Loss: 0.1856\n",
      "Epoch [78/1000], Loss: 0.1838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/1000], Loss: 0.1822\n",
      "Epoch [80/1000], Loss: 0.1816\n",
      "Epoch [81/1000], Loss: 0.1805\n",
      "Epoch [82/1000], Loss: 0.1784\n",
      "Epoch [83/1000], Loss: 0.1779\n",
      "Epoch [84/1000], Loss: 0.1769\n",
      "Epoch [85/1000], Loss: 0.1758\n",
      "Epoch [86/1000], Loss: 0.1752\n",
      "Epoch [87/1000], Loss: 0.1746\n",
      "Epoch [88/1000], Loss: 0.1737\n",
      "Epoch [89/1000], Loss: 0.1730\n",
      "Epoch [90/1000], Loss: 0.1720\n",
      "Epoch [91/1000], Loss: 0.1710\n",
      "Epoch [92/1000], Loss: 0.1710\n",
      "Epoch [93/1000], Loss: 0.1699\n",
      "Epoch [94/1000], Loss: 0.1692\n",
      "Epoch [95/1000], Loss: 0.1691\n",
      "Epoch [96/1000], Loss: 0.1684\n",
      "Epoch [97/1000], Loss: 0.1673\n",
      "Epoch [98/1000], Loss: 0.1672\n",
      "Epoch [99/1000], Loss: 0.1670\n",
      "Epoch [100/1000], Loss: 0.1663\n",
      "Epoch [101/1000], Loss: 0.1657\n",
      "Epoch [102/1000], Loss: 0.1656\n",
      "Epoch [103/1000], Loss: 0.1648\n",
      "Epoch [104/1000], Loss: 0.1640\n",
      "Epoch [105/1000], Loss: 0.1640\n",
      "Epoch [106/1000], Loss: 0.1639\n",
      "Epoch [107/1000], Loss: 0.1637\n",
      "Epoch [108/1000], Loss: 0.1631\n",
      "Epoch [109/1000], Loss: 0.1631\n",
      "Epoch [110/1000], Loss: 0.1627\n",
      "Epoch [111/1000], Loss: 0.1622\n",
      "Epoch [112/1000], Loss: 0.1616\n",
      "Epoch [113/1000], Loss: 0.1620\n",
      "Epoch [114/1000], Loss: 0.1607\n",
      "Epoch [115/1000], Loss: 0.1606\n",
      "Epoch [116/1000], Loss: 0.1609\n",
      "Epoch [117/1000], Loss: 0.1606\n",
      "Epoch [118/1000], Loss: 0.1604\n",
      "Epoch [119/1000], Loss: 0.1600\n",
      "Epoch [120/1000], Loss: 0.1597\n",
      "Epoch [121/1000], Loss: 0.1600\n",
      "Epoch [122/1000], Loss: 0.1596\n",
      "Epoch [123/1000], Loss: 0.1587\n",
      "Epoch [124/1000], Loss: 0.1586\n",
      "Epoch [125/1000], Loss: 0.1583\n",
      "Epoch [126/1000], Loss: 0.1584\n",
      "Epoch [127/1000], Loss: 0.1584\n",
      "Epoch [128/1000], Loss: 0.1580\n",
      "Epoch [129/1000], Loss: 0.1578\n",
      "Epoch [130/1000], Loss: 0.1573\n",
      "Epoch [131/1000], Loss: 0.1570\n",
      "Epoch [132/1000], Loss: 0.1568\n",
      "Epoch [133/1000], Loss: 0.1564\n",
      "Epoch [134/1000], Loss: 0.1557\n",
      "Epoch [135/1000], Loss: 0.1559\n",
      "Epoch [136/1000], Loss: 0.1551\n",
      "Epoch [137/1000], Loss: 0.1549\n",
      "Epoch [138/1000], Loss: 0.1549\n",
      "Epoch [139/1000], Loss: 0.1545\n",
      "Epoch [140/1000], Loss: 0.1541\n",
      "Epoch [141/1000], Loss: 0.1539\n",
      "Epoch [142/1000], Loss: 0.1535\n",
      "Epoch [143/1000], Loss: 0.1530\n",
      "Epoch [144/1000], Loss: 0.1531\n",
      "Epoch [145/1000], Loss: 0.1525\n",
      "Epoch [146/1000], Loss: 0.1523\n",
      "Epoch [147/1000], Loss: 0.1518\n",
      "Epoch [148/1000], Loss: 0.1514\n",
      "Epoch [149/1000], Loss: 0.1515\n",
      "Epoch [150/1000], Loss: 0.1509\n",
      "Epoch [151/1000], Loss: 0.1510\n",
      "Epoch [152/1000], Loss: 0.1504\n",
      "Epoch [153/1000], Loss: 0.1500\n",
      "Epoch [154/1000], Loss: 0.1499\n",
      "Epoch [155/1000], Loss: 0.1497\n",
      "Epoch [156/1000], Loss: 0.1489\n",
      "Epoch [157/1000], Loss: 0.1488\n",
      "Epoch [158/1000], Loss: 0.1490\n",
      "Epoch [159/1000], Loss: 0.1483\n",
      "Epoch [160/1000], Loss: 0.1482\n",
      "Epoch [161/1000], Loss: 0.1480\n",
      "Epoch [162/1000], Loss: 0.1478\n",
      "Epoch [163/1000], Loss: 0.1473\n",
      "Epoch [164/1000], Loss: 0.1472\n",
      "Epoch [165/1000], Loss: 0.1469\n",
      "Epoch [166/1000], Loss: 0.1463\n",
      "Epoch [167/1000], Loss: 0.1465\n",
      "Epoch [168/1000], Loss: 0.1460\n",
      "Epoch [169/1000], Loss: 0.1457\n",
      "Epoch [170/1000], Loss: 0.1456\n",
      "Epoch [171/1000], Loss: 0.1454\n",
      "Epoch [172/1000], Loss: 0.1450\n",
      "Epoch [173/1000], Loss: 0.1452\n",
      "Epoch [174/1000], Loss: 0.1443\n",
      "Epoch [175/1000], Loss: 0.1445\n",
      "Epoch [176/1000], Loss: 0.1442\n",
      "Epoch [177/1000], Loss: 0.1440\n",
      "Epoch [178/1000], Loss: 0.1438\n",
      "Epoch [179/1000], Loss: 0.1434\n",
      "Epoch [180/1000], Loss: 0.1432\n",
      "Epoch [181/1000], Loss: 0.1431\n",
      "Epoch [182/1000], Loss: 0.1430\n",
      "Epoch [183/1000], Loss: 0.1426\n",
      "Epoch [184/1000], Loss: 0.1422\n",
      "Epoch [185/1000], Loss: 0.1423\n",
      "Epoch [186/1000], Loss: 0.1417\n",
      "Epoch [187/1000], Loss: 0.1415\n",
      "Epoch [188/1000], Loss: 0.1414\n",
      "Epoch [189/1000], Loss: 0.1415\n",
      "Epoch [190/1000], Loss: 0.1412\n",
      "Epoch [191/1000], Loss: 0.1412\n",
      "Epoch [192/1000], Loss: 0.1407\n",
      "Epoch [193/1000], Loss: 0.1404\n",
      "Epoch [194/1000], Loss: 0.1402\n",
      "Epoch [195/1000], Loss: 0.1402\n",
      "Epoch [196/1000], Loss: 0.1397\n",
      "Epoch [197/1000], Loss: 0.1397\n",
      "Epoch [198/1000], Loss: 0.1394\n",
      "Epoch [199/1000], Loss: 0.1390\n",
      "Epoch [200/1000], Loss: 0.1390\n",
      "Epoch [201/1000], Loss: 0.1388\n",
      "Epoch [202/1000], Loss: 0.1381\n",
      "Epoch [203/1000], Loss: 0.1382\n",
      "Epoch [204/1000], Loss: 0.1381\n",
      "Epoch [205/1000], Loss: 0.1376\n",
      "Epoch [206/1000], Loss: 0.1376\n",
      "Epoch [207/1000], Loss: 0.1375\n",
      "Epoch [208/1000], Loss: 0.1372\n",
      "Epoch [209/1000], Loss: 0.1368\n",
      "Epoch [210/1000], Loss: 0.1364\n",
      "Epoch [211/1000], Loss: 0.1366\n",
      "Epoch [212/1000], Loss: 0.1361\n",
      "Epoch [213/1000], Loss: 0.1360\n",
      "Epoch [214/1000], Loss: 0.1358\n",
      "Epoch [215/1000], Loss: 0.1356\n",
      "Epoch [216/1000], Loss: 0.1353\n",
      "Epoch [217/1000], Loss: 0.1352\n",
      "Epoch [218/1000], Loss: 0.1348\n",
      "Epoch [219/1000], Loss: 0.1348\n",
      "Epoch [220/1000], Loss: 0.1344\n",
      "Epoch [221/1000], Loss: 0.1344\n",
      "Epoch [222/1000], Loss: 0.1341\n",
      "Epoch [223/1000], Loss: 0.1340\n",
      "Epoch [224/1000], Loss: 0.1333\n",
      "Epoch [225/1000], Loss: 0.1336\n",
      "Epoch [226/1000], Loss: 0.1331\n",
      "Epoch [227/1000], Loss: 0.1329\n",
      "Epoch [228/1000], Loss: 0.1330\n",
      "Epoch [229/1000], Loss: 0.1328\n",
      "Epoch [230/1000], Loss: 0.1325\n",
      "Epoch [231/1000], Loss: 0.1320\n",
      "Epoch [232/1000], Loss: 0.1318\n",
      "Epoch [233/1000], Loss: 0.1317\n",
      "Epoch [234/1000], Loss: 0.1314\n",
      "Epoch [235/1000], Loss: 0.1313\n",
      "Epoch [236/1000], Loss: 0.1309\n",
      "Epoch [237/1000], Loss: 0.1305\n",
      "Epoch [238/1000], Loss: 0.1306\n",
      "Epoch [239/1000], Loss: 0.1302\n",
      "Epoch [240/1000], Loss: 0.1304\n",
      "Epoch [241/1000], Loss: 0.1301\n",
      "Epoch [242/1000], Loss: 0.1294\n",
      "Epoch [243/1000], Loss: 0.1295\n",
      "Epoch [244/1000], Loss: 0.1286\n",
      "Epoch [245/1000], Loss: 0.1289\n",
      "Epoch [246/1000], Loss: 0.1289\n",
      "Epoch [247/1000], Loss: 0.1285\n",
      "Epoch [248/1000], Loss: 0.1282\n",
      "Epoch [249/1000], Loss: 0.1278\n",
      "Epoch [250/1000], Loss: 0.1273\n",
      "Epoch [251/1000], Loss: 0.1274\n",
      "Epoch [252/1000], Loss: 0.1274\n",
      "Epoch [253/1000], Loss: 0.1270\n",
      "Epoch [254/1000], Loss: 0.1266\n",
      "Epoch [255/1000], Loss: 0.1260\n",
      "Epoch [256/1000], Loss: 0.1254\n",
      "Epoch [257/1000], Loss: 0.1257\n",
      "Epoch [258/1000], Loss: 0.1251\n",
      "Epoch [259/1000], Loss: 0.1249\n",
      "Epoch [260/1000], Loss: 0.1245\n",
      "Epoch [261/1000], Loss: 0.1237\n",
      "Epoch [262/1000], Loss: 0.1231\n",
      "Epoch [263/1000], Loss: 0.1224\n",
      "Epoch [264/1000], Loss: 0.1219\n",
      "Epoch [265/1000], Loss: 0.1204\n",
      "Epoch [266/1000], Loss: 0.1184\n",
      "Epoch [267/1000], Loss: 0.1174\n",
      "Epoch [268/1000], Loss: 0.1152\n",
      "Epoch [269/1000], Loss: 0.1133\n",
      "Epoch [270/1000], Loss: 0.1106\n",
      "Epoch [271/1000], Loss: 0.1097\n",
      "Epoch [272/1000], Loss: 0.1081\n",
      "Epoch [273/1000], Loss: 0.1070\n",
      "Epoch [274/1000], Loss: 0.1063\n",
      "Epoch [275/1000], Loss: 0.1059\n",
      "Epoch [276/1000], Loss: 0.1042\n",
      "Epoch [277/1000], Loss: 0.1044\n",
      "Epoch [278/1000], Loss: 0.1037\n",
      "Epoch [279/1000], Loss: 0.1028\n",
      "Epoch [280/1000], Loss: 0.1025\n",
      "Epoch [281/1000], Loss: 0.1012\n",
      "Epoch [282/1000], Loss: 0.1009\n",
      "Epoch [283/1000], Loss: 0.1010\n",
      "Epoch [284/1000], Loss: 0.1006\n",
      "Epoch [285/1000], Loss: 0.0997\n",
      "Epoch [286/1000], Loss: 0.0987\n",
      "Epoch [287/1000], Loss: 0.0991\n",
      "Epoch [288/1000], Loss: 0.0985\n",
      "Epoch [289/1000], Loss: 0.0979\n",
      "Epoch [290/1000], Loss: 0.0978\n",
      "Epoch [291/1000], Loss: 0.0969\n",
      "Epoch [292/1000], Loss: 0.0964\n",
      "Epoch [293/1000], Loss: 0.0966\n",
      "Epoch [294/1000], Loss: 0.0965\n",
      "Epoch [295/1000], Loss: 0.0957\n",
      "Epoch [296/1000], Loss: 0.0955\n",
      "Epoch [297/1000], Loss: 0.0949\n",
      "Epoch [298/1000], Loss: 0.0943\n",
      "Epoch [299/1000], Loss: 0.0949\n",
      "Epoch [300/1000], Loss: 0.0944\n",
      "Epoch [301/1000], Loss: 0.0939\n",
      "Epoch [302/1000], Loss: 0.0938\n",
      "Epoch [303/1000], Loss: 0.0933\n",
      "Epoch [304/1000], Loss: 0.0929\n",
      "Epoch [305/1000], Loss: 0.0924\n",
      "Epoch [306/1000], Loss: 0.0925\n",
      "Epoch [307/1000], Loss: 0.0923\n",
      "Epoch [308/1000], Loss: 0.0920\n",
      "Epoch [309/1000], Loss: 0.0912\n",
      "Epoch [310/1000], Loss: 0.0912\n",
      "Epoch [311/1000], Loss: 0.0914\n",
      "Epoch [312/1000], Loss: 0.0909\n",
      "Epoch [313/1000], Loss: 0.0901\n",
      "Epoch [314/1000], Loss: 0.0905\n",
      "Epoch [315/1000], Loss: 0.0901\n",
      "Epoch [316/1000], Loss: 0.0897\n",
      "Epoch [317/1000], Loss: 0.0892\n",
      "Epoch [318/1000], Loss: 0.0892\n",
      "Epoch [319/1000], Loss: 0.0887\n",
      "Epoch [320/1000], Loss: 0.0886\n",
      "Epoch [321/1000], Loss: 0.0883\n",
      "Epoch [322/1000], Loss: 0.0882\n",
      "Epoch [323/1000], Loss: 0.0875\n",
      "Epoch [324/1000], Loss: 0.0874\n",
      "Epoch [325/1000], Loss: 0.0871\n",
      "Epoch [326/1000], Loss: 0.0866\n",
      "Epoch [327/1000], Loss: 0.0865\n",
      "Epoch [328/1000], Loss: 0.0862\n",
      "Epoch [329/1000], Loss: 0.0857\n",
      "Epoch [330/1000], Loss: 0.0855\n",
      "Epoch [331/1000], Loss: 0.0852\n",
      "Epoch [332/1000], Loss: 0.0849\n",
      "Epoch [333/1000], Loss: 0.0845\n",
      "Epoch [334/1000], Loss: 0.0846\n",
      "Epoch [335/1000], Loss: 0.0833\n",
      "Epoch [336/1000], Loss: 0.0831\n",
      "Epoch [337/1000], Loss: 0.0832\n",
      "Epoch [338/1000], Loss: 0.0819\n",
      "Epoch [339/1000], Loss: 0.0816\n",
      "Epoch [340/1000], Loss: 0.0815\n",
      "Epoch [341/1000], Loss: 0.0806\n",
      "Epoch [342/1000], Loss: 0.0798\n",
      "Epoch [343/1000], Loss: 0.0790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [344/1000], Loss: 0.0780\n",
      "Epoch [345/1000], Loss: 0.0771\n",
      "Epoch [346/1000], Loss: 0.0758\n",
      "Epoch [347/1000], Loss: 0.0749\n",
      "Epoch [348/1000], Loss: 0.0739\n",
      "Epoch [349/1000], Loss: 0.0730\n",
      "Epoch [350/1000], Loss: 0.0718\n",
      "Epoch [351/1000], Loss: 0.0707\n",
      "Epoch [352/1000], Loss: 0.0701\n",
      "Epoch [353/1000], Loss: 0.0695\n",
      "Epoch [354/1000], Loss: 0.0686\n",
      "Epoch [355/1000], Loss: 0.0679\n",
      "Epoch [356/1000], Loss: 0.0674\n",
      "Epoch [357/1000], Loss: 0.0672\n",
      "Epoch [358/1000], Loss: 0.0666\n",
      "Epoch [359/1000], Loss: 0.0666\n",
      "Epoch [360/1000], Loss: 0.0654\n",
      "Epoch [361/1000], Loss: 0.0653\n",
      "Epoch [362/1000], Loss: 0.0645\n",
      "Epoch [363/1000], Loss: 0.0646\n",
      "Epoch [364/1000], Loss: 0.0642\n",
      "Epoch [365/1000], Loss: 0.0639\n",
      "Epoch [366/1000], Loss: 0.0635\n",
      "Epoch [367/1000], Loss: 0.0633\n",
      "Epoch [368/1000], Loss: 0.0625\n",
      "Epoch [369/1000], Loss: 0.0624\n",
      "Epoch [370/1000], Loss: 0.0620\n",
      "Epoch [371/1000], Loss: 0.0617\n",
      "Epoch [372/1000], Loss: 0.0613\n",
      "Epoch [373/1000], Loss: 0.0606\n",
      "Epoch [374/1000], Loss: 0.0613\n",
      "Epoch [375/1000], Loss: 0.0610\n",
      "Epoch [376/1000], Loss: 0.0602\n",
      "Epoch [377/1000], Loss: 0.0599\n",
      "Epoch [378/1000], Loss: 0.0594\n",
      "Epoch [379/1000], Loss: 0.0594\n",
      "Epoch [380/1000], Loss: 0.0588\n",
      "Epoch [381/1000], Loss: 0.0581\n",
      "Epoch [382/1000], Loss: 0.0579\n",
      "Epoch [383/1000], Loss: 0.0579\n",
      "Epoch [384/1000], Loss: 0.0578\n",
      "Epoch [385/1000], Loss: 0.0571\n",
      "Epoch [386/1000], Loss: 0.0560\n",
      "Epoch [387/1000], Loss: 0.0563\n",
      "Epoch [388/1000], Loss: 0.0563\n",
      "Epoch [389/1000], Loss: 0.0548\n",
      "Epoch [390/1000], Loss: 0.0554\n",
      "Epoch [391/1000], Loss: 0.0553\n",
      "Epoch [392/1000], Loss: 0.0549\n",
      "Epoch [393/1000], Loss: 0.0540\n",
      "Epoch [394/1000], Loss: 0.0538\n",
      "Epoch [395/1000], Loss: 0.0544\n",
      "Epoch [396/1000], Loss: 0.0536\n",
      "Epoch [397/1000], Loss: 0.0533\n",
      "Epoch [398/1000], Loss: 0.0519\n",
      "Epoch [399/1000], Loss: 0.0521\n",
      "Epoch [400/1000], Loss: 0.0520\n",
      "Epoch [401/1000], Loss: 0.0516\n",
      "Epoch [402/1000], Loss: 0.0508\n",
      "Epoch [403/1000], Loss: 0.0504\n",
      "Epoch [404/1000], Loss: 0.0506\n",
      "Epoch [405/1000], Loss: 0.0506\n",
      "Epoch [406/1000], Loss: 0.0497\n",
      "Epoch [407/1000], Loss: 0.0486\n",
      "Epoch [408/1000], Loss: 0.0488\n",
      "Epoch [409/1000], Loss: 0.0489\n",
      "Epoch [410/1000], Loss: 0.0484\n",
      "Epoch [411/1000], Loss: 0.0466\n",
      "Epoch [412/1000], Loss: 0.0464\n",
      "Epoch [413/1000], Loss: 0.0469\n",
      "Epoch [414/1000], Loss: 0.0468\n",
      "Epoch [415/1000], Loss: 0.0447\n",
      "Epoch [416/1000], Loss: 0.0464\n",
      "Epoch [417/1000], Loss: 0.0442\n",
      "Epoch [418/1000], Loss: 0.0451\n",
      "Epoch [419/1000], Loss: 0.0433\n",
      "Epoch [420/1000], Loss: 0.0429\n",
      "Epoch [421/1000], Loss: 0.0430\n",
      "Epoch [422/1000], Loss: 0.0426\n",
      "Epoch [423/1000], Loss: 0.0422\n",
      "Epoch [424/1000], Loss: 0.0378\n",
      "Epoch [425/1000], Loss: 0.0362\n",
      "Epoch [426/1000], Loss: 0.0360\n",
      "Epoch [427/1000], Loss: 0.0317\n",
      "Epoch [428/1000], Loss: 0.0304\n",
      "Epoch [429/1000], Loss: 0.0271\n",
      "Epoch [430/1000], Loss: 0.0256\n",
      "Epoch [431/1000], Loss: 0.0247\n",
      "Epoch [432/1000], Loss: 0.0233\n",
      "Epoch [433/1000], Loss: 0.0229\n",
      "Epoch [434/1000], Loss: 0.0208\n",
      "Epoch [435/1000], Loss: 0.0229\n",
      "Epoch [436/1000], Loss: 0.0202\n",
      "Epoch [437/1000], Loss: 0.0206\n",
      "Epoch [438/1000], Loss: 0.0198\n",
      "Epoch [439/1000], Loss: 0.0188\n",
      "Epoch [440/1000], Loss: 0.0202\n",
      "Epoch [441/1000], Loss: 0.0181\n",
      "Epoch [442/1000], Loss: 0.0176\n",
      "Epoch [443/1000], Loss: 0.0168\n",
      "Epoch [444/1000], Loss: 0.0176\n",
      "Epoch [445/1000], Loss: 0.0151\n",
      "Epoch [446/1000], Loss: 0.0170\n",
      "Epoch [447/1000], Loss: 0.0170\n",
      "Epoch [448/1000], Loss: 0.0145\n",
      "Epoch [449/1000], Loss: 0.0179\n",
      "Epoch [450/1000], Loss: 0.0191\n",
      "Epoch [451/1000], Loss: 0.0171\n",
      "Epoch [452/1000], Loss: 0.0150\n",
      "Epoch [453/1000], Loss: 0.0157\n",
      "Epoch [454/1000], Loss: 0.0142\n",
      "Epoch [455/1000], Loss: 0.0146\n",
      "Epoch [456/1000], Loss: 0.0173\n",
      "Epoch [457/1000], Loss: 0.0134\n",
      "Epoch [458/1000], Loss: 0.0129\n",
      "Epoch [459/1000], Loss: 0.0151\n",
      "Epoch [460/1000], Loss: 0.0166\n",
      "Epoch [461/1000], Loss: 0.0164\n",
      "Epoch [462/1000], Loss: 0.0141\n",
      "Epoch [463/1000], Loss: 0.0127\n",
      "Epoch [464/1000], Loss: 0.0125\n",
      "Epoch [465/1000], Loss: 0.0141\n",
      "Epoch [466/1000], Loss: 0.0132\n",
      "Epoch [467/1000], Loss: 0.0137\n",
      "Epoch [468/1000], Loss: 0.0110\n",
      "Epoch [469/1000], Loss: 0.0132\n",
      "Epoch [470/1000], Loss: 0.0144\n",
      "Epoch [471/1000], Loss: 0.0099\n",
      "Epoch [472/1000], Loss: 0.0100\n",
      "Epoch [473/1000], Loss: 0.0117\n",
      "Epoch [474/1000], Loss: 0.0104\n",
      "Epoch [475/1000], Loss: 0.0134\n",
      "Epoch [476/1000], Loss: 0.0120\n",
      "Epoch [477/1000], Loss: 0.0119\n",
      "Epoch [478/1000], Loss: 0.0129\n",
      "Epoch [479/1000], Loss: 0.0096\n",
      "Epoch [480/1000], Loss: 0.0095\n",
      "Epoch [481/1000], Loss: 0.0089\n",
      "Epoch [482/1000], Loss: 0.0095\n",
      "Epoch [483/1000], Loss: 0.0145\n",
      "Epoch [484/1000], Loss: 0.0085\n",
      "Epoch [485/1000], Loss: 0.0081\n",
      "Epoch [486/1000], Loss: 0.0092\n",
      "Epoch [487/1000], Loss: 0.0092\n",
      "Epoch [488/1000], Loss: 0.0100\n",
      "Epoch [489/1000], Loss: 0.0077\n",
      "Epoch [490/1000], Loss: 0.0131\n",
      "Epoch [491/1000], Loss: 0.0090\n",
      "Epoch [492/1000], Loss: 0.0081\n",
      "Epoch [493/1000], Loss: 0.0080\n",
      "Epoch [494/1000], Loss: 0.0073\n",
      "Epoch [495/1000], Loss: 0.0090\n",
      "Epoch [496/1000], Loss: 0.0090\n",
      "Epoch [497/1000], Loss: 0.0119\n",
      "Epoch [498/1000], Loss: 0.0071\n",
      "Epoch [499/1000], Loss: 0.0069\n",
      "Epoch [500/1000], Loss: 0.0063\n",
      "Epoch [501/1000], Loss: 0.0070\n",
      "Epoch [502/1000], Loss: 0.0077\n",
      "Epoch [503/1000], Loss: 0.0075\n",
      "Epoch [504/1000], Loss: 0.0068\n",
      "Epoch [505/1000], Loss: 0.0071\n",
      "Epoch [506/1000], Loss: 0.0059\n",
      "Epoch [507/1000], Loss: 0.0059\n",
      "Epoch [508/1000], Loss: 0.0062\n",
      "Epoch [509/1000], Loss: 0.0062\n",
      "Epoch [510/1000], Loss: 0.0064\n",
      "Epoch [511/1000], Loss: 0.0060\n",
      "Epoch [512/1000], Loss: 0.0063\n",
      "Epoch [513/1000], Loss: 0.0067\n",
      "Epoch [514/1000], Loss: 0.0055\n",
      "Epoch [515/1000], Loss: 0.0054\n",
      "Epoch [516/1000], Loss: 0.0073\n",
      "Epoch [517/1000], Loss: 0.0067\n",
      "Epoch [518/1000], Loss: 0.0058\n",
      "Epoch [519/1000], Loss: 0.0059\n",
      "Epoch [520/1000], Loss: 0.0057\n",
      "Epoch [521/1000], Loss: 0.0084\n",
      "Epoch [522/1000], Loss: 0.0061\n",
      "Epoch [523/1000], Loss: 0.0051\n",
      "Epoch [524/1000], Loss: 0.0061\n",
      "Epoch [525/1000], Loss: 0.0056\n",
      "Epoch [526/1000], Loss: 0.0052\n",
      "Epoch [527/1000], Loss: 0.0056\n",
      "Epoch [528/1000], Loss: 0.0052\n",
      "Epoch [529/1000], Loss: 0.0051\n",
      "Epoch [530/1000], Loss: 0.0051\n",
      "Epoch [531/1000], Loss: 0.0050\n",
      "Epoch [532/1000], Loss: 0.0056\n",
      "Epoch [533/1000], Loss: 0.0047\n",
      "Epoch [534/1000], Loss: 0.0063\n",
      "Epoch [535/1000], Loss: 0.0044\n",
      "Epoch [536/1000], Loss: 0.0048\n",
      "Epoch [537/1000], Loss: 0.0050\n",
      "Epoch [538/1000], Loss: 0.0048\n",
      "Epoch [539/1000], Loss: 0.0041\n",
      "Epoch [540/1000], Loss: 0.0049\n",
      "Epoch [541/1000], Loss: 0.0050\n",
      "Epoch [542/1000], Loss: 0.0042\n",
      "Epoch [543/1000], Loss: 0.0047\n",
      "Epoch [544/1000], Loss: 0.0043\n",
      "Epoch [545/1000], Loss: 0.0054\n",
      "Epoch [546/1000], Loss: 0.0065\n",
      "Epoch [547/1000], Loss: 0.0039\n",
      "Epoch [548/1000], Loss: 0.0072\n",
      "Epoch [549/1000], Loss: 0.0054\n",
      "Epoch [550/1000], Loss: 0.0043\n",
      "Epoch [551/1000], Loss: 0.0110\n",
      "Epoch [552/1000], Loss: 0.0053\n",
      "Epoch [553/1000], Loss: 0.0036\n",
      "Epoch [554/1000], Loss: 0.0048\n",
      "Epoch [555/1000], Loss: 0.0043\n",
      "Epoch [556/1000], Loss: 0.0059\n",
      "Epoch [557/1000], Loss: 0.0036\n",
      "Epoch [558/1000], Loss: 0.0038\n",
      "Epoch [559/1000], Loss: 0.0041\n",
      "Epoch [560/1000], Loss: 0.0058\n",
      "Epoch [561/1000], Loss: 0.0041\n",
      "Epoch [562/1000], Loss: 0.0044\n",
      "Epoch [563/1000], Loss: 0.0039\n",
      "Epoch [564/1000], Loss: 0.0041\n",
      "Epoch [565/1000], Loss: 0.0038\n",
      "Epoch [566/1000], Loss: 0.0051\n",
      "Epoch [567/1000], Loss: 0.0048\n",
      "Epoch [568/1000], Loss: 0.0055\n",
      "Epoch [569/1000], Loss: 0.0045\n",
      "Epoch [570/1000], Loss: 0.0034\n",
      "Epoch [571/1000], Loss: 0.0034\n",
      "Epoch [572/1000], Loss: 0.0032\n",
      "Epoch [573/1000], Loss: 0.0038\n",
      "Epoch [574/1000], Loss: 0.0040\n",
      "Epoch [575/1000], Loss: 0.0045\n",
      "Epoch [576/1000], Loss: 0.0036\n",
      "Epoch [577/1000], Loss: 0.0039\n",
      "Epoch [578/1000], Loss: 0.0060\n",
      "Epoch [579/1000], Loss: 0.0047\n",
      "Epoch [580/1000], Loss: 0.0055\n",
      "Epoch [581/1000], Loss: 0.0030\n",
      "Epoch [582/1000], Loss: 0.0036\n",
      "Epoch [583/1000], Loss: 0.0039\n",
      "Epoch [584/1000], Loss: 0.0039\n",
      "Epoch [585/1000], Loss: 0.0030\n",
      "Epoch [586/1000], Loss: 0.0054\n",
      "Epoch [587/1000], Loss: 0.0039\n",
      "Epoch [588/1000], Loss: 0.0032\n",
      "Epoch [589/1000], Loss: 0.0058\n",
      "Epoch [590/1000], Loss: 0.0028\n",
      "Epoch [591/1000], Loss: 0.0032\n",
      "Epoch [592/1000], Loss: 0.0046\n",
      "Epoch [593/1000], Loss: 0.0038\n",
      "Epoch [594/1000], Loss: 0.0034\n",
      "Epoch [595/1000], Loss: 0.0035\n",
      "Epoch [596/1000], Loss: 0.0028\n",
      "Epoch [597/1000], Loss: 0.0030\n",
      "Epoch [598/1000], Loss: 0.0045\n",
      "Epoch [599/1000], Loss: 0.0042\n",
      "Epoch [600/1000], Loss: 0.0041\n",
      "Epoch [601/1000], Loss: 0.0049\n",
      "Epoch [602/1000], Loss: 0.0116\n",
      "Epoch [603/1000], Loss: 0.0038\n",
      "Epoch [604/1000], Loss: 0.0042\n",
      "Epoch [605/1000], Loss: 0.0067\n",
      "Epoch [606/1000], Loss: 0.0032\n",
      "Epoch [607/1000], Loss: 0.0032\n",
      "Epoch [608/1000], Loss: 0.0039\n",
      "Epoch [609/1000], Loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [610/1000], Loss: 0.0039\n",
      "Epoch [611/1000], Loss: 0.0030\n",
      "Epoch [612/1000], Loss: 0.0027\n",
      "Epoch [613/1000], Loss: 0.0041\n",
      "Epoch [614/1000], Loss: 0.0051\n",
      "Epoch [615/1000], Loss: 0.0028\n",
      "Epoch [616/1000], Loss: 0.0075\n",
      "Epoch [617/1000], Loss: 0.0034\n",
      "Epoch [618/1000], Loss: 0.0027\n",
      "Epoch [619/1000], Loss: 0.0027\n",
      "Epoch [620/1000], Loss: 0.0029\n",
      "Epoch [621/1000], Loss: 0.0030\n",
      "Epoch [622/1000], Loss: 0.0041\n",
      "Epoch [623/1000], Loss: 0.0045\n",
      "Epoch [624/1000], Loss: 0.0025\n",
      "Epoch [625/1000], Loss: 0.0028\n",
      "Epoch [626/1000], Loss: 0.0042\n",
      "Epoch [627/1000], Loss: 0.0028\n",
      "Epoch [628/1000], Loss: 0.0028\n",
      "Epoch [629/1000], Loss: 0.0029\n",
      "Epoch [630/1000], Loss: 0.0046\n",
      "Epoch [631/1000], Loss: 0.0060\n",
      "Epoch [632/1000], Loss: 0.0025\n",
      "Epoch [633/1000], Loss: 0.0024\n",
      "Epoch [634/1000], Loss: 0.0033\n",
      "Epoch [635/1000], Loss: 0.0031\n",
      "Epoch [636/1000], Loss: 0.0024\n",
      "Epoch [637/1000], Loss: 0.0026\n",
      "Epoch [638/1000], Loss: 0.0052\n",
      "Epoch [639/1000], Loss: 0.0025\n",
      "Epoch [640/1000], Loss: 0.0035\n",
      "Epoch [641/1000], Loss: 0.0026\n",
      "Epoch [642/1000], Loss: 0.0031\n",
      "Epoch [643/1000], Loss: 0.0023\n",
      "Epoch [644/1000], Loss: 0.0023\n",
      "Epoch [645/1000], Loss: 0.0029\n",
      "Epoch [646/1000], Loss: 0.0026\n",
      "Epoch [647/1000], Loss: 0.0029\n",
      "Epoch [648/1000], Loss: 0.0039\n",
      "Epoch [649/1000], Loss: 0.0024\n",
      "Epoch [650/1000], Loss: 0.0034\n",
      "Epoch [651/1000], Loss: 0.0026\n",
      "Epoch [652/1000], Loss: 0.0045\n",
      "Epoch [653/1000], Loss: 0.0030\n",
      "Epoch [654/1000], Loss: 0.0040\n",
      "Epoch [655/1000], Loss: 0.0026\n",
      "Epoch [656/1000], Loss: 0.0024\n",
      "Epoch [657/1000], Loss: 0.0025\n",
      "Epoch [658/1000], Loss: 0.0027\n",
      "Epoch [659/1000], Loss: 0.0026\n",
      "Epoch [660/1000], Loss: 0.0100\n",
      "Epoch [661/1000], Loss: 0.0029\n",
      "Epoch [662/1000], Loss: 0.0087\n",
      "Epoch [663/1000], Loss: 0.0032\n",
      "Epoch [664/1000], Loss: 0.0044\n",
      "Epoch [665/1000], Loss: 0.0032\n",
      "Epoch [666/1000], Loss: 0.0033\n",
      "Epoch [667/1000], Loss: 0.0025\n",
      "Epoch [668/1000], Loss: 0.0101\n",
      "Epoch [669/1000], Loss: 0.0027\n",
      "Epoch [670/1000], Loss: 0.0030\n",
      "Epoch [671/1000], Loss: 0.0029\n",
      "Epoch [672/1000], Loss: 0.0032\n",
      "Epoch [673/1000], Loss: 0.0022\n",
      "Epoch [674/1000], Loss: 0.0025\n",
      "Epoch [675/1000], Loss: 0.0022\n",
      "Epoch [676/1000], Loss: 0.0026\n",
      "Epoch [677/1000], Loss: 0.0025\n",
      "Epoch [678/1000], Loss: 0.0018\n",
      "Epoch [679/1000], Loss: 0.0036\n",
      "Epoch [680/1000], Loss: 0.0030\n",
      "Epoch [681/1000], Loss: 0.0020\n",
      "Epoch [682/1000], Loss: 0.0038\n",
      "Epoch [683/1000], Loss: 0.0043\n",
      "Epoch [684/1000], Loss: 0.0033\n",
      "Epoch [685/1000], Loss: 0.0031\n",
      "Epoch [686/1000], Loss: 0.0029\n",
      "Epoch [687/1000], Loss: 0.0090\n",
      "Epoch [688/1000], Loss: 0.0027\n",
      "Epoch [689/1000], Loss: 0.0019\n",
      "Epoch [690/1000], Loss: 0.0036\n",
      "Epoch [691/1000], Loss: 0.0034\n",
      "Epoch [692/1000], Loss: 0.0082\n",
      "Epoch [693/1000], Loss: 0.0083\n",
      "Epoch [694/1000], Loss: 0.0102\n",
      "Epoch [695/1000], Loss: 0.0071\n",
      "Epoch [696/1000], Loss: 0.0020\n",
      "Epoch [697/1000], Loss: 0.0037\n",
      "Epoch [698/1000], Loss: 0.0024\n",
      "Epoch [699/1000], Loss: 0.0040\n",
      "Epoch [700/1000], Loss: 0.0023\n",
      "Epoch [701/1000], Loss: 0.0030\n",
      "Epoch [702/1000], Loss: 0.0020\n",
      "Epoch [703/1000], Loss: 0.0024\n",
      "Epoch [704/1000], Loss: 0.0021\n",
      "Epoch [705/1000], Loss: 0.0047\n",
      "Epoch [706/1000], Loss: 0.0034\n",
      "Epoch [707/1000], Loss: 0.0019\n",
      "Epoch [708/1000], Loss: 0.0023\n",
      "Epoch [709/1000], Loss: 0.0022\n",
      "Epoch [710/1000], Loss: 0.0032\n",
      "Epoch [711/1000], Loss: 0.0036\n",
      "Epoch [712/1000], Loss: 0.0022\n",
      "Epoch [713/1000], Loss: 0.0025\n",
      "Epoch [714/1000], Loss: 0.0022\n",
      "Epoch [715/1000], Loss: 0.0034\n",
      "Epoch [716/1000], Loss: 0.0025\n",
      "Epoch [717/1000], Loss: 0.0046\n",
      "Epoch [718/1000], Loss: 0.0026\n",
      "Epoch [719/1000], Loss: 0.0024\n",
      "Epoch [720/1000], Loss: 0.0021\n",
      "Epoch [721/1000], Loss: 0.0020\n",
      "Epoch [722/1000], Loss: 0.0022\n",
      "Epoch [723/1000], Loss: 0.0018\n",
      "Epoch [724/1000], Loss: 0.0021\n",
      "Epoch [725/1000], Loss: 0.0038\n",
      "Epoch [726/1000], Loss: 0.0027\n",
      "Epoch [727/1000], Loss: 0.0023\n",
      "Epoch [728/1000], Loss: 0.0021\n",
      "Epoch [729/1000], Loss: 0.0023\n",
      "Epoch [730/1000], Loss: 0.0024\n",
      "Epoch [731/1000], Loss: 0.0017\n",
      "Epoch [732/1000], Loss: 0.0025\n",
      "Epoch [733/1000], Loss: 0.0020\n",
      "Epoch [734/1000], Loss: 0.0017\n",
      "Epoch [735/1000], Loss: 0.0109\n",
      "Epoch [736/1000], Loss: 0.0022\n",
      "Epoch [737/1000], Loss: 0.0031\n",
      "Epoch [738/1000], Loss: 0.0059\n",
      "Epoch [739/1000], Loss: 0.0025\n",
      "Epoch [740/1000], Loss: 0.0017\n",
      "Epoch [741/1000], Loss: 0.0036\n",
      "Epoch [742/1000], Loss: 0.0021\n",
      "Epoch [743/1000], Loss: 0.0260\n",
      "Epoch [744/1000], Loss: 0.0073\n",
      "Epoch [745/1000], Loss: 0.0021\n",
      "Epoch [746/1000], Loss: 0.0019\n",
      "Epoch [747/1000], Loss: 0.0022\n",
      "Epoch [748/1000], Loss: 0.0016\n",
      "Epoch [749/1000], Loss: 0.0028\n",
      "Epoch [750/1000], Loss: 0.0021\n",
      "Epoch [751/1000], Loss: 0.0024\n",
      "Epoch [752/1000], Loss: 0.0017\n",
      "Epoch [753/1000], Loss: 0.0020\n",
      "Epoch [754/1000], Loss: 0.0015\n",
      "Epoch [755/1000], Loss: 0.0032\n",
      "Epoch [756/1000], Loss: 0.0017\n",
      "Epoch [757/1000], Loss: 0.0046\n",
      "Epoch [758/1000], Loss: 0.0052\n",
      "Epoch [759/1000], Loss: 0.0032\n",
      "Epoch [760/1000], Loss: 0.0026\n",
      "Epoch [761/1000], Loss: 0.0020\n",
      "Epoch [762/1000], Loss: 0.0015\n",
      "Epoch [763/1000], Loss: 0.0027\n",
      "Epoch [764/1000], Loss: 0.0019\n",
      "Epoch [765/1000], Loss: 0.0015\n",
      "Epoch [766/1000], Loss: 0.0018\n",
      "Epoch [767/1000], Loss: 0.0014\n",
      "Epoch [768/1000], Loss: 0.0023\n",
      "Epoch [769/1000], Loss: 0.0021\n",
      "Epoch [770/1000], Loss: 0.0028\n",
      "Epoch [771/1000], Loss: 0.0015\n",
      "Epoch [772/1000], Loss: 0.0018\n",
      "Epoch [773/1000], Loss: 0.0068\n",
      "Epoch [774/1000], Loss: 0.0032\n",
      "Epoch [775/1000], Loss: 0.0019\n",
      "Epoch [776/1000], Loss: 0.0039\n",
      "Epoch [777/1000], Loss: 0.0016\n",
      "Epoch [778/1000], Loss: 0.0044\n",
      "Epoch [779/1000], Loss: 0.0355\n",
      "Epoch [780/1000], Loss: 0.0089\n",
      "Epoch [781/1000], Loss: 0.0033\n",
      "Epoch [782/1000], Loss: 0.0040\n",
      "Epoch [783/1000], Loss: 0.0026\n",
      "Epoch [784/1000], Loss: 0.0032\n",
      "Epoch [785/1000], Loss: 0.0022\n",
      "Epoch [786/1000], Loss: 0.0015\n",
      "Epoch [787/1000], Loss: 0.0064\n",
      "Epoch [788/1000], Loss: 0.0016\n",
      "Epoch [789/1000], Loss: 0.0019\n",
      "Epoch [790/1000], Loss: 0.0015\n",
      "Epoch [791/1000], Loss: 0.0014\n",
      "Epoch [792/1000], Loss: 0.0020\n",
      "Epoch [793/1000], Loss: 0.0070\n",
      "Epoch [794/1000], Loss: 0.0023\n",
      "Epoch [795/1000], Loss: 0.0023\n",
      "Epoch [796/1000], Loss: 0.0019\n",
      "Epoch [797/1000], Loss: 0.0024\n",
      "Epoch [798/1000], Loss: 0.0028\n",
      "Epoch [799/1000], Loss: 0.0021\n",
      "Epoch [800/1000], Loss: 0.0014\n",
      "Epoch [801/1000], Loss: 0.0024\n",
      "Epoch [802/1000], Loss: 0.0018\n",
      "Epoch [803/1000], Loss: 0.0016\n",
      "Epoch [804/1000], Loss: 0.0021\n",
      "Epoch [805/1000], Loss: 0.0056\n",
      "Epoch [806/1000], Loss: 0.0021\n",
      "Epoch [807/1000], Loss: 0.0083\n",
      "Epoch [808/1000], Loss: 0.0020\n",
      "Epoch [809/1000], Loss: 0.0014\n",
      "Epoch [810/1000], Loss: 0.0018\n",
      "Epoch [811/1000], Loss: 0.0052\n",
      "Epoch [812/1000], Loss: 0.0020\n",
      "Epoch [813/1000], Loss: 0.0016\n",
      "Epoch [814/1000], Loss: 0.0020\n",
      "Epoch [815/1000], Loss: 0.0017\n",
      "Epoch [816/1000], Loss: 0.0016\n",
      "Epoch [817/1000], Loss: 0.0013\n",
      "Epoch [818/1000], Loss: 0.0015\n",
      "Epoch [819/1000], Loss: 0.0024\n",
      "Epoch [820/1000], Loss: 0.0015\n",
      "Epoch [821/1000], Loss: 0.0035\n",
      "Epoch [822/1000], Loss: 0.0025\n",
      "Epoch [823/1000], Loss: 0.0021\n",
      "Epoch [824/1000], Loss: 0.0038\n",
      "Epoch [825/1000], Loss: 0.0014\n",
      "Epoch [826/1000], Loss: 0.0015\n",
      "Epoch [827/1000], Loss: 0.0091\n",
      "Epoch [828/1000], Loss: 0.0019\n",
      "Epoch [829/1000], Loss: 0.0014\n",
      "Epoch [830/1000], Loss: 0.0012\n",
      "Epoch [831/1000], Loss: 0.0021\n",
      "Epoch [832/1000], Loss: 0.0013\n",
      "Epoch [833/1000], Loss: 0.0031\n",
      "Epoch [834/1000], Loss: 0.0026\n",
      "Epoch [835/1000], Loss: 0.0020\n",
      "Epoch [836/1000], Loss: 0.0014\n",
      "Epoch [837/1000], Loss: 0.0017\n",
      "Epoch [838/1000], Loss: 0.0019\n",
      "Epoch [839/1000], Loss: 0.0022\n",
      "Epoch [840/1000], Loss: 0.0024\n",
      "Epoch [841/1000], Loss: 0.0014\n",
      "Epoch [842/1000], Loss: 0.0015\n",
      "Epoch [843/1000], Loss: 0.0016\n",
      "Epoch [844/1000], Loss: 0.0014\n",
      "Epoch [845/1000], Loss: 0.0020\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 3, activation : tanh, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2501\n",
      "Epoch [2/1000], Loss: 0.2453\n",
      "Epoch [3/1000], Loss: 0.2433\n",
      "Epoch [4/1000], Loss: 0.2421\n",
      "Epoch [5/1000], Loss: 0.2412\n",
      "Epoch [6/1000], Loss: 0.2405\n",
      "Epoch [7/1000], Loss: 0.2399\n",
      "Epoch [8/1000], Loss: 0.2395\n",
      "Epoch [9/1000], Loss: 0.2391\n",
      "Epoch [10/1000], Loss: 0.2387\n",
      "Epoch [11/1000], Loss: 0.2383\n",
      "Epoch [12/1000], Loss: 0.2379\n",
      "Epoch [13/1000], Loss: 0.2376\n",
      "Epoch [14/1000], Loss: 0.2372\n",
      "Epoch [15/1000], Loss: 0.2368\n",
      "Epoch [16/1000], Loss: 0.2364\n",
      "Epoch [17/1000], Loss: 0.2360\n",
      "Epoch [18/1000], Loss: 0.2355\n",
      "Epoch [19/1000], Loss: 0.2351\n",
      "Epoch [20/1000], Loss: 0.2346\n",
      "Epoch [21/1000], Loss: 0.2341\n",
      "Epoch [22/1000], Loss: 0.2336\n",
      "Epoch [23/1000], Loss: 0.2331\n",
      "Epoch [24/1000], Loss: 0.2325\n",
      "Epoch [25/1000], Loss: 0.2319\n",
      "Epoch [26/1000], Loss: 0.2313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/1000], Loss: 0.2306\n",
      "Epoch [28/1000], Loss: 0.2300\n",
      "Epoch [29/1000], Loss: 0.2292\n",
      "Epoch [30/1000], Loss: 0.2285\n",
      "Epoch [31/1000], Loss: 0.2277\n",
      "Epoch [32/1000], Loss: 0.2269\n",
      "Epoch [33/1000], Loss: 0.2260\n",
      "Epoch [34/1000], Loss: 0.2251\n",
      "Epoch [35/1000], Loss: 0.2241\n",
      "Epoch [36/1000], Loss: 0.2233\n",
      "Epoch [37/1000], Loss: 0.2223\n",
      "Epoch [38/1000], Loss: 0.2211\n",
      "Epoch [39/1000], Loss: 0.2202\n",
      "Epoch [40/1000], Loss: 0.2189\n",
      "Epoch [41/1000], Loss: 0.2180\n",
      "Epoch [42/1000], Loss: 0.2167\n",
      "Epoch [43/1000], Loss: 0.2153\n",
      "Epoch [44/1000], Loss: 0.2142\n",
      "Epoch [45/1000], Loss: 0.2129\n",
      "Epoch [46/1000], Loss: 0.2118\n",
      "Epoch [47/1000], Loss: 0.2102\n",
      "Epoch [48/1000], Loss: 0.2092\n",
      "Epoch [49/1000], Loss: 0.2077\n",
      "Epoch [50/1000], Loss: 0.2063\n",
      "Epoch [51/1000], Loss: 0.2045\n",
      "Epoch [52/1000], Loss: 0.2029\n",
      "Epoch [53/1000], Loss: 0.2020\n",
      "Epoch [54/1000], Loss: 0.1997\n",
      "Epoch [55/1000], Loss: 0.1987\n",
      "Epoch [56/1000], Loss: 0.1968\n",
      "Epoch [57/1000], Loss: 0.1950\n",
      "Epoch [58/1000], Loss: 0.1934\n",
      "Epoch [59/1000], Loss: 0.1911\n",
      "Epoch [60/1000], Loss: 0.1897\n",
      "Epoch [61/1000], Loss: 0.1877\n",
      "Epoch [62/1000], Loss: 0.1861\n",
      "Epoch [63/1000], Loss: 0.1839\n",
      "Epoch [64/1000], Loss: 0.1824\n",
      "Epoch [65/1000], Loss: 0.1799\n",
      "Epoch [66/1000], Loss: 0.1780\n",
      "Epoch [67/1000], Loss: 0.1756\n",
      "Epoch [68/1000], Loss: 0.1747\n",
      "Epoch [69/1000], Loss: 0.1729\n",
      "Epoch [70/1000], Loss: 0.1713\n",
      "Epoch [71/1000], Loss: 0.1689\n",
      "Epoch [72/1000], Loss: 0.1679\n",
      "Epoch [73/1000], Loss: 0.1667\n",
      "Epoch [74/1000], Loss: 0.1645\n",
      "Epoch [75/1000], Loss: 0.1641\n",
      "Epoch [76/1000], Loss: 0.1626\n",
      "Epoch [77/1000], Loss: 0.1607\n",
      "Epoch [78/1000], Loss: 0.1593\n",
      "Epoch [79/1000], Loss: 0.1581\n",
      "Epoch [80/1000], Loss: 0.1567\n",
      "Epoch [81/1000], Loss: 0.1560\n",
      "Epoch [82/1000], Loss: 0.1541\n",
      "Epoch [83/1000], Loss: 0.1538\n",
      "Epoch [84/1000], Loss: 0.1520\n",
      "Epoch [85/1000], Loss: 0.1498\n",
      "Epoch [86/1000], Loss: 0.1510\n",
      "Epoch [87/1000], Loss: 0.1474\n",
      "Epoch [88/1000], Loss: 0.1455\n",
      "Epoch [89/1000], Loss: 0.1418\n",
      "Epoch [90/1000], Loss: 0.1388\n",
      "Epoch [91/1000], Loss: 0.1328\n",
      "Epoch [92/1000], Loss: 0.1281\n",
      "Epoch [93/1000], Loss: 0.1247\n",
      "Epoch [94/1000], Loss: 0.1190\n",
      "Epoch [95/1000], Loss: 0.1172\n",
      "Epoch [96/1000], Loss: 0.1144\n",
      "Epoch [97/1000], Loss: 0.1109\n",
      "Epoch [98/1000], Loss: 0.1094\n",
      "Epoch [99/1000], Loss: 0.1069\n",
      "Epoch [100/1000], Loss: 0.1040\n",
      "Epoch [101/1000], Loss: 0.1023\n",
      "Epoch [102/1000], Loss: 0.1005\n",
      "Epoch [103/1000], Loss: 0.0995\n",
      "Epoch [104/1000], Loss: 0.0974\n",
      "Epoch [105/1000], Loss: 0.0943\n",
      "Epoch [106/1000], Loss: 0.0930\n",
      "Epoch [107/1000], Loss: 0.0911\n",
      "Epoch [108/1000], Loss: 0.0884\n",
      "Epoch [109/1000], Loss: 0.0867\n",
      "Epoch [110/1000], Loss: 0.0846\n",
      "Epoch [111/1000], Loss: 0.0834\n",
      "Epoch [112/1000], Loss: 0.0830\n",
      "Epoch [113/1000], Loss: 0.0797\n",
      "Epoch [114/1000], Loss: 0.0777\n",
      "Epoch [115/1000], Loss: 0.0759\n",
      "Epoch [116/1000], Loss: 0.0745\n",
      "Epoch [117/1000], Loss: 0.0730\n",
      "Epoch [118/1000], Loss: 0.0711\n",
      "Epoch [119/1000], Loss: 0.0699\n",
      "Epoch [120/1000], Loss: 0.0676\n",
      "Epoch [121/1000], Loss: 0.0684\n",
      "Epoch [122/1000], Loss: 0.0649\n",
      "Epoch [123/1000], Loss: 0.0634\n",
      "Epoch [124/1000], Loss: 0.0628\n",
      "Epoch [125/1000], Loss: 0.0600\n",
      "Epoch [126/1000], Loss: 0.0607\n",
      "Epoch [127/1000], Loss: 0.0611\n",
      "Epoch [128/1000], Loss: 0.0579\n",
      "Epoch [129/1000], Loss: 0.0568\n",
      "Epoch [130/1000], Loss: 0.0541\n",
      "Epoch [131/1000], Loss: 0.0533\n",
      "Epoch [132/1000], Loss: 0.0528\n",
      "Epoch [133/1000], Loss: 0.0522\n",
      "Epoch [134/1000], Loss: 0.0506\n",
      "Epoch [135/1000], Loss: 0.0506\n",
      "Epoch [136/1000], Loss: 0.0480\n",
      "Epoch [137/1000], Loss: 0.0481\n",
      "Epoch [138/1000], Loss: 0.0485\n",
      "Epoch [139/1000], Loss: 0.0451\n",
      "Epoch [140/1000], Loss: 0.0449\n",
      "Epoch [141/1000], Loss: 0.0428\n",
      "Epoch [142/1000], Loss: 0.0454\n",
      "Epoch [143/1000], Loss: 0.0421\n",
      "Epoch [144/1000], Loss: 0.0408\n",
      "Epoch [145/1000], Loss: 0.0414\n",
      "Epoch [146/1000], Loss: 0.0413\n",
      "Epoch [147/1000], Loss: 0.0406\n",
      "Epoch [148/1000], Loss: 0.0383\n",
      "Epoch [149/1000], Loss: 0.0394\n",
      "Epoch [150/1000], Loss: 0.0362\n",
      "Epoch [151/1000], Loss: 0.0343\n",
      "Epoch [152/1000], Loss: 0.0339\n",
      "Epoch [153/1000], Loss: 0.0352\n",
      "Epoch [154/1000], Loss: 0.0326\n",
      "Epoch [155/1000], Loss: 0.0317\n",
      "Epoch [156/1000], Loss: 0.0294\n",
      "Epoch [157/1000], Loss: 0.0271\n",
      "Epoch [158/1000], Loss: 0.0281\n",
      "Epoch [159/1000], Loss: 0.0247\n",
      "Epoch [160/1000], Loss: 0.0252\n",
      "Epoch [161/1000], Loss: 0.0232\n",
      "Epoch [162/1000], Loss: 0.0294\n",
      "Epoch [163/1000], Loss: 0.0204\n",
      "Epoch [164/1000], Loss: 0.0185\n",
      "Epoch [165/1000], Loss: 0.0170\n",
      "Epoch [166/1000], Loss: 0.0155\n",
      "Epoch [167/1000], Loss: 0.0143\n",
      "Epoch [168/1000], Loss: 0.0151\n",
      "Epoch [169/1000], Loss: 0.0156\n",
      "Epoch [170/1000], Loss: 0.0154\n",
      "Epoch [171/1000], Loss: 0.0143\n",
      "Epoch [172/1000], Loss: 0.0105\n",
      "Epoch [173/1000], Loss: 0.0119\n",
      "Epoch [174/1000], Loss: 0.0104\n",
      "Epoch [175/1000], Loss: 0.0112\n",
      "Epoch [176/1000], Loss: 0.0089\n",
      "Epoch [177/1000], Loss: 0.0086\n",
      "Epoch [178/1000], Loss: 0.0093\n",
      "Epoch [179/1000], Loss: 0.0121\n",
      "Epoch [180/1000], Loss: 0.0073\n",
      "Epoch [181/1000], Loss: 0.0065\n",
      "Epoch [182/1000], Loss: 0.0092\n",
      "Epoch [183/1000], Loss: 0.0109\n",
      "Epoch [184/1000], Loss: 0.0064\n",
      "Epoch [185/1000], Loss: 0.0059\n",
      "Epoch [186/1000], Loss: 0.0065\n",
      "Epoch [187/1000], Loss: 0.0056\n",
      "Epoch [188/1000], Loss: 0.0101\n",
      "Epoch [189/1000], Loss: 0.0055\n",
      "Epoch [190/1000], Loss: 0.0051\n",
      "Epoch [191/1000], Loss: 0.0047\n",
      "Epoch [192/1000], Loss: 0.0049\n",
      "Epoch [193/1000], Loss: 0.0046\n",
      "Epoch [194/1000], Loss: 0.0045\n",
      "Epoch [195/1000], Loss: 0.0046\n",
      "Epoch [196/1000], Loss: 0.0051\n",
      "Epoch [197/1000], Loss: 0.0041\n",
      "Epoch [198/1000], Loss: 0.0053\n",
      "Epoch [199/1000], Loss: 0.0051\n",
      "Epoch [200/1000], Loss: 0.0042\n",
      "Epoch [201/1000], Loss: 0.0039\n",
      "Epoch [202/1000], Loss: 0.0042\n",
      "Epoch [203/1000], Loss: 0.0038\n",
      "Epoch [204/1000], Loss: 0.0049\n",
      "Epoch [205/1000], Loss: 0.0036\n",
      "Epoch [206/1000], Loss: 0.0036\n",
      "Epoch [207/1000], Loss: 0.0038\n",
      "Epoch [208/1000], Loss: 0.0035\n",
      "Epoch [209/1000], Loss: 0.0043\n",
      "Epoch [210/1000], Loss: 0.0036\n",
      "Epoch [211/1000], Loss: 0.0036\n",
      "Epoch [212/1000], Loss: 0.0046\n",
      "Epoch [213/1000], Loss: 0.0034\n",
      "Epoch [214/1000], Loss: 0.0035\n",
      "Epoch [215/1000], Loss: 0.0033\n",
      "Epoch [216/1000], Loss: 0.0031\n",
      "Epoch [217/1000], Loss: 0.0071\n",
      "Epoch [218/1000], Loss: 0.0243\n",
      "Epoch [219/1000], Loss: 0.0032\n",
      "Epoch [220/1000], Loss: 0.0031\n",
      "Epoch [221/1000], Loss: 0.0030\n",
      "Epoch [222/1000], Loss: 0.0031\n",
      "Epoch [223/1000], Loss: 0.0029\n",
      "Epoch [224/1000], Loss: 0.0030\n",
      "Epoch [225/1000], Loss: 0.0030\n",
      "Epoch [226/1000], Loss: 0.0028\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 3, activation : tanh, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2496\n",
      "Epoch [2/1000], Loss: 0.2431\n",
      "Epoch [3/1000], Loss: 0.2407\n",
      "Epoch [4/1000], Loss: 0.2399\n",
      "Epoch [5/1000], Loss: 0.2394\n",
      "Epoch [6/1000], Loss: 0.2392\n",
      "Epoch [7/1000], Loss: 0.2389\n",
      "Epoch [8/1000], Loss: 0.2386\n",
      "Epoch [9/1000], Loss: 0.2384\n",
      "Epoch [10/1000], Loss: 0.2382\n",
      "Epoch [11/1000], Loss: 0.2380\n",
      "Epoch [12/1000], Loss: 0.2377\n",
      "Epoch [13/1000], Loss: 0.2375\n",
      "Epoch [14/1000], Loss: 0.2373\n",
      "Epoch [15/1000], Loss: 0.2370\n",
      "Epoch [16/1000], Loss: 0.2368\n",
      "Epoch [17/1000], Loss: 0.2365\n",
      "Epoch [18/1000], Loss: 0.2361\n",
      "Epoch [19/1000], Loss: 0.2359\n",
      "Epoch [20/1000], Loss: 0.2355\n",
      "Epoch [21/1000], Loss: 0.2352\n",
      "Epoch [22/1000], Loss: 0.2347\n",
      "Epoch [23/1000], Loss: 0.2344\n",
      "Epoch [24/1000], Loss: 0.2339\n",
      "Epoch [25/1000], Loss: 0.2334\n",
      "Epoch [26/1000], Loss: 0.2328\n",
      "Epoch [27/1000], Loss: 0.2321\n",
      "Epoch [28/1000], Loss: 0.2313\n",
      "Epoch [29/1000], Loss: 0.2306\n",
      "Epoch [30/1000], Loss: 0.2296\n",
      "Epoch [31/1000], Loss: 0.2286\n",
      "Epoch [32/1000], Loss: 0.2274\n",
      "Epoch [33/1000], Loss: 0.2260\n",
      "Epoch [34/1000], Loss: 0.2245\n",
      "Epoch [35/1000], Loss: 0.2227\n",
      "Epoch [36/1000], Loss: 0.2213\n",
      "Epoch [37/1000], Loss: 0.2194\n",
      "Epoch [38/1000], Loss: 0.2169\n",
      "Epoch [39/1000], Loss: 0.2145\n",
      "Epoch [40/1000], Loss: 0.2117\n",
      "Epoch [41/1000], Loss: 0.2086\n",
      "Epoch [42/1000], Loss: 0.2050\n",
      "Epoch [43/1000], Loss: 0.2013\n",
      "Epoch [44/1000], Loss: 0.1970\n",
      "Epoch [45/1000], Loss: 0.1923\n",
      "Epoch [46/1000], Loss: 0.1886\n",
      "Epoch [47/1000], Loss: 0.1831\n",
      "Epoch [48/1000], Loss: 0.1786\n",
      "Epoch [49/1000], Loss: 0.1738\n",
      "Epoch [50/1000], Loss: 0.1685\n",
      "Epoch [51/1000], Loss: 0.1647\n",
      "Epoch [52/1000], Loss: 0.1609\n",
      "Epoch [53/1000], Loss: 0.1567\n",
      "Epoch [54/1000], Loss: 0.1512\n",
      "Epoch [55/1000], Loss: 0.1497\n",
      "Epoch [56/1000], Loss: 0.1457\n",
      "Epoch [57/1000], Loss: 0.1423\n",
      "Epoch [58/1000], Loss: 0.1398\n",
      "Epoch [59/1000], Loss: 0.1388\n",
      "Epoch [60/1000], Loss: 0.1335\n",
      "Epoch [61/1000], Loss: 0.1320\n",
      "Epoch [62/1000], Loss: 0.1298\n",
      "Epoch [63/1000], Loss: 0.1269\n",
      "Epoch [64/1000], Loss: 0.1257\n",
      "Epoch [65/1000], Loss: 0.1216\n",
      "Epoch [66/1000], Loss: 0.1203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/1000], Loss: 0.1174\n",
      "Epoch [68/1000], Loss: 0.1162\n",
      "Epoch [69/1000], Loss: 0.1139\n",
      "Epoch [70/1000], Loss: 0.1124\n",
      "Epoch [71/1000], Loss: 0.1103\n",
      "Epoch [72/1000], Loss: 0.1078\n",
      "Epoch [73/1000], Loss: 0.1052\n",
      "Epoch [74/1000], Loss: 0.1040\n",
      "Epoch [75/1000], Loss: 0.1010\n",
      "Epoch [76/1000], Loss: 0.0985\n",
      "Epoch [77/1000], Loss: 0.0962\n",
      "Epoch [78/1000], Loss: 0.0932\n",
      "Epoch [79/1000], Loss: 0.0892\n",
      "Epoch [80/1000], Loss: 0.0881\n",
      "Epoch [81/1000], Loss: 0.0839\n",
      "Epoch [82/1000], Loss: 0.0807\n",
      "Epoch [83/1000], Loss: 0.0774\n",
      "Epoch [84/1000], Loss: 0.0737\n",
      "Epoch [85/1000], Loss: 0.0714\n",
      "Epoch [86/1000], Loss: 0.0673\n",
      "Epoch [87/1000], Loss: 0.0632\n",
      "Epoch [88/1000], Loss: 0.0585\n",
      "Epoch [89/1000], Loss: 0.0529\n",
      "Epoch [90/1000], Loss: 0.0542\n",
      "Epoch [91/1000], Loss: 0.0463\n",
      "Epoch [92/1000], Loss: 0.0452\n",
      "Epoch [93/1000], Loss: 0.0408\n",
      "Epoch [94/1000], Loss: 0.0380\n",
      "Epoch [95/1000], Loss: 0.0339\n",
      "Epoch [96/1000], Loss: 0.0294\n",
      "Epoch [97/1000], Loss: 0.0289\n",
      "Epoch [98/1000], Loss: 0.0239\n",
      "Epoch [99/1000], Loss: 0.0211\n",
      "Epoch [100/1000], Loss: 0.0194\n",
      "Epoch [101/1000], Loss: 0.0203\n",
      "Epoch [102/1000], Loss: 0.0186\n",
      "Epoch [103/1000], Loss: 0.0149\n",
      "Epoch [104/1000], Loss: 0.0124\n",
      "Epoch [105/1000], Loss: 0.0116\n",
      "Epoch [106/1000], Loss: 0.0115\n",
      "Epoch [107/1000], Loss: 0.0117\n",
      "Epoch [108/1000], Loss: 0.0103\n",
      "Epoch [109/1000], Loss: 0.0092\n",
      "Epoch [110/1000], Loss: 0.0089\n",
      "Epoch [111/1000], Loss: 0.0088\n",
      "Epoch [112/1000], Loss: 0.0077\n",
      "Epoch [113/1000], Loss: 0.0075\n",
      "Epoch [114/1000], Loss: 0.0085\n",
      "Epoch [115/1000], Loss: 0.0054\n",
      "Epoch [116/1000], Loss: 0.0051\n",
      "Epoch [117/1000], Loss: 0.0063\n",
      "Epoch [118/1000], Loss: 0.0053\n",
      "Epoch [119/1000], Loss: 0.0070\n",
      "Epoch [120/1000], Loss: 0.0065\n",
      "Epoch [121/1000], Loss: 0.0049\n",
      "Epoch [122/1000], Loss: 0.0044\n",
      "Epoch [123/1000], Loss: 0.0050\n",
      "Epoch [124/1000], Loss: 0.0052\n",
      "Epoch [125/1000], Loss: 0.0050\n",
      "Epoch [126/1000], Loss: 0.0036\n",
      "Epoch [127/1000], Loss: 0.0045\n",
      "Epoch [128/1000], Loss: 0.0048\n",
      "Epoch [129/1000], Loss: 0.0030\n",
      "Epoch [130/1000], Loss: 0.0034\n",
      "Epoch [131/1000], Loss: 0.0028\n",
      "Epoch [132/1000], Loss: 0.0029\n",
      "Epoch [133/1000], Loss: 0.0026\n",
      "Epoch [134/1000], Loss: 0.0069\n",
      "Epoch [135/1000], Loss: 0.0025\n",
      "Epoch [136/1000], Loss: 0.0023\n",
      "Epoch [137/1000], Loss: 0.0025\n",
      "Epoch [138/1000], Loss: 0.0022\n",
      "Epoch [139/1000], Loss: 0.0021\n",
      "Epoch [140/1000], Loss: 0.0021\n",
      "Epoch [141/1000], Loss: 0.0027\n",
      "Epoch [142/1000], Loss: 0.0021\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 4, activation : relu, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2527\n",
      "Epoch [2/1000], Loss: 0.2504\n",
      "Epoch [3/1000], Loss: 0.2491\n",
      "Epoch [4/1000], Loss: 0.2481\n",
      "Epoch [5/1000], Loss: 0.2469\n",
      "Epoch [6/1000], Loss: 0.2456\n",
      "Epoch [7/1000], Loss: 0.2443\n",
      "Epoch [8/1000], Loss: 0.2431\n",
      "Epoch [9/1000], Loss: 0.2422\n",
      "Epoch [10/1000], Loss: 0.2415\n",
      "Epoch [11/1000], Loss: 0.2409\n",
      "Epoch [12/1000], Loss: 0.2404\n",
      "Epoch [13/1000], Loss: 0.2400\n",
      "Epoch [14/1000], Loss: 0.2395\n",
      "Epoch [15/1000], Loss: 0.2390\n",
      "Epoch [16/1000], Loss: 0.2386\n",
      "Epoch [17/1000], Loss: 0.2380\n",
      "Epoch [18/1000], Loss: 0.2375\n",
      "Epoch [19/1000], Loss: 0.2370\n",
      "Epoch [20/1000], Loss: 0.2364\n",
      "Epoch [21/1000], Loss: 0.2359\n",
      "Epoch [22/1000], Loss: 0.2353\n",
      "Epoch [23/1000], Loss: 0.2348\n",
      "Epoch [24/1000], Loss: 0.2342\n",
      "Epoch [25/1000], Loss: 0.2336\n",
      "Epoch [26/1000], Loss: 0.2330\n",
      "Epoch [27/1000], Loss: 0.2324\n",
      "Epoch [28/1000], Loss: 0.2317\n",
      "Epoch [29/1000], Loss: 0.2308\n",
      "Epoch [30/1000], Loss: 0.2299\n",
      "Epoch [31/1000], Loss: 0.2288\n",
      "Epoch [32/1000], Loss: 0.2275\n",
      "Epoch [33/1000], Loss: 0.2259\n",
      "Epoch [34/1000], Loss: 0.2238\n",
      "Epoch [35/1000], Loss: 0.2217\n",
      "Epoch [36/1000], Loss: 0.2192\n",
      "Epoch [37/1000], Loss: 0.2161\n",
      "Epoch [38/1000], Loss: 0.2126\n",
      "Epoch [39/1000], Loss: 0.2083\n",
      "Epoch [40/1000], Loss: 0.2034\n",
      "Epoch [41/1000], Loss: 0.1966\n",
      "Epoch [42/1000], Loss: 0.1883\n",
      "Epoch [43/1000], Loss: 0.1794\n",
      "Epoch [44/1000], Loss: 0.1695\n",
      "Epoch [45/1000], Loss: 0.1598\n",
      "Epoch [46/1000], Loss: 0.1506\n",
      "Epoch [47/1000], Loss: 0.1416\n",
      "Epoch [48/1000], Loss: 0.1315\n",
      "Epoch [49/1000], Loss: 0.1233\n",
      "Epoch [50/1000], Loss: 0.1150\n",
      "Epoch [51/1000], Loss: 0.1091\n",
      "Epoch [52/1000], Loss: 0.1045\n",
      "Epoch [53/1000], Loss: 0.1011\n",
      "Epoch [54/1000], Loss: 0.0973\n",
      "Epoch [55/1000], Loss: 0.0950\n",
      "Epoch [56/1000], Loss: 0.0929\n",
      "Epoch [57/1000], Loss: 0.0908\n",
      "Epoch [58/1000], Loss: 0.0872\n",
      "Epoch [59/1000], Loss: 0.0829\n",
      "Epoch [60/1000], Loss: 0.0801\n",
      "Epoch [61/1000], Loss: 0.0772\n",
      "Epoch [62/1000], Loss: 0.0741\n",
      "Epoch [63/1000], Loss: 0.0698\n",
      "Epoch [64/1000], Loss: 0.0663\n",
      "Epoch [65/1000], Loss: 0.0641\n",
      "Epoch [66/1000], Loss: 0.0620\n",
      "Epoch [67/1000], Loss: 0.0607\n",
      "Epoch [68/1000], Loss: 0.0596\n",
      "Epoch [69/1000], Loss: 0.0580\n",
      "Epoch [70/1000], Loss: 0.0570\n",
      "Epoch [71/1000], Loss: 0.0553\n",
      "Epoch [72/1000], Loss: 0.0542\n",
      "Epoch [73/1000], Loss: 0.0535\n",
      "Epoch [74/1000], Loss: 0.0524\n",
      "Epoch [75/1000], Loss: 0.0515\n",
      "Epoch [76/1000], Loss: 0.0499\n",
      "Epoch [77/1000], Loss: 0.0493\n",
      "Epoch [78/1000], Loss: 0.0488\n",
      "Epoch [79/1000], Loss: 0.0474\n",
      "Epoch [80/1000], Loss: 0.0465\n",
      "Epoch [81/1000], Loss: 0.0453\n",
      "Epoch [82/1000], Loss: 0.0449\n",
      "Epoch [83/1000], Loss: 0.0432\n",
      "Epoch [84/1000], Loss: 0.0423\n",
      "Epoch [85/1000], Loss: 0.0413\n",
      "Epoch [86/1000], Loss: 0.0409\n",
      "Epoch [87/1000], Loss: 0.0398\n",
      "Epoch [88/1000], Loss: 0.0392\n",
      "Epoch [89/1000], Loss: 0.0385\n",
      "Epoch [90/1000], Loss: 0.0377\n",
      "Epoch [91/1000], Loss: 0.0369\n",
      "Epoch [92/1000], Loss: 0.0361\n",
      "Epoch [93/1000], Loss: 0.0358\n",
      "Epoch [94/1000], Loss: 0.0348\n",
      "Epoch [95/1000], Loss: 0.0342\n",
      "Epoch [96/1000], Loss: 0.0339\n",
      "Epoch [97/1000], Loss: 0.0331\n",
      "Epoch [98/1000], Loss: 0.0322\n",
      "Epoch [99/1000], Loss: 0.0318\n",
      "Epoch [100/1000], Loss: 0.0315\n",
      "Epoch [101/1000], Loss: 0.0300\n",
      "Epoch [102/1000], Loss: 0.0296\n",
      "Epoch [103/1000], Loss: 0.0287\n",
      "Epoch [104/1000], Loss: 0.0275\n",
      "Epoch [105/1000], Loss: 0.0272\n",
      "Epoch [106/1000], Loss: 0.0262\n",
      "Epoch [107/1000], Loss: 0.0253\n",
      "Epoch [108/1000], Loss: 0.0245\n",
      "Epoch [109/1000], Loss: 0.0236\n",
      "Epoch [110/1000], Loss: 0.0233\n",
      "Epoch [111/1000], Loss: 0.0225\n",
      "Epoch [112/1000], Loss: 0.0214\n",
      "Epoch [113/1000], Loss: 0.0211\n",
      "Epoch [114/1000], Loss: 0.0202\n",
      "Epoch [115/1000], Loss: 0.0195\n",
      "Epoch [116/1000], Loss: 0.0188\n",
      "Epoch [117/1000], Loss: 0.0181\n",
      "Epoch [118/1000], Loss: 0.0176\n",
      "Epoch [119/1000], Loss: 0.0167\n",
      "Epoch [120/1000], Loss: 0.0166\n",
      "Epoch [121/1000], Loss: 0.0159\n",
      "Epoch [122/1000], Loss: 0.0154\n",
      "Epoch [123/1000], Loss: 0.0147\n",
      "Epoch [124/1000], Loss: 0.0146\n",
      "Epoch [125/1000], Loss: 0.0138\n",
      "Epoch [126/1000], Loss: 0.0136\n",
      "Epoch [127/1000], Loss: 0.0127\n",
      "Epoch [128/1000], Loss: 0.0127\n",
      "Epoch [129/1000], Loss: 0.0124\n",
      "Epoch [130/1000], Loss: 0.0117\n",
      "Epoch [131/1000], Loss: 0.0113\n",
      "Epoch [132/1000], Loss: 0.0111\n",
      "Epoch [133/1000], Loss: 0.0107\n",
      "Epoch [134/1000], Loss: 0.0104\n",
      "Epoch [135/1000], Loss: 0.0106\n",
      "Epoch [136/1000], Loss: 0.0101\n",
      "Epoch [137/1000], Loss: 0.0097\n",
      "Epoch [138/1000], Loss: 0.0094\n",
      "Epoch [139/1000], Loss: 0.0088\n",
      "Epoch [140/1000], Loss: 0.0096\n",
      "Epoch [141/1000], Loss: 0.0088\n",
      "Epoch [142/1000], Loss: 0.0084\n",
      "Epoch [143/1000], Loss: 0.0087\n",
      "Epoch [144/1000], Loss: 0.0076\n",
      "Epoch [145/1000], Loss: 0.0079\n",
      "Epoch [146/1000], Loss: 0.0076\n",
      "Epoch [147/1000], Loss: 0.0075\n",
      "Epoch [148/1000], Loss: 0.0068\n",
      "Epoch [149/1000], Loss: 0.0066\n",
      "Epoch [150/1000], Loss: 0.0068\n",
      "Epoch [151/1000], Loss: 0.0061\n",
      "Epoch [152/1000], Loss: 0.0061\n",
      "Epoch [153/1000], Loss: 0.0062\n",
      "Epoch [154/1000], Loss: 0.0058\n",
      "Epoch [155/1000], Loss: 0.0061\n",
      "Epoch [156/1000], Loss: 0.0059\n",
      "Epoch [157/1000], Loss: 0.0058\n",
      "Epoch [158/1000], Loss: 0.0055\n",
      "Epoch [159/1000], Loss: 0.0057\n",
      "Epoch [160/1000], Loss: 0.0057\n",
      "Epoch [161/1000], Loss: 0.0051\n",
      "Epoch [162/1000], Loss: 0.0048\n",
      "Epoch [163/1000], Loss: 0.0050\n",
      "Epoch [164/1000], Loss: 0.0048\n",
      "Epoch [165/1000], Loss: 0.0044\n",
      "Epoch [166/1000], Loss: 0.0047\n",
      "Epoch [167/1000], Loss: 0.0049\n",
      "Epoch [168/1000], Loss: 0.0046\n",
      "Epoch [169/1000], Loss: 0.0048\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 4, activation : relu, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2494\n",
      "Epoch [2/1000], Loss: 0.2487\n",
      "Epoch [3/1000], Loss: 0.2480\n",
      "Epoch [4/1000], Loss: 0.2472\n",
      "Epoch [5/1000], Loss: 0.2463\n",
      "Epoch [6/1000], Loss: 0.2450\n",
      "Epoch [7/1000], Loss: 0.2435\n",
      "Epoch [8/1000], Loss: 0.2416\n",
      "Epoch [9/1000], Loss: 0.2396\n",
      "Epoch [10/1000], Loss: 0.2378\n",
      "Epoch [11/1000], Loss: 0.2364\n",
      "Epoch [12/1000], Loss: 0.2353\n",
      "Epoch [13/1000], Loss: 0.2347\n",
      "Epoch [14/1000], Loss: 0.2342\n",
      "Epoch [15/1000], Loss: 0.2337\n",
      "Epoch [16/1000], Loss: 0.2332\n",
      "Epoch [17/1000], Loss: 0.2327\n",
      "Epoch [18/1000], Loss: 0.2322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/1000], Loss: 0.2317\n",
      "Epoch [20/1000], Loss: 0.2312\n",
      "Epoch [21/1000], Loss: 0.2307\n",
      "Epoch [22/1000], Loss: 0.2299\n",
      "Epoch [23/1000], Loss: 0.2292\n",
      "Epoch [24/1000], Loss: 0.2286\n",
      "Epoch [25/1000], Loss: 0.2278\n",
      "Epoch [26/1000], Loss: 0.2270\n",
      "Epoch [27/1000], Loss: 0.2259\n",
      "Epoch [28/1000], Loss: 0.2248\n",
      "Epoch [29/1000], Loss: 0.2233\n",
      "Epoch [30/1000], Loss: 0.2217\n",
      "Epoch [31/1000], Loss: 0.2198\n",
      "Epoch [32/1000], Loss: 0.2174\n",
      "Epoch [33/1000], Loss: 0.2151\n",
      "Epoch [34/1000], Loss: 0.2127\n",
      "Epoch [35/1000], Loss: 0.2100\n",
      "Epoch [36/1000], Loss: 0.2072\n",
      "Epoch [37/1000], Loss: 0.2044\n",
      "Epoch [38/1000], Loss: 0.2013\n",
      "Epoch [39/1000], Loss: 0.1981\n",
      "Epoch [40/1000], Loss: 0.1948\n",
      "Epoch [41/1000], Loss: 0.1914\n",
      "Epoch [42/1000], Loss: 0.1876\n",
      "Epoch [43/1000], Loss: 0.1840\n",
      "Epoch [44/1000], Loss: 0.1806\n",
      "Epoch [45/1000], Loss: 0.1761\n",
      "Epoch [46/1000], Loss: 0.1723\n",
      "Epoch [47/1000], Loss: 0.1676\n",
      "Epoch [48/1000], Loss: 0.1623\n",
      "Epoch [49/1000], Loss: 0.1582\n",
      "Epoch [50/1000], Loss: 0.1538\n",
      "Epoch [51/1000], Loss: 0.1492\n",
      "Epoch [52/1000], Loss: 0.1435\n",
      "Epoch [53/1000], Loss: 0.1357\n",
      "Epoch [54/1000], Loss: 0.1266\n",
      "Epoch [55/1000], Loss: 0.1177\n",
      "Epoch [56/1000], Loss: 0.1087\n",
      "Epoch [57/1000], Loss: 0.0999\n",
      "Epoch [58/1000], Loss: 0.0920\n",
      "Epoch [59/1000], Loss: 0.0840\n",
      "Epoch [60/1000], Loss: 0.0773\n",
      "Epoch [61/1000], Loss: 0.0701\n",
      "Epoch [62/1000], Loss: 0.0628\n",
      "Epoch [63/1000], Loss: 0.0553\n",
      "Epoch [64/1000], Loss: 0.0491\n",
      "Epoch [65/1000], Loss: 0.0425\n",
      "Epoch [66/1000], Loss: 0.0375\n",
      "Epoch [67/1000], Loss: 0.0330\n",
      "Epoch [68/1000], Loss: 0.0288\n",
      "Epoch [69/1000], Loss: 0.0250\n",
      "Epoch [70/1000], Loss: 0.0226\n",
      "Epoch [71/1000], Loss: 0.0196\n",
      "Epoch [72/1000], Loss: 0.0172\n",
      "Epoch [73/1000], Loss: 0.0161\n",
      "Epoch [74/1000], Loss: 0.0138\n",
      "Epoch [75/1000], Loss: 0.0129\n",
      "Epoch [76/1000], Loss: 0.0112\n",
      "Epoch [77/1000], Loss: 0.0104\n",
      "Epoch [78/1000], Loss: 0.0091\n",
      "Epoch [79/1000], Loss: 0.0083\n",
      "Epoch [80/1000], Loss: 0.0074\n",
      "Epoch [81/1000], Loss: 0.0067\n",
      "Epoch [82/1000], Loss: 0.0065\n",
      "Epoch [83/1000], Loss: 0.0056\n",
      "Epoch [84/1000], Loss: 0.0053\n",
      "Epoch [85/1000], Loss: 0.0051\n",
      "Epoch [86/1000], Loss: 0.0046\n",
      "Epoch [87/1000], Loss: 0.0044\n",
      "Epoch [88/1000], Loss: 0.0041\n",
      "Epoch [89/1000], Loss: 0.0041\n",
      "Epoch [90/1000], Loss: 0.0037\n",
      "Epoch [91/1000], Loss: 0.0036\n",
      "Epoch [92/1000], Loss: 0.0033\n",
      "Epoch [93/1000], Loss: 0.0032\n",
      "Epoch [94/1000], Loss: 0.0030\n",
      "Epoch [95/1000], Loss: 0.0029\n",
      "Epoch [96/1000], Loss: 0.0028\n",
      "Epoch [97/1000], Loss: 0.0026\n",
      "Epoch [98/1000], Loss: 0.0026\n",
      "Epoch [99/1000], Loss: 0.0025\n",
      "Epoch [100/1000], Loss: 0.0024\n",
      "Epoch [101/1000], Loss: 0.0023\n",
      "Epoch [102/1000], Loss: 0.0023\n",
      "Epoch [103/1000], Loss: 0.0021\n",
      "Epoch [104/1000], Loss: 0.0020\n",
      "Epoch [105/1000], Loss: 0.0020\n",
      "Epoch [106/1000], Loss: 0.0019\n",
      "Epoch [107/1000], Loss: 0.0018\n",
      "Epoch [108/1000], Loss: 0.0018\n",
      "Epoch [109/1000], Loss: 0.0017\n",
      "Epoch [110/1000], Loss: 0.0017\n",
      "Epoch [111/1000], Loss: 0.0016\n",
      "Epoch [112/1000], Loss: 0.0016\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 4, activation : relu, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2505\n",
      "Epoch [2/1000], Loss: 0.2465\n",
      "Epoch [3/1000], Loss: 0.2436\n",
      "Epoch [4/1000], Loss: 0.2412\n",
      "Epoch [5/1000], Loss: 0.2392\n",
      "Epoch [6/1000], Loss: 0.2376\n",
      "Epoch [7/1000], Loss: 0.2366\n",
      "Epoch [8/1000], Loss: 0.2360\n",
      "Epoch [9/1000], Loss: 0.2354\n",
      "Epoch [10/1000], Loss: 0.2349\n",
      "Epoch [11/1000], Loss: 0.2346\n",
      "Epoch [12/1000], Loss: 0.2342\n",
      "Epoch [13/1000], Loss: 0.2338\n",
      "Epoch [14/1000], Loss: 0.2335\n",
      "Epoch [15/1000], Loss: 0.2331\n",
      "Epoch [16/1000], Loss: 0.2326\n",
      "Epoch [17/1000], Loss: 0.2322\n",
      "Epoch [18/1000], Loss: 0.2317\n",
      "Epoch [19/1000], Loss: 0.2311\n",
      "Epoch [20/1000], Loss: 0.2305\n",
      "Epoch [21/1000], Loss: 0.2299\n",
      "Epoch [22/1000], Loss: 0.2293\n",
      "Epoch [23/1000], Loss: 0.2285\n",
      "Epoch [24/1000], Loss: 0.2276\n",
      "Epoch [25/1000], Loss: 0.2266\n",
      "Epoch [26/1000], Loss: 0.2251\n",
      "Epoch [27/1000], Loss: 0.2234\n",
      "Epoch [28/1000], Loss: 0.2217\n",
      "Epoch [29/1000], Loss: 0.2195\n",
      "Epoch [30/1000], Loss: 0.2170\n",
      "Epoch [31/1000], Loss: 0.2140\n",
      "Epoch [32/1000], Loss: 0.2106\n",
      "Epoch [33/1000], Loss: 0.2062\n",
      "Epoch [34/1000], Loss: 0.2007\n",
      "Epoch [35/1000], Loss: 0.1932\n",
      "Epoch [36/1000], Loss: 0.1849\n",
      "Epoch [37/1000], Loss: 0.1744\n",
      "Epoch [38/1000], Loss: 0.1626\n",
      "Epoch [39/1000], Loss: 0.1499\n",
      "Epoch [40/1000], Loss: 0.1372\n",
      "Epoch [41/1000], Loss: 0.1249\n",
      "Epoch [42/1000], Loss: 0.1124\n",
      "Epoch [43/1000], Loss: 0.1017\n",
      "Epoch [44/1000], Loss: 0.0917\n",
      "Epoch [45/1000], Loss: 0.0813\n",
      "Epoch [46/1000], Loss: 0.0707\n",
      "Epoch [47/1000], Loss: 0.0613\n",
      "Epoch [48/1000], Loss: 0.0527\n",
      "Epoch [49/1000], Loss: 0.0466\n",
      "Epoch [50/1000], Loss: 0.0414\n",
      "Epoch [51/1000], Loss: 0.0376\n",
      "Epoch [52/1000], Loss: 0.0343\n",
      "Epoch [53/1000], Loss: 0.0315\n",
      "Epoch [54/1000], Loss: 0.0291\n",
      "Epoch [55/1000], Loss: 0.0271\n",
      "Epoch [56/1000], Loss: 0.0248\n",
      "Epoch [57/1000], Loss: 0.0227\n",
      "Epoch [58/1000], Loss: 0.0213\n",
      "Epoch [59/1000], Loss: 0.0198\n",
      "Epoch [60/1000], Loss: 0.0184\n",
      "Epoch [61/1000], Loss: 0.0171\n",
      "Epoch [62/1000], Loss: 0.0160\n",
      "Epoch [63/1000], Loss: 0.0147\n",
      "Epoch [64/1000], Loss: 0.0138\n",
      "Epoch [65/1000], Loss: 0.0128\n",
      "Epoch [66/1000], Loss: 0.0115\n",
      "Epoch [67/1000], Loss: 0.0103\n",
      "Epoch [68/1000], Loss: 0.0089\n",
      "Epoch [69/1000], Loss: 0.0078\n",
      "Epoch [70/1000], Loss: 0.0064\n",
      "Epoch [71/1000], Loss: 0.0055\n",
      "Epoch [72/1000], Loss: 0.0048\n",
      "Epoch [73/1000], Loss: 0.0043\n",
      "Epoch [74/1000], Loss: 0.0038\n",
      "Epoch [75/1000], Loss: 0.0034\n",
      "Epoch [76/1000], Loss: 0.0030\n",
      "Epoch [77/1000], Loss: 0.0027\n",
      "Epoch [78/1000], Loss: 0.0025\n",
      "Epoch [79/1000], Loss: 0.0022\n",
      "Epoch [80/1000], Loss: 0.0020\n",
      "Epoch [81/1000], Loss: 0.0019\n",
      "Epoch [82/1000], Loss: 0.0017\n",
      "Epoch [83/1000], Loss: 0.0016\n",
      "Epoch [84/1000], Loss: 0.0015\n",
      "Epoch [85/1000], Loss: 0.0014\n",
      "Epoch [86/1000], Loss: 0.0013\n",
      "Epoch [87/1000], Loss: 0.0012\n",
      "Epoch [88/1000], Loss: 0.0012\n",
      "Epoch [89/1000], Loss: 0.0011\n",
      "Epoch [90/1000], Loss: 0.0011\n",
      "Epoch [91/1000], Loss: 0.0010\n",
      "Epoch [92/1000], Loss: 0.0010\n",
      "Epoch [93/1000], Loss: 0.0009\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 4, activation : lrelu, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2586\n",
      "Epoch [2/1000], Loss: 0.2522\n",
      "Epoch [3/1000], Loss: 0.2501\n",
      "Epoch [4/1000], Loss: 0.2492\n",
      "Epoch [5/1000], Loss: 0.2488\n",
      "Epoch [6/1000], Loss: 0.2485\n",
      "Epoch [7/1000], Loss: 0.2482\n",
      "Epoch [8/1000], Loss: 0.2480\n",
      "Epoch [9/1000], Loss: 0.2477\n",
      "Epoch [10/1000], Loss: 0.2474\n",
      "Epoch [11/1000], Loss: 0.2470\n",
      "Epoch [12/1000], Loss: 0.2465\n",
      "Epoch [13/1000], Loss: 0.2457\n",
      "Epoch [14/1000], Loss: 0.2447\n",
      "Epoch [15/1000], Loss: 0.2436\n",
      "Epoch [16/1000], Loss: 0.2426\n",
      "Epoch [17/1000], Loss: 0.2417\n",
      "Epoch [18/1000], Loss: 0.2410\n",
      "Epoch [19/1000], Loss: 0.2404\n",
      "Epoch [20/1000], Loss: 0.2399\n",
      "Epoch [21/1000], Loss: 0.2395\n",
      "Epoch [22/1000], Loss: 0.2392\n",
      "Epoch [23/1000], Loss: 0.2389\n",
      "Epoch [24/1000], Loss: 0.2388\n",
      "Epoch [25/1000], Loss: 0.2385\n",
      "Epoch [26/1000], Loss: 0.2383\n",
      "Epoch [27/1000], Loss: 0.2382\n",
      "Epoch [28/1000], Loss: 0.2380\n",
      "Epoch [29/1000], Loss: 0.2379\n",
      "Epoch [30/1000], Loss: 0.2378\n",
      "Epoch [31/1000], Loss: 0.2376\n",
      "Epoch [32/1000], Loss: 0.2375\n",
      "Epoch [33/1000], Loss: 0.2374\n",
      "Epoch [34/1000], Loss: 0.2374\n",
      "Epoch [35/1000], Loss: 0.2373\n",
      "Epoch [36/1000], Loss: 0.2371\n",
      "Epoch [37/1000], Loss: 0.2370\n",
      "Epoch [38/1000], Loss: 0.2370\n",
      "Epoch [39/1000], Loss: 0.2368\n",
      "Epoch [40/1000], Loss: 0.2367\n",
      "Epoch [41/1000], Loss: 0.2366\n",
      "Epoch [42/1000], Loss: 0.2365\n",
      "Epoch [43/1000], Loss: 0.2364\n",
      "Epoch [44/1000], Loss: 0.2363\n",
      "Epoch [45/1000], Loss: 0.2362\n",
      "Epoch [46/1000], Loss: 0.2361\n",
      "Epoch [47/1000], Loss: 0.2360\n",
      "Epoch [48/1000], Loss: 0.2358\n",
      "Epoch [49/1000], Loss: 0.2357\n",
      "Epoch [50/1000], Loss: 0.2356\n",
      "Epoch [51/1000], Loss: 0.2354\n",
      "Epoch [52/1000], Loss: 0.2352\n",
      "Epoch [53/1000], Loss: 0.2349\n",
      "Epoch [54/1000], Loss: 0.2346\n",
      "Epoch [55/1000], Loss: 0.2342\n",
      "Epoch [56/1000], Loss: 0.2339\n",
      "Epoch [57/1000], Loss: 0.2338\n",
      "Epoch [58/1000], Loss: 0.2335\n",
      "Epoch [59/1000], Loss: 0.2332\n",
      "Epoch [60/1000], Loss: 0.2330\n",
      "Epoch [61/1000], Loss: 0.2326\n",
      "Epoch [62/1000], Loss: 0.2325\n",
      "Epoch [63/1000], Loss: 0.2321\n",
      "Epoch [64/1000], Loss: 0.2318\n",
      "Epoch [65/1000], Loss: 0.2314\n",
      "Epoch [66/1000], Loss: 0.2309\n",
      "Epoch [67/1000], Loss: 0.2305\n",
      "Epoch [68/1000], Loss: 0.2301\n",
      "Epoch [69/1000], Loss: 0.2295\n",
      "Epoch [70/1000], Loss: 0.2289\n",
      "Epoch [71/1000], Loss: 0.2283\n",
      "Epoch [72/1000], Loss: 0.2277\n",
      "Epoch [73/1000], Loss: 0.2269\n",
      "Epoch [74/1000], Loss: 0.2262\n",
      "Epoch [75/1000], Loss: 0.2253\n",
      "Epoch [76/1000], Loss: 0.2244\n",
      "Epoch [77/1000], Loss: 0.2236\n",
      "Epoch [78/1000], Loss: 0.2226\n",
      "Epoch [79/1000], Loss: 0.2218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/1000], Loss: 0.2208\n",
      "Epoch [81/1000], Loss: 0.2199\n",
      "Epoch [82/1000], Loss: 0.2189\n",
      "Epoch [83/1000], Loss: 0.2178\n",
      "Epoch [84/1000], Loss: 0.2167\n",
      "Epoch [85/1000], Loss: 0.2157\n",
      "Epoch [86/1000], Loss: 0.2145\n",
      "Epoch [87/1000], Loss: 0.2133\n",
      "Epoch [88/1000], Loss: 0.2121\n",
      "Epoch [89/1000], Loss: 0.2107\n",
      "Epoch [90/1000], Loss: 0.2094\n",
      "Epoch [91/1000], Loss: 0.2079\n",
      "Epoch [92/1000], Loss: 0.2067\n",
      "Epoch [93/1000], Loss: 0.2058\n",
      "Epoch [94/1000], Loss: 0.2047\n",
      "Epoch [95/1000], Loss: 0.2035\n",
      "Epoch [96/1000], Loss: 0.2020\n",
      "Epoch [97/1000], Loss: 0.2008\n",
      "Epoch [98/1000], Loss: 0.1998\n",
      "Epoch [99/1000], Loss: 0.1986\n",
      "Epoch [100/1000], Loss: 0.1976\n",
      "Epoch [101/1000], Loss: 0.1963\n",
      "Epoch [102/1000], Loss: 0.1946\n",
      "Epoch [103/1000], Loss: 0.1928\n",
      "Epoch [104/1000], Loss: 0.1909\n",
      "Epoch [105/1000], Loss: 0.1894\n",
      "Epoch [106/1000], Loss: 0.1881\n",
      "Epoch [107/1000], Loss: 0.1865\n",
      "Epoch [108/1000], Loss: 0.1861\n",
      "Epoch [109/1000], Loss: 0.1852\n",
      "Epoch [110/1000], Loss: 0.1844\n",
      "Epoch [111/1000], Loss: 0.1838\n",
      "Epoch [112/1000], Loss: 0.1834\n",
      "Epoch [113/1000], Loss: 0.1826\n",
      "Epoch [114/1000], Loss: 0.1819\n",
      "Epoch [115/1000], Loss: 0.1814\n",
      "Epoch [116/1000], Loss: 0.1810\n",
      "Epoch [117/1000], Loss: 0.1807\n",
      "Epoch [118/1000], Loss: 0.1797\n",
      "Epoch [119/1000], Loss: 0.1797\n",
      "Epoch [120/1000], Loss: 0.1792\n",
      "Epoch [121/1000], Loss: 0.1788\n",
      "Epoch [122/1000], Loss: 0.1787\n",
      "Epoch [123/1000], Loss: 0.1785\n",
      "Epoch [124/1000], Loss: 0.1778\n",
      "Epoch [125/1000], Loss: 0.1780\n",
      "Epoch [126/1000], Loss: 0.1769\n",
      "Epoch [127/1000], Loss: 0.1756\n",
      "Epoch [128/1000], Loss: 0.1765\n",
      "Epoch [129/1000], Loss: 0.1761\n",
      "Epoch [130/1000], Loss: 0.1760\n",
      "Epoch [131/1000], Loss: 0.1753\n",
      "Epoch [132/1000], Loss: 0.1746\n",
      "Epoch [133/1000], Loss: 0.1752\n",
      "Epoch [134/1000], Loss: 0.1751\n",
      "Epoch [135/1000], Loss: 0.1740\n",
      "Epoch [136/1000], Loss: 0.1735\n",
      "Epoch [137/1000], Loss: 0.1742\n",
      "Epoch [138/1000], Loss: 0.1718\n",
      "Epoch [139/1000], Loss: 0.1714\n",
      "Epoch [140/1000], Loss: 0.1720\n",
      "Epoch [141/1000], Loss: 0.1719\n",
      "Epoch [142/1000], Loss: 0.1705\n",
      "Epoch [143/1000], Loss: 0.1719\n",
      "Epoch [144/1000], Loss: 0.1698\n",
      "Epoch [145/1000], Loss: 0.1684\n",
      "Epoch [146/1000], Loss: 0.1692\n",
      "Epoch [147/1000], Loss: 0.1686\n",
      "Epoch [148/1000], Loss: 0.1680\n",
      "Epoch [149/1000], Loss: 0.1670\n",
      "Epoch [150/1000], Loss: 0.1667\n",
      "Epoch [151/1000], Loss: 0.1656\n",
      "Epoch [152/1000], Loss: 0.1646\n",
      "Epoch [153/1000], Loss: 0.1638\n",
      "Epoch [154/1000], Loss: 0.1634\n",
      "Epoch [155/1000], Loss: 0.1620\n",
      "Epoch [156/1000], Loss: 0.1614\n",
      "Epoch [157/1000], Loss: 0.1604\n",
      "Epoch [158/1000], Loss: 0.1593\n",
      "Epoch [159/1000], Loss: 0.1582\n",
      "Epoch [160/1000], Loss: 0.1580\n",
      "Epoch [161/1000], Loss: 0.1565\n",
      "Epoch [162/1000], Loss: 0.1553\n",
      "Epoch [163/1000], Loss: 0.1538\n",
      "Epoch [164/1000], Loss: 0.1526\n",
      "Epoch [165/1000], Loss: 0.1512\n",
      "Epoch [166/1000], Loss: 0.1511\n",
      "Epoch [167/1000], Loss: 0.1513\n",
      "Epoch [168/1000], Loss: 0.1482\n",
      "Epoch [169/1000], Loss: 0.1465\n",
      "Epoch [170/1000], Loss: 0.1453\n",
      "Epoch [171/1000], Loss: 0.1446\n",
      "Epoch [172/1000], Loss: 0.1427\n",
      "Epoch [173/1000], Loss: 0.1417\n",
      "Epoch [174/1000], Loss: 0.1394\n",
      "Epoch [175/1000], Loss: 0.1386\n",
      "Epoch [176/1000], Loss: 0.1339\n",
      "Epoch [177/1000], Loss: 0.1311\n",
      "Epoch [178/1000], Loss: 0.1271\n",
      "Epoch [179/1000], Loss: 0.1242\n",
      "Epoch [180/1000], Loss: 0.1221\n",
      "Epoch [181/1000], Loss: 0.1196\n",
      "Epoch [182/1000], Loss: 0.1168\n",
      "Epoch [183/1000], Loss: 0.1147\n",
      "Epoch [184/1000], Loss: 0.1118\n",
      "Epoch [185/1000], Loss: 0.1069\n",
      "Epoch [186/1000], Loss: 0.0983\n",
      "Epoch [187/1000], Loss: 0.0885\n",
      "Epoch [188/1000], Loss: 0.0798\n",
      "Epoch [189/1000], Loss: 0.0751\n",
      "Epoch [190/1000], Loss: 0.0714\n",
      "Epoch [191/1000], Loss: 0.0701\n",
      "Epoch [192/1000], Loss: 0.0662\n",
      "Epoch [193/1000], Loss: 0.0639\n",
      "Epoch [194/1000], Loss: 0.0642\n",
      "Epoch [195/1000], Loss: 0.0604\n",
      "Epoch [196/1000], Loss: 0.0592\n",
      "Epoch [197/1000], Loss: 0.0551\n",
      "Epoch [198/1000], Loss: 0.0579\n",
      "Epoch [199/1000], Loss: 0.0555\n",
      "Epoch [200/1000], Loss: 0.0536\n",
      "Epoch [201/1000], Loss: 0.0496\n",
      "Epoch [202/1000], Loss: 0.0533\n",
      "Epoch [203/1000], Loss: 0.0538\n",
      "Epoch [204/1000], Loss: 0.0523\n",
      "Epoch [205/1000], Loss: 0.0487\n",
      "Epoch [206/1000], Loss: 0.0454\n",
      "Epoch [207/1000], Loss: 0.0475\n",
      "Epoch [208/1000], Loss: 0.0469\n",
      "Epoch [209/1000], Loss: 0.0423\n",
      "Epoch [210/1000], Loss: 0.0454\n",
      "Epoch [211/1000], Loss: 0.0465\n",
      "Epoch [212/1000], Loss: 0.0427\n",
      "Epoch [213/1000], Loss: 0.0441\n",
      "Epoch [214/1000], Loss: 0.0456\n",
      "Epoch [215/1000], Loss: 0.0432\n",
      "Epoch [216/1000], Loss: 0.0428\n",
      "Epoch [217/1000], Loss: 0.0357\n",
      "Epoch [218/1000], Loss: 0.0327\n",
      "Epoch [219/1000], Loss: 0.0312\n",
      "Epoch [220/1000], Loss: 0.0292\n",
      "Epoch [221/1000], Loss: 0.0328\n",
      "Epoch [222/1000], Loss: 0.0324\n",
      "Epoch [223/1000], Loss: 0.0293\n",
      "Epoch [224/1000], Loss: 0.0279\n",
      "Epoch [225/1000], Loss: 0.0374\n",
      "Epoch [226/1000], Loss: 0.0271\n",
      "Epoch [227/1000], Loss: 0.0287\n",
      "Epoch [228/1000], Loss: 0.0266\n",
      "Epoch [229/1000], Loss: 0.0325\n",
      "Epoch [230/1000], Loss: 0.0433\n",
      "Epoch [231/1000], Loss: 0.0339\n",
      "Epoch [232/1000], Loss: 0.0295\n",
      "Epoch [233/1000], Loss: 0.0278\n",
      "Epoch [234/1000], Loss: 0.0342\n",
      "Epoch [235/1000], Loss: 0.0249\n",
      "Epoch [236/1000], Loss: 0.0277\n",
      "Epoch [237/1000], Loss: 0.0291\n",
      "Epoch [238/1000], Loss: 0.0256\n",
      "Epoch [239/1000], Loss: 0.0258\n",
      "Epoch [240/1000], Loss: 0.0303\n",
      "Epoch [241/1000], Loss: 0.0283\n",
      "Epoch [242/1000], Loss: 0.0299\n",
      "Epoch [243/1000], Loss: 0.0301\n",
      "Epoch [244/1000], Loss: 0.0297\n",
      "Epoch [245/1000], Loss: 0.0290\n",
      "Epoch [246/1000], Loss: 0.0273\n",
      "Epoch [247/1000], Loss: 0.0282\n",
      "Epoch [248/1000], Loss: 0.0267\n",
      "Epoch [249/1000], Loss: 0.0248\n",
      "Epoch [250/1000], Loss: 0.0293\n",
      "Epoch [251/1000], Loss: 0.0305\n",
      "Epoch [252/1000], Loss: 0.0229\n",
      "Epoch [253/1000], Loss: 0.0283\n",
      "Epoch [254/1000], Loss: 0.0263\n",
      "Epoch [255/1000], Loss: 0.0238\n",
      "Epoch [256/1000], Loss: 0.0240\n",
      "Epoch [257/1000], Loss: 0.0305\n",
      "Epoch [258/1000], Loss: 0.0248\n",
      "Epoch [259/1000], Loss: 0.0268\n",
      "Epoch [260/1000], Loss: 0.0306\n",
      "Epoch [261/1000], Loss: 0.0301\n",
      "Epoch [262/1000], Loss: 0.0252\n",
      "Epoch [263/1000], Loss: 0.0239\n",
      "Epoch [264/1000], Loss: 0.0294\n",
      "Epoch [265/1000], Loss: 0.0277\n",
      "Epoch [266/1000], Loss: 0.0309\n",
      "Epoch [267/1000], Loss: 0.0300\n",
      "Epoch [268/1000], Loss: 0.0248\n",
      "Epoch [269/1000], Loss: 0.0244\n",
      "Epoch [270/1000], Loss: 0.0272\n",
      "Epoch [271/1000], Loss: 0.0256\n",
      "Epoch [272/1000], Loss: 0.0215\n",
      "Epoch [273/1000], Loss: 0.0204\n",
      "Epoch [274/1000], Loss: 0.0280\n",
      "Epoch [275/1000], Loss: 0.0246\n",
      "Epoch [276/1000], Loss: 0.0209\n",
      "Epoch [277/1000], Loss: 0.0295\n",
      "Epoch [278/1000], Loss: 0.0239\n",
      "Epoch [279/1000], Loss: 0.0256\n",
      "Epoch [280/1000], Loss: 0.0230\n",
      "Epoch [281/1000], Loss: 0.0250\n",
      "Epoch [282/1000], Loss: 0.0227\n",
      "Epoch [283/1000], Loss: 0.0253\n",
      "Epoch [284/1000], Loss: 0.0218\n",
      "Epoch [285/1000], Loss: 0.0256\n",
      "Epoch [286/1000], Loss: 0.0204\n",
      "Epoch [287/1000], Loss: 0.0196\n",
      "Epoch [288/1000], Loss: 0.0270\n",
      "Epoch [289/1000], Loss: 0.0228\n",
      "Epoch [290/1000], Loss: 0.0256\n",
      "Epoch [291/1000], Loss: 0.0253\n",
      "Epoch [292/1000], Loss: 0.0242\n",
      "Epoch [293/1000], Loss: 0.0289\n",
      "Epoch [294/1000], Loss: 0.0247\n",
      "Epoch [295/1000], Loss: 0.0256\n",
      "Epoch [296/1000], Loss: 0.0308\n",
      "Epoch [297/1000], Loss: 0.0226\n",
      "Epoch [298/1000], Loss: 0.0204\n",
      "Epoch [299/1000], Loss: 0.0175\n",
      "Epoch [300/1000], Loss: 0.0204\n",
      "Epoch [301/1000], Loss: 0.0206\n",
      "Epoch [302/1000], Loss: 0.0229\n",
      "Epoch [303/1000], Loss: 0.0228\n",
      "Epoch [304/1000], Loss: 0.0219\n",
      "Epoch [305/1000], Loss: 0.0197\n",
      "Epoch [306/1000], Loss: 0.0243\n",
      "Epoch [307/1000], Loss: 0.0200\n",
      "Epoch [308/1000], Loss: 0.0212\n",
      "Epoch [309/1000], Loss: 0.0174\n",
      "Epoch [310/1000], Loss: 0.0228\n",
      "Epoch [311/1000], Loss: 0.0221\n",
      "Epoch [312/1000], Loss: 0.0200\n",
      "Epoch [313/1000], Loss: 0.0248\n",
      "Epoch [314/1000], Loss: 0.0197\n",
      "Epoch [315/1000], Loss: 0.0193\n",
      "Epoch [316/1000], Loss: 0.0211\n",
      "Epoch [317/1000], Loss: 0.0211\n",
      "Epoch [318/1000], Loss: 0.0167\n",
      "Epoch [319/1000], Loss: 0.0203\n",
      "Epoch [320/1000], Loss: 0.0174\n",
      "Epoch [321/1000], Loss: 0.0192\n",
      "Epoch [322/1000], Loss: 0.0186\n",
      "Epoch [323/1000], Loss: 0.0260\n",
      "Epoch [324/1000], Loss: 0.0191\n",
      "Epoch [325/1000], Loss: 0.0262\n",
      "Epoch [326/1000], Loss: 0.0219\n",
      "Epoch [327/1000], Loss: 0.0241\n",
      "Epoch [328/1000], Loss: 0.0174\n",
      "Epoch [329/1000], Loss: 0.0175\n",
      "Epoch [330/1000], Loss: 0.0198\n",
      "Epoch [331/1000], Loss: 0.0202\n",
      "Epoch [332/1000], Loss: 0.0203\n",
      "Epoch [333/1000], Loss: 0.0226\n",
      "Epoch [334/1000], Loss: 0.0273\n",
      "Epoch [335/1000], Loss: 0.0218\n",
      "Epoch [336/1000], Loss: 0.0198\n",
      "Epoch [337/1000], Loss: 0.0194\n",
      "Epoch [338/1000], Loss: 0.0202\n",
      "Epoch [339/1000], Loss: 0.0137\n",
      "Epoch [340/1000], Loss: 0.0161\n",
      "Epoch [341/1000], Loss: 0.0200\n",
      "Epoch [342/1000], Loss: 0.0172\n",
      "Epoch [343/1000], Loss: 0.0205\n",
      "Epoch [344/1000], Loss: 0.0177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [345/1000], Loss: 0.0166\n",
      "Epoch [346/1000], Loss: 0.0144\n",
      "Epoch [347/1000], Loss: 0.0152\n",
      "Epoch [348/1000], Loss: 0.0175\n",
      "Epoch [349/1000], Loss: 0.0183\n",
      "Epoch [350/1000], Loss: 0.0169\n",
      "Epoch [351/1000], Loss: 0.0159\n",
      "Epoch [352/1000], Loss: 0.0155\n",
      "Epoch [353/1000], Loss: 0.0167\n",
      "Epoch [354/1000], Loss: 0.0141\n",
      "Epoch [355/1000], Loss: 0.0138\n",
      "Epoch [356/1000], Loss: 0.0137\n",
      "Epoch [357/1000], Loss: 0.0167\n",
      "Epoch [358/1000], Loss: 0.0121\n",
      "Epoch [359/1000], Loss: 0.0164\n",
      "Epoch [360/1000], Loss: 0.0148\n",
      "Epoch [361/1000], Loss: 0.0145\n",
      "Epoch [362/1000], Loss: 0.0153\n",
      "Epoch [363/1000], Loss: 0.0119\n",
      "Epoch [364/1000], Loss: 0.0127\n",
      "Epoch [365/1000], Loss: 0.0162\n",
      "Epoch [366/1000], Loss: 0.0136\n",
      "Epoch [367/1000], Loss: 0.0113\n",
      "Epoch [368/1000], Loss: 0.0180\n",
      "Epoch [369/1000], Loss: 0.0170\n",
      "Epoch [370/1000], Loss: 0.0119\n",
      "Epoch [371/1000], Loss: 0.0124\n",
      "Epoch [372/1000], Loss: 0.0096\n",
      "Epoch [373/1000], Loss: 0.0094\n",
      "Epoch [374/1000], Loss: 0.0119\n",
      "Epoch [375/1000], Loss: 0.0106\n",
      "Epoch [376/1000], Loss: 0.0175\n",
      "Epoch [377/1000], Loss: 0.0113\n",
      "Epoch [378/1000], Loss: 0.0097\n",
      "Epoch [379/1000], Loss: 0.0133\n",
      "Epoch [380/1000], Loss: 0.0114\n",
      "Epoch [381/1000], Loss: 0.0143\n",
      "Epoch [382/1000], Loss: 0.0151\n",
      "Epoch [383/1000], Loss: 0.0117\n",
      "Epoch [384/1000], Loss: 0.0134\n",
      "Epoch [385/1000], Loss: 0.0091\n",
      "Epoch [386/1000], Loss: 0.0100\n",
      "Epoch [387/1000], Loss: 0.0163\n",
      "Epoch [388/1000], Loss: 0.0119\n",
      "Epoch [389/1000], Loss: 0.0114\n",
      "Epoch [390/1000], Loss: 0.0155\n",
      "Epoch [391/1000], Loss: 0.0138\n",
      "Epoch [392/1000], Loss: 0.0117\n",
      "Epoch [393/1000], Loss: 0.0131\n",
      "Epoch [394/1000], Loss: 0.0114\n",
      "Epoch [395/1000], Loss: 0.0117\n",
      "Epoch [396/1000], Loss: 0.0101\n",
      "Epoch [397/1000], Loss: 0.0099\n",
      "Epoch [398/1000], Loss: 0.0124\n",
      "Epoch [399/1000], Loss: 0.0141\n",
      "Epoch [400/1000], Loss: 0.0123\n",
      "Epoch [401/1000], Loss: 0.0111\n",
      "Epoch [402/1000], Loss: 0.0116\n",
      "Epoch [403/1000], Loss: 0.0113\n",
      "Epoch [404/1000], Loss: 0.0097\n",
      "Epoch [405/1000], Loss: 0.0116\n",
      "Epoch [406/1000], Loss: 0.0120\n",
      "Epoch [407/1000], Loss: 0.0091\n",
      "Epoch [408/1000], Loss: 0.0085\n",
      "Epoch [409/1000], Loss: 0.0099\n",
      "Epoch [410/1000], Loss: 0.0107\n",
      "Epoch [411/1000], Loss: 0.0111\n",
      "Epoch [412/1000], Loss: 0.0097\n",
      "Epoch [413/1000], Loss: 0.0116\n",
      "Epoch [414/1000], Loss: 0.0101\n",
      "Epoch [415/1000], Loss: 0.0102\n",
      "Epoch [416/1000], Loss: 0.0086\n",
      "Epoch [417/1000], Loss: 0.0077\n",
      "Epoch [418/1000], Loss: 0.0127\n",
      "Epoch [419/1000], Loss: 0.0133\n",
      "Epoch [420/1000], Loss: 0.0088\n",
      "Epoch [421/1000], Loss: 0.0093\n",
      "Epoch [422/1000], Loss: 0.0115\n",
      "Epoch [423/1000], Loss: 0.0108\n",
      "Epoch [424/1000], Loss: 0.0080\n",
      "Epoch [425/1000], Loss: 0.0122\n",
      "Epoch [426/1000], Loss: 0.0119\n",
      "Epoch [427/1000], Loss: 0.0092\n",
      "Epoch [428/1000], Loss: 0.0111\n",
      "Epoch [429/1000], Loss: 0.0085\n",
      "Epoch [430/1000], Loss: 0.0174\n",
      "Epoch [431/1000], Loss: 0.0115\n",
      "Epoch [432/1000], Loss: 0.0106\n",
      "Epoch [433/1000], Loss: 0.0090\n",
      "Epoch [434/1000], Loss: 0.0126\n",
      "Epoch [435/1000], Loss: 0.0108\n",
      "Epoch [436/1000], Loss: 0.0106\n",
      "Epoch [437/1000], Loss: 0.0095\n",
      "Epoch [438/1000], Loss: 0.0096\n",
      "Epoch [439/1000], Loss: 0.0111\n",
      "Epoch [440/1000], Loss: 0.0080\n",
      "Epoch [441/1000], Loss: 0.0104\n",
      "Epoch [442/1000], Loss: 0.0110\n",
      "Epoch [443/1000], Loss: 0.0100\n",
      "Epoch [444/1000], Loss: 0.0135\n",
      "Epoch [445/1000], Loss: 0.0076\n",
      "Epoch [446/1000], Loss: 0.0094\n",
      "Epoch [447/1000], Loss: 0.0096\n",
      "Epoch [448/1000], Loss: 0.0110\n",
      "Epoch [449/1000], Loss: 0.0098\n",
      "Epoch [450/1000], Loss: 0.0107\n",
      "Epoch [451/1000], Loss: 0.0112\n",
      "Epoch [452/1000], Loss: 0.0086\n",
      "Epoch [453/1000], Loss: 0.0090\n",
      "Epoch [454/1000], Loss: 0.0111\n",
      "Epoch [455/1000], Loss: 0.0084\n",
      "Epoch [456/1000], Loss: 0.0084\n",
      "Epoch [457/1000], Loss: 0.0147\n",
      "Epoch [458/1000], Loss: 0.0156\n",
      "Epoch [459/1000], Loss: 0.0141\n",
      "Epoch [460/1000], Loss: 0.0108\n",
      "Epoch [461/1000], Loss: 0.0090\n",
      "Epoch [462/1000], Loss: 0.0100\n",
      "Epoch [463/1000], Loss: 0.0082\n",
      "Epoch [464/1000], Loss: 0.0093\n",
      "Epoch [465/1000], Loss: 0.0086\n",
      "Epoch [466/1000], Loss: 0.0159\n",
      "Epoch [467/1000], Loss: 0.0102\n",
      "Epoch [468/1000], Loss: 0.0098\n",
      "Epoch [469/1000], Loss: 0.0105\n",
      "Epoch [470/1000], Loss: 0.0127\n",
      "Epoch [471/1000], Loss: 0.0084\n",
      "Epoch [472/1000], Loss: 0.0102\n",
      "Epoch [473/1000], Loss: 0.0092\n",
      "Epoch [474/1000], Loss: 0.0102\n",
      "Epoch [475/1000], Loss: 0.0102\n",
      "Epoch [476/1000], Loss: 0.0116\n",
      "Epoch [477/1000], Loss: 0.0110\n",
      "Epoch [478/1000], Loss: 0.0105\n",
      "Epoch [479/1000], Loss: 0.0096\n",
      "Epoch [480/1000], Loss: 0.0100\n",
      "Epoch [481/1000], Loss: 0.0099\n",
      "Epoch [482/1000], Loss: 0.0080\n",
      "Epoch [483/1000], Loss: 0.0106\n",
      "Epoch [484/1000], Loss: 0.0096\n",
      "Epoch [485/1000], Loss: 0.0102\n",
      "Epoch [486/1000], Loss: 0.0122\n",
      "Epoch [487/1000], Loss: 0.0104\n",
      "Epoch [488/1000], Loss: 0.0101\n",
      "Epoch [489/1000], Loss: 0.0088\n",
      "Epoch [490/1000], Loss: 0.0079\n",
      "Epoch [491/1000], Loss: 0.0065\n",
      "Epoch [492/1000], Loss: 0.0074\n",
      "Epoch [493/1000], Loss: 0.0076\n",
      "Epoch [494/1000], Loss: 0.0075\n",
      "Epoch [495/1000], Loss: 0.0068\n",
      "Epoch [496/1000], Loss: 0.0111\n",
      "Epoch [497/1000], Loss: 0.0091\n",
      "Epoch [498/1000], Loss: 0.0082\n",
      "Epoch [499/1000], Loss: 0.0192\n",
      "Epoch [500/1000], Loss: 0.0121\n",
      "Epoch [501/1000], Loss: 0.0115\n",
      "Epoch [502/1000], Loss: 0.0103\n",
      "Epoch [503/1000], Loss: 0.0096\n",
      "Epoch [504/1000], Loss: 0.0093\n",
      "Epoch [505/1000], Loss: 0.0078\n",
      "Epoch [506/1000], Loss: 0.0101\n",
      "Epoch [507/1000], Loss: 0.0103\n",
      "Epoch [508/1000], Loss: 0.0078\n",
      "Epoch [509/1000], Loss: 0.0074\n",
      "Epoch [510/1000], Loss: 0.0117\n",
      "Epoch [511/1000], Loss: 0.0062\n",
      "Epoch [512/1000], Loss: 0.0091\n",
      "Epoch [513/1000], Loss: 0.0113\n",
      "Epoch [514/1000], Loss: 0.0092\n",
      "Epoch [515/1000], Loss: 0.0128\n",
      "Epoch [516/1000], Loss: 0.0076\n",
      "Epoch [517/1000], Loss: 0.0056\n",
      "Epoch [518/1000], Loss: 0.0150\n",
      "Epoch [519/1000], Loss: 0.0098\n",
      "Epoch [520/1000], Loss: 0.0155\n",
      "Epoch [521/1000], Loss: 0.0103\n",
      "Epoch [522/1000], Loss: 0.0106\n",
      "Epoch [523/1000], Loss: 0.0082\n",
      "Epoch [524/1000], Loss: 0.0079\n",
      "Epoch [525/1000], Loss: 0.0100\n",
      "Epoch [526/1000], Loss: 0.0096\n",
      "Epoch [527/1000], Loss: 0.0102\n",
      "Epoch [528/1000], Loss: 0.0086\n",
      "Epoch [529/1000], Loss: 0.0085\n",
      "Epoch [530/1000], Loss: 0.0182\n",
      "Epoch [531/1000], Loss: 0.0087\n",
      "Epoch [532/1000], Loss: 0.0105\n",
      "Epoch [533/1000], Loss: 0.0059\n",
      "Epoch [534/1000], Loss: 0.0080\n",
      "Epoch [535/1000], Loss: 0.0121\n",
      "Epoch [536/1000], Loss: 0.0145\n",
      "Epoch [537/1000], Loss: 0.0113\n",
      "Epoch [538/1000], Loss: 0.0071\n",
      "Epoch [539/1000], Loss: 0.0066\n",
      "Epoch [540/1000], Loss: 0.0095\n",
      "Epoch [541/1000], Loss: 0.0083\n",
      "Epoch [542/1000], Loss: 0.0120\n",
      "Epoch [543/1000], Loss: 0.0085\n",
      "Epoch [544/1000], Loss: 0.0115\n",
      "Epoch [545/1000], Loss: 0.0087\n",
      "Epoch [546/1000], Loss: 0.0070\n",
      "Epoch [547/1000], Loss: 0.0104\n",
      "Epoch [548/1000], Loss: 0.0092\n",
      "Epoch [549/1000], Loss: 0.0116\n",
      "Epoch [550/1000], Loss: 0.0096\n",
      "Epoch [551/1000], Loss: 0.0056\n",
      "Epoch [552/1000], Loss: 0.0091\n",
      "Epoch [553/1000], Loss: 0.0084\n",
      "Epoch [554/1000], Loss: 0.0077\n",
      "Epoch [555/1000], Loss: 0.0108\n",
      "Epoch [556/1000], Loss: 0.0095\n",
      "Epoch [557/1000], Loss: 0.0062\n",
      "Epoch [558/1000], Loss: 0.0067\n",
      "Epoch [559/1000], Loss: 0.0139\n",
      "Epoch [560/1000], Loss: 0.0072\n",
      "Epoch [561/1000], Loss: 0.0063\n",
      "Epoch [562/1000], Loss: 0.0091\n",
      "Epoch [563/1000], Loss: 0.0099\n",
      "Epoch [564/1000], Loss: 0.0112\n",
      "Epoch [565/1000], Loss: 0.0065\n",
      "Epoch [566/1000], Loss: 0.0060\n",
      "Epoch [567/1000], Loss: 0.0152\n",
      "Epoch [568/1000], Loss: 0.0126\n",
      "Epoch [569/1000], Loss: 0.0127\n",
      "Epoch [570/1000], Loss: 0.0107\n",
      "Epoch [571/1000], Loss: 0.0072\n",
      "Epoch [572/1000], Loss: 0.0080\n",
      "Epoch [573/1000], Loss: 0.0091\n",
      "Epoch [574/1000], Loss: 0.0101\n",
      "Epoch [575/1000], Loss: 0.0115\n",
      "Epoch [576/1000], Loss: 0.0076\n",
      "Epoch [577/1000], Loss: 0.0107\n",
      "Epoch [578/1000], Loss: 0.0083\n",
      "Epoch [579/1000], Loss: 0.0071\n",
      "Epoch [580/1000], Loss: 0.0086\n",
      "Epoch [581/1000], Loss: 0.0067\n",
      "Epoch [582/1000], Loss: 0.0071\n",
      "Epoch [583/1000], Loss: 0.0072\n",
      "Epoch [584/1000], Loss: 0.0082\n",
      "Epoch [585/1000], Loss: 0.0133\n",
      "Epoch [586/1000], Loss: 0.0097\n",
      "Epoch [587/1000], Loss: 0.0129\n",
      "Epoch [588/1000], Loss: 0.0089\n",
      "Epoch [589/1000], Loss: 0.0092\n",
      "Epoch [590/1000], Loss: 0.0093\n",
      "Epoch [591/1000], Loss: 0.0091\n",
      "Epoch [592/1000], Loss: 0.0108\n",
      "Epoch [593/1000], Loss: 0.0084\n",
      "Epoch [594/1000], Loss: 0.0107\n",
      "Epoch [595/1000], Loss: 0.0091\n",
      "Epoch [596/1000], Loss: 0.0089\n",
      "Epoch [597/1000], Loss: 0.0098\n",
      "Epoch [598/1000], Loss: 0.0071\n",
      "Epoch [599/1000], Loss: 0.0093\n",
      "Epoch [600/1000], Loss: 0.0081\n",
      "Epoch [601/1000], Loss: 0.0079\n",
      "Epoch [602/1000], Loss: 0.0068\n",
      "Epoch [603/1000], Loss: 0.0083\n",
      "Epoch [604/1000], Loss: 0.0133\n",
      "Epoch [605/1000], Loss: 0.0130\n",
      "Epoch [606/1000], Loss: 0.0073\n",
      "Epoch [607/1000], Loss: 0.0163\n",
      "Epoch [608/1000], Loss: 0.0058\n",
      "Epoch [609/1000], Loss: 0.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [610/1000], Loss: 0.0061\n",
      "Epoch [611/1000], Loss: 0.0080\n",
      "Epoch [612/1000], Loss: 0.0112\n",
      "Epoch [613/1000], Loss: 0.0112\n",
      "Epoch [614/1000], Loss: 0.0089\n",
      "Epoch [615/1000], Loss: 0.0120\n",
      "Epoch [616/1000], Loss: 0.0111\n",
      "Epoch [617/1000], Loss: 0.0096\n",
      "Epoch [618/1000], Loss: 0.0091\n",
      "Epoch [619/1000], Loss: 0.0193\n",
      "Epoch [620/1000], Loss: 0.0075\n",
      "Epoch [621/1000], Loss: 0.0108\n",
      "Epoch [622/1000], Loss: 0.0087\n",
      "Epoch [623/1000], Loss: 0.0094\n",
      "Epoch [624/1000], Loss: 0.0061\n",
      "Epoch [625/1000], Loss: 0.0079\n",
      "Epoch [626/1000], Loss: 0.0082\n",
      "Epoch [627/1000], Loss: 0.0057\n",
      "Epoch [628/1000], Loss: 0.0088\n",
      "Epoch [629/1000], Loss: 0.0104\n",
      "Epoch [630/1000], Loss: 0.0067\n",
      "Epoch [631/1000], Loss: 0.0087\n",
      "Epoch [632/1000], Loss: 0.0076\n",
      "Epoch [633/1000], Loss: 0.0083\n",
      "Epoch [634/1000], Loss: 0.0079\n",
      "Epoch [635/1000], Loss: 0.0071\n",
      "Epoch [636/1000], Loss: 0.0087\n",
      "Epoch [637/1000], Loss: 0.0101\n",
      "Epoch [638/1000], Loss: 0.0068\n",
      "Epoch [639/1000], Loss: 0.0161\n",
      "Epoch [640/1000], Loss: 0.0070\n",
      "Epoch [641/1000], Loss: 0.0074\n",
      "Epoch [642/1000], Loss: 0.0068\n",
      "Epoch [643/1000], Loss: 0.0058\n",
      "Epoch [644/1000], Loss: 0.0077\n",
      "Epoch [645/1000], Loss: 0.0067\n",
      "Epoch [646/1000], Loss: 0.0092\n",
      "Epoch [647/1000], Loss: 0.0084\n",
      "Epoch [648/1000], Loss: 0.0078\n",
      "Epoch [649/1000], Loss: 0.0082\n",
      "Epoch [650/1000], Loss: 0.0072\n",
      "Epoch [651/1000], Loss: 0.0071\n",
      "Epoch [652/1000], Loss: 0.0115\n",
      "Epoch [653/1000], Loss: 0.0080\n",
      "Epoch [654/1000], Loss: 0.0066\n",
      "Epoch [655/1000], Loss: 0.0057\n",
      "Epoch [656/1000], Loss: 0.0060\n",
      "Epoch [657/1000], Loss: 0.0117\n",
      "Epoch [658/1000], Loss: 0.0081\n",
      "Epoch [659/1000], Loss: 0.0126\n",
      "Epoch [660/1000], Loss: 0.0070\n",
      "Epoch [661/1000], Loss: 0.0063\n",
      "Epoch [662/1000], Loss: 0.0062\n",
      "Epoch [663/1000], Loss: 0.0074\n",
      "Epoch [664/1000], Loss: 0.0110\n",
      "Epoch [665/1000], Loss: 0.0066\n",
      "Epoch [666/1000], Loss: 0.0062\n",
      "Epoch [667/1000], Loss: 0.0065\n",
      "Epoch [668/1000], Loss: 0.0081\n",
      "Epoch [669/1000], Loss: 0.0116\n",
      "Epoch [670/1000], Loss: 0.0099\n",
      "Epoch [671/1000], Loss: 0.0078\n",
      "Epoch [672/1000], Loss: 0.0062\n",
      "Epoch [673/1000], Loss: 0.0129\n",
      "Epoch [674/1000], Loss: 0.0094\n",
      "Epoch [675/1000], Loss: 0.0090\n",
      "Epoch [676/1000], Loss: 0.0105\n",
      "Epoch [677/1000], Loss: 0.0106\n",
      "Epoch [678/1000], Loss: 0.0117\n",
      "Epoch [679/1000], Loss: 0.0080\n",
      "Epoch [680/1000], Loss: 0.0073\n",
      "Epoch [681/1000], Loss: 0.0080\n",
      "Epoch [682/1000], Loss: 0.0111\n",
      "Epoch [683/1000], Loss: 0.0089\n",
      "Epoch [684/1000], Loss: 0.0103\n",
      "Epoch [685/1000], Loss: 0.0074\n",
      "Epoch [686/1000], Loss: 0.0138\n",
      "Epoch [687/1000], Loss: 0.0072\n",
      "Epoch [688/1000], Loss: 0.0076\n",
      "Epoch [689/1000], Loss: 0.0069\n",
      "Epoch [690/1000], Loss: 0.0138\n",
      "Epoch [691/1000], Loss: 0.0084\n",
      "Epoch [692/1000], Loss: 0.0091\n",
      "Epoch [693/1000], Loss: 0.0082\n",
      "Epoch [694/1000], Loss: 0.0199\n",
      "Epoch [695/1000], Loss: 0.0089\n",
      "Epoch [696/1000], Loss: 0.0085\n",
      "Epoch [697/1000], Loss: 0.0084\n",
      "Epoch [698/1000], Loss: 0.0174\n",
      "Epoch [699/1000], Loss: 0.0057\n",
      "Epoch [700/1000], Loss: 0.0085\n",
      "Epoch [701/1000], Loss: 0.0070\n",
      "Epoch [702/1000], Loss: 0.0100\n",
      "Epoch [703/1000], Loss: 0.0074\n",
      "Epoch [704/1000], Loss: 0.0084\n",
      "Epoch [705/1000], Loss: 0.0099\n",
      "Epoch [706/1000], Loss: 0.0067\n",
      "Epoch [707/1000], Loss: 0.0087\n",
      "Epoch [708/1000], Loss: 0.0069\n",
      "Epoch [709/1000], Loss: 0.0090\n",
      "Epoch [710/1000], Loss: 0.0067\n",
      "Epoch [711/1000], Loss: 0.0079\n",
      "Epoch [712/1000], Loss: 0.0069\n",
      "Epoch [713/1000], Loss: 0.0076\n",
      "Epoch [714/1000], Loss: 0.0070\n",
      "Epoch [715/1000], Loss: 0.0081\n",
      "Epoch [716/1000], Loss: 0.0057\n",
      "Epoch [717/1000], Loss: 0.0048\n",
      "Epoch [718/1000], Loss: 0.0076\n",
      "Epoch [719/1000], Loss: 0.0085\n",
      "Epoch [720/1000], Loss: 0.0060\n",
      "Epoch [721/1000], Loss: 0.0090\n",
      "Epoch [722/1000], Loss: 0.0081\n",
      "Epoch [723/1000], Loss: 0.0113\n",
      "Epoch [724/1000], Loss: 0.0159\n",
      "Epoch [725/1000], Loss: 0.0053\n",
      "Epoch [726/1000], Loss: 0.0072\n",
      "Epoch [727/1000], Loss: 0.0055\n",
      "Epoch [728/1000], Loss: 0.0081\n",
      "Epoch [729/1000], Loss: 0.0090\n",
      "Epoch [730/1000], Loss: 0.0072\n",
      "Epoch [731/1000], Loss: 0.0067\n",
      "Epoch [732/1000], Loss: 0.0064\n",
      "Epoch [733/1000], Loss: 0.0079\n",
      "Epoch [734/1000], Loss: 0.0044\n",
      "Epoch [735/1000], Loss: 0.0053\n",
      "Epoch [736/1000], Loss: 0.0083\n",
      "Epoch [737/1000], Loss: 0.0055\n",
      "Epoch [738/1000], Loss: 0.0051\n",
      "Epoch [739/1000], Loss: 0.0060\n",
      "Epoch [740/1000], Loss: 0.0081\n",
      "Epoch [741/1000], Loss: 0.0048\n",
      "Epoch [742/1000], Loss: 0.0070\n",
      "Epoch [743/1000], Loss: 0.0105\n",
      "Epoch [744/1000], Loss: 0.0046\n",
      "Epoch [745/1000], Loss: 0.0038\n",
      "Epoch [746/1000], Loss: 0.0125\n",
      "Epoch [747/1000], Loss: 0.0078\n",
      "Epoch [748/1000], Loss: 0.0080\n",
      "Epoch [749/1000], Loss: 0.0062\n",
      "Epoch [750/1000], Loss: 0.0057\n",
      "Epoch [751/1000], Loss: 0.0069\n",
      "Epoch [752/1000], Loss: 0.0074\n",
      "Epoch [753/1000], Loss: 0.0056\n",
      "Epoch [754/1000], Loss: 0.0166\n",
      "Epoch [755/1000], Loss: 0.0064\n",
      "Epoch [756/1000], Loss: 0.0081\n",
      "Epoch [757/1000], Loss: 0.0063\n",
      "Epoch [758/1000], Loss: 0.0085\n",
      "Epoch [759/1000], Loss: 0.0073\n",
      "Epoch [760/1000], Loss: 0.0063\n",
      "Epoch [761/1000], Loss: 0.0050\n",
      "Epoch [762/1000], Loss: 0.0095\n",
      "Epoch [763/1000], Loss: 0.0081\n",
      "Epoch [764/1000], Loss: 0.0063\n",
      "Epoch [765/1000], Loss: 0.0053\n",
      "Epoch [766/1000], Loss: 0.0061\n",
      "Epoch [767/1000], Loss: 0.0059\n",
      "Epoch [768/1000], Loss: 0.0072\n",
      "Epoch [769/1000], Loss: 0.0100\n",
      "Epoch [770/1000], Loss: 0.0044\n",
      "Epoch [771/1000], Loss: 0.0083\n",
      "Epoch [772/1000], Loss: 0.0059\n",
      "Epoch [773/1000], Loss: 0.0060\n",
      "Epoch [774/1000], Loss: 0.0199\n",
      "Epoch [775/1000], Loss: 0.0045\n",
      "Epoch [776/1000], Loss: 0.0054\n",
      "Epoch [777/1000], Loss: 0.0047\n",
      "Epoch [778/1000], Loss: 0.0131\n",
      "Epoch [779/1000], Loss: 0.0096\n",
      "Epoch [780/1000], Loss: 0.0108\n",
      "Epoch [781/1000], Loss: 0.0060\n",
      "Epoch [782/1000], Loss: 0.0081\n",
      "Epoch [783/1000], Loss: 0.0071\n",
      "Epoch [784/1000], Loss: 0.0057\n",
      "Epoch [785/1000], Loss: 0.0097\n",
      "Epoch [786/1000], Loss: 0.0064\n",
      "Epoch [787/1000], Loss: 0.0057\n",
      "Epoch [788/1000], Loss: 0.0111\n",
      "Epoch [789/1000], Loss: 0.0092\n",
      "Epoch [790/1000], Loss: 0.0042\n",
      "Epoch [791/1000], Loss: 0.0065\n",
      "Epoch [792/1000], Loss: 0.0071\n",
      "Epoch [793/1000], Loss: 0.0067\n",
      "Epoch [794/1000], Loss: 0.0084\n",
      "Epoch [795/1000], Loss: 0.0070\n",
      "Epoch [796/1000], Loss: 0.0124\n",
      "Epoch [797/1000], Loss: 0.0089\n",
      "Epoch [798/1000], Loss: 0.0088\n",
      "Epoch [799/1000], Loss: 0.0084\n",
      "Epoch [800/1000], Loss: 0.0072\n",
      "Epoch [801/1000], Loss: 0.0078\n",
      "Epoch [802/1000], Loss: 0.0078\n",
      "Epoch [803/1000], Loss: 0.0087\n",
      "Epoch [804/1000], Loss: 0.0072\n",
      "Epoch [805/1000], Loss: 0.0120\n",
      "Epoch [806/1000], Loss: 0.0095\n",
      "Epoch [807/1000], Loss: 0.0089\n",
      "Epoch [808/1000], Loss: 0.0050\n",
      "Epoch [809/1000], Loss: 0.0130\n",
      "Epoch [810/1000], Loss: 0.0076\n",
      "Epoch [811/1000], Loss: 0.0084\n",
      "Epoch [812/1000], Loss: 0.0092\n",
      "Epoch [813/1000], Loss: 0.0084\n",
      "Epoch [814/1000], Loss: 0.0114\n",
      "Epoch [815/1000], Loss: 0.0058\n",
      "Epoch [816/1000], Loss: 0.0377\n",
      "Epoch [817/1000], Loss: 0.0249\n",
      "Epoch [818/1000], Loss: 0.0079\n",
      "Epoch [819/1000], Loss: 0.0135\n",
      "Epoch [820/1000], Loss: 0.0060\n",
      "Epoch [821/1000], Loss: 0.0065\n",
      "Epoch [822/1000], Loss: 0.0139\n",
      "Epoch [823/1000], Loss: 0.0055\n",
      "Epoch [824/1000], Loss: 0.0055\n",
      "Epoch [825/1000], Loss: 0.0062\n",
      "Epoch [826/1000], Loss: 0.0113\n",
      "Epoch [827/1000], Loss: 0.0085\n",
      "Epoch [828/1000], Loss: 0.0102\n",
      "Epoch [829/1000], Loss: 0.0080\n",
      "Epoch [830/1000], Loss: 0.0096\n",
      "Epoch [831/1000], Loss: 0.0093\n",
      "Epoch [832/1000], Loss: 0.0083\n",
      "Epoch [833/1000], Loss: 0.0068\n",
      "Epoch [834/1000], Loss: 0.0057\n",
      "Epoch [835/1000], Loss: 0.0058\n",
      "Epoch [836/1000], Loss: 0.0126\n",
      "Epoch [837/1000], Loss: 0.0051\n",
      "Epoch [838/1000], Loss: 0.0056\n",
      "Epoch [839/1000], Loss: 0.0071\n",
      "Epoch [840/1000], Loss: 0.0056\n",
      "Epoch [841/1000], Loss: 0.0045\n",
      "Epoch [842/1000], Loss: 0.0070\n",
      "Epoch [843/1000], Loss: 0.0052\n",
      "Epoch [844/1000], Loss: 0.0059\n",
      "Epoch [845/1000], Loss: 0.0042\n",
      "Epoch [846/1000], Loss: 0.0040\n",
      "Epoch [847/1000], Loss: 0.0104\n",
      "Epoch [848/1000], Loss: 0.0149\n",
      "Epoch [849/1000], Loss: 0.0056\n",
      "Epoch [850/1000], Loss: 0.0192\n",
      "Epoch [851/1000], Loss: 0.0101\n",
      "Epoch [852/1000], Loss: 0.0067\n",
      "Epoch [853/1000], Loss: 0.0037\n",
      "Epoch [854/1000], Loss: 0.0040\n",
      "Epoch [855/1000], Loss: 0.0050\n",
      "Epoch [856/1000], Loss: 0.0060\n",
      "Epoch [857/1000], Loss: 0.0053\n",
      "Epoch [858/1000], Loss: 0.0056\n",
      "Epoch [859/1000], Loss: 0.0052\n",
      "Epoch [860/1000], Loss: 0.0045\n",
      "Epoch [861/1000], Loss: 0.0066\n",
      "Epoch [862/1000], Loss: 0.0060\n",
      "Epoch [863/1000], Loss: 0.0082\n",
      "Epoch [864/1000], Loss: 0.0075\n",
      "Epoch [865/1000], Loss: 0.0094\n",
      "Epoch [866/1000], Loss: 0.0115\n",
      "Epoch [867/1000], Loss: 0.0048\n",
      "Epoch [868/1000], Loss: 0.0048\n",
      "Epoch [869/1000], Loss: 0.0066\n",
      "Epoch [870/1000], Loss: 0.0041\n",
      "Epoch [871/1000], Loss: 0.0060\n",
      "Epoch [872/1000], Loss: 0.0041\n",
      "Epoch [873/1000], Loss: 0.0067\n",
      "Epoch [874/1000], Loss: 0.0078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [875/1000], Loss: 0.0054\n",
      "Epoch [876/1000], Loss: 0.0032\n",
      "Epoch [877/1000], Loss: 0.0055\n",
      "Epoch [878/1000], Loss: 0.0068\n",
      "Epoch [879/1000], Loss: 0.0069\n",
      "Epoch [880/1000], Loss: 0.0070\n",
      "Epoch [881/1000], Loss: 0.0048\n",
      "Epoch [882/1000], Loss: 0.0117\n",
      "Epoch [883/1000], Loss: 0.0057\n",
      "Epoch [884/1000], Loss: 0.0072\n",
      "Epoch [885/1000], Loss: 0.0046\n",
      "Epoch [886/1000], Loss: 0.0064\n",
      "Epoch [887/1000], Loss: 0.0055\n",
      "Epoch [888/1000], Loss: 0.0045\n",
      "Epoch [889/1000], Loss: 0.0049\n",
      "Epoch [890/1000], Loss: 0.0041\n",
      "Epoch [891/1000], Loss: 0.0042\n",
      "Epoch [892/1000], Loss: 0.0042\n",
      "Epoch [893/1000], Loss: 0.0078\n",
      "Epoch [894/1000], Loss: 0.0078\n",
      "Epoch [895/1000], Loss: 0.0039\n",
      "Epoch [896/1000], Loss: 0.0040\n",
      "Epoch [897/1000], Loss: 0.0041\n",
      "Epoch [898/1000], Loss: 0.0080\n",
      "Epoch [899/1000], Loss: 0.0062\n",
      "Epoch [900/1000], Loss: 0.0052\n",
      "Epoch [901/1000], Loss: 0.0200\n",
      "Epoch [902/1000], Loss: 0.0062\n",
      "Epoch [903/1000], Loss: 0.0072\n",
      "Epoch [904/1000], Loss: 0.0049\n",
      "Epoch [905/1000], Loss: 0.0046\n",
      "Epoch [906/1000], Loss: 0.0067\n",
      "Epoch [907/1000], Loss: 0.0059\n",
      "Epoch [908/1000], Loss: 0.0031\n",
      "Epoch [909/1000], Loss: 0.0112\n",
      "Epoch [910/1000], Loss: 0.0075\n",
      "Epoch [911/1000], Loss: 0.0096\n",
      "Epoch [912/1000], Loss: 0.0060\n",
      "Epoch [913/1000], Loss: 0.0066\n",
      "Epoch [914/1000], Loss: 0.0337\n",
      "Epoch [915/1000], Loss: 0.0134\n",
      "Epoch [916/1000], Loss: 0.0052\n",
      "Epoch [917/1000], Loss: 0.0052\n",
      "Epoch [918/1000], Loss: 0.0090\n",
      "Epoch [919/1000], Loss: 0.0060\n",
      "Epoch [920/1000], Loss: 0.0054\n",
      "Epoch [921/1000], Loss: 0.0044\n",
      "Epoch [922/1000], Loss: 0.0066\n",
      "Epoch [923/1000], Loss: 0.0049\n",
      "Epoch [924/1000], Loss: 0.0042\n",
      "Epoch [925/1000], Loss: 0.0057\n",
      "Epoch [926/1000], Loss: 0.0059\n",
      "Epoch [927/1000], Loss: 0.0058\n",
      "Epoch [928/1000], Loss: 0.0088\n",
      "Epoch [929/1000], Loss: 0.0076\n",
      "Epoch [930/1000], Loss: 0.0035\n",
      "Epoch [931/1000], Loss: 0.0068\n",
      "Epoch [932/1000], Loss: 0.0028\n",
      "Epoch [933/1000], Loss: 0.0033\n",
      "Epoch [934/1000], Loss: 0.0081\n",
      "Epoch [935/1000], Loss: 0.0060\n",
      "Epoch [936/1000], Loss: 0.0059\n",
      "Epoch [937/1000], Loss: 0.0045\n",
      "Epoch [938/1000], Loss: 0.0048\n",
      "Epoch [939/1000], Loss: 0.0057\n",
      "Epoch [940/1000], Loss: 0.0044\n",
      "Epoch [941/1000], Loss: 0.0048\n",
      "Epoch [942/1000], Loss: 0.0032\n",
      "Epoch [943/1000], Loss: 0.0052\n",
      "Epoch [944/1000], Loss: 0.0064\n",
      "Epoch [945/1000], Loss: 0.0078\n",
      "Epoch [946/1000], Loss: 0.0063\n",
      "Epoch [947/1000], Loss: 0.0029\n",
      "Epoch [948/1000], Loss: 0.0157\n",
      "Epoch [949/1000], Loss: 0.0050\n",
      "Epoch [950/1000], Loss: 0.0064\n",
      "Epoch [951/1000], Loss: 0.0060\n",
      "Epoch [952/1000], Loss: 0.0032\n",
      "Epoch [953/1000], Loss: 0.0146\n",
      "Epoch [954/1000], Loss: 0.0129\n",
      "Epoch [955/1000], Loss: 0.0077\n",
      "Epoch [956/1000], Loss: 0.0081\n",
      "Epoch [957/1000], Loss: 0.0121\n",
      "Epoch [958/1000], Loss: 0.0081\n",
      "Epoch [959/1000], Loss: 0.0046\n",
      "Epoch [960/1000], Loss: 0.0060\n",
      "Epoch [961/1000], Loss: 0.0096\n",
      "Epoch [962/1000], Loss: 0.0042\n",
      "Epoch [963/1000], Loss: 0.0046\n",
      "Epoch [964/1000], Loss: 0.0046\n",
      "Epoch [965/1000], Loss: 0.0041\n",
      "Epoch [966/1000], Loss: 0.0056\n",
      "Epoch [967/1000], Loss: 0.0048\n",
      "Epoch [968/1000], Loss: 0.0242\n",
      "Epoch [969/1000], Loss: 0.0048\n",
      "Epoch [970/1000], Loss: 0.0035\n",
      "Epoch [971/1000], Loss: 0.0041\n",
      "Epoch [972/1000], Loss: 0.0040\n",
      "Epoch [973/1000], Loss: 0.0062\n",
      "Epoch [974/1000], Loss: 0.0344\n",
      "Epoch [975/1000], Loss: 0.0077\n",
      "Epoch [976/1000], Loss: 0.0036\n",
      "Epoch [977/1000], Loss: 0.0062\n",
      "Epoch [978/1000], Loss: 0.0041\n",
      "Epoch [979/1000], Loss: 0.0056\n",
      "Epoch [980/1000], Loss: 0.0054\n",
      "Epoch [981/1000], Loss: 0.0055\n",
      "Epoch [982/1000], Loss: 0.0043\n",
      "Epoch [983/1000], Loss: 0.0057\n",
      "Epoch [984/1000], Loss: 0.0035\n",
      "Epoch [985/1000], Loss: 0.0039\n",
      "Epoch [986/1000], Loss: 0.0076\n",
      "Epoch [987/1000], Loss: 0.0030\n",
      "Epoch [988/1000], Loss: 0.0113\n",
      "Epoch [989/1000], Loss: 0.0134\n",
      "Epoch [990/1000], Loss: 0.0131\n",
      "Epoch [991/1000], Loss: 0.0080\n",
      "Epoch [992/1000], Loss: 0.0059\n",
      "Epoch [993/1000], Loss: 0.0060\n",
      "Epoch [994/1000], Loss: 0.0060\n",
      "Epoch [995/1000], Loss: 0.0051\n",
      "Epoch [996/1000], Loss: 0.0064\n",
      "Epoch [997/1000], Loss: 0.0070\n",
      "Epoch [998/1000], Loss: 0.0033\n",
      "Epoch [999/1000], Loss: 0.0039\n",
      "Epoch [1000/1000], Loss: 0.0033\n",
      "------- Training model with depth : 4, activation : lrelu, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2526\n",
      "Epoch [2/1000], Loss: 0.2504\n",
      "Epoch [3/1000], Loss: 0.2497\n",
      "Epoch [4/1000], Loss: 0.2493\n",
      "Epoch [5/1000], Loss: 0.2490\n",
      "Epoch [6/1000], Loss: 0.2485\n",
      "Epoch [7/1000], Loss: 0.2481\n",
      "Epoch [8/1000], Loss: 0.2475\n",
      "Epoch [9/1000], Loss: 0.2467\n",
      "Epoch [10/1000], Loss: 0.2458\n",
      "Epoch [11/1000], Loss: 0.2449\n",
      "Epoch [12/1000], Loss: 0.2442\n",
      "Epoch [13/1000], Loss: 0.2435\n",
      "Epoch [14/1000], Loss: 0.2431\n",
      "Epoch [15/1000], Loss: 0.2427\n",
      "Epoch [16/1000], Loss: 0.2422\n",
      "Epoch [17/1000], Loss: 0.2419\n",
      "Epoch [18/1000], Loss: 0.2415\n",
      "Epoch [19/1000], Loss: 0.2411\n",
      "Epoch [20/1000], Loss: 0.2407\n",
      "Epoch [21/1000], Loss: 0.2403\n",
      "Epoch [22/1000], Loss: 0.2398\n",
      "Epoch [23/1000], Loss: 0.2393\n",
      "Epoch [24/1000], Loss: 0.2388\n",
      "Epoch [25/1000], Loss: 0.2384\n",
      "Epoch [26/1000], Loss: 0.2381\n",
      "Epoch [27/1000], Loss: 0.2379\n",
      "Epoch [28/1000], Loss: 0.2377\n",
      "Epoch [29/1000], Loss: 0.2375\n",
      "Epoch [30/1000], Loss: 0.2373\n",
      "Epoch [31/1000], Loss: 0.2371\n",
      "Epoch [32/1000], Loss: 0.2370\n",
      "Epoch [33/1000], Loss: 0.2368\n",
      "Epoch [34/1000], Loss: 0.2366\n",
      "Epoch [35/1000], Loss: 0.2364\n",
      "Epoch [36/1000], Loss: 0.2363\n",
      "Epoch [37/1000], Loss: 0.2361\n",
      "Epoch [38/1000], Loss: 0.2359\n",
      "Epoch [39/1000], Loss: 0.2357\n",
      "Epoch [40/1000], Loss: 0.2355\n",
      "Epoch [41/1000], Loss: 0.2352\n",
      "Epoch [42/1000], Loss: 0.2350\n",
      "Epoch [43/1000], Loss: 0.2348\n",
      "Epoch [44/1000], Loss: 0.2345\n",
      "Epoch [45/1000], Loss: 0.2343\n",
      "Epoch [46/1000], Loss: 0.2339\n",
      "Epoch [47/1000], Loss: 0.2337\n",
      "Epoch [48/1000], Loss: 0.2334\n",
      "Epoch [49/1000], Loss: 0.2330\n",
      "Epoch [50/1000], Loss: 0.2325\n",
      "Epoch [51/1000], Loss: 0.2324\n",
      "Epoch [52/1000], Loss: 0.2320\n",
      "Epoch [53/1000], Loss: 0.2317\n",
      "Epoch [54/1000], Loss: 0.2312\n",
      "Epoch [55/1000], Loss: 0.2307\n",
      "Epoch [56/1000], Loss: 0.2302\n",
      "Epoch [57/1000], Loss: 0.2297\n",
      "Epoch [58/1000], Loss: 0.2289\n",
      "Epoch [59/1000], Loss: 0.2281\n",
      "Epoch [60/1000], Loss: 0.2272\n",
      "Epoch [61/1000], Loss: 0.2264\n",
      "Epoch [62/1000], Loss: 0.2250\n",
      "Epoch [63/1000], Loss: 0.2241\n",
      "Epoch [64/1000], Loss: 0.2224\n",
      "Epoch [65/1000], Loss: 0.2207\n",
      "Epoch [66/1000], Loss: 0.2187\n",
      "Epoch [67/1000], Loss: 0.2154\n",
      "Epoch [68/1000], Loss: 0.2113\n",
      "Epoch [69/1000], Loss: 0.2073\n",
      "Epoch [70/1000], Loss: 0.2030\n",
      "Epoch [71/1000], Loss: 0.1978\n",
      "Epoch [72/1000], Loss: 0.1916\n",
      "Epoch [73/1000], Loss: 0.1857\n",
      "Epoch [74/1000], Loss: 0.1800\n",
      "Epoch [75/1000], Loss: 0.1745\n",
      "Epoch [76/1000], Loss: 0.1700\n",
      "Epoch [77/1000], Loss: 0.1654\n",
      "Epoch [78/1000], Loss: 0.1592\n",
      "Epoch [79/1000], Loss: 0.1538\n",
      "Epoch [80/1000], Loss: 0.1484\n",
      "Epoch [81/1000], Loss: 0.1427\n",
      "Epoch [82/1000], Loss: 0.1359\n",
      "Epoch [83/1000], Loss: 0.1281\n",
      "Epoch [84/1000], Loss: 0.1220\n",
      "Epoch [85/1000], Loss: 0.1149\n",
      "Epoch [86/1000], Loss: 0.1085\n",
      "Epoch [87/1000], Loss: 0.1022\n",
      "Epoch [88/1000], Loss: 0.0963\n",
      "Epoch [89/1000], Loss: 0.0868\n",
      "Epoch [90/1000], Loss: 0.0788\n",
      "Epoch [91/1000], Loss: 0.0719\n",
      "Epoch [92/1000], Loss: 0.0655\n",
      "Epoch [93/1000], Loss: 0.0592\n",
      "Epoch [94/1000], Loss: 0.0528\n",
      "Epoch [95/1000], Loss: 0.0456\n",
      "Epoch [96/1000], Loss: 0.0390\n",
      "Epoch [97/1000], Loss: 0.0340\n",
      "Epoch [98/1000], Loss: 0.0294\n",
      "Epoch [99/1000], Loss: 0.0258\n",
      "Epoch [100/1000], Loss: 0.0221\n",
      "Epoch [101/1000], Loss: 0.0195\n",
      "Epoch [102/1000], Loss: 0.0164\n",
      "Epoch [103/1000], Loss: 0.0138\n",
      "Epoch [104/1000], Loss: 0.0121\n",
      "Epoch [105/1000], Loss: 0.0108\n",
      "Epoch [106/1000], Loss: 0.0095\n",
      "Epoch [107/1000], Loss: 0.0089\n",
      "Epoch [108/1000], Loss: 0.0079\n",
      "Epoch [109/1000], Loss: 0.0073\n",
      "Epoch [110/1000], Loss: 0.0065\n",
      "Epoch [111/1000], Loss: 0.0061\n",
      "Epoch [112/1000], Loss: 0.0056\n",
      "Epoch [113/1000], Loss: 0.0051\n",
      "Epoch [114/1000], Loss: 0.0048\n",
      "Epoch [115/1000], Loss: 0.0045\n",
      "Epoch [116/1000], Loss: 0.0040\n",
      "Epoch [117/1000], Loss: 0.0037\n",
      "Epoch [118/1000], Loss: 0.0035\n",
      "Epoch [119/1000], Loss: 0.0033\n",
      "Epoch [120/1000], Loss: 0.0033\n",
      "Epoch [121/1000], Loss: 0.0030\n",
      "Epoch [122/1000], Loss: 0.0027\n",
      "Epoch [123/1000], Loss: 0.0025\n",
      "Epoch [124/1000], Loss: 0.0024\n",
      "Epoch [125/1000], Loss: 0.0023\n",
      "Epoch [126/1000], Loss: 0.0022\n",
      "Epoch [127/1000], Loss: 0.0020\n",
      "Epoch [128/1000], Loss: 0.0020\n",
      "Epoch [129/1000], Loss: 0.0019\n",
      "Epoch [130/1000], Loss: 0.0018\n",
      "Epoch [131/1000], Loss: 0.0017\n",
      "Epoch [132/1000], Loss: 0.0017\n",
      "Epoch [133/1000], Loss: 0.0016\n",
      "Epoch [134/1000], Loss: 0.0015\n",
      "Epoch [135/1000], Loss: 0.0014\n",
      "Epoch [136/1000], Loss: 0.0014\n",
      "Epoch [137/1000], Loss: 0.0013\n",
      "Epoch [138/1000], Loss: 0.0013\n",
      "Epoch [139/1000], Loss: 0.0012\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 4, activation : lrelu, and neurons: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 0.2501\n",
      "Epoch [2/1000], Loss: 0.2476\n",
      "Epoch [3/1000], Loss: 0.2454\n",
      "Epoch [4/1000], Loss: 0.2428\n",
      "Epoch [5/1000], Loss: 0.2398\n",
      "Epoch [6/1000], Loss: 0.2371\n",
      "Epoch [7/1000], Loss: 0.2355\n",
      "Epoch [8/1000], Loss: 0.2348\n",
      "Epoch [9/1000], Loss: 0.2343\n",
      "Epoch [10/1000], Loss: 0.2339\n",
      "Epoch [11/1000], Loss: 0.2333\n",
      "Epoch [12/1000], Loss: 0.2332\n",
      "Epoch [13/1000], Loss: 0.2328\n",
      "Epoch [14/1000], Loss: 0.2324\n",
      "Epoch [15/1000], Loss: 0.2320\n",
      "Epoch [16/1000], Loss: 0.2317\n",
      "Epoch [17/1000], Loss: 0.2312\n",
      "Epoch [18/1000], Loss: 0.2307\n",
      "Epoch [19/1000], Loss: 0.2303\n",
      "Epoch [20/1000], Loss: 0.2298\n",
      "Epoch [21/1000], Loss: 0.2292\n",
      "Epoch [22/1000], Loss: 0.2286\n",
      "Epoch [23/1000], Loss: 0.2279\n",
      "Epoch [24/1000], Loss: 0.2269\n",
      "Epoch [25/1000], Loss: 0.2260\n",
      "Epoch [26/1000], Loss: 0.2248\n",
      "Epoch [27/1000], Loss: 0.2237\n",
      "Epoch [28/1000], Loss: 0.2224\n",
      "Epoch [29/1000], Loss: 0.2207\n",
      "Epoch [30/1000], Loss: 0.2192\n",
      "Epoch [31/1000], Loss: 0.2172\n",
      "Epoch [32/1000], Loss: 0.2150\n",
      "Epoch [33/1000], Loss: 0.2124\n",
      "Epoch [34/1000], Loss: 0.2095\n",
      "Epoch [35/1000], Loss: 0.2061\n",
      "Epoch [36/1000], Loss: 0.2022\n",
      "Epoch [37/1000], Loss: 0.1976\n",
      "Epoch [38/1000], Loss: 0.1919\n",
      "Epoch [39/1000], Loss: 0.1853\n",
      "Epoch [40/1000], Loss: 0.1780\n",
      "Epoch [41/1000], Loss: 0.1696\n",
      "Epoch [42/1000], Loss: 0.1608\n",
      "Epoch [43/1000], Loss: 0.1502\n",
      "Epoch [44/1000], Loss: 0.1385\n",
      "Epoch [45/1000], Loss: 0.1250\n",
      "Epoch [46/1000], Loss: 0.1105\n",
      "Epoch [47/1000], Loss: 0.0949\n",
      "Epoch [48/1000], Loss: 0.0787\n",
      "Epoch [49/1000], Loss: 0.0645\n",
      "Epoch [50/1000], Loss: 0.0524\n",
      "Epoch [51/1000], Loss: 0.0422\n",
      "Epoch [52/1000], Loss: 0.0326\n",
      "Epoch [53/1000], Loss: 0.0244\n",
      "Epoch [54/1000], Loss: 0.0183\n",
      "Epoch [55/1000], Loss: 0.0145\n",
      "Epoch [56/1000], Loss: 0.0117\n",
      "Epoch [57/1000], Loss: 0.0097\n",
      "Epoch [58/1000], Loss: 0.0082\n",
      "Epoch [59/1000], Loss: 0.0070\n",
      "Epoch [60/1000], Loss: 0.0060\n",
      "Epoch [61/1000], Loss: 0.0055\n",
      "Epoch [62/1000], Loss: 0.0049\n",
      "Epoch [63/1000], Loss: 0.0043\n",
      "Epoch [64/1000], Loss: 0.0039\n",
      "Epoch [65/1000], Loss: 0.0036\n",
      "Epoch [66/1000], Loss: 0.0032\n",
      "Epoch [67/1000], Loss: 0.0030\n",
      "Epoch [68/1000], Loss: 0.0028\n",
      "Epoch [69/1000], Loss: 0.0026\n",
      "Epoch [70/1000], Loss: 0.0024\n",
      "Epoch [71/1000], Loss: 0.0023\n",
      "Epoch [72/1000], Loss: 0.0022\n",
      "Epoch [73/1000], Loss: 0.0020\n",
      "Epoch [74/1000], Loss: 0.0019\n",
      "Epoch [75/1000], Loss: 0.0018\n",
      "Epoch [76/1000], Loss: 0.0017\n",
      "Epoch [77/1000], Loss: 0.0016\n",
      "Epoch [78/1000], Loss: 0.0015\n",
      "Epoch [79/1000], Loss: 0.0015\n",
      "Epoch [80/1000], Loss: 0.0014\n",
      "Epoch [81/1000], Loss: 0.0014\n",
      "Epoch [82/1000], Loss: 0.0013\n",
      "Epoch [83/1000], Loss: 0.0012\n",
      "Epoch [84/1000], Loss: 0.0012\n",
      "Epoch [85/1000], Loss: 0.0012\n",
      "Epoch [86/1000], Loss: 0.0011\n",
      "Epoch [87/1000], Loss: 0.0011\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 4, activation : sigmoid, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2555\n",
      "Epoch [2/1000], Loss: 0.2507\n",
      "Epoch [3/1000], Loss: 0.2501\n",
      "Epoch [4/1000], Loss: 0.2501\n",
      "Epoch [5/1000], Loss: 0.2501\n",
      "Epoch [6/1000], Loss: 0.2501\n",
      "Epoch [7/1000], Loss: 0.2501\n",
      "Epoch [8/1000], Loss: 0.2501\n",
      "Epoch [9/1000], Loss: 0.2500\n",
      "Epoch [10/1000], Loss: 0.2500\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 4, activation : sigmoid, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2532\n",
      "Epoch [2/1000], Loss: 0.2502\n",
      "Epoch [3/1000], Loss: 0.2501\n",
      "Epoch [4/1000], Loss: 0.2501\n",
      "Epoch [5/1000], Loss: 0.2500\n",
      "Epoch [6/1000], Loss: 0.2501\n",
      "Epoch [7/1000], Loss: 0.2501\n",
      "Epoch [8/1000], Loss: 0.2501\n",
      "Epoch [9/1000], Loss: 0.2501\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 4, activation : sigmoid, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2502\n",
      "Epoch [2/1000], Loss: 0.2501\n",
      "Epoch [3/1000], Loss: 0.2502\n",
      "Epoch [4/1000], Loss: 0.2501\n",
      "Epoch [5/1000], Loss: 0.2501\n",
      "Epoch [6/1000], Loss: 0.2502\n",
      "Epoch [7/1000], Loss: 0.2501\n",
      "Epoch [8/1000], Loss: 0.2501\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 4, activation : tanh, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2632\n",
      "Epoch [2/1000], Loss: 0.2516\n",
      "Epoch [3/1000], Loss: 0.2499\n",
      "Epoch [4/1000], Loss: 0.2493\n",
      "Epoch [5/1000], Loss: 0.2489\n",
      "Epoch [6/1000], Loss: 0.2484\n",
      "Epoch [7/1000], Loss: 0.2479\n",
      "Epoch [8/1000], Loss: 0.2472\n",
      "Epoch [9/1000], Loss: 0.2466\n",
      "Epoch [10/1000], Loss: 0.2458\n",
      "Epoch [11/1000], Loss: 0.2449\n",
      "Epoch [12/1000], Loss: 0.2440\n",
      "Epoch [13/1000], Loss: 0.2431\n",
      "Epoch [14/1000], Loss: 0.2423\n",
      "Epoch [15/1000], Loss: 0.2415\n",
      "Epoch [16/1000], Loss: 0.2407\n",
      "Epoch [17/1000], Loss: 0.2400\n",
      "Epoch [18/1000], Loss: 0.2394\n",
      "Epoch [19/1000], Loss: 0.2389\n",
      "Epoch [20/1000], Loss: 0.2384\n",
      "Epoch [21/1000], Loss: 0.2382\n",
      "Epoch [22/1000], Loss: 0.2379\n",
      "Epoch [23/1000], Loss: 0.2377\n",
      "Epoch [24/1000], Loss: 0.2376\n",
      "Epoch [25/1000], Loss: 0.2374\n",
      "Epoch [26/1000], Loss: 0.2373\n",
      "Epoch [27/1000], Loss: 0.2372\n",
      "Epoch [28/1000], Loss: 0.2371\n",
      "Epoch [29/1000], Loss: 0.2369\n",
      "Epoch [30/1000], Loss: 0.2368\n",
      "Epoch [31/1000], Loss: 0.2366\n",
      "Epoch [32/1000], Loss: 0.2365\n",
      "Epoch [33/1000], Loss: 0.2363\n",
      "Epoch [34/1000], Loss: 0.2362\n",
      "Epoch [35/1000], Loss: 0.2360\n",
      "Epoch [36/1000], Loss: 0.2359\n",
      "Epoch [37/1000], Loss: 0.2357\n",
      "Epoch [38/1000], Loss: 0.2355\n",
      "Epoch [39/1000], Loss: 0.2353\n",
      "Epoch [40/1000], Loss: 0.2351\n",
      "Epoch [41/1000], Loss: 0.2349\n",
      "Epoch [42/1000], Loss: 0.2346\n",
      "Epoch [43/1000], Loss: 0.2344\n",
      "Epoch [44/1000], Loss: 0.2342\n",
      "Epoch [45/1000], Loss: 0.2339\n",
      "Epoch [46/1000], Loss: 0.2336\n",
      "Epoch [47/1000], Loss: 0.2333\n",
      "Epoch [48/1000], Loss: 0.2331\n",
      "Epoch [49/1000], Loss: 0.2328\n",
      "Epoch [50/1000], Loss: 0.2325\n",
      "Epoch [51/1000], Loss: 0.2323\n",
      "Epoch [52/1000], Loss: 0.2319\n",
      "Epoch [53/1000], Loss: 0.2317\n",
      "Epoch [54/1000], Loss: 0.2314\n",
      "Epoch [55/1000], Loss: 0.2311\n",
      "Epoch [56/1000], Loss: 0.2308\n",
      "Epoch [57/1000], Loss: 0.2305\n",
      "Epoch [58/1000], Loss: 0.2303\n",
      "Epoch [59/1000], Loss: 0.2300\n",
      "Epoch [60/1000], Loss: 0.2297\n",
      "Epoch [61/1000], Loss: 0.2294\n",
      "Epoch [62/1000], Loss: 0.2291\n",
      "Epoch [63/1000], Loss: 0.2288\n",
      "Epoch [64/1000], Loss: 0.2284\n",
      "Epoch [65/1000], Loss: 0.2281\n",
      "Epoch [66/1000], Loss: 0.2278\n",
      "Epoch [67/1000], Loss: 0.2274\n",
      "Epoch [68/1000], Loss: 0.2271\n",
      "Epoch [69/1000], Loss: 0.2267\n",
      "Epoch [70/1000], Loss: 0.2264\n",
      "Epoch [71/1000], Loss: 0.2260\n",
      "Epoch [72/1000], Loss: 0.2256\n",
      "Epoch [73/1000], Loss: 0.2253\n",
      "Epoch [74/1000], Loss: 0.2250\n",
      "Epoch [75/1000], Loss: 0.2247\n",
      "Epoch [76/1000], Loss: 0.2243\n",
      "Epoch [77/1000], Loss: 0.2241\n",
      "Epoch [78/1000], Loss: 0.2236\n",
      "Epoch [79/1000], Loss: 0.2233\n",
      "Epoch [80/1000], Loss: 0.2231\n",
      "Epoch [81/1000], Loss: 0.2226\n",
      "Epoch [82/1000], Loss: 0.2223\n",
      "Epoch [83/1000], Loss: 0.2219\n",
      "Epoch [84/1000], Loss: 0.2214\n",
      "Epoch [85/1000], Loss: 0.2212\n",
      "Epoch [86/1000], Loss: 0.2207\n",
      "Epoch [87/1000], Loss: 0.2203\n",
      "Epoch [88/1000], Loss: 0.2198\n",
      "Epoch [89/1000], Loss: 0.2194\n",
      "Epoch [90/1000], Loss: 0.2190\n",
      "Epoch [91/1000], Loss: 0.2184\n",
      "Epoch [92/1000], Loss: 0.2178\n",
      "Epoch [93/1000], Loss: 0.2172\n",
      "Epoch [94/1000], Loss: 0.2166\n",
      "Epoch [95/1000], Loss: 0.2158\n",
      "Epoch [96/1000], Loss: 0.2153\n",
      "Epoch [97/1000], Loss: 0.2144\n",
      "Epoch [98/1000], Loss: 0.2137\n",
      "Epoch [99/1000], Loss: 0.2127\n",
      "Epoch [100/1000], Loss: 0.2116\n",
      "Epoch [101/1000], Loss: 0.2105\n",
      "Epoch [102/1000], Loss: 0.2093\n",
      "Epoch [103/1000], Loss: 0.2077\n",
      "Epoch [104/1000], Loss: 0.2063\n",
      "Epoch [105/1000], Loss: 0.2046\n",
      "Epoch [106/1000], Loss: 0.2023\n",
      "Epoch [107/1000], Loss: 0.2001\n",
      "Epoch [108/1000], Loss: 0.1982\n",
      "Epoch [109/1000], Loss: 0.1959\n",
      "Epoch [110/1000], Loss: 0.1942\n",
      "Epoch [111/1000], Loss: 0.1908\n",
      "Epoch [112/1000], Loss: 0.1889\n",
      "Epoch [113/1000], Loss: 0.1868\n",
      "Epoch [114/1000], Loss: 0.1853\n",
      "Epoch [115/1000], Loss: 0.1831\n",
      "Epoch [116/1000], Loss: 0.1798\n",
      "Epoch [117/1000], Loss: 0.1772\n",
      "Epoch [118/1000], Loss: 0.1767\n",
      "Epoch [119/1000], Loss: 0.1735\n",
      "Epoch [120/1000], Loss: 0.1718\n",
      "Epoch [121/1000], Loss: 0.1718\n",
      "Epoch [122/1000], Loss: 0.1699\n",
      "Epoch [123/1000], Loss: 0.1695\n",
      "Epoch [124/1000], Loss: 0.1702\n",
      "Epoch [125/1000], Loss: 0.1671\n",
      "Epoch [126/1000], Loss: 0.1660\n",
      "Epoch [127/1000], Loss: 0.1662\n",
      "Epoch [128/1000], Loss: 0.1654\n",
      "Epoch [129/1000], Loss: 0.1645\n",
      "Epoch [130/1000], Loss: 0.1639\n",
      "Epoch [131/1000], Loss: 0.1633\n",
      "Epoch [132/1000], Loss: 0.1623\n",
      "Epoch [133/1000], Loss: 0.1627\n",
      "Epoch [134/1000], Loss: 0.1614\n",
      "Epoch [135/1000], Loss: 0.1618\n",
      "Epoch [136/1000], Loss: 0.1611\n",
      "Epoch [137/1000], Loss: 0.1614\n",
      "Epoch [138/1000], Loss: 0.1628\n",
      "Epoch [139/1000], Loss: 0.1634\n",
      "Epoch [140/1000], Loss: 0.1618\n",
      "Epoch [141/1000], Loss: 0.1578\n",
      "Epoch [142/1000], Loss: 0.1587\n",
      "Epoch [143/1000], Loss: 0.1600\n",
      "Epoch [144/1000], Loss: 0.1597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [145/1000], Loss: 0.1571\n",
      "Epoch [146/1000], Loss: 0.1589\n",
      "Epoch [147/1000], Loss: 0.1577\n",
      "Epoch [148/1000], Loss: 0.1602\n",
      "Epoch [149/1000], Loss: 0.1561\n",
      "Epoch [150/1000], Loss: 0.1625\n",
      "Epoch [151/1000], Loss: 0.1579\n",
      "Epoch [152/1000], Loss: 0.1569\n",
      "Epoch [153/1000], Loss: 0.1596\n",
      "Epoch [154/1000], Loss: 0.1603\n",
      "Epoch [155/1000], Loss: 0.1571\n",
      "Epoch [156/1000], Loss: 0.1586\n",
      "Epoch [157/1000], Loss: 0.1596\n",
      "Epoch [158/1000], Loss: 0.1573\n",
      "Epoch [159/1000], Loss: 0.1594\n",
      "Epoch [160/1000], Loss: 0.1567\n",
      "Epoch [161/1000], Loss: 0.1541\n",
      "Epoch [162/1000], Loss: 0.1596\n",
      "Epoch [163/1000], Loss: 0.1543\n",
      "Epoch [164/1000], Loss: 0.1553\n",
      "Epoch [165/1000], Loss: 0.1560\n",
      "Epoch [166/1000], Loss: 0.1534\n",
      "Epoch [167/1000], Loss: 0.1603\n",
      "Epoch [168/1000], Loss: 0.1550\n",
      "Epoch [169/1000], Loss: 0.1541\n",
      "Epoch [170/1000], Loss: 0.1512\n",
      "Epoch [171/1000], Loss: 0.1551\n",
      "Epoch [172/1000], Loss: 0.1547\n",
      "Epoch [173/1000], Loss: 0.1532\n",
      "Epoch [174/1000], Loss: 0.1506\n",
      "Epoch [175/1000], Loss: 0.1545\n",
      "Epoch [176/1000], Loss: 0.1536\n",
      "Epoch [177/1000], Loss: 0.1498\n",
      "Epoch [178/1000], Loss: 0.1523\n",
      "Epoch [179/1000], Loss: 0.1496\n",
      "Epoch [180/1000], Loss: 0.1507\n",
      "Epoch [181/1000], Loss: 0.1514\n",
      "Epoch [182/1000], Loss: 0.1532\n",
      "Epoch [183/1000], Loss: 0.1489\n",
      "Epoch [184/1000], Loss: 0.1484\n",
      "Epoch [185/1000], Loss: 0.1479\n",
      "Epoch [186/1000], Loss: 0.1496\n",
      "Epoch [187/1000], Loss: 0.1515\n",
      "Epoch [188/1000], Loss: 0.1495\n",
      "Epoch [189/1000], Loss: 0.1511\n",
      "Epoch [190/1000], Loss: 0.1475\n",
      "Epoch [191/1000], Loss: 0.1559\n",
      "Epoch [192/1000], Loss: 0.1489\n",
      "Epoch [193/1000], Loss: 0.1541\n",
      "Epoch [194/1000], Loss: 0.1513\n",
      "Epoch [195/1000], Loss: 0.1503\n",
      "Epoch [196/1000], Loss: 0.1534\n",
      "Epoch [197/1000], Loss: 0.1497\n",
      "Epoch [198/1000], Loss: 0.1482\n",
      "Epoch [199/1000], Loss: 0.1497\n",
      "Epoch [200/1000], Loss: 0.1492\n",
      "Epoch [201/1000], Loss: 0.1472\n",
      "Epoch [202/1000], Loss: 0.1504\n",
      "Epoch [203/1000], Loss: 0.1491\n",
      "Epoch [204/1000], Loss: 0.1462\n",
      "Epoch [205/1000], Loss: 0.1501\n",
      "Epoch [206/1000], Loss: 0.1476\n",
      "Epoch [207/1000], Loss: 0.1473\n",
      "Epoch [208/1000], Loss: 0.1445\n",
      "Epoch [209/1000], Loss: 0.1491\n",
      "Epoch [210/1000], Loss: 0.1479\n",
      "Epoch [211/1000], Loss: 0.1494\n",
      "Epoch [212/1000], Loss: 0.1452\n",
      "Epoch [213/1000], Loss: 0.1483\n",
      "Epoch [214/1000], Loss: 0.1479\n",
      "Epoch [215/1000], Loss: 0.1490\n",
      "Epoch [216/1000], Loss: 0.1454\n",
      "Epoch [217/1000], Loss: 0.1463\n",
      "Epoch [218/1000], Loss: 0.1467\n",
      "Epoch [219/1000], Loss: 0.1458\n",
      "Epoch [220/1000], Loss: 0.1464\n",
      "Epoch [221/1000], Loss: 0.1446\n",
      "Epoch [222/1000], Loss: 0.1510\n",
      "Epoch [223/1000], Loss: 0.1442\n",
      "Epoch [224/1000], Loss: 0.1442\n",
      "Epoch [225/1000], Loss: 0.1461\n",
      "Epoch [226/1000], Loss: 0.1435\n",
      "Epoch [227/1000], Loss: 0.1499\n",
      "Epoch [228/1000], Loss: 0.1444\n",
      "Epoch [229/1000], Loss: 0.1531\n",
      "Epoch [230/1000], Loss: 0.1451\n",
      "Epoch [231/1000], Loss: 0.1475\n",
      "Epoch [232/1000], Loss: 0.1443\n",
      "Epoch [233/1000], Loss: 0.1424\n",
      "Epoch [234/1000], Loss: 0.1459\n",
      "Epoch [235/1000], Loss: 0.1426\n",
      "Epoch [236/1000], Loss: 0.1436\n",
      "Epoch [237/1000], Loss: 0.1484\n",
      "Epoch [238/1000], Loss: 0.1420\n",
      "Epoch [239/1000], Loss: 0.1453\n",
      "Epoch [240/1000], Loss: 0.1462\n",
      "Epoch [241/1000], Loss: 0.1474\n",
      "Epoch [242/1000], Loss: 0.1407\n",
      "Epoch [243/1000], Loss: 0.1517\n",
      "Epoch [244/1000], Loss: 0.1531\n",
      "Epoch [245/1000], Loss: 0.1425\n",
      "Epoch [246/1000], Loss: 0.1481\n",
      "Epoch [247/1000], Loss: 0.1446\n",
      "Epoch [248/1000], Loss: 0.1475\n",
      "Epoch [249/1000], Loss: 0.1453\n",
      "Epoch [250/1000], Loss: 0.1445\n",
      "Epoch [251/1000], Loss: 0.1438\n",
      "Epoch [252/1000], Loss: 0.1440\n",
      "Epoch [253/1000], Loss: 0.1437\n",
      "Epoch [254/1000], Loss: 0.1415\n",
      "Epoch [255/1000], Loss: 0.1474\n",
      "Epoch [256/1000], Loss: 0.1431\n",
      "Epoch [257/1000], Loss: 0.1428\n",
      "Epoch [258/1000], Loss: 0.1415\n",
      "Epoch [259/1000], Loss: 0.1405\n",
      "Epoch [260/1000], Loss: 0.1516\n",
      "Epoch [261/1000], Loss: 0.1422\n",
      "Epoch [262/1000], Loss: 0.1363\n",
      "Epoch [263/1000], Loss: 0.1466\n",
      "Epoch [264/1000], Loss: 0.1452\n",
      "Epoch [265/1000], Loss: 0.1441\n",
      "Epoch [266/1000], Loss: 0.1415\n",
      "Epoch [267/1000], Loss: 0.1396\n",
      "Epoch [268/1000], Loss: 0.1411\n",
      "Epoch [269/1000], Loss: 0.1468\n",
      "Epoch [270/1000], Loss: 0.1378\n",
      "Epoch [271/1000], Loss: 0.1417\n",
      "Epoch [272/1000], Loss: 0.1448\n",
      "Epoch [273/1000], Loss: 0.1413\n",
      "Epoch [274/1000], Loss: 0.1423\n",
      "Epoch [275/1000], Loss: 0.1408\n",
      "Epoch [276/1000], Loss: 0.1383\n",
      "Epoch [277/1000], Loss: 0.1466\n",
      "Epoch [278/1000], Loss: 0.1457\n",
      "Epoch [279/1000], Loss: 0.1442\n",
      "Epoch [280/1000], Loss: 0.1400\n",
      "Epoch [281/1000], Loss: 0.1394\n",
      "Epoch [282/1000], Loss: 0.1418\n",
      "Epoch [283/1000], Loss: 0.1428\n",
      "Epoch [284/1000], Loss: 0.1415\n",
      "Epoch [285/1000], Loss: 0.1455\n",
      "Epoch [286/1000], Loss: 0.1404\n",
      "Epoch [287/1000], Loss: 0.1600\n",
      "Epoch [288/1000], Loss: 0.1400\n",
      "Epoch [289/1000], Loss: 0.1353\n",
      "Epoch [290/1000], Loss: 0.1391\n",
      "Epoch [291/1000], Loss: 0.1394\n",
      "Epoch [292/1000], Loss: 0.1426\n",
      "Epoch [293/1000], Loss: 0.1369\n",
      "Epoch [294/1000], Loss: 0.1381\n",
      "Epoch [295/1000], Loss: 0.1416\n",
      "Epoch [296/1000], Loss: 0.1396\n",
      "Epoch [297/1000], Loss: 0.1429\n",
      "Epoch [298/1000], Loss: 0.1396\n",
      "Epoch [299/1000], Loss: 0.1404\n",
      "Epoch [300/1000], Loss: 0.1420\n",
      "Epoch [301/1000], Loss: 0.1527\n",
      "Epoch [302/1000], Loss: 0.1384\n",
      "Epoch [303/1000], Loss: 0.1378\n",
      "Epoch [304/1000], Loss: 0.1374\n",
      "Epoch [305/1000], Loss: 0.1446\n",
      "Epoch [306/1000], Loss: 0.1409\n",
      "Epoch [307/1000], Loss: 0.1387\n",
      "Epoch [308/1000], Loss: 0.1412\n",
      "Epoch [309/1000], Loss: 0.1367\n",
      "Epoch [310/1000], Loss: 0.1388\n",
      "Epoch [311/1000], Loss: 0.1423\n",
      "Epoch [312/1000], Loss: 0.1432\n",
      "Epoch [313/1000], Loss: 0.1385\n",
      "Epoch [314/1000], Loss: 0.1399\n",
      "Epoch [315/1000], Loss: 0.1409\n",
      "Epoch [316/1000], Loss: 0.1580\n",
      "Epoch [317/1000], Loss: 0.1390\n",
      "Epoch [318/1000], Loss: 0.1410\n",
      "Epoch [319/1000], Loss: 0.1391\n",
      "Epoch [320/1000], Loss: 0.1415\n",
      "Epoch [321/1000], Loss: 0.1393\n",
      "Epoch [322/1000], Loss: 0.1366\n",
      "Epoch [323/1000], Loss: 0.1431\n",
      "Epoch [324/1000], Loss: 0.1369\n",
      "Epoch [325/1000], Loss: 0.1376\n",
      "Epoch [326/1000], Loss: 0.1364\n",
      "Epoch [327/1000], Loss: 0.1354\n",
      "Epoch [328/1000], Loss: 0.1383\n",
      "Epoch [329/1000], Loss: 0.1381\n",
      "Epoch [330/1000], Loss: 0.1402\n",
      "Epoch [331/1000], Loss: 0.1396\n",
      "Epoch [332/1000], Loss: 0.1384\n",
      "Epoch [333/1000], Loss: 0.1417\n",
      "Epoch [334/1000], Loss: 0.1373\n",
      "Epoch [335/1000], Loss: 0.1379\n",
      "Epoch [336/1000], Loss: 0.1392\n",
      "Epoch [337/1000], Loss: 0.1398\n",
      "Epoch [338/1000], Loss: 0.1361\n",
      "Epoch [339/1000], Loss: 0.1409\n",
      "Epoch [340/1000], Loss: 0.1337\n",
      "Epoch [341/1000], Loss: 0.1384\n",
      "Epoch [342/1000], Loss: 0.1410\n",
      "Epoch [343/1000], Loss: 0.1362\n",
      "Epoch [344/1000], Loss: 0.1383\n",
      "Epoch [345/1000], Loss: 0.1310\n",
      "Epoch [346/1000], Loss: 0.1372\n",
      "Epoch [347/1000], Loss: 0.1374\n",
      "Epoch [348/1000], Loss: 0.1354\n",
      "Epoch [349/1000], Loss: 0.1319\n",
      "Epoch [350/1000], Loss: 0.1303\n",
      "Epoch [351/1000], Loss: 0.1369\n",
      "Epoch [352/1000], Loss: 0.1341\n",
      "Epoch [353/1000], Loss: 0.1306\n",
      "Epoch [354/1000], Loss: 0.1293\n",
      "Epoch [355/1000], Loss: 0.1373\n",
      "Epoch [356/1000], Loss: 0.1381\n",
      "Epoch [357/1000], Loss: 0.1325\n",
      "Epoch [358/1000], Loss: 0.1288\n",
      "Epoch [359/1000], Loss: 0.1320\n",
      "Epoch [360/1000], Loss: 0.1316\n",
      "Epoch [361/1000], Loss: 0.1288\n",
      "Epoch [362/1000], Loss: 0.1380\n",
      "Epoch [363/1000], Loss: 0.1335\n",
      "Epoch [364/1000], Loss: 0.1321\n",
      "Epoch [365/1000], Loss: 0.1311\n",
      "Epoch [366/1000], Loss: 0.1276\n",
      "Epoch [367/1000], Loss: 0.1362\n",
      "Epoch [368/1000], Loss: 0.1325\n",
      "Epoch [369/1000], Loss: 0.1301\n",
      "Epoch [370/1000], Loss: 0.1303\n",
      "Epoch [371/1000], Loss: 0.1304\n",
      "Epoch [372/1000], Loss: 0.1250\n",
      "Epoch [373/1000], Loss: 0.1325\n",
      "Epoch [374/1000], Loss: 0.1268\n",
      "Epoch [375/1000], Loss: 0.1235\n",
      "Epoch [376/1000], Loss: 0.1307\n",
      "Epoch [377/1000], Loss: 0.1296\n",
      "Epoch [378/1000], Loss: 0.1255\n",
      "Epoch [379/1000], Loss: 0.1262\n",
      "Epoch [380/1000], Loss: 0.1245\n",
      "Epoch [381/1000], Loss: 0.1220\n",
      "Epoch [382/1000], Loss: 0.1356\n",
      "Epoch [383/1000], Loss: 0.1222\n",
      "Epoch [384/1000], Loss: 0.1247\n",
      "Epoch [385/1000], Loss: 0.1217\n",
      "Epoch [386/1000], Loss: 0.1198\n",
      "Epoch [387/1000], Loss: 0.1281\n",
      "Epoch [388/1000], Loss: 0.1263\n",
      "Epoch [389/1000], Loss: 0.1231\n",
      "Epoch [390/1000], Loss: 0.1212\n",
      "Epoch [391/1000], Loss: 0.1195\n",
      "Epoch [392/1000], Loss: 0.1198\n",
      "Epoch [393/1000], Loss: 0.1206\n",
      "Epoch [394/1000], Loss: 0.1172\n",
      "Epoch [395/1000], Loss: 0.1157\n",
      "Epoch [396/1000], Loss: 0.1183\n",
      "Epoch [397/1000], Loss: 0.1195\n",
      "Epoch [398/1000], Loss: 0.1188\n",
      "Epoch [399/1000], Loss: 0.1204\n",
      "Epoch [400/1000], Loss: 0.1173\n",
      "Epoch [401/1000], Loss: 0.1188\n",
      "Epoch [402/1000], Loss: 0.1153\n",
      "Epoch [403/1000], Loss: 0.1178\n",
      "Epoch [404/1000], Loss: 0.1162\n",
      "Epoch [405/1000], Loss: 0.1162\n",
      "Epoch [406/1000], Loss: 0.1146\n",
      "Epoch [407/1000], Loss: 0.1131\n",
      "Epoch [408/1000], Loss: 0.1123\n",
      "Epoch [409/1000], Loss: 0.1120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [410/1000], Loss: 0.1123\n",
      "Epoch [411/1000], Loss: 0.1130\n",
      "Epoch [412/1000], Loss: 0.1121\n",
      "Epoch [413/1000], Loss: 0.1118\n",
      "Epoch [414/1000], Loss: 0.1159\n",
      "Epoch [415/1000], Loss: 0.1153\n",
      "Epoch [416/1000], Loss: 0.1102\n",
      "Epoch [417/1000], Loss: 0.1119\n",
      "Epoch [418/1000], Loss: 0.1131\n",
      "Epoch [419/1000], Loss: 0.1139\n",
      "Epoch [420/1000], Loss: 0.1108\n",
      "Epoch [421/1000], Loss: 0.1094\n",
      "Epoch [422/1000], Loss: 0.1105\n",
      "Epoch [423/1000], Loss: 0.1100\n",
      "Epoch [424/1000], Loss: 0.1108\n",
      "Epoch [425/1000], Loss: 0.1091\n",
      "Epoch [426/1000], Loss: 0.1090\n",
      "Epoch [427/1000], Loss: 0.1073\n",
      "Epoch [428/1000], Loss: 0.1113\n",
      "Epoch [429/1000], Loss: 0.1088\n",
      "Epoch [430/1000], Loss: 0.1076\n",
      "Epoch [431/1000], Loss: 0.1099\n",
      "Epoch [432/1000], Loss: 0.1061\n",
      "Epoch [433/1000], Loss: 0.1085\n",
      "Epoch [434/1000], Loss: 0.1064\n",
      "Epoch [435/1000], Loss: 0.1074\n",
      "Epoch [436/1000], Loss: 0.1073\n",
      "Epoch [437/1000], Loss: 0.1055\n",
      "Epoch [438/1000], Loss: 0.1035\n",
      "Epoch [439/1000], Loss: 0.1058\n",
      "Epoch [440/1000], Loss: 0.1036\n",
      "Epoch [441/1000], Loss: 0.1070\n",
      "Epoch [442/1000], Loss: 0.1089\n",
      "Epoch [443/1000], Loss: 0.1051\n",
      "Epoch [444/1000], Loss: 0.1032\n",
      "Epoch [445/1000], Loss: 0.1042\n",
      "Epoch [446/1000], Loss: 0.1011\n",
      "Epoch [447/1000], Loss: 0.1035\n",
      "Epoch [448/1000], Loss: 0.1041\n",
      "Epoch [449/1000], Loss: 0.1015\n",
      "Epoch [450/1000], Loss: 0.1034\n",
      "Epoch [451/1000], Loss: 0.1041\n",
      "Epoch [452/1000], Loss: 0.1009\n",
      "Epoch [453/1000], Loss: 0.0991\n",
      "Epoch [454/1000], Loss: 0.1019\n",
      "Epoch [455/1000], Loss: 0.0989\n",
      "Epoch [456/1000], Loss: 0.1015\n",
      "Epoch [457/1000], Loss: 0.0994\n",
      "Epoch [458/1000], Loss: 0.0957\n",
      "Epoch [459/1000], Loss: 0.0963\n",
      "Epoch [460/1000], Loss: 0.0981\n",
      "Epoch [461/1000], Loss: 0.0953\n",
      "Epoch [462/1000], Loss: 0.0920\n",
      "Epoch [463/1000], Loss: 0.0950\n",
      "Epoch [464/1000], Loss: 0.1023\n",
      "Epoch [465/1000], Loss: 0.0910\n",
      "Epoch [466/1000], Loss: 0.0948\n",
      "Epoch [467/1000], Loss: 0.0937\n",
      "Epoch [468/1000], Loss: 0.0852\n",
      "Epoch [469/1000], Loss: 0.0928\n",
      "Epoch [470/1000], Loss: 0.0963\n",
      "Epoch [471/1000], Loss: 0.0962\n",
      "Epoch [472/1000], Loss: 0.0873\n",
      "Epoch [473/1000], Loss: 0.0900\n",
      "Epoch [474/1000], Loss: 0.0811\n",
      "Epoch [475/1000], Loss: 0.0811\n",
      "Epoch [476/1000], Loss: 0.0792\n",
      "Epoch [477/1000], Loss: 0.0791\n",
      "Epoch [478/1000], Loss: 0.0856\n",
      "Epoch [479/1000], Loss: 0.0896\n",
      "Epoch [480/1000], Loss: 0.0787\n",
      "Epoch [481/1000], Loss: 0.0763\n",
      "Epoch [482/1000], Loss: 0.0813\n",
      "Epoch [483/1000], Loss: 0.0880\n",
      "Epoch [484/1000], Loss: 0.0704\n",
      "Epoch [485/1000], Loss: 0.0714\n",
      "Epoch [486/1000], Loss: 0.0853\n",
      "Epoch [487/1000], Loss: 0.0856\n",
      "Epoch [488/1000], Loss: 0.0753\n",
      "Epoch [489/1000], Loss: 0.0738\n",
      "Epoch [490/1000], Loss: 0.0753\n",
      "Epoch [491/1000], Loss: 0.0696\n",
      "Epoch [492/1000], Loss: 0.0667\n",
      "Epoch [493/1000], Loss: 0.0665\n",
      "Epoch [494/1000], Loss: 0.0681\n",
      "Epoch [495/1000], Loss: 0.0697\n",
      "Epoch [496/1000], Loss: 0.0675\n",
      "Epoch [497/1000], Loss: 0.0698\n",
      "Epoch [498/1000], Loss: 0.0710\n",
      "Epoch [499/1000], Loss: 0.0642\n",
      "Epoch [500/1000], Loss: 0.0687\n",
      "Epoch [501/1000], Loss: 0.0702\n",
      "Epoch [502/1000], Loss: 0.0580\n",
      "Epoch [503/1000], Loss: 0.0650\n",
      "Epoch [504/1000], Loss: 0.0669\n",
      "Epoch [505/1000], Loss: 0.0629\n",
      "Epoch [506/1000], Loss: 0.0620\n",
      "Epoch [507/1000], Loss: 0.0500\n",
      "Epoch [508/1000], Loss: 0.0603\n",
      "Epoch [509/1000], Loss: 0.0612\n",
      "Epoch [510/1000], Loss: 0.0473\n",
      "Epoch [511/1000], Loss: 0.0540\n",
      "Epoch [512/1000], Loss: 0.0584\n",
      "Epoch [513/1000], Loss: 0.0469\n",
      "Epoch [514/1000], Loss: 0.0434\n",
      "Epoch [515/1000], Loss: 0.0519\n",
      "Epoch [516/1000], Loss: 0.0501\n",
      "Epoch [517/1000], Loss: 0.0489\n",
      "Epoch [518/1000], Loss: 0.0376\n",
      "Epoch [519/1000], Loss: 0.0531\n",
      "Epoch [520/1000], Loss: 0.0307\n",
      "Epoch [521/1000], Loss: 0.0255\n",
      "Epoch [522/1000], Loss: 0.0337\n",
      "Epoch [523/1000], Loss: 0.0253\n",
      "Epoch [524/1000], Loss: 0.0277\n",
      "Epoch [525/1000], Loss: 0.0319\n",
      "Epoch [526/1000], Loss: 0.0181\n",
      "Epoch [527/1000], Loss: 0.0383\n",
      "Epoch [528/1000], Loss: 0.0222\n",
      "Epoch [529/1000], Loss: 0.0223\n",
      "Epoch [530/1000], Loss: 0.0222\n",
      "Epoch [531/1000], Loss: 0.0204\n",
      "Epoch [532/1000], Loss: 0.0160\n",
      "Epoch [533/1000], Loss: 0.0200\n",
      "Epoch [534/1000], Loss: 0.0219\n",
      "Epoch [535/1000], Loss: 0.0352\n",
      "Epoch [536/1000], Loss: 0.0108\n",
      "Epoch [537/1000], Loss: 0.0126\n",
      "Epoch [538/1000], Loss: 0.0146\n",
      "Epoch [539/1000], Loss: 0.0125\n",
      "Epoch [540/1000], Loss: 0.0086\n",
      "Epoch [541/1000], Loss: 0.0088\n",
      "Epoch [542/1000], Loss: 0.0085\n",
      "Epoch [543/1000], Loss: 0.0043\n",
      "Epoch [544/1000], Loss: 0.0177\n",
      "Epoch [545/1000], Loss: 0.0072\n",
      "Epoch [546/1000], Loss: 0.0053\n",
      "Epoch [547/1000], Loss: 0.0068\n",
      "Epoch [548/1000], Loss: 0.0069\n",
      "Epoch [549/1000], Loss: 0.0042\n",
      "Epoch [550/1000], Loss: 0.0095\n",
      "Epoch [551/1000], Loss: 0.0186\n",
      "Epoch [552/1000], Loss: 0.0104\n",
      "Epoch [553/1000], Loss: 0.0066\n",
      "Epoch [554/1000], Loss: 0.0110\n",
      "Epoch [555/1000], Loss: 0.0043\n",
      "Epoch [556/1000], Loss: 0.0179\n",
      "Epoch [557/1000], Loss: 0.0171\n",
      "Epoch [558/1000], Loss: 0.0042\n",
      "Epoch [559/1000], Loss: 0.0056\n",
      "Epoch [560/1000], Loss: 0.0073\n",
      "Epoch [561/1000], Loss: 0.0055\n",
      "Epoch [562/1000], Loss: 0.0078\n",
      "Epoch [563/1000], Loss: 0.0049\n",
      "Epoch [564/1000], Loss: 0.0064\n",
      "Epoch [565/1000], Loss: 0.0039\n",
      "Epoch [566/1000], Loss: 0.0053\n",
      "Epoch [567/1000], Loss: 0.0043\n",
      "Epoch [568/1000], Loss: 0.0046\n",
      "Epoch [569/1000], Loss: 0.0070\n",
      "Epoch [570/1000], Loss: 0.0045\n",
      "Epoch [571/1000], Loss: 0.0035\n",
      "Epoch [572/1000], Loss: 0.0033\n",
      "Epoch [573/1000], Loss: 0.0086\n",
      "Epoch [574/1000], Loss: 0.0049\n",
      "Epoch [575/1000], Loss: 0.0028\n",
      "Epoch [576/1000], Loss: 0.0025\n",
      "Epoch [577/1000], Loss: 0.0143\n",
      "Epoch [578/1000], Loss: 0.0124\n",
      "Epoch [579/1000], Loss: 0.0151\n",
      "Epoch [580/1000], Loss: 0.0060\n",
      "Epoch [581/1000], Loss: 0.0046\n",
      "Epoch [582/1000], Loss: 0.0079\n",
      "Epoch [583/1000], Loss: 0.0049\n",
      "Epoch [584/1000], Loss: 0.0056\n",
      "Epoch [585/1000], Loss: 0.0048\n",
      "Epoch [586/1000], Loss: 0.0140\n",
      "Epoch [587/1000], Loss: 0.0180\n",
      "Epoch [588/1000], Loss: 0.0145\n",
      "Epoch [589/1000], Loss: 0.0059\n",
      "Epoch [590/1000], Loss: 0.0072\n",
      "Epoch [591/1000], Loss: 0.0048\n",
      "Epoch [592/1000], Loss: 0.0039\n",
      "Epoch [593/1000], Loss: 0.0051\n",
      "Epoch [594/1000], Loss: 0.0026\n",
      "Epoch [595/1000], Loss: 0.0047\n",
      "Epoch [596/1000], Loss: 0.0052\n",
      "Epoch [597/1000], Loss: 0.0102\n",
      "Epoch [598/1000], Loss: 0.0034\n",
      "Epoch [599/1000], Loss: 0.0024\n",
      "Epoch [600/1000], Loss: 0.0070\n",
      "Epoch [601/1000], Loss: 0.0086\n",
      "Epoch [602/1000], Loss: 0.0026\n",
      "Epoch [603/1000], Loss: 0.0052\n",
      "Epoch [604/1000], Loss: 0.0085\n",
      "Epoch [605/1000], Loss: 0.0047\n",
      "Epoch [606/1000], Loss: 0.0038\n",
      "Epoch [607/1000], Loss: 0.0026\n",
      "Epoch [608/1000], Loss: 0.0023\n",
      "Epoch [609/1000], Loss: 0.0031\n",
      "Epoch [610/1000], Loss: 0.0168\n",
      "Epoch [611/1000], Loss: 0.0082\n",
      "Epoch [612/1000], Loss: 0.0023\n",
      "Epoch [613/1000], Loss: 0.0038\n",
      "Epoch [614/1000], Loss: 0.0019\n",
      "Epoch [615/1000], Loss: 0.0058\n",
      "Epoch [616/1000], Loss: 0.0069\n",
      "Epoch [617/1000], Loss: 0.0026\n",
      "Epoch [618/1000], Loss: 0.0083\n",
      "Epoch [619/1000], Loss: 0.0022\n",
      "Epoch [620/1000], Loss: 0.0053\n",
      "Epoch [621/1000], Loss: 0.0027\n",
      "Epoch [622/1000], Loss: 0.0017\n",
      "Epoch [623/1000], Loss: 0.0056\n",
      "Epoch [624/1000], Loss: 0.0056\n",
      "Epoch [625/1000], Loss: 0.0022\n",
      "Epoch [626/1000], Loss: 0.0019\n",
      "Epoch [627/1000], Loss: 0.0022\n",
      "Epoch [628/1000], Loss: 0.0068\n",
      "Epoch [629/1000], Loss: 0.0021\n",
      "Epoch [630/1000], Loss: 0.0079\n",
      "Epoch [631/1000], Loss: 0.0086\n",
      "Epoch [632/1000], Loss: 0.0021\n",
      "Epoch [633/1000], Loss: 0.0018\n",
      "Epoch [634/1000], Loss: 0.0086\n",
      "Epoch [635/1000], Loss: 0.0087\n",
      "Epoch [636/1000], Loss: 0.0024\n",
      "Epoch [637/1000], Loss: 0.0025\n",
      "Epoch [638/1000], Loss: 0.0021\n",
      "Epoch [639/1000], Loss: 0.0053\n",
      "Epoch [640/1000], Loss: 0.0024\n",
      "Epoch [641/1000], Loss: 0.0073\n",
      "Epoch [642/1000], Loss: 0.0018\n",
      "Epoch [643/1000], Loss: 0.0017\n",
      "Epoch [644/1000], Loss: 0.0018\n",
      "Epoch [645/1000], Loss: 0.0104\n",
      "Epoch [646/1000], Loss: 0.0040\n",
      "Epoch [647/1000], Loss: 0.0017\n",
      "Epoch [648/1000], Loss: 0.0034\n",
      "Epoch [649/1000], Loss: 0.0018\n",
      "Epoch [650/1000], Loss: 0.0028\n",
      "Epoch [651/1000], Loss: 0.0210\n",
      "Epoch [652/1000], Loss: 0.0024\n",
      "Epoch [653/1000], Loss: 0.0070\n",
      "Epoch [654/1000], Loss: 0.0022\n",
      "Epoch [655/1000], Loss: 0.0023\n",
      "Epoch [656/1000], Loss: 0.0017\n",
      "Epoch [657/1000], Loss: 0.0014\n",
      "Epoch [658/1000], Loss: 0.0044\n",
      "Epoch [659/1000], Loss: 0.0046\n",
      "Epoch [660/1000], Loss: 0.0017\n",
      "Epoch [661/1000], Loss: 0.0072\n",
      "Epoch [662/1000], Loss: 0.0022\n",
      "Epoch [663/1000], Loss: 0.0028\n",
      "Epoch [664/1000], Loss: 0.0023\n",
      "Epoch [665/1000], Loss: 0.0018\n",
      "Epoch [666/1000], Loss: 0.0014\n",
      "Epoch [667/1000], Loss: 0.0039\n",
      "Epoch [668/1000], Loss: 0.0025\n",
      "Epoch [669/1000], Loss: 0.0018\n",
      "Epoch [670/1000], Loss: 0.0037\n",
      "Epoch [671/1000], Loss: 0.0242\n",
      "Epoch [672/1000], Loss: 0.0068\n",
      "Epoch [673/1000], Loss: 0.0015\n",
      "Epoch [674/1000], Loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [675/1000], Loss: 0.0129\n",
      "Epoch [676/1000], Loss: 0.0031\n",
      "Epoch [677/1000], Loss: 0.0016\n",
      "Epoch [678/1000], Loss: 0.0016\n",
      "Epoch [679/1000], Loss: 0.0069\n",
      "Epoch [680/1000], Loss: 0.0023\n",
      "Epoch [681/1000], Loss: 0.0014\n",
      "Epoch [682/1000], Loss: 0.0022\n",
      "Epoch [683/1000], Loss: 0.0028\n",
      "Epoch [684/1000], Loss: 0.0080\n",
      "Epoch [685/1000], Loss: 0.0019\n",
      "Epoch [686/1000], Loss: 0.0015\n",
      "Epoch [687/1000], Loss: 0.0062\n",
      "Epoch [688/1000], Loss: 0.0018\n",
      "Epoch [689/1000], Loss: 0.0014\n",
      "Epoch [690/1000], Loss: 0.0025\n",
      "Epoch [691/1000], Loss: 0.0013\n",
      "Epoch [692/1000], Loss: 0.0031\n",
      "Epoch [693/1000], Loss: 0.0014\n",
      "Epoch [694/1000], Loss: 0.0040\n",
      "Epoch [695/1000], Loss: 0.0013\n",
      "Epoch [696/1000], Loss: 0.0052\n",
      "Epoch [697/1000], Loss: 0.0022\n",
      "Epoch [698/1000], Loss: 0.0014\n",
      "Epoch [699/1000], Loss: 0.0014\n",
      "Epoch [700/1000], Loss: 0.0011\n",
      "Epoch [701/1000], Loss: 0.0024\n",
      "Epoch [702/1000], Loss: 0.0019\n",
      "Epoch [703/1000], Loss: 0.0012\n",
      "Epoch [704/1000], Loss: 0.0011\n",
      "Epoch [705/1000], Loss: 0.0014\n",
      "Epoch [706/1000], Loss: 0.0010\n",
      "Epoch [707/1000], Loss: 0.0011\n",
      "Epoch [708/1000], Loss: 0.0012\n",
      "Epoch [709/1000], Loss: 0.0019\n",
      "Epoch [710/1000], Loss: 0.0014\n",
      "Epoch [711/1000], Loss: 0.0020\n",
      "Epoch [712/1000], Loss: 0.0012\n",
      "Epoch [713/1000], Loss: 0.0014\n",
      "Epoch [714/1000], Loss: 0.0011\n",
      "Epoch [715/1000], Loss: 0.0011\n",
      "Epoch [716/1000], Loss: 0.0009\n",
      "Epoch [717/1000], Loss: 0.0013\n",
      "Epoch [718/1000], Loss: 0.0013\n",
      "Epoch [719/1000], Loss: 0.0010\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 4, activation : tanh, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2538\n",
      "Epoch [2/1000], Loss: 0.2509\n",
      "Epoch [3/1000], Loss: 0.2496\n",
      "Epoch [4/1000], Loss: 0.2485\n",
      "Epoch [5/1000], Loss: 0.2473\n",
      "Epoch [6/1000], Loss: 0.2459\n",
      "Epoch [7/1000], Loss: 0.2444\n",
      "Epoch [8/1000], Loss: 0.2429\n",
      "Epoch [9/1000], Loss: 0.2416\n",
      "Epoch [10/1000], Loss: 0.2407\n",
      "Epoch [11/1000], Loss: 0.2400\n",
      "Epoch [12/1000], Loss: 0.2397\n",
      "Epoch [13/1000], Loss: 0.2394\n",
      "Epoch [14/1000], Loss: 0.2393\n",
      "Epoch [15/1000], Loss: 0.2391\n",
      "Epoch [16/1000], Loss: 0.2390\n",
      "Epoch [17/1000], Loss: 0.2389\n",
      "Epoch [18/1000], Loss: 0.2388\n",
      "Epoch [19/1000], Loss: 0.2387\n",
      "Epoch [20/1000], Loss: 0.2386\n",
      "Epoch [21/1000], Loss: 0.2385\n",
      "Epoch [22/1000], Loss: 0.2384\n",
      "Epoch [23/1000], Loss: 0.2383\n",
      "Epoch [24/1000], Loss: 0.2382\n",
      "Epoch [25/1000], Loss: 0.2380\n",
      "Epoch [26/1000], Loss: 0.2379\n",
      "Epoch [27/1000], Loss: 0.2378\n",
      "Epoch [28/1000], Loss: 0.2377\n",
      "Epoch [29/1000], Loss: 0.2376\n",
      "Epoch [30/1000], Loss: 0.2375\n",
      "Epoch [31/1000], Loss: 0.2374\n",
      "Epoch [32/1000], Loss: 0.2373\n",
      "Epoch [33/1000], Loss: 0.2371\n",
      "Epoch [34/1000], Loss: 0.2370\n",
      "Epoch [35/1000], Loss: 0.2369\n",
      "Epoch [36/1000], Loss: 0.2367\n",
      "Epoch [37/1000], Loss: 0.2366\n",
      "Epoch [38/1000], Loss: 0.2364\n",
      "Epoch [39/1000], Loss: 0.2363\n",
      "Epoch [40/1000], Loss: 0.2361\n",
      "Epoch [41/1000], Loss: 0.2359\n",
      "Epoch [42/1000], Loss: 0.2357\n",
      "Epoch [43/1000], Loss: 0.2355\n",
      "Epoch [44/1000], Loss: 0.2354\n",
      "Epoch [45/1000], Loss: 0.2352\n",
      "Epoch [46/1000], Loss: 0.2350\n",
      "Epoch [47/1000], Loss: 0.2347\n",
      "Epoch [48/1000], Loss: 0.2344\n",
      "Epoch [49/1000], Loss: 0.2342\n",
      "Epoch [50/1000], Loss: 0.2339\n",
      "Epoch [51/1000], Loss: 0.2335\n",
      "Epoch [52/1000], Loss: 0.2332\n",
      "Epoch [53/1000], Loss: 0.2328\n",
      "Epoch [54/1000], Loss: 0.2324\n",
      "Epoch [55/1000], Loss: 0.2319\n",
      "Epoch [56/1000], Loss: 0.2315\n",
      "Epoch [57/1000], Loss: 0.2309\n",
      "Epoch [58/1000], Loss: 0.2303\n",
      "Epoch [59/1000], Loss: 0.2297\n",
      "Epoch [60/1000], Loss: 0.2290\n",
      "Epoch [61/1000], Loss: 0.2282\n",
      "Epoch [62/1000], Loss: 0.2274\n",
      "Epoch [63/1000], Loss: 0.2264\n",
      "Epoch [64/1000], Loss: 0.2255\n",
      "Epoch [65/1000], Loss: 0.2245\n",
      "Epoch [66/1000], Loss: 0.2231\n",
      "Epoch [67/1000], Loss: 0.2222\n",
      "Epoch [68/1000], Loss: 0.2208\n",
      "Epoch [69/1000], Loss: 0.2196\n",
      "Epoch [70/1000], Loss: 0.2184\n",
      "Epoch [71/1000], Loss: 0.2170\n",
      "Epoch [72/1000], Loss: 0.2156\n",
      "Epoch [73/1000], Loss: 0.2139\n",
      "Epoch [74/1000], Loss: 0.2127\n",
      "Epoch [75/1000], Loss: 0.2112\n",
      "Epoch [76/1000], Loss: 0.2094\n",
      "Epoch [77/1000], Loss: 0.2080\n",
      "Epoch [78/1000], Loss: 0.2059\n",
      "Epoch [79/1000], Loss: 0.2042\n",
      "Epoch [80/1000], Loss: 0.2026\n",
      "Epoch [81/1000], Loss: 0.1996\n",
      "Epoch [82/1000], Loss: 0.1980\n",
      "Epoch [83/1000], Loss: 0.1936\n",
      "Epoch [84/1000], Loss: 0.1916\n",
      "Epoch [85/1000], Loss: 0.1890\n",
      "Epoch [86/1000], Loss: 0.1858\n",
      "Epoch [87/1000], Loss: 0.1824\n",
      "Epoch [88/1000], Loss: 0.1802\n",
      "Epoch [89/1000], Loss: 0.1778\n",
      "Epoch [90/1000], Loss: 0.1751\n",
      "Epoch [91/1000], Loss: 0.1716\n",
      "Epoch [92/1000], Loss: 0.1682\n",
      "Epoch [93/1000], Loss: 0.1648\n",
      "Epoch [94/1000], Loss: 0.1613\n",
      "Epoch [95/1000], Loss: 0.1621\n",
      "Epoch [96/1000], Loss: 0.1589\n",
      "Epoch [97/1000], Loss: 0.1548\n",
      "Epoch [98/1000], Loss: 0.1528\n",
      "Epoch [99/1000], Loss: 0.1528\n",
      "Epoch [100/1000], Loss: 0.1506\n",
      "Epoch [101/1000], Loss: 0.1477\n",
      "Epoch [102/1000], Loss: 0.1444\n",
      "Epoch [103/1000], Loss: 0.1433\n",
      "Epoch [104/1000], Loss: 0.1431\n",
      "Epoch [105/1000], Loss: 0.1413\n",
      "Epoch [106/1000], Loss: 0.1380\n",
      "Epoch [107/1000], Loss: 0.1401\n",
      "Epoch [108/1000], Loss: 0.1344\n",
      "Epoch [109/1000], Loss: 0.1367\n",
      "Epoch [110/1000], Loss: 0.1317\n",
      "Epoch [111/1000], Loss: 0.1334\n",
      "Epoch [112/1000], Loss: 0.1282\n",
      "Epoch [113/1000], Loss: 0.1251\n",
      "Epoch [114/1000], Loss: 0.1263\n",
      "Epoch [115/1000], Loss: 0.1199\n",
      "Epoch [116/1000], Loss: 0.1194\n",
      "Epoch [117/1000], Loss: 0.1172\n",
      "Epoch [118/1000], Loss: 0.1125\n",
      "Epoch [119/1000], Loss: 0.1153\n",
      "Epoch [120/1000], Loss: 0.1152\n",
      "Epoch [121/1000], Loss: 0.1100\n",
      "Epoch [122/1000], Loss: 0.1103\n",
      "Epoch [123/1000], Loss: 0.1079\n",
      "Epoch [124/1000], Loss: 0.1074\n",
      "Epoch [125/1000], Loss: 0.1095\n",
      "Epoch [126/1000], Loss: 0.1001\n",
      "Epoch [127/1000], Loss: 0.1046\n",
      "Epoch [128/1000], Loss: 0.1018\n",
      "Epoch [129/1000], Loss: 0.1018\n",
      "Epoch [130/1000], Loss: 0.0999\n",
      "Epoch [131/1000], Loss: 0.1008\n",
      "Epoch [132/1000], Loss: 0.0950\n",
      "Epoch [133/1000], Loss: 0.0962\n",
      "Epoch [134/1000], Loss: 0.0962\n",
      "Epoch [135/1000], Loss: 0.0947\n",
      "Epoch [136/1000], Loss: 0.0935\n",
      "Epoch [137/1000], Loss: 0.0928\n",
      "Epoch [138/1000], Loss: 0.0883\n",
      "Epoch [139/1000], Loss: 0.0915\n",
      "Epoch [140/1000], Loss: 0.0887\n",
      "Epoch [141/1000], Loss: 0.0924\n",
      "Epoch [142/1000], Loss: 0.0856\n",
      "Epoch [143/1000], Loss: 0.0820\n",
      "Epoch [144/1000], Loss: 0.0770\n",
      "Epoch [145/1000], Loss: 0.0774\n",
      "Epoch [146/1000], Loss: 0.0735\n",
      "Epoch [147/1000], Loss: 0.0675\n",
      "Epoch [148/1000], Loss: 0.0614\n",
      "Epoch [149/1000], Loss: 0.0532\n",
      "Epoch [150/1000], Loss: 0.0520\n",
      "Epoch [151/1000], Loss: 0.0511\n",
      "Epoch [152/1000], Loss: 0.0420\n",
      "Epoch [153/1000], Loss: 0.0411\n",
      "Epoch [154/1000], Loss: 0.0363\n",
      "Epoch [155/1000], Loss: 0.0271\n",
      "Epoch [156/1000], Loss: 0.0262\n",
      "Epoch [157/1000], Loss: 0.0269\n",
      "Epoch [158/1000], Loss: 0.0168\n",
      "Epoch [159/1000], Loss: 0.0238\n",
      "Epoch [160/1000], Loss: 0.0152\n",
      "Epoch [161/1000], Loss: 0.0119\n",
      "Epoch [162/1000], Loss: 0.0113\n",
      "Epoch [163/1000], Loss: 0.0101\n",
      "Epoch [164/1000], Loss: 0.0062\n",
      "Epoch [165/1000], Loss: 0.0064\n",
      "Epoch [166/1000], Loss: 0.0095\n",
      "Epoch [167/1000], Loss: 0.0079\n",
      "Epoch [168/1000], Loss: 0.0057\n",
      "Epoch [169/1000], Loss: 0.0044\n",
      "Epoch [170/1000], Loss: 0.0038\n",
      "Epoch [171/1000], Loss: 0.0032\n",
      "Epoch [172/1000], Loss: 0.0033\n",
      "Epoch [173/1000], Loss: 0.0037\n",
      "Epoch [174/1000], Loss: 0.0025\n",
      "Epoch [175/1000], Loss: 0.0030\n",
      "Epoch [176/1000], Loss: 0.0041\n",
      "Epoch [177/1000], Loss: 0.0022\n",
      "Epoch [178/1000], Loss: 0.0024\n",
      "Epoch [179/1000], Loss: 0.0024\n",
      "Epoch [180/1000], Loss: 0.0021\n",
      "Epoch [181/1000], Loss: 0.0017\n",
      "Epoch [182/1000], Loss: 0.0018\n",
      "Epoch [183/1000], Loss: 0.0019\n",
      "Epoch [184/1000], Loss: 0.0018\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 4, activation : tanh, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2469\n",
      "Epoch [2/1000], Loss: 0.2441\n",
      "Epoch [3/1000], Loss: 0.2420\n",
      "Epoch [4/1000], Loss: 0.2406\n",
      "Epoch [5/1000], Loss: 0.2397\n",
      "Epoch [6/1000], Loss: 0.2392\n",
      "Epoch [7/1000], Loss: 0.2388\n",
      "Epoch [8/1000], Loss: 0.2385\n",
      "Epoch [9/1000], Loss: 0.2382\n",
      "Epoch [10/1000], Loss: 0.2380\n",
      "Epoch [11/1000], Loss: 0.2377\n",
      "Epoch [12/1000], Loss: 0.2373\n",
      "Epoch [13/1000], Loss: 0.2371\n",
      "Epoch [14/1000], Loss: 0.2368\n",
      "Epoch [15/1000], Loss: 0.2366\n",
      "Epoch [16/1000], Loss: 0.2362\n",
      "Epoch [17/1000], Loss: 0.2359\n",
      "Epoch [18/1000], Loss: 0.2355\n",
      "Epoch [19/1000], Loss: 0.2352\n",
      "Epoch [20/1000], Loss: 0.2348\n",
      "Epoch [21/1000], Loss: 0.2343\n",
      "Epoch [22/1000], Loss: 0.2338\n",
      "Epoch [23/1000], Loss: 0.2333\n",
      "Epoch [24/1000], Loss: 0.2327\n",
      "Epoch [25/1000], Loss: 0.2321\n",
      "Epoch [26/1000], Loss: 0.2314\n",
      "Epoch [27/1000], Loss: 0.2307\n",
      "Epoch [28/1000], Loss: 0.2299\n",
      "Epoch [29/1000], Loss: 0.2289\n",
      "Epoch [30/1000], Loss: 0.2281\n",
      "Epoch [31/1000], Loss: 0.2271\n",
      "Epoch [32/1000], Loss: 0.2260\n",
      "Epoch [33/1000], Loss: 0.2249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/1000], Loss: 0.2236\n",
      "Epoch [35/1000], Loss: 0.2224\n",
      "Epoch [36/1000], Loss: 0.2209\n",
      "Epoch [37/1000], Loss: 0.2193\n",
      "Epoch [38/1000], Loss: 0.2175\n",
      "Epoch [39/1000], Loss: 0.2153\n",
      "Epoch [40/1000], Loss: 0.2128\n",
      "Epoch [41/1000], Loss: 0.2106\n",
      "Epoch [42/1000], Loss: 0.2073\n",
      "Epoch [43/1000], Loss: 0.2036\n",
      "Epoch [44/1000], Loss: 0.2000\n",
      "Epoch [45/1000], Loss: 0.1954\n",
      "Epoch [46/1000], Loss: 0.1903\n",
      "Epoch [47/1000], Loss: 0.1844\n",
      "Epoch [48/1000], Loss: 0.1810\n",
      "Epoch [49/1000], Loss: 0.1759\n",
      "Epoch [50/1000], Loss: 0.1711\n",
      "Epoch [51/1000], Loss: 0.1659\n",
      "Epoch [52/1000], Loss: 0.1613\n",
      "Epoch [53/1000], Loss: 0.1561\n",
      "Epoch [54/1000], Loss: 0.1537\n",
      "Epoch [55/1000], Loss: 0.1486\n",
      "Epoch [56/1000], Loss: 0.1459\n",
      "Epoch [57/1000], Loss: 0.1432\n",
      "Epoch [58/1000], Loss: 0.1400\n",
      "Epoch [59/1000], Loss: 0.1374\n",
      "Epoch [60/1000], Loss: 0.1338\n",
      "Epoch [61/1000], Loss: 0.1314\n",
      "Epoch [62/1000], Loss: 0.1293\n",
      "Epoch [63/1000], Loss: 0.1242\n",
      "Epoch [64/1000], Loss: 0.1236\n",
      "Epoch [65/1000], Loss: 0.1242\n",
      "Epoch [66/1000], Loss: 0.1204\n",
      "Epoch [67/1000], Loss: 0.1173\n",
      "Epoch [68/1000], Loss: 0.1151\n",
      "Epoch [69/1000], Loss: 0.1136\n",
      "Epoch [70/1000], Loss: 0.1104\n",
      "Epoch [71/1000], Loss: 0.1106\n",
      "Epoch [72/1000], Loss: 0.1094\n",
      "Epoch [73/1000], Loss: 0.1087\n",
      "Epoch [74/1000], Loss: 0.1063\n",
      "Epoch [75/1000], Loss: 0.1025\n",
      "Epoch [76/1000], Loss: 0.1017\n",
      "Epoch [77/1000], Loss: 0.1017\n",
      "Epoch [78/1000], Loss: 0.1007\n",
      "Epoch [79/1000], Loss: 0.0996\n",
      "Epoch [80/1000], Loss: 0.0949\n",
      "Epoch [81/1000], Loss: 0.0938\n",
      "Epoch [82/1000], Loss: 0.0948\n",
      "Epoch [83/1000], Loss: 0.0901\n",
      "Epoch [84/1000], Loss: 0.0900\n",
      "Epoch [85/1000], Loss: 0.0888\n",
      "Epoch [86/1000], Loss: 0.0878\n",
      "Epoch [87/1000], Loss: 0.0849\n",
      "Epoch [88/1000], Loss: 0.0823\n",
      "Epoch [89/1000], Loss: 0.0819\n",
      "Epoch [90/1000], Loss: 0.0800\n",
      "Epoch [91/1000], Loss: 0.0783\n",
      "Epoch [92/1000], Loss: 0.0789\n",
      "Epoch [93/1000], Loss: 0.0754\n",
      "Epoch [94/1000], Loss: 0.0739\n",
      "Epoch [95/1000], Loss: 0.0748\n",
      "Epoch [96/1000], Loss: 0.0679\n",
      "Epoch [97/1000], Loss: 0.0658\n",
      "Epoch [98/1000], Loss: 0.0648\n",
      "Epoch [99/1000], Loss: 0.0631\n",
      "Epoch [100/1000], Loss: 0.0586\n",
      "Epoch [101/1000], Loss: 0.0583\n",
      "Epoch [102/1000], Loss: 0.0527\n",
      "Epoch [103/1000], Loss: 0.0509\n",
      "Epoch [104/1000], Loss: 0.0459\n",
      "Epoch [105/1000], Loss: 0.0429\n",
      "Epoch [106/1000], Loss: 0.0438\n",
      "Epoch [107/1000], Loss: 0.0419\n",
      "Epoch [108/1000], Loss: 0.0411\n",
      "Epoch [109/1000], Loss: 0.0408\n",
      "Epoch [110/1000], Loss: 0.0386\n",
      "Epoch [111/1000], Loss: 0.0331\n",
      "Epoch [112/1000], Loss: 0.0415\n",
      "Epoch [113/1000], Loss: 0.0307\n",
      "Epoch [114/1000], Loss: 0.0320\n",
      "Epoch [115/1000], Loss: 0.0282\n",
      "Epoch [116/1000], Loss: 0.0288\n",
      "Epoch [117/1000], Loss: 0.0268\n",
      "Epoch [118/1000], Loss: 0.0236\n",
      "Epoch [119/1000], Loss: 0.0275\n",
      "Epoch [120/1000], Loss: 0.0255\n",
      "Epoch [121/1000], Loss: 0.0231\n",
      "Epoch [122/1000], Loss: 0.0198\n",
      "Epoch [123/1000], Loss: 0.0215\n",
      "Epoch [124/1000], Loss: 0.0223\n",
      "Epoch [125/1000], Loss: 0.0172\n",
      "Epoch [126/1000], Loss: 0.0209\n",
      "Epoch [127/1000], Loss: 0.0139\n",
      "Epoch [128/1000], Loss: 0.0127\n",
      "Epoch [129/1000], Loss: 0.0162\n",
      "Epoch [130/1000], Loss: 0.0131\n",
      "Epoch [131/1000], Loss: 0.0149\n",
      "Epoch [132/1000], Loss: 0.0093\n",
      "Epoch [133/1000], Loss: 0.0144\n",
      "Epoch [134/1000], Loss: 0.0092\n",
      "Epoch [135/1000], Loss: 0.0134\n",
      "Epoch [136/1000], Loss: 0.0085\n",
      "Epoch [137/1000], Loss: 0.0076\n",
      "Epoch [138/1000], Loss: 0.0176\n",
      "Epoch [139/1000], Loss: 0.0079\n",
      "Epoch [140/1000], Loss: 0.0084\n",
      "Epoch [141/1000], Loss: 0.0074\n",
      "Epoch [142/1000], Loss: 0.0105\n",
      "Epoch [143/1000], Loss: 0.0095\n",
      "Epoch [144/1000], Loss: 0.0105\n",
      "Epoch [145/1000], Loss: 0.0081\n",
      "Epoch [146/1000], Loss: 0.0089\n",
      "Epoch [147/1000], Loss: 0.0048\n",
      "Epoch [148/1000], Loss: 0.0058\n",
      "Epoch [149/1000], Loss: 0.0114\n",
      "Epoch [150/1000], Loss: 0.0077\n",
      "Epoch [151/1000], Loss: 0.0200\n",
      "Epoch [152/1000], Loss: 0.0087\n",
      "Epoch [153/1000], Loss: 0.0055\n",
      "Epoch [154/1000], Loss: 0.0115\n",
      "Epoch [155/1000], Loss: 0.0053\n",
      "Epoch [156/1000], Loss: 0.0082\n",
      "Epoch [157/1000], Loss: 0.0037\n",
      "Epoch [158/1000], Loss: 0.0020\n",
      "Epoch [159/1000], Loss: 0.0016\n",
      "Epoch [160/1000], Loss: 0.0035\n",
      "Epoch [161/1000], Loss: 0.0051\n",
      "Epoch [162/1000], Loss: 0.0021\n",
      "Epoch [163/1000], Loss: 0.0015\n",
      "Epoch [164/1000], Loss: 0.0019\n",
      "Epoch [165/1000], Loss: 0.0027\n",
      "Epoch [166/1000], Loss: 0.0020\n",
      "Epoch [167/1000], Loss: 0.0046\n",
      "Epoch [168/1000], Loss: 0.0015\n",
      "Epoch [169/1000], Loss: 0.0034\n",
      "Epoch [170/1000], Loss: 0.0017\n",
      "Epoch [171/1000], Loss: 0.0010\n",
      "Epoch [172/1000], Loss: 0.0014\n",
      "Epoch [173/1000], Loss: 0.0011\n",
      "Epoch [174/1000], Loss: 0.0065\n",
      "Epoch [175/1000], Loss: 0.0013\n",
      "Epoch [176/1000], Loss: 0.0011\n",
      "Epoch [177/1000], Loss: 0.0060\n",
      "Epoch [178/1000], Loss: 0.0048\n",
      "Epoch [179/1000], Loss: 0.0013\n",
      "Epoch [180/1000], Loss: 0.0012\n",
      "Epoch [181/1000], Loss: 0.0010\n",
      "Epoch [182/1000], Loss: 0.0008\n",
      "Epoch [183/1000], Loss: 0.0007\n",
      "Epoch [184/1000], Loss: 0.0008\n",
      "Epoch [185/1000], Loss: 0.0007\n",
      "Epoch [186/1000], Loss: 0.0007\n",
      "Epoch [187/1000], Loss: 0.0007\n",
      "Epoch [188/1000], Loss: 0.0008\n",
      "Epoch [189/1000], Loss: 0.0007\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 5, activation : relu, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2505\n",
      "Epoch [2/1000], Loss: 0.2502\n",
      "Epoch [3/1000], Loss: 0.2501\n",
      "Epoch [4/1000], Loss: 0.2501\n",
      "Epoch [5/1000], Loss: 0.2501\n",
      "Epoch [6/1000], Loss: 0.2501\n",
      "Epoch [7/1000], Loss: 0.2501\n",
      "Epoch [8/1000], Loss: 0.2500\n",
      "Epoch [9/1000], Loss: 0.2500\n",
      "Epoch [10/1000], Loss: 0.2500\n",
      "Epoch [11/1000], Loss: 0.2500\n",
      "Epoch [12/1000], Loss: 0.2500\n",
      "Epoch [13/1000], Loss: 0.2500\n",
      "Epoch [14/1000], Loss: 0.2500\n",
      "Epoch [15/1000], Loss: 0.2500\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 5, activation : relu, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2510\n",
      "Epoch [2/1000], Loss: 0.2498\n",
      "Epoch [3/1000], Loss: 0.2487\n",
      "Epoch [4/1000], Loss: 0.2472\n",
      "Epoch [5/1000], Loss: 0.2460\n",
      "Epoch [6/1000], Loss: 0.2448\n",
      "Epoch [7/1000], Loss: 0.2435\n",
      "Epoch [8/1000], Loss: 0.2422\n",
      "Epoch [9/1000], Loss: 0.2411\n",
      "Epoch [10/1000], Loss: 0.2402\n",
      "Epoch [11/1000], Loss: 0.2394\n",
      "Epoch [12/1000], Loss: 0.2389\n",
      "Epoch [13/1000], Loss: 0.2384\n",
      "Epoch [14/1000], Loss: 0.2379\n",
      "Epoch [15/1000], Loss: 0.2375\n",
      "Epoch [16/1000], Loss: 0.2373\n",
      "Epoch [17/1000], Loss: 0.2370\n",
      "Epoch [18/1000], Loss: 0.2367\n",
      "Epoch [19/1000], Loss: 0.2365\n",
      "Epoch [20/1000], Loss: 0.2364\n",
      "Epoch [21/1000], Loss: 0.2361\n",
      "Epoch [22/1000], Loss: 0.2359\n",
      "Epoch [23/1000], Loss: 0.2357\n",
      "Epoch [24/1000], Loss: 0.2354\n",
      "Epoch [25/1000], Loss: 0.2352\n",
      "Epoch [26/1000], Loss: 0.2350\n",
      "Epoch [27/1000], Loss: 0.2347\n",
      "Epoch [28/1000], Loss: 0.2345\n",
      "Epoch [29/1000], Loss: 0.2341\n",
      "Epoch [30/1000], Loss: 0.2338\n",
      "Epoch [31/1000], Loss: 0.2334\n",
      "Epoch [32/1000], Loss: 0.2331\n",
      "Epoch [33/1000], Loss: 0.2328\n",
      "Epoch [34/1000], Loss: 0.2324\n",
      "Epoch [35/1000], Loss: 0.2322\n",
      "Epoch [36/1000], Loss: 0.2316\n",
      "Epoch [37/1000], Loss: 0.2314\n",
      "Epoch [38/1000], Loss: 0.2310\n",
      "Epoch [39/1000], Loss: 0.2306\n",
      "Epoch [40/1000], Loss: 0.2301\n",
      "Epoch [41/1000], Loss: 0.2296\n",
      "Epoch [42/1000], Loss: 0.2292\n",
      "Epoch [43/1000], Loss: 0.2287\n",
      "Epoch [44/1000], Loss: 0.2282\n",
      "Epoch [45/1000], Loss: 0.2276\n",
      "Epoch [46/1000], Loss: 0.2272\n",
      "Epoch [47/1000], Loss: 0.2267\n",
      "Epoch [48/1000], Loss: 0.2262\n",
      "Epoch [49/1000], Loss: 0.2257\n",
      "Epoch [50/1000], Loss: 0.2252\n",
      "Epoch [51/1000], Loss: 0.2248\n",
      "Epoch [52/1000], Loss: 0.2245\n",
      "Epoch [53/1000], Loss: 0.2240\n",
      "Epoch [54/1000], Loss: 0.2235\n",
      "Epoch [55/1000], Loss: 0.2233\n",
      "Epoch [56/1000], Loss: 0.2228\n",
      "Epoch [57/1000], Loss: 0.2224\n",
      "Epoch [58/1000], Loss: 0.2221\n",
      "Epoch [59/1000], Loss: 0.2215\n",
      "Epoch [60/1000], Loss: 0.2211\n",
      "Epoch [61/1000], Loss: 0.2205\n",
      "Epoch [62/1000], Loss: 0.2201\n",
      "Epoch [63/1000], Loss: 0.2196\n",
      "Epoch [64/1000], Loss: 0.2190\n",
      "Epoch [65/1000], Loss: 0.2186\n",
      "Epoch [66/1000], Loss: 0.2180\n",
      "Epoch [67/1000], Loss: 0.2174\n",
      "Epoch [68/1000], Loss: 0.2168\n",
      "Epoch [69/1000], Loss: 0.2162\n",
      "Epoch [70/1000], Loss: 0.2154\n",
      "Epoch [71/1000], Loss: 0.2147\n",
      "Epoch [72/1000], Loss: 0.2138\n",
      "Epoch [73/1000], Loss: 0.2129\n",
      "Epoch [74/1000], Loss: 0.2118\n",
      "Epoch [75/1000], Loss: 0.2108\n",
      "Epoch [76/1000], Loss: 0.2096\n",
      "Epoch [77/1000], Loss: 0.2084\n",
      "Epoch [78/1000], Loss: 0.2069\n",
      "Epoch [79/1000], Loss: 0.2053\n",
      "Epoch [80/1000], Loss: 0.2034\n",
      "Epoch [81/1000], Loss: 0.2014\n",
      "Epoch [82/1000], Loss: 0.1987\n",
      "Epoch [83/1000], Loss: 0.1966\n",
      "Epoch [84/1000], Loss: 0.1933\n",
      "Epoch [85/1000], Loss: 0.1877\n",
      "Epoch [86/1000], Loss: 0.1818\n",
      "Epoch [87/1000], Loss: 0.1753\n",
      "Epoch [88/1000], Loss: 0.1668\n",
      "Epoch [89/1000], Loss: 0.1543\n",
      "Epoch [90/1000], Loss: 0.1397\n",
      "Epoch [91/1000], Loss: 0.1255\n",
      "Epoch [92/1000], Loss: 0.1123\n",
      "Epoch [93/1000], Loss: 0.0943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/1000], Loss: 0.0804\n",
      "Epoch [95/1000], Loss: 0.0720\n",
      "Epoch [96/1000], Loss: 0.0657\n",
      "Epoch [97/1000], Loss: 0.0603\n",
      "Epoch [98/1000], Loss: 0.0554\n",
      "Epoch [99/1000], Loss: 0.0502\n",
      "Epoch [100/1000], Loss: 0.0452\n",
      "Epoch [101/1000], Loss: 0.0418\n",
      "Epoch [102/1000], Loss: 0.0390\n",
      "Epoch [103/1000], Loss: 0.0361\n",
      "Epoch [104/1000], Loss: 0.0332\n",
      "Epoch [105/1000], Loss: 0.0304\n",
      "Epoch [106/1000], Loss: 0.0278\n",
      "Epoch [107/1000], Loss: 0.0254\n",
      "Epoch [108/1000], Loss: 0.0228\n",
      "Epoch [109/1000], Loss: 0.0201\n",
      "Epoch [110/1000], Loss: 0.0168\n",
      "Epoch [111/1000], Loss: 0.0130\n",
      "Epoch [112/1000], Loss: 0.0106\n",
      "Epoch [113/1000], Loss: 0.0089\n",
      "Epoch [114/1000], Loss: 0.0077\n",
      "Epoch [115/1000], Loss: 0.0067\n",
      "Epoch [116/1000], Loss: 0.0060\n",
      "Epoch [117/1000], Loss: 0.0055\n",
      "Epoch [118/1000], Loss: 0.0048\n",
      "Epoch [119/1000], Loss: 0.0044\n",
      "Epoch [120/1000], Loss: 0.0039\n",
      "Epoch [121/1000], Loss: 0.0038\n",
      "Epoch [122/1000], Loss: 0.0033\n",
      "Epoch [123/1000], Loss: 0.0031\n",
      "Epoch [124/1000], Loss: 0.0030\n",
      "Epoch [125/1000], Loss: 0.0027\n",
      "Epoch [126/1000], Loss: 0.0025\n",
      "Epoch [127/1000], Loss: 0.0024\n",
      "Epoch [128/1000], Loss: 0.0023\n",
      "Epoch [129/1000], Loss: 0.0021\n",
      "Epoch [130/1000], Loss: 0.0019\n",
      "Epoch [131/1000], Loss: 0.0018\n",
      "Epoch [132/1000], Loss: 0.0017\n",
      "Epoch [133/1000], Loss: 0.0018\n",
      "Epoch [134/1000], Loss: 0.0015\n",
      "Epoch [135/1000], Loss: 0.0015\n",
      "Epoch [136/1000], Loss: 0.0014\n",
      "Epoch [137/1000], Loss: 0.0014\n",
      "Epoch [138/1000], Loss: 0.0014\n",
      "Epoch [139/1000], Loss: 0.0012\n",
      "Epoch [140/1000], Loss: 0.0012\n",
      "Epoch [141/1000], Loss: 0.0011\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 5, activation : relu, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2519\n",
      "Epoch [2/1000], Loss: 0.2508\n",
      "Epoch [3/1000], Loss: 0.2501\n",
      "Epoch [4/1000], Loss: 0.2496\n",
      "Epoch [5/1000], Loss: 0.2491\n",
      "Epoch [6/1000], Loss: 0.2486\n",
      "Epoch [7/1000], Loss: 0.2481\n",
      "Epoch [8/1000], Loss: 0.2476\n",
      "Epoch [9/1000], Loss: 0.2469\n",
      "Epoch [10/1000], Loss: 0.2461\n",
      "Epoch [11/1000], Loss: 0.2450\n",
      "Epoch [12/1000], Loss: 0.2433\n",
      "Epoch [13/1000], Loss: 0.2415\n",
      "Epoch [14/1000], Loss: 0.2397\n",
      "Epoch [15/1000], Loss: 0.2381\n",
      "Epoch [16/1000], Loss: 0.2366\n",
      "Epoch [17/1000], Loss: 0.2353\n",
      "Epoch [18/1000], Loss: 0.2341\n",
      "Epoch [19/1000], Loss: 0.2329\n",
      "Epoch [20/1000], Loss: 0.2318\n",
      "Epoch [21/1000], Loss: 0.2306\n",
      "Epoch [22/1000], Loss: 0.2290\n",
      "Epoch [23/1000], Loss: 0.2274\n",
      "Epoch [24/1000], Loss: 0.2250\n",
      "Epoch [25/1000], Loss: 0.2225\n",
      "Epoch [26/1000], Loss: 0.2192\n",
      "Epoch [27/1000], Loss: 0.2149\n",
      "Epoch [28/1000], Loss: 0.2092\n",
      "Epoch [29/1000], Loss: 0.2015\n",
      "Epoch [30/1000], Loss: 0.1909\n",
      "Epoch [31/1000], Loss: 0.1760\n",
      "Epoch [32/1000], Loss: 0.1552\n",
      "Epoch [33/1000], Loss: 0.1278\n",
      "Epoch [34/1000], Loss: 0.0972\n",
      "Epoch [35/1000], Loss: 0.0697\n",
      "Epoch [36/1000], Loss: 0.0478\n",
      "Epoch [37/1000], Loss: 0.0327\n",
      "Epoch [38/1000], Loss: 0.0227\n",
      "Epoch [39/1000], Loss: 0.0160\n",
      "Epoch [40/1000], Loss: 0.0119\n",
      "Epoch [41/1000], Loss: 0.0093\n",
      "Epoch [42/1000], Loss: 0.0073\n",
      "Epoch [43/1000], Loss: 0.0060\n",
      "Epoch [44/1000], Loss: 0.0050\n",
      "Epoch [45/1000], Loss: 0.0042\n",
      "Epoch [46/1000], Loss: 0.0036\n",
      "Epoch [47/1000], Loss: 0.0032\n",
      "Epoch [48/1000], Loss: 0.0028\n",
      "Epoch [49/1000], Loss: 0.0025\n",
      "Epoch [50/1000], Loss: 0.0023\n",
      "Epoch [51/1000], Loss: 0.0020\n",
      "Epoch [52/1000], Loss: 0.0019\n",
      "Epoch [53/1000], Loss: 0.0017\n",
      "Epoch [54/1000], Loss: 0.0016\n",
      "Epoch [55/1000], Loss: 0.0015\n",
      "Epoch [56/1000], Loss: 0.0014\n",
      "Epoch [57/1000], Loss: 0.0013\n",
      "Epoch [58/1000], Loss: 0.0012\n",
      "Epoch [59/1000], Loss: 0.0011\n",
      "Epoch [60/1000], Loss: 0.0010\n",
      "Epoch [61/1000], Loss: 0.0010\n",
      "Epoch [62/1000], Loss: 0.0010\n",
      "Epoch [63/1000], Loss: 0.0009\n",
      "Epoch [64/1000], Loss: 0.0009\n",
      "Epoch [65/1000], Loss: 0.0008\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 5, activation : lrelu, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2527\n",
      "Epoch [2/1000], Loss: 0.2495\n",
      "Epoch [3/1000], Loss: 0.2478\n",
      "Epoch [4/1000], Loss: 0.2466\n",
      "Epoch [5/1000], Loss: 0.2453\n",
      "Epoch [6/1000], Loss: 0.2440\n",
      "Epoch [7/1000], Loss: 0.2426\n",
      "Epoch [8/1000], Loss: 0.2414\n",
      "Epoch [9/1000], Loss: 0.2403\n",
      "Epoch [10/1000], Loss: 0.2394\n",
      "Epoch [11/1000], Loss: 0.2388\n",
      "Epoch [12/1000], Loss: 0.2382\n",
      "Epoch [13/1000], Loss: 0.2378\n",
      "Epoch [14/1000], Loss: 0.2375\n",
      "Epoch [15/1000], Loss: 0.2371\n",
      "Epoch [16/1000], Loss: 0.2367\n",
      "Epoch [17/1000], Loss: 0.2364\n",
      "Epoch [18/1000], Loss: 0.2360\n",
      "Epoch [19/1000], Loss: 0.2356\n",
      "Epoch [20/1000], Loss: 0.2351\n",
      "Epoch [21/1000], Loss: 0.2347\n",
      "Epoch [22/1000], Loss: 0.2342\n",
      "Epoch [23/1000], Loss: 0.2339\n",
      "Epoch [24/1000], Loss: 0.2334\n",
      "Epoch [25/1000], Loss: 0.2330\n",
      "Epoch [26/1000], Loss: 0.2325\n",
      "Epoch [27/1000], Loss: 0.2320\n",
      "Epoch [28/1000], Loss: 0.2314\n",
      "Epoch [29/1000], Loss: 0.2309\n",
      "Epoch [30/1000], Loss: 0.2303\n",
      "Epoch [31/1000], Loss: 0.2297\n",
      "Epoch [32/1000], Loss: 0.2291\n",
      "Epoch [33/1000], Loss: 0.2286\n",
      "Epoch [34/1000], Loss: 0.2280\n",
      "Epoch [35/1000], Loss: 0.2276\n",
      "Epoch [36/1000], Loss: 0.2271\n",
      "Epoch [37/1000], Loss: 0.2267\n",
      "Epoch [38/1000], Loss: 0.2262\n",
      "Epoch [39/1000], Loss: 0.2258\n",
      "Epoch [40/1000], Loss: 0.2254\n",
      "Epoch [41/1000], Loss: 0.2250\n",
      "Epoch [42/1000], Loss: 0.2246\n",
      "Epoch [43/1000], Loss: 0.2242\n",
      "Epoch [44/1000], Loss: 0.2238\n",
      "Epoch [45/1000], Loss: 0.2235\n",
      "Epoch [46/1000], Loss: 0.2231\n",
      "Epoch [47/1000], Loss: 0.2226\n",
      "Epoch [48/1000], Loss: 0.2222\n",
      "Epoch [49/1000], Loss: 0.2218\n",
      "Epoch [50/1000], Loss: 0.2214\n",
      "Epoch [51/1000], Loss: 0.2211\n",
      "Epoch [52/1000], Loss: 0.2206\n",
      "Epoch [53/1000], Loss: 0.2204\n",
      "Epoch [54/1000], Loss: 0.2201\n",
      "Epoch [55/1000], Loss: 0.2197\n",
      "Epoch [56/1000], Loss: 0.2194\n",
      "Epoch [57/1000], Loss: 0.2191\n",
      "Epoch [58/1000], Loss: 0.2186\n",
      "Epoch [59/1000], Loss: 0.2184\n",
      "Epoch [60/1000], Loss: 0.2180\n",
      "Epoch [61/1000], Loss: 0.2176\n",
      "Epoch [62/1000], Loss: 0.2172\n",
      "Epoch [63/1000], Loss: 0.2169\n",
      "Epoch [64/1000], Loss: 0.2164\n",
      "Epoch [65/1000], Loss: 0.2160\n",
      "Epoch [66/1000], Loss: 0.2155\n",
      "Epoch [67/1000], Loss: 0.2150\n",
      "Epoch [68/1000], Loss: 0.2148\n",
      "Epoch [69/1000], Loss: 0.2143\n",
      "Epoch [70/1000], Loss: 0.2138\n",
      "Epoch [71/1000], Loss: 0.2133\n",
      "Epoch [72/1000], Loss: 0.2127\n",
      "Epoch [73/1000], Loss: 0.2121\n",
      "Epoch [74/1000], Loss: 0.2115\n",
      "Epoch [75/1000], Loss: 0.2110\n",
      "Epoch [76/1000], Loss: 0.2103\n",
      "Epoch [77/1000], Loss: 0.2097\n",
      "Epoch [78/1000], Loss: 0.2089\n",
      "Epoch [79/1000], Loss: 0.2081\n",
      "Epoch [80/1000], Loss: 0.2073\n",
      "Epoch [81/1000], Loss: 0.2062\n",
      "Epoch [82/1000], Loss: 0.2053\n",
      "Epoch [83/1000], Loss: 0.2043\n",
      "Epoch [84/1000], Loss: 0.2027\n",
      "Epoch [85/1000], Loss: 0.2016\n",
      "Epoch [86/1000], Loss: 0.1995\n",
      "Epoch [87/1000], Loss: 0.1957\n",
      "Epoch [88/1000], Loss: 0.1938\n",
      "Epoch [89/1000], Loss: 0.1911\n",
      "Epoch [90/1000], Loss: 0.1890\n",
      "Epoch [91/1000], Loss: 0.1871\n",
      "Epoch [92/1000], Loss: 0.1844\n",
      "Epoch [93/1000], Loss: 0.1806\n",
      "Epoch [94/1000], Loss: 0.1768\n",
      "Epoch [95/1000], Loss: 0.1733\n",
      "Epoch [96/1000], Loss: 0.1690\n",
      "Epoch [97/1000], Loss: 0.1650\n",
      "Epoch [98/1000], Loss: 0.1602\n",
      "Epoch [99/1000], Loss: 0.1562\n",
      "Epoch [100/1000], Loss: 0.1507\n",
      "Epoch [101/1000], Loss: 0.1467\n",
      "Epoch [102/1000], Loss: 0.1417\n",
      "Epoch [103/1000], Loss: 0.1379\n",
      "Epoch [104/1000], Loss: 0.1344\n",
      "Epoch [105/1000], Loss: 0.1305\n",
      "Epoch [106/1000], Loss: 0.1257\n",
      "Epoch [107/1000], Loss: 0.1231\n",
      "Epoch [108/1000], Loss: 0.1200\n",
      "Epoch [109/1000], Loss: 0.1179\n",
      "Epoch [110/1000], Loss: 0.1140\n",
      "Epoch [111/1000], Loss: 0.1110\n",
      "Epoch [112/1000], Loss: 0.1079\n",
      "Epoch [113/1000], Loss: 0.1055\n",
      "Epoch [114/1000], Loss: 0.1040\n",
      "Epoch [115/1000], Loss: 0.1020\n",
      "Epoch [116/1000], Loss: 0.1021\n",
      "Epoch [117/1000], Loss: 0.0981\n",
      "Epoch [118/1000], Loss: 0.0970\n",
      "Epoch [119/1000], Loss: 0.0964\n",
      "Epoch [120/1000], Loss: 0.0935\n",
      "Epoch [121/1000], Loss: 0.0927\n",
      "Epoch [122/1000], Loss: 0.0884\n",
      "Epoch [123/1000], Loss: 0.0879\n",
      "Epoch [124/1000], Loss: 0.0871\n",
      "Epoch [125/1000], Loss: 0.0866\n",
      "Epoch [126/1000], Loss: 0.0841\n",
      "Epoch [127/1000], Loss: 0.0842\n",
      "Epoch [128/1000], Loss: 0.0854\n",
      "Epoch [129/1000], Loss: 0.0840\n",
      "Epoch [130/1000], Loss: 0.0781\n",
      "Epoch [131/1000], Loss: 0.0785\n",
      "Epoch [132/1000], Loss: 0.0779\n",
      "Epoch [133/1000], Loss: 0.0780\n",
      "Epoch [134/1000], Loss: 0.0777\n",
      "Epoch [135/1000], Loss: 0.0746\n",
      "Epoch [136/1000], Loss: 0.0714\n",
      "Epoch [137/1000], Loss: 0.0723\n",
      "Epoch [138/1000], Loss: 0.0684\n",
      "Epoch [139/1000], Loss: 0.0670\n",
      "Epoch [140/1000], Loss: 0.0648\n",
      "Epoch [141/1000], Loss: 0.0646\n",
      "Epoch [142/1000], Loss: 0.0580\n",
      "Epoch [143/1000], Loss: 0.0565\n",
      "Epoch [144/1000], Loss: 0.0514\n",
      "Epoch [145/1000], Loss: 0.0480\n",
      "Epoch [146/1000], Loss: 0.0452\n",
      "Epoch [147/1000], Loss: 0.0406\n",
      "Epoch [148/1000], Loss: 0.0375\n",
      "Epoch [149/1000], Loss: 0.0316\n",
      "Epoch [150/1000], Loss: 0.0310\n",
      "Epoch [151/1000], Loss: 0.0289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [152/1000], Loss: 0.0296\n",
      "Epoch [153/1000], Loss: 0.0250\n",
      "Epoch [154/1000], Loss: 0.0226\n",
      "Epoch [155/1000], Loss: 0.0231\n",
      "Epoch [156/1000], Loss: 0.0216\n",
      "Epoch [157/1000], Loss: 0.0201\n",
      "Epoch [158/1000], Loss: 0.0182\n",
      "Epoch [159/1000], Loss: 0.0191\n",
      "Epoch [160/1000], Loss: 0.0179\n",
      "Epoch [161/1000], Loss: 0.0171\n",
      "Epoch [162/1000], Loss: 0.0185\n",
      "Epoch [163/1000], Loss: 0.0138\n",
      "Epoch [164/1000], Loss: 0.0157\n",
      "Epoch [165/1000], Loss: 0.0157\n",
      "Epoch [166/1000], Loss: 0.0145\n",
      "Epoch [167/1000], Loss: 0.0146\n",
      "Epoch [168/1000], Loss: 0.0134\n",
      "Epoch [169/1000], Loss: 0.0154\n",
      "Epoch [170/1000], Loss: 0.0141\n",
      "Epoch [171/1000], Loss: 0.0125\n",
      "Epoch [172/1000], Loss: 0.0133\n",
      "Epoch [173/1000], Loss: 0.0115\n",
      "Epoch [174/1000], Loss: 0.0129\n",
      "Epoch [175/1000], Loss: 0.0106\n",
      "Epoch [176/1000], Loss: 0.0111\n",
      "Epoch [177/1000], Loss: 0.0098\n",
      "Epoch [178/1000], Loss: 0.0093\n",
      "Epoch [179/1000], Loss: 0.0091\n",
      "Epoch [180/1000], Loss: 0.0095\n",
      "Epoch [181/1000], Loss: 0.0090\n",
      "Epoch [182/1000], Loss: 0.0095\n",
      "Epoch [183/1000], Loss: 0.0082\n",
      "Epoch [184/1000], Loss: 0.0085\n",
      "Epoch [185/1000], Loss: 0.0097\n",
      "Epoch [186/1000], Loss: 0.0081\n",
      "Epoch [187/1000], Loss: 0.0080\n",
      "Epoch [188/1000], Loss: 0.0105\n",
      "Epoch [189/1000], Loss: 0.0073\n",
      "Epoch [190/1000], Loss: 0.0064\n",
      "Epoch [191/1000], Loss: 0.0081\n",
      "Epoch [192/1000], Loss: 0.0092\n",
      "Epoch [193/1000], Loss: 0.0111\n",
      "Epoch [194/1000], Loss: 0.0084\n",
      "Epoch [195/1000], Loss: 0.0075\n",
      "Epoch [196/1000], Loss: 0.0089\n",
      "Epoch [197/1000], Loss: 0.0097\n",
      "Epoch [198/1000], Loss: 0.0078\n",
      "Epoch [199/1000], Loss: 0.0069\n",
      "Epoch [200/1000], Loss: 0.0065\n",
      "Epoch [201/1000], Loss: 0.0085\n",
      "Epoch [202/1000], Loss: 0.0073\n",
      "Epoch [203/1000], Loss: 0.0074\n",
      "Epoch [204/1000], Loss: 0.0074\n",
      "Epoch [205/1000], Loss: 0.0075\n",
      "Epoch [206/1000], Loss: 0.0073\n",
      "Epoch [207/1000], Loss: 0.0071\n",
      "Epoch [208/1000], Loss: 0.0078\n",
      "Epoch [209/1000], Loss: 0.0063\n",
      "Epoch [210/1000], Loss: 0.0064\n",
      "Epoch [211/1000], Loss: 0.0066\n",
      "Epoch [212/1000], Loss: 0.0080\n",
      "Epoch [213/1000], Loss: 0.0088\n",
      "Epoch [214/1000], Loss: 0.0097\n",
      "Epoch [215/1000], Loss: 0.0070\n",
      "Epoch [216/1000], Loss: 0.0068\n",
      "Epoch [217/1000], Loss: 0.0074\n",
      "Epoch [218/1000], Loss: 0.0105\n",
      "Epoch [219/1000], Loss: 0.0088\n",
      "Epoch [220/1000], Loss: 0.0100\n",
      "Epoch [221/1000], Loss: 0.0079\n",
      "Epoch [222/1000], Loss: 0.0068\n",
      "Epoch [223/1000], Loss: 0.0071\n",
      "Epoch [224/1000], Loss: 0.0084\n",
      "Epoch [225/1000], Loss: 0.0071\n",
      "Epoch [226/1000], Loss: 0.0076\n",
      "Epoch [227/1000], Loss: 0.0061\n",
      "Epoch [228/1000], Loss: 0.0068\n",
      "Epoch [229/1000], Loss: 0.0056\n",
      "Epoch [230/1000], Loss: 0.0056\n",
      "Epoch [231/1000], Loss: 0.0068\n",
      "Epoch [232/1000], Loss: 0.0071\n",
      "Epoch [233/1000], Loss: 0.0069\n",
      "Epoch [234/1000], Loss: 0.0085\n",
      "Epoch [235/1000], Loss: 0.0127\n",
      "Epoch [236/1000], Loss: 0.0074\n",
      "Epoch [237/1000], Loss: 0.0052\n",
      "Epoch [238/1000], Loss: 0.0068\n",
      "Epoch [239/1000], Loss: 0.0064\n",
      "Epoch [240/1000], Loss: 0.0056\n",
      "Epoch [241/1000], Loss: 0.0062\n",
      "Epoch [242/1000], Loss: 0.0050\n",
      "Epoch [243/1000], Loss: 0.0051\n",
      "Epoch [244/1000], Loss: 0.0046\n",
      "Epoch [245/1000], Loss: 0.0061\n",
      "Epoch [246/1000], Loss: 0.0053\n",
      "Epoch [247/1000], Loss: 0.0060\n",
      "Epoch [248/1000], Loss: 0.0042\n",
      "Epoch [249/1000], Loss: 0.0057\n",
      "Epoch [250/1000], Loss: 0.0061\n",
      "Epoch [251/1000], Loss: 0.0090\n",
      "Epoch [252/1000], Loss: 0.0054\n",
      "Epoch [253/1000], Loss: 0.0080\n",
      "Epoch [254/1000], Loss: 0.0066\n",
      "Epoch [255/1000], Loss: 0.0074\n",
      "Epoch [256/1000], Loss: 0.0072\n",
      "Epoch [257/1000], Loss: 0.0051\n",
      "Epoch [258/1000], Loss: 0.0043\n",
      "Epoch [259/1000], Loss: 0.0046\n",
      "Epoch [260/1000], Loss: 0.0042\n",
      "Epoch [261/1000], Loss: 0.0055\n",
      "Epoch [262/1000], Loss: 0.0072\n",
      "Epoch [263/1000], Loss: 0.0082\n",
      "Epoch [264/1000], Loss: 0.0064\n",
      "Epoch [265/1000], Loss: 0.0049\n",
      "Epoch [266/1000], Loss: 0.0049\n",
      "Epoch [267/1000], Loss: 0.0045\n",
      "Epoch [268/1000], Loss: 0.0047\n",
      "Epoch [269/1000], Loss: 0.0032\n",
      "Epoch [270/1000], Loss: 0.0043\n",
      "Epoch [271/1000], Loss: 0.0037\n",
      "Epoch [272/1000], Loss: 0.0050\n",
      "Epoch [273/1000], Loss: 0.0036\n",
      "Epoch [274/1000], Loss: 0.0054\n",
      "Epoch [275/1000], Loss: 0.0036\n",
      "Epoch [276/1000], Loss: 0.0042\n",
      "Epoch [277/1000], Loss: 0.0032\n",
      "Epoch [278/1000], Loss: 0.0033\n",
      "Epoch [279/1000], Loss: 0.0061\n",
      "Epoch [280/1000], Loss: 0.0033\n",
      "Epoch [281/1000], Loss: 0.0063\n",
      "Epoch [282/1000], Loss: 0.0048\n",
      "Epoch [283/1000], Loss: 0.0038\n",
      "Epoch [284/1000], Loss: 0.0028\n",
      "Epoch [285/1000], Loss: 0.0030\n",
      "Epoch [286/1000], Loss: 0.0042\n",
      "Epoch [287/1000], Loss: 0.0031\n",
      "Epoch [288/1000], Loss: 0.0080\n",
      "Epoch [289/1000], Loss: 0.0076\n",
      "Epoch [290/1000], Loss: 0.0033\n",
      "Epoch [291/1000], Loss: 0.0042\n",
      "Epoch [292/1000], Loss: 0.0040\n",
      "Epoch [293/1000], Loss: 0.0032\n",
      "Epoch [294/1000], Loss: 0.0211\n",
      "Epoch [295/1000], Loss: 0.0043\n",
      "Epoch [296/1000], Loss: 0.0052\n",
      "Epoch [297/1000], Loss: 0.0025\n",
      "Epoch [298/1000], Loss: 0.0025\n",
      "Epoch [299/1000], Loss: 0.0031\n",
      "Epoch [300/1000], Loss: 0.0019\n",
      "Epoch [301/1000], Loss: 0.0026\n",
      "Epoch [302/1000], Loss: 0.0037\n",
      "Epoch [303/1000], Loss: 0.0056\n",
      "Epoch [304/1000], Loss: 0.0049\n",
      "Epoch [305/1000], Loss: 0.0036\n",
      "Epoch [306/1000], Loss: 0.0044\n",
      "Epoch [307/1000], Loss: 0.0051\n",
      "Epoch [308/1000], Loss: 0.0050\n",
      "Epoch [309/1000], Loss: 0.0030\n",
      "Epoch [310/1000], Loss: 0.0042\n",
      "Epoch [311/1000], Loss: 0.0174\n",
      "Epoch [312/1000], Loss: 0.0081\n",
      "Epoch [313/1000], Loss: 0.0059\n",
      "Epoch [314/1000], Loss: 0.0102\n",
      "Epoch [315/1000], Loss: 0.0026\n",
      "Epoch [316/1000], Loss: 0.0043\n",
      "Epoch [317/1000], Loss: 0.0035\n",
      "Epoch [318/1000], Loss: 0.0038\n",
      "Epoch [319/1000], Loss: 0.0029\n",
      "Epoch [320/1000], Loss: 0.0069\n",
      "Epoch [321/1000], Loss: 0.0061\n",
      "Epoch [322/1000], Loss: 0.0346\n",
      "Epoch [323/1000], Loss: 0.0031\n",
      "Epoch [324/1000], Loss: 0.0025\n",
      "Epoch [325/1000], Loss: 0.0036\n",
      "Epoch [326/1000], Loss: 0.0021\n",
      "Epoch [327/1000], Loss: 0.0013\n",
      "Epoch [328/1000], Loss: 0.0051\n",
      "Epoch [329/1000], Loss: 0.0034\n",
      "Epoch [330/1000], Loss: 0.0030\n",
      "Epoch [331/1000], Loss: 0.0030\n",
      "Epoch [332/1000], Loss: 0.0026\n",
      "Epoch [333/1000], Loss: 0.0030\n",
      "Epoch [334/1000], Loss: 0.0026\n",
      "Epoch [335/1000], Loss: 0.0023\n",
      "Epoch [336/1000], Loss: 0.0033\n",
      "Epoch [337/1000], Loss: 0.0025\n",
      "Epoch [338/1000], Loss: 0.0034\n",
      "Epoch [339/1000], Loss: 0.0045\n",
      "Epoch [340/1000], Loss: 0.0041\n",
      "Epoch [341/1000], Loss: 0.0032\n",
      "Epoch [342/1000], Loss: 0.0027\n",
      "Epoch [343/1000], Loss: 0.0031\n",
      "Epoch [344/1000], Loss: 0.0029\n",
      "Epoch [345/1000], Loss: 0.0026\n",
      "Epoch [346/1000], Loss: 0.0025\n",
      "Epoch [347/1000], Loss: 0.0019\n",
      "Epoch [348/1000], Loss: 0.0023\n",
      "Epoch [349/1000], Loss: 0.0039\n",
      "Epoch [350/1000], Loss: 0.0058\n",
      "Epoch [351/1000], Loss: 0.0271\n",
      "Epoch [352/1000], Loss: 0.0089\n",
      "Epoch [353/1000], Loss: 0.0029\n",
      "Epoch [354/1000], Loss: 0.0031\n",
      "Epoch [355/1000], Loss: 0.0029\n",
      "Epoch [356/1000], Loss: 0.0040\n",
      "Epoch [357/1000], Loss: 0.0035\n",
      "Epoch [358/1000], Loss: 0.0036\n",
      "Epoch [359/1000], Loss: 0.0027\n",
      "Epoch [360/1000], Loss: 0.0032\n",
      "Epoch [361/1000], Loss: 0.0025\n",
      "Epoch [362/1000], Loss: 0.0027\n",
      "Epoch [363/1000], Loss: 0.0025\n",
      "Epoch [364/1000], Loss: 0.0050\n",
      "Epoch [365/1000], Loss: 0.0369\n",
      "Epoch [366/1000], Loss: 0.0063\n",
      "Epoch [367/1000], Loss: 0.0131\n",
      "Epoch [368/1000], Loss: 0.0030\n",
      "Epoch [369/1000], Loss: 0.0054\n",
      "Epoch [370/1000], Loss: 0.0031\n",
      "Epoch [371/1000], Loss: 0.0246\n",
      "Epoch [372/1000], Loss: 0.0044\n",
      "Epoch [373/1000], Loss: 0.0032\n",
      "Epoch [374/1000], Loss: 0.0023\n",
      "Epoch [375/1000], Loss: 0.0025\n",
      "Epoch [376/1000], Loss: 0.0027\n",
      "Epoch [377/1000], Loss: 0.0030\n",
      "Epoch [378/1000], Loss: 0.0028\n",
      "Epoch [379/1000], Loss: 0.0032\n",
      "Epoch [380/1000], Loss: 0.0033\n",
      "Epoch [381/1000], Loss: 0.0026\n",
      "Epoch [382/1000], Loss: 0.0046\n",
      "Epoch [383/1000], Loss: 0.0027\n",
      "Epoch [384/1000], Loss: 0.0036\n",
      "Epoch [385/1000], Loss: 0.0025\n",
      "Epoch [386/1000], Loss: 0.0070\n",
      "Epoch [387/1000], Loss: 0.0074\n",
      "Epoch [388/1000], Loss: 0.0072\n",
      "Epoch [389/1000], Loss: 0.0045\n",
      "Epoch [390/1000], Loss: 0.0035\n",
      "Epoch [391/1000], Loss: 0.0021\n",
      "Epoch [392/1000], Loss: 0.0022\n",
      "Epoch [393/1000], Loss: 0.0036\n",
      "Epoch [394/1000], Loss: 0.0028\n",
      "Epoch [395/1000], Loss: 0.0033\n",
      "Epoch [396/1000], Loss: 0.0025\n",
      "Epoch [397/1000], Loss: 0.0028\n",
      "Epoch [398/1000], Loss: 0.0026\n",
      "Epoch [399/1000], Loss: 0.0035\n",
      "Epoch [400/1000], Loss: 0.0026\n",
      "Epoch [401/1000], Loss: 0.0027\n",
      "Epoch [402/1000], Loss: 0.0027\n",
      "Epoch [403/1000], Loss: 0.0033\n",
      "Epoch [404/1000], Loss: 0.0027\n",
      "Epoch [405/1000], Loss: 0.0034\n",
      "Epoch [406/1000], Loss: 0.0026\n",
      "Epoch [407/1000], Loss: 0.0025\n",
      "Epoch [408/1000], Loss: 0.0018\n",
      "Epoch [409/1000], Loss: 0.0023\n",
      "Epoch [410/1000], Loss: 0.0018\n",
      "Epoch [411/1000], Loss: 0.0017\n",
      "Epoch [412/1000], Loss: 0.0016\n",
      "Epoch [413/1000], Loss: 0.0025\n",
      "Epoch [414/1000], Loss: 0.0026\n",
      "Epoch [415/1000], Loss: 0.0024\n",
      "Epoch [416/1000], Loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [417/1000], Loss: 0.0014\n",
      "Epoch [418/1000], Loss: 0.0025\n",
      "Epoch [419/1000], Loss: 0.0012\n",
      "Epoch [420/1000], Loss: 0.0018\n",
      "Epoch [421/1000], Loss: 0.0009\n",
      "Epoch [422/1000], Loss: 0.0028\n",
      "Epoch [423/1000], Loss: 0.0013\n",
      "Epoch [424/1000], Loss: 0.0028\n",
      "Epoch [425/1000], Loss: 0.0031\n",
      "Epoch [426/1000], Loss: 0.0023\n",
      "Epoch [427/1000], Loss: 0.0019\n",
      "Epoch [428/1000], Loss: 0.0019\n",
      "Epoch [429/1000], Loss: 0.0023\n",
      "Epoch [430/1000], Loss: 0.0026\n",
      "Epoch [431/1000], Loss: 0.0025\n",
      "Epoch [432/1000], Loss: 0.0017\n",
      "Epoch [433/1000], Loss: 0.0024\n",
      "Epoch [434/1000], Loss: 0.0020\n",
      "Epoch [435/1000], Loss: 0.0017\n",
      "Epoch [436/1000], Loss: 0.0013\n",
      "Epoch [437/1000], Loss: 0.0028\n",
      "Epoch [438/1000], Loss: 0.0023\n",
      "Epoch [439/1000], Loss: 0.0013\n",
      "Epoch [440/1000], Loss: 0.0016\n",
      "Epoch [441/1000], Loss: 0.0051\n",
      "Epoch [442/1000], Loss: 0.0019\n",
      "Epoch [443/1000], Loss: 0.0013\n",
      "Epoch [444/1000], Loss: 0.0036\n",
      "Epoch [445/1000], Loss: 0.0020\n",
      "Epoch [446/1000], Loss: 0.0016\n",
      "Epoch [447/1000], Loss: 0.0035\n",
      "Epoch [448/1000], Loss: 0.0021\n",
      "Epoch [449/1000], Loss: 0.0023\n",
      "Epoch [450/1000], Loss: 0.0014\n",
      "Epoch [451/1000], Loss: 0.0016\n",
      "Epoch [452/1000], Loss: 0.0018\n",
      "Epoch [453/1000], Loss: 0.0017\n",
      "Epoch [454/1000], Loss: 0.0016\n",
      "Epoch [455/1000], Loss: 0.0021\n",
      "Epoch [456/1000], Loss: 0.0020\n",
      "Epoch [457/1000], Loss: 0.0020\n",
      "Epoch [458/1000], Loss: 0.0024\n",
      "Epoch [459/1000], Loss: 0.0014\n",
      "Epoch [460/1000], Loss: 0.0024\n",
      "Epoch [461/1000], Loss: 0.0023\n",
      "Epoch [462/1000], Loss: 0.0031\n",
      "Epoch [463/1000], Loss: 0.0015\n",
      "Epoch [464/1000], Loss: 0.0021\n",
      "Epoch [465/1000], Loss: 0.0017\n",
      "Epoch [466/1000], Loss: 0.0013\n",
      "Epoch [467/1000], Loss: 0.0026\n",
      "Epoch [468/1000], Loss: 0.0014\n",
      "Epoch [469/1000], Loss: 0.0016\n",
      "Epoch [470/1000], Loss: 0.0020\n",
      "Epoch [471/1000], Loss: 0.0020\n",
      "Epoch [472/1000], Loss: 0.0013\n",
      "Epoch [473/1000], Loss: 0.0018\n",
      "Epoch [474/1000], Loss: 0.0014\n",
      "Epoch [475/1000], Loss: 0.0019\n",
      "Epoch [476/1000], Loss: 0.0015\n",
      "Epoch [477/1000], Loss: 0.0010\n",
      "Epoch [478/1000], Loss: 0.0012\n",
      "Epoch [479/1000], Loss: 0.0018\n",
      "Epoch [480/1000], Loss: 0.0014\n",
      "Epoch [481/1000], Loss: 0.0012\n",
      "Epoch [482/1000], Loss: 0.0007\n",
      "Epoch [483/1000], Loss: 0.0008\n",
      "Epoch [484/1000], Loss: 0.0007\n",
      "Epoch [485/1000], Loss: 0.0016\n",
      "Epoch [486/1000], Loss: 0.0025\n",
      "Epoch [487/1000], Loss: 0.0019\n",
      "Epoch [488/1000], Loss: 0.0047\n",
      "Epoch [489/1000], Loss: 0.0052\n",
      "Epoch [490/1000], Loss: 0.0032\n",
      "Epoch [491/1000], Loss: 0.0012\n",
      "Epoch [492/1000], Loss: 0.0017\n",
      "Epoch [493/1000], Loss: 0.0009\n",
      "Epoch [494/1000], Loss: 0.0014\n",
      "Epoch [495/1000], Loss: 0.0012\n",
      "Epoch [496/1000], Loss: 0.0017\n",
      "Epoch [497/1000], Loss: 0.0017\n",
      "Epoch [498/1000], Loss: 0.0035\n",
      "Epoch [499/1000], Loss: 0.0020\n",
      "Epoch [500/1000], Loss: 0.0010\n",
      "Epoch [501/1000], Loss: 0.0014\n",
      "Epoch [502/1000], Loss: 0.0006\n",
      "Epoch [503/1000], Loss: 0.0005\n",
      "Epoch [504/1000], Loss: 0.0007\n",
      "Epoch [505/1000], Loss: 0.0014\n",
      "Epoch [506/1000], Loss: 0.0010\n",
      "Epoch [507/1000], Loss: 0.0008\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 5, activation : lrelu, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2534\n",
      "Epoch [2/1000], Loss: 0.2508\n",
      "Epoch [3/1000], Loss: 0.2500\n",
      "Epoch [4/1000], Loss: 0.2496\n",
      "Epoch [5/1000], Loss: 0.2494\n",
      "Epoch [6/1000], Loss: 0.2492\n",
      "Epoch [7/1000], Loss: 0.2489\n",
      "Epoch [8/1000], Loss: 0.2486\n",
      "Epoch [9/1000], Loss: 0.2482\n",
      "Epoch [10/1000], Loss: 0.2478\n",
      "Epoch [11/1000], Loss: 0.2473\n",
      "Epoch [12/1000], Loss: 0.2467\n",
      "Epoch [13/1000], Loss: 0.2459\n",
      "Epoch [14/1000], Loss: 0.2451\n",
      "Epoch [15/1000], Loss: 0.2442\n",
      "Epoch [16/1000], Loss: 0.2432\n",
      "Epoch [17/1000], Loss: 0.2423\n",
      "Epoch [18/1000], Loss: 0.2416\n",
      "Epoch [19/1000], Loss: 0.2411\n",
      "Epoch [20/1000], Loss: 0.2407\n",
      "Epoch [21/1000], Loss: 0.2403\n",
      "Epoch [22/1000], Loss: 0.2400\n",
      "Epoch [23/1000], Loss: 0.2397\n",
      "Epoch [24/1000], Loss: 0.2395\n",
      "Epoch [25/1000], Loss: 0.2392\n",
      "Epoch [26/1000], Loss: 0.2392\n",
      "Epoch [27/1000], Loss: 0.2389\n",
      "Epoch [28/1000], Loss: 0.2388\n",
      "Epoch [29/1000], Loss: 0.2386\n",
      "Epoch [30/1000], Loss: 0.2385\n",
      "Epoch [31/1000], Loss: 0.2382\n",
      "Epoch [32/1000], Loss: 0.2380\n",
      "Epoch [33/1000], Loss: 0.2377\n",
      "Epoch [34/1000], Loss: 0.2376\n",
      "Epoch [35/1000], Loss: 0.2372\n",
      "Epoch [36/1000], Loss: 0.2370\n",
      "Epoch [37/1000], Loss: 0.2367\n",
      "Epoch [38/1000], Loss: 0.2363\n",
      "Epoch [39/1000], Loss: 0.2360\n",
      "Epoch [40/1000], Loss: 0.2356\n",
      "Epoch [41/1000], Loss: 0.2353\n",
      "Epoch [42/1000], Loss: 0.2349\n",
      "Epoch [43/1000], Loss: 0.2344\n",
      "Epoch [44/1000], Loss: 0.2340\n",
      "Epoch [45/1000], Loss: 0.2335\n",
      "Epoch [46/1000], Loss: 0.2328\n",
      "Epoch [47/1000], Loss: 0.2323\n",
      "Epoch [48/1000], Loss: 0.2317\n",
      "Epoch [49/1000], Loss: 0.2310\n",
      "Epoch [50/1000], Loss: 0.2303\n",
      "Epoch [51/1000], Loss: 0.2294\n",
      "Epoch [52/1000], Loss: 0.2281\n",
      "Epoch [53/1000], Loss: 0.2269\n",
      "Epoch [54/1000], Loss: 0.2254\n",
      "Epoch [55/1000], Loss: 0.2237\n",
      "Epoch [56/1000], Loss: 0.2219\n",
      "Epoch [57/1000], Loss: 0.2198\n",
      "Epoch [58/1000], Loss: 0.2180\n",
      "Epoch [59/1000], Loss: 0.2159\n",
      "Epoch [60/1000], Loss: 0.2132\n",
      "Epoch [61/1000], Loss: 0.2108\n",
      "Epoch [62/1000], Loss: 0.2077\n",
      "Epoch [63/1000], Loss: 0.2038\n",
      "Epoch [64/1000], Loss: 0.1996\n",
      "Epoch [65/1000], Loss: 0.1960\n",
      "Epoch [66/1000], Loss: 0.1917\n",
      "Epoch [67/1000], Loss: 0.1862\n",
      "Epoch [68/1000], Loss: 0.1780\n",
      "Epoch [69/1000], Loss: 0.1686\n",
      "Epoch [70/1000], Loss: 0.1588\n",
      "Epoch [71/1000], Loss: 0.1479\n",
      "Epoch [72/1000], Loss: 0.1315\n",
      "Epoch [73/1000], Loss: 0.1140\n",
      "Epoch [74/1000], Loss: 0.0980\n",
      "Epoch [75/1000], Loss: 0.0799\n",
      "Epoch [76/1000], Loss: 0.0620\n",
      "Epoch [77/1000], Loss: 0.0481\n",
      "Epoch [78/1000], Loss: 0.0356\n",
      "Epoch [79/1000], Loss: 0.0276\n",
      "Epoch [80/1000], Loss: 0.0222\n",
      "Epoch [81/1000], Loss: 0.0177\n",
      "Epoch [82/1000], Loss: 0.0150\n",
      "Epoch [83/1000], Loss: 0.0121\n",
      "Epoch [84/1000], Loss: 0.0097\n",
      "Epoch [85/1000], Loss: 0.0080\n",
      "Epoch [86/1000], Loss: 0.0064\n",
      "Epoch [87/1000], Loss: 0.0056\n",
      "Epoch [88/1000], Loss: 0.0046\n",
      "Epoch [89/1000], Loss: 0.0043\n",
      "Epoch [90/1000], Loss: 0.0036\n",
      "Epoch [91/1000], Loss: 0.0031\n",
      "Epoch [92/1000], Loss: 0.0027\n",
      "Epoch [93/1000], Loss: 0.0025\n",
      "Epoch [94/1000], Loss: 0.0023\n",
      "Epoch [95/1000], Loss: 0.0025\n",
      "Epoch [96/1000], Loss: 0.0019\n",
      "Epoch [97/1000], Loss: 0.0022\n",
      "Epoch [98/1000], Loss: 0.0018\n",
      "Epoch [99/1000], Loss: 0.0016\n",
      "Epoch [100/1000], Loss: 0.0016\n",
      "Epoch [101/1000], Loss: 0.0014\n",
      "Epoch [102/1000], Loss: 0.0012\n",
      "Epoch [103/1000], Loss: 0.0012\n",
      "Epoch [104/1000], Loss: 0.0011\n",
      "Epoch [105/1000], Loss: 0.0011\n",
      "Epoch [106/1000], Loss: 0.0009\n",
      "Epoch [107/1000], Loss: 0.0009\n",
      "Epoch [108/1000], Loss: 0.0019\n",
      "Epoch [109/1000], Loss: 0.0008\n",
      "Epoch [110/1000], Loss: 0.0009\n",
      "Epoch [111/1000], Loss: 0.0007\n",
      "Epoch [112/1000], Loss: 0.0007\n",
      "Epoch [113/1000], Loss: 0.0007\n",
      "Epoch [114/1000], Loss: 0.0012\n",
      "Epoch [115/1000], Loss: 0.0007\n",
      "Epoch [116/1000], Loss: 0.0006\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 5, activation : lrelu, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2506\n",
      "Epoch [2/1000], Loss: 0.2500\n",
      "Epoch [3/1000], Loss: 0.2498\n",
      "Epoch [4/1000], Loss: 0.2496\n",
      "Epoch [5/1000], Loss: 0.2494\n",
      "Epoch [6/1000], Loss: 0.2493\n",
      "Epoch [7/1000], Loss: 0.2490\n",
      "Epoch [8/1000], Loss: 0.2488\n",
      "Epoch [9/1000], Loss: 0.2485\n",
      "Epoch [10/1000], Loss: 0.2481\n",
      "Epoch [11/1000], Loss: 0.2476\n",
      "Epoch [12/1000], Loss: 0.2470\n",
      "Epoch [13/1000], Loss: 0.2462\n",
      "Epoch [14/1000], Loss: 0.2451\n",
      "Epoch [15/1000], Loss: 0.2438\n",
      "Epoch [16/1000], Loss: 0.2423\n",
      "Epoch [17/1000], Loss: 0.2409\n",
      "Epoch [18/1000], Loss: 0.2398\n",
      "Epoch [19/1000], Loss: 0.2389\n",
      "Epoch [20/1000], Loss: 0.2383\n",
      "Epoch [21/1000], Loss: 0.2376\n",
      "Epoch [22/1000], Loss: 0.2370\n",
      "Epoch [23/1000], Loss: 0.2364\n",
      "Epoch [24/1000], Loss: 0.2359\n",
      "Epoch [25/1000], Loss: 0.2353\n",
      "Epoch [26/1000], Loss: 0.2347\n",
      "Epoch [27/1000], Loss: 0.2342\n",
      "Epoch [28/1000], Loss: 0.2335\n",
      "Epoch [29/1000], Loss: 0.2329\n",
      "Epoch [30/1000], Loss: 0.2322\n",
      "Epoch [31/1000], Loss: 0.2315\n",
      "Epoch [32/1000], Loss: 0.2306\n",
      "Epoch [33/1000], Loss: 0.2297\n",
      "Epoch [34/1000], Loss: 0.2286\n",
      "Epoch [35/1000], Loss: 0.2274\n",
      "Epoch [36/1000], Loss: 0.2260\n",
      "Epoch [37/1000], Loss: 0.2245\n",
      "Epoch [38/1000], Loss: 0.2226\n",
      "Epoch [39/1000], Loss: 0.2205\n",
      "Epoch [40/1000], Loss: 0.2179\n",
      "Epoch [41/1000], Loss: 0.2148\n",
      "Epoch [42/1000], Loss: 0.2108\n",
      "Epoch [43/1000], Loss: 0.2061\n",
      "Epoch [44/1000], Loss: 0.1991\n",
      "Epoch [45/1000], Loss: 0.1907\n",
      "Epoch [46/1000], Loss: 0.1805\n",
      "Epoch [47/1000], Loss: 0.1669\n",
      "Epoch [48/1000], Loss: 0.1481\n",
      "Epoch [49/1000], Loss: 0.1234\n",
      "Epoch [50/1000], Loss: 0.0980\n",
      "Epoch [51/1000], Loss: 0.0725\n",
      "Epoch [52/1000], Loss: 0.0553\n",
      "Epoch [53/1000], Loss: 0.0406\n",
      "Epoch [54/1000], Loss: 0.0301\n",
      "Epoch [55/1000], Loss: 0.0236\n",
      "Epoch [56/1000], Loss: 0.0177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/1000], Loss: 0.0151\n",
      "Epoch [58/1000], Loss: 0.0118\n",
      "Epoch [59/1000], Loss: 0.0090\n",
      "Epoch [60/1000], Loss: 0.0110\n",
      "Epoch [61/1000], Loss: 0.0061\n",
      "Epoch [62/1000], Loss: 0.0054\n",
      "Epoch [63/1000], Loss: 0.0047\n",
      "Epoch [64/1000], Loss: 0.0123\n",
      "Epoch [65/1000], Loss: 0.0035\n",
      "Epoch [66/1000], Loss: 0.0030\n",
      "Epoch [67/1000], Loss: 0.0025\n",
      "Epoch [68/1000], Loss: 0.0023\n",
      "Epoch [69/1000], Loss: 0.0021\n",
      "Epoch [70/1000], Loss: 0.0037\n",
      "Epoch [71/1000], Loss: 0.0022\n",
      "Epoch [72/1000], Loss: 0.0017\n",
      "Epoch [73/1000], Loss: 0.0016\n",
      "Epoch [74/1000], Loss: 0.0016\n",
      "Epoch [75/1000], Loss: 0.0013\n",
      "Epoch [76/1000], Loss: 0.0013\n",
      "Epoch [77/1000], Loss: 0.0012\n",
      "Epoch [78/1000], Loss: 0.0091\n",
      "Epoch [79/1000], Loss: 0.0014\n",
      "Epoch [80/1000], Loss: 0.0010\n",
      "Epoch [81/1000], Loss: 0.0010\n",
      "Epoch [82/1000], Loss: 0.0010\n",
      "Epoch [83/1000], Loss: 0.0009\n",
      "Epoch [84/1000], Loss: 0.0008\n",
      "Epoch [85/1000], Loss: 0.0008\n",
      "Epoch [86/1000], Loss: 0.0008\n",
      "Epoch [87/1000], Loss: 0.0007\n",
      "Epoch [88/1000], Loss: 0.0007\n",
      "Epoch [89/1000], Loss: 0.0007\n",
      "Epoch [90/1000], Loss: 0.0014\n",
      "Epoch [91/1000], Loss: 0.0010\n",
      "Epoch [92/1000], Loss: 0.0006\n",
      "Epoch [93/1000], Loss: 0.0005\n",
      "Epoch [94/1000], Loss: 0.0005\n",
      "Epoch [95/1000], Loss: 0.0121\n",
      "Epoch [96/1000], Loss: 0.0006\n",
      "Epoch [97/1000], Loss: 0.0005\n",
      "Epoch [98/1000], Loss: 0.0005\n",
      "Epoch [99/1000], Loss: 0.0005\n",
      "Epoch [100/1000], Loss: 0.0004\n",
      "Epoch [101/1000], Loss: 0.0004\n",
      "Epoch [102/1000], Loss: 0.0004\n",
      "Epoch [103/1000], Loss: 0.0004\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 5, activation : sigmoid, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2507\n",
      "Epoch [2/1000], Loss: 0.2501\n",
      "Epoch [3/1000], Loss: 0.2501\n",
      "Epoch [4/1000], Loss: 0.2501\n",
      "Epoch [5/1000], Loss: 0.2501\n",
      "Epoch [6/1000], Loss: 0.2501\n",
      "Epoch [7/1000], Loss: 0.2501\n",
      "Epoch [8/1000], Loss: 0.2501\n",
      "Epoch [9/1000], Loss: 0.2501\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 5, activation : sigmoid, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2521\n",
      "Epoch [2/1000], Loss: 0.2502\n",
      "Epoch [3/1000], Loss: 0.2501\n",
      "Epoch [4/1000], Loss: 0.2501\n",
      "Epoch [5/1000], Loss: 0.2501\n",
      "Epoch [6/1000], Loss: 0.2501\n",
      "Epoch [7/1000], Loss: 0.2501\n",
      "Epoch [8/1000], Loss: 0.2501\n",
      "Epoch [9/1000], Loss: 0.2501\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 5, activation : sigmoid, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2514\n",
      "Epoch [2/1000], Loss: 0.2502\n",
      "Epoch [3/1000], Loss: 0.2501\n",
      "Epoch [4/1000], Loss: 0.2501\n",
      "Epoch [5/1000], Loss: 0.2502\n",
      "Epoch [6/1000], Loss: 0.2502\n",
      "Epoch [7/1000], Loss: 0.2502\n",
      "Epoch [8/1000], Loss: 0.2502\n",
      "Epoch [9/1000], Loss: 0.2502\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 5, activation : tanh, and neurons: 5\n",
      "Epoch [1/1000], Loss: 0.2596\n",
      "Epoch [2/1000], Loss: 0.2521\n",
      "Epoch [3/1000], Loss: 0.2498\n",
      "Epoch [4/1000], Loss: 0.2487\n",
      "Epoch [5/1000], Loss: 0.2480\n",
      "Epoch [6/1000], Loss: 0.2472\n",
      "Epoch [7/1000], Loss: 0.2463\n",
      "Epoch [8/1000], Loss: 0.2452\n",
      "Epoch [9/1000], Loss: 0.2440\n",
      "Epoch [10/1000], Loss: 0.2426\n",
      "Epoch [11/1000], Loss: 0.2412\n",
      "Epoch [12/1000], Loss: 0.2400\n",
      "Epoch [13/1000], Loss: 0.2390\n",
      "Epoch [14/1000], Loss: 0.2384\n",
      "Epoch [15/1000], Loss: 0.2379\n",
      "Epoch [16/1000], Loss: 0.2377\n",
      "Epoch [17/1000], Loss: 0.2375\n",
      "Epoch [18/1000], Loss: 0.2374\n",
      "Epoch [19/1000], Loss: 0.2372\n",
      "Epoch [20/1000], Loss: 0.2372\n",
      "Epoch [21/1000], Loss: 0.2371\n",
      "Epoch [22/1000], Loss: 0.2370\n",
      "Epoch [23/1000], Loss: 0.2369\n",
      "Epoch [24/1000], Loss: 0.2369\n",
      "Epoch [25/1000], Loss: 0.2368\n",
      "Epoch [26/1000], Loss: 0.2367\n",
      "Epoch [27/1000], Loss: 0.2366\n",
      "Epoch [28/1000], Loss: 0.2365\n",
      "Epoch [29/1000], Loss: 0.2364\n",
      "Epoch [30/1000], Loss: 0.2363\n",
      "Epoch [31/1000], Loss: 0.2362\n",
      "Epoch [32/1000], Loss: 0.2362\n",
      "Epoch [33/1000], Loss: 0.2360\n",
      "Epoch [34/1000], Loss: 0.2359\n",
      "Epoch [35/1000], Loss: 0.2358\n",
      "Epoch [36/1000], Loss: 0.2357\n",
      "Epoch [37/1000], Loss: 0.2355\n",
      "Epoch [38/1000], Loss: 0.2354\n",
      "Epoch [39/1000], Loss: 0.2353\n",
      "Epoch [40/1000], Loss: 0.2351\n",
      "Epoch [41/1000], Loss: 0.2350\n",
      "Epoch [42/1000], Loss: 0.2348\n",
      "Epoch [43/1000], Loss: 0.2347\n",
      "Epoch [44/1000], Loss: 0.2345\n",
      "Epoch [45/1000], Loss: 0.2343\n",
      "Epoch [46/1000], Loss: 0.2342\n",
      "Epoch [47/1000], Loss: 0.2340\n",
      "Epoch [48/1000], Loss: 0.2338\n",
      "Epoch [49/1000], Loss: 0.2336\n",
      "Epoch [50/1000], Loss: 0.2334\n",
      "Epoch [51/1000], Loss: 0.2332\n",
      "Epoch [52/1000], Loss: 0.2330\n",
      "Epoch [53/1000], Loss: 0.2327\n",
      "Epoch [54/1000], Loss: 0.2325\n",
      "Epoch [55/1000], Loss: 0.2322\n",
      "Epoch [56/1000], Loss: 0.2320\n",
      "Epoch [57/1000], Loss: 0.2317\n",
      "Epoch [58/1000], Loss: 0.2315\n",
      "Epoch [59/1000], Loss: 0.2312\n",
      "Epoch [60/1000], Loss: 0.2309\n",
      "Epoch [61/1000], Loss: 0.2307\n",
      "Epoch [62/1000], Loss: 0.2304\n",
      "Epoch [63/1000], Loss: 0.2301\n",
      "Epoch [64/1000], Loss: 0.2299\n",
      "Epoch [65/1000], Loss: 0.2296\n",
      "Epoch [66/1000], Loss: 0.2294\n",
      "Epoch [67/1000], Loss: 0.2291\n",
      "Epoch [68/1000], Loss: 0.2289\n",
      "Epoch [69/1000], Loss: 0.2286\n",
      "Epoch [70/1000], Loss: 0.2284\n",
      "Epoch [71/1000], Loss: 0.2281\n",
      "Epoch [72/1000], Loss: 0.2279\n",
      "Epoch [73/1000], Loss: 0.2277\n",
      "Epoch [74/1000], Loss: 0.2275\n",
      "Epoch [75/1000], Loss: 0.2272\n",
      "Epoch [76/1000], Loss: 0.2270\n",
      "Epoch [77/1000], Loss: 0.2268\n",
      "Epoch [78/1000], Loss: 0.2266\n",
      "Epoch [79/1000], Loss: 0.2264\n",
      "Epoch [80/1000], Loss: 0.2262\n",
      "Epoch [81/1000], Loss: 0.2260\n",
      "Epoch [82/1000], Loss: 0.2257\n",
      "Epoch [83/1000], Loss: 0.2255\n",
      "Epoch [84/1000], Loss: 0.2253\n",
      "Epoch [85/1000], Loss: 0.2251\n",
      "Epoch [86/1000], Loss: 0.2249\n",
      "Epoch [87/1000], Loss: 0.2246\n",
      "Epoch [88/1000], Loss: 0.2244\n",
      "Epoch [89/1000], Loss: 0.2242\n",
      "Epoch [90/1000], Loss: 0.2240\n",
      "Epoch [91/1000], Loss: 0.2238\n",
      "Epoch [92/1000], Loss: 0.2236\n",
      "Epoch [93/1000], Loss: 0.2233\n",
      "Epoch [94/1000], Loss: 0.2231\n",
      "Epoch [95/1000], Loss: 0.2229\n",
      "Epoch [96/1000], Loss: 0.2227\n",
      "Epoch [97/1000], Loss: 0.2225\n",
      "Epoch [98/1000], Loss: 0.2223\n",
      "Epoch [99/1000], Loss: 0.2220\n",
      "Epoch [100/1000], Loss: 0.2218\n",
      "Epoch [101/1000], Loss: 0.2216\n",
      "Epoch [102/1000], Loss: 0.2213\n",
      "Epoch [103/1000], Loss: 0.2211\n",
      "Epoch [104/1000], Loss: 0.2208\n",
      "Epoch [105/1000], Loss: 0.2205\n",
      "Epoch [106/1000], Loss: 0.2202\n",
      "Epoch [107/1000], Loss: 0.2197\n",
      "Epoch [108/1000], Loss: 0.2195\n",
      "Epoch [109/1000], Loss: 0.2191\n",
      "Epoch [110/1000], Loss: 0.2186\n",
      "Epoch [111/1000], Loss: 0.2182\n",
      "Epoch [112/1000], Loss: 0.2175\n",
      "Epoch [113/1000], Loss: 0.2168\n",
      "Epoch [114/1000], Loss: 0.2161\n",
      "Epoch [115/1000], Loss: 0.2154\n",
      "Epoch [116/1000], Loss: 0.2147\n",
      "Epoch [117/1000], Loss: 0.2138\n",
      "Epoch [118/1000], Loss: 0.2128\n",
      "Epoch [119/1000], Loss: 0.2121\n",
      "Epoch [120/1000], Loss: 0.2112\n",
      "Epoch [121/1000], Loss: 0.2103\n",
      "Epoch [122/1000], Loss: 0.2093\n",
      "Epoch [123/1000], Loss: 0.2082\n",
      "Epoch [124/1000], Loss: 0.2071\n",
      "Epoch [125/1000], Loss: 0.2061\n",
      "Epoch [126/1000], Loss: 0.2051\n",
      "Epoch [127/1000], Loss: 0.2041\n",
      "Epoch [128/1000], Loss: 0.2023\n",
      "Epoch [129/1000], Loss: 0.2011\n",
      "Epoch [130/1000], Loss: 0.2006\n",
      "Epoch [131/1000], Loss: 0.1988\n",
      "Epoch [132/1000], Loss: 0.1979\n",
      "Epoch [133/1000], Loss: 0.1968\n",
      "Epoch [134/1000], Loss: 0.1943\n",
      "Epoch [135/1000], Loss: 0.1929\n",
      "Epoch [136/1000], Loss: 0.1906\n",
      "Epoch [137/1000], Loss: 0.1893\n",
      "Epoch [138/1000], Loss: 0.1877\n",
      "Epoch [139/1000], Loss: 0.1847\n",
      "Epoch [140/1000], Loss: 0.1825\n",
      "Epoch [141/1000], Loss: 0.1797\n",
      "Epoch [142/1000], Loss: 0.1776\n",
      "Epoch [143/1000], Loss: 0.1747\n",
      "Epoch [144/1000], Loss: 0.1744\n",
      "Epoch [145/1000], Loss: 0.1716\n",
      "Epoch [146/1000], Loss: 0.1710\n",
      "Epoch [147/1000], Loss: 0.1704\n",
      "Epoch [148/1000], Loss: 0.1702\n",
      "Epoch [149/1000], Loss: 0.1689\n",
      "Epoch [150/1000], Loss: 0.1699\n",
      "Epoch [151/1000], Loss: 0.1677\n",
      "Epoch [152/1000], Loss: 0.1677\n",
      "Epoch [153/1000], Loss: 0.1705\n",
      "Epoch [154/1000], Loss: 0.1666\n",
      "Epoch [155/1000], Loss: 0.1664\n",
      "Epoch [156/1000], Loss: 0.1677\n",
      "Epoch [157/1000], Loss: 0.1699\n",
      "Epoch [158/1000], Loss: 0.1681\n",
      "Epoch [159/1000], Loss: 0.1718\n",
      "Epoch [160/1000], Loss: 0.1663\n",
      "Epoch [161/1000], Loss: 0.1659\n",
      "Epoch [162/1000], Loss: 0.1649\n",
      "Epoch [163/1000], Loss: 0.1645\n",
      "Epoch [164/1000], Loss: 0.1632\n",
      "Epoch [165/1000], Loss: 0.1637\n",
      "Epoch [166/1000], Loss: 0.1665\n",
      "Epoch [167/1000], Loss: 0.1639\n",
      "Epoch [168/1000], Loss: 0.1619\n",
      "Epoch [169/1000], Loss: 0.1628\n",
      "Epoch [170/1000], Loss: 0.1625\n",
      "Epoch [171/1000], Loss: 0.1647\n",
      "Epoch [172/1000], Loss: 0.1606\n",
      "Epoch [173/1000], Loss: 0.1618\n",
      "Epoch [174/1000], Loss: 0.1561\n",
      "Epoch [175/1000], Loss: 0.1556\n",
      "Epoch [176/1000], Loss: 0.1590\n",
      "Epoch [177/1000], Loss: 0.1600\n",
      "Epoch [178/1000], Loss: 0.1570\n",
      "Epoch [179/1000], Loss: 0.1580\n",
      "Epoch [180/1000], Loss: 0.1587\n",
      "Epoch [181/1000], Loss: 0.1516\n",
      "Epoch [182/1000], Loss: 0.1498\n",
      "Epoch [183/1000], Loss: 0.1431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [184/1000], Loss: 0.1414\n",
      "Epoch [185/1000], Loss: 0.1394\n",
      "Epoch [186/1000], Loss: 0.1378\n",
      "Epoch [187/1000], Loss: 0.1381\n",
      "Epoch [188/1000], Loss: 0.1349\n",
      "Epoch [189/1000], Loss: 0.1379\n",
      "Epoch [190/1000], Loss: 0.1348\n",
      "Epoch [191/1000], Loss: 0.1357\n",
      "Epoch [192/1000], Loss: 0.1340\n",
      "Epoch [193/1000], Loss: 0.1355\n",
      "Epoch [194/1000], Loss: 0.1316\n",
      "Epoch [195/1000], Loss: 0.1331\n",
      "Epoch [196/1000], Loss: 0.1338\n",
      "Epoch [197/1000], Loss: 0.1329\n",
      "Epoch [198/1000], Loss: 0.1309\n",
      "Epoch [199/1000], Loss: 0.1326\n",
      "Epoch [200/1000], Loss: 0.1351\n",
      "Epoch [201/1000], Loss: 0.1335\n",
      "Epoch [202/1000], Loss: 0.1329\n",
      "Epoch [203/1000], Loss: 0.1309\n",
      "Epoch [204/1000], Loss: 0.1324\n",
      "Epoch [205/1000], Loss: 0.1311\n",
      "Epoch [206/1000], Loss: 0.1324\n",
      "Epoch [207/1000], Loss: 0.1304\n",
      "Epoch [208/1000], Loss: 0.1352\n",
      "Epoch [209/1000], Loss: 0.1301\n",
      "Epoch [210/1000], Loss: 0.1341\n",
      "Epoch [211/1000], Loss: 0.1286\n",
      "Epoch [212/1000], Loss: 0.1296\n",
      "Epoch [213/1000], Loss: 0.1318\n",
      "Epoch [214/1000], Loss: 0.1284\n",
      "Epoch [215/1000], Loss: 0.1290\n",
      "Epoch [216/1000], Loss: 0.1280\n",
      "Epoch [217/1000], Loss: 0.1283\n",
      "Epoch [218/1000], Loss: 0.1264\n",
      "Epoch [219/1000], Loss: 0.1316\n",
      "Epoch [220/1000], Loss: 0.1326\n",
      "Epoch [221/1000], Loss: 0.1397\n",
      "Epoch [222/1000], Loss: 0.1300\n",
      "Epoch [223/1000], Loss: 0.1265\n",
      "Epoch [224/1000], Loss: 0.1302\n",
      "Epoch [225/1000], Loss: 0.1263\n",
      "Epoch [226/1000], Loss: 0.1282\n",
      "Epoch [227/1000], Loss: 0.1289\n",
      "Epoch [228/1000], Loss: 0.1270\n",
      "Epoch [229/1000], Loss: 0.1280\n",
      "Epoch [230/1000], Loss: 0.1299\n",
      "Epoch [231/1000], Loss: 0.1330\n",
      "Epoch [232/1000], Loss: 0.1262\n",
      "Epoch [233/1000], Loss: 0.1251\n",
      "Epoch [234/1000], Loss: 0.1316\n",
      "Epoch [235/1000], Loss: 0.1276\n",
      "Epoch [236/1000], Loss: 0.1339\n",
      "Epoch [237/1000], Loss: 0.1276\n",
      "Epoch [238/1000], Loss: 0.1284\n",
      "Epoch [239/1000], Loss: 0.1235\n",
      "Epoch [240/1000], Loss: 0.1284\n",
      "Epoch [241/1000], Loss: 0.1269\n",
      "Epoch [242/1000], Loss: 0.1287\n",
      "Epoch [243/1000], Loss: 0.1340\n",
      "Epoch [244/1000], Loss: 0.1299\n",
      "Epoch [245/1000], Loss: 0.1302\n",
      "Epoch [246/1000], Loss: 0.1289\n",
      "Epoch [247/1000], Loss: 0.1306\n",
      "Epoch [248/1000], Loss: 0.1263\n",
      "Epoch [249/1000], Loss: 0.1237\n",
      "Epoch [250/1000], Loss: 0.1271\n",
      "Epoch [251/1000], Loss: 0.1276\n",
      "Epoch [252/1000], Loss: 0.1263\n",
      "Epoch [253/1000], Loss: 0.1182\n",
      "Epoch [254/1000], Loss: 0.1226\n",
      "Epoch [255/1000], Loss: 0.1198\n",
      "Epoch [256/1000], Loss: 0.1217\n",
      "Epoch [257/1000], Loss: 0.1229\n",
      "Epoch [258/1000], Loss: 0.1223\n",
      "Epoch [259/1000], Loss: 0.1229\n",
      "Epoch [260/1000], Loss: 0.1241\n",
      "Epoch [261/1000], Loss: 0.1202\n",
      "Epoch [262/1000], Loss: 0.1197\n",
      "Epoch [263/1000], Loss: 0.1179\n",
      "Epoch [264/1000], Loss: 0.1400\n",
      "Epoch [265/1000], Loss: 0.1297\n",
      "Epoch [266/1000], Loss: 0.1207\n",
      "Epoch [267/1000], Loss: 0.1240\n",
      "Epoch [268/1000], Loss: 0.1251\n",
      "Epoch [269/1000], Loss: 0.1185\n",
      "Epoch [270/1000], Loss: 0.1271\n",
      "Epoch [271/1000], Loss: 0.1199\n",
      "Epoch [272/1000], Loss: 0.1316\n",
      "Epoch [273/1000], Loss: 0.1208\n",
      "Epoch [274/1000], Loss: 0.1208\n",
      "Epoch [275/1000], Loss: 0.1210\n",
      "Epoch [276/1000], Loss: 0.1183\n",
      "Epoch [277/1000], Loss: 0.1211\n",
      "Epoch [278/1000], Loss: 0.1188\n",
      "Epoch [279/1000], Loss: 0.1228\n",
      "Epoch [280/1000], Loss: 0.1196\n",
      "Epoch [281/1000], Loss: 0.1182\n",
      "Epoch [282/1000], Loss: 0.1270\n",
      "Epoch [283/1000], Loss: 0.1221\n",
      "Epoch [284/1000], Loss: 0.1167\n",
      "Epoch [285/1000], Loss: 0.1160\n",
      "Epoch [286/1000], Loss: 0.1209\n",
      "Epoch [287/1000], Loss: 0.1234\n",
      "Epoch [288/1000], Loss: 0.1153\n",
      "Epoch [289/1000], Loss: 0.1175\n",
      "Epoch [290/1000], Loss: 0.1184\n",
      "Epoch [291/1000], Loss: 0.1175\n",
      "Epoch [292/1000], Loss: 0.1161\n",
      "Epoch [293/1000], Loss: 0.1292\n",
      "Epoch [294/1000], Loss: 0.1191\n",
      "Epoch [295/1000], Loss: 0.1194\n",
      "Epoch [296/1000], Loss: 0.1194\n",
      "Epoch [297/1000], Loss: 0.1149\n",
      "Epoch [298/1000], Loss: 0.1184\n",
      "Epoch [299/1000], Loss: 0.1172\n",
      "Epoch [300/1000], Loss: 0.1163\n",
      "Epoch [301/1000], Loss: 0.1214\n",
      "Epoch [302/1000], Loss: 0.1149\n",
      "Epoch [303/1000], Loss: 0.1128\n",
      "Epoch [304/1000], Loss: 0.1169\n",
      "Epoch [305/1000], Loss: 0.1135\n",
      "Epoch [306/1000], Loss: 0.1122\n",
      "Epoch [307/1000], Loss: 0.1113\n",
      "Epoch [308/1000], Loss: 0.1127\n",
      "Epoch [309/1000], Loss: 0.1267\n",
      "Epoch [310/1000], Loss: 0.1150\n",
      "Epoch [311/1000], Loss: 0.1147\n",
      "Epoch [312/1000], Loss: 0.1147\n",
      "Epoch [313/1000], Loss: 0.1086\n",
      "Epoch [314/1000], Loss: 0.1166\n",
      "Epoch [315/1000], Loss: 0.1166\n",
      "Epoch [316/1000], Loss: 0.1168\n",
      "Epoch [317/1000], Loss: 0.1185\n",
      "Epoch [318/1000], Loss: 0.1097\n",
      "Epoch [319/1000], Loss: 0.1119\n",
      "Epoch [320/1000], Loss: 0.1155\n",
      "Epoch [321/1000], Loss: 0.1166\n",
      "Epoch [322/1000], Loss: 0.1119\n",
      "Epoch [323/1000], Loss: 0.1169\n",
      "Epoch [324/1000], Loss: 0.1105\n",
      "Epoch [325/1000], Loss: 0.1159\n",
      "Epoch [326/1000], Loss: 0.1155\n",
      "Epoch [327/1000], Loss: 0.1111\n",
      "Epoch [328/1000], Loss: 0.1105\n",
      "Epoch [329/1000], Loss: 0.1192\n",
      "Epoch [330/1000], Loss: 0.1095\n",
      "Epoch [331/1000], Loss: 0.1150\n",
      "Epoch [332/1000], Loss: 0.1103\n",
      "Epoch [333/1000], Loss: 0.1086\n",
      "Epoch [334/1000], Loss: 0.1090\n",
      "Epoch [335/1000], Loss: 0.1068\n",
      "Epoch [336/1000], Loss: 0.1104\n",
      "Epoch [337/1000], Loss: 0.1091\n",
      "Epoch [338/1000], Loss: 0.1043\n",
      "Epoch [339/1000], Loss: 0.1079\n",
      "Epoch [340/1000], Loss: 0.1139\n",
      "Epoch [341/1000], Loss: 0.1154\n",
      "Epoch [342/1000], Loss: 0.1098\n",
      "Epoch [343/1000], Loss: 0.1101\n",
      "Epoch [344/1000], Loss: 0.1080\n",
      "Epoch [345/1000], Loss: 0.1064\n",
      "Epoch [346/1000], Loss: 0.1093\n",
      "Epoch [347/1000], Loss: 0.1108\n",
      "Epoch [348/1000], Loss: 0.1176\n",
      "Epoch [349/1000], Loss: 0.1124\n",
      "Epoch [350/1000], Loss: 0.1070\n",
      "Epoch [351/1000], Loss: 0.1108\n",
      "Epoch [352/1000], Loss: 0.1107\n",
      "Epoch [353/1000], Loss: 0.1052\n",
      "Epoch [354/1000], Loss: 0.1134\n",
      "Epoch [355/1000], Loss: 0.1051\n",
      "Epoch [356/1000], Loss: 0.1059\n",
      "Epoch [357/1000], Loss: 0.1135\n",
      "Epoch [358/1000], Loss: 0.1051\n",
      "Epoch [359/1000], Loss: 0.1034\n",
      "Epoch [360/1000], Loss: 0.1087\n",
      "Epoch [361/1000], Loss: 0.1030\n",
      "Epoch [362/1000], Loss: 0.0991\n",
      "Epoch [363/1000], Loss: 0.1036\n",
      "Epoch [364/1000], Loss: 0.1029\n",
      "Epoch [365/1000], Loss: 0.0999\n",
      "Epoch [366/1000], Loss: 0.1054\n",
      "Epoch [367/1000], Loss: 0.1053\n",
      "Epoch [368/1000], Loss: 0.1007\n",
      "Epoch [369/1000], Loss: 0.0993\n",
      "Epoch [370/1000], Loss: 0.1028\n",
      "Epoch [371/1000], Loss: 0.0990\n",
      "Epoch [372/1000], Loss: 0.0995\n",
      "Epoch [373/1000], Loss: 0.0982\n",
      "Epoch [374/1000], Loss: 0.1061\n",
      "Epoch [375/1000], Loss: 0.0974\n",
      "Epoch [376/1000], Loss: 0.1078\n",
      "Epoch [377/1000], Loss: 0.1008\n",
      "Epoch [378/1000], Loss: 0.1000\n",
      "Epoch [379/1000], Loss: 0.0990\n",
      "Epoch [380/1000], Loss: 0.1057\n",
      "Epoch [381/1000], Loss: 0.0975\n",
      "Epoch [382/1000], Loss: 0.1023\n",
      "Epoch [383/1000], Loss: 0.0972\n",
      "Epoch [384/1000], Loss: 0.1074\n",
      "Epoch [385/1000], Loss: 0.0972\n",
      "Epoch [386/1000], Loss: 0.0954\n",
      "Epoch [387/1000], Loss: 0.1032\n",
      "Epoch [388/1000], Loss: 0.0973\n",
      "Epoch [389/1000], Loss: 0.0950\n",
      "Epoch [390/1000], Loss: 0.0984\n",
      "Epoch [391/1000], Loss: 0.1054\n",
      "Epoch [392/1000], Loss: 0.0960\n",
      "Epoch [393/1000], Loss: 0.0941\n",
      "Epoch [394/1000], Loss: 0.0972\n",
      "Epoch [395/1000], Loss: 0.0947\n",
      "Epoch [396/1000], Loss: 0.0994\n",
      "Epoch [397/1000], Loss: 0.0936\n",
      "Epoch [398/1000], Loss: 0.0983\n",
      "Epoch [399/1000], Loss: 0.0920\n",
      "Epoch [400/1000], Loss: 0.0965\n",
      "Epoch [401/1000], Loss: 0.1002\n",
      "Epoch [402/1000], Loss: 0.0913\n",
      "Epoch [403/1000], Loss: 0.0953\n",
      "Epoch [404/1000], Loss: 0.0892\n",
      "Epoch [405/1000], Loss: 0.0934\n",
      "Epoch [406/1000], Loss: 0.0951\n",
      "Epoch [407/1000], Loss: 0.0998\n",
      "Epoch [408/1000], Loss: 0.0935\n",
      "Epoch [409/1000], Loss: 0.0905\n",
      "Epoch [410/1000], Loss: 0.0984\n",
      "Epoch [411/1000], Loss: 0.0862\n",
      "Epoch [412/1000], Loss: 0.0868\n",
      "Epoch [413/1000], Loss: 0.0825\n",
      "Epoch [414/1000], Loss: 0.0863\n",
      "Epoch [415/1000], Loss: 0.0799\n",
      "Epoch [416/1000], Loss: 0.0800\n",
      "Epoch [417/1000], Loss: 0.0841\n",
      "Epoch [418/1000], Loss: 0.0764\n",
      "Epoch [419/1000], Loss: 0.0730\n",
      "Epoch [420/1000], Loss: 0.0717\n",
      "Epoch [421/1000], Loss: 0.0673\n",
      "Epoch [422/1000], Loss: 0.0640\n",
      "Epoch [423/1000], Loss: 0.0670\n",
      "Epoch [424/1000], Loss: 0.0634\n",
      "Epoch [425/1000], Loss: 0.0582\n",
      "Epoch [426/1000], Loss: 0.0646\n",
      "Epoch [427/1000], Loss: 0.0622\n",
      "Epoch [428/1000], Loss: 0.0869\n",
      "Epoch [429/1000], Loss: 0.0655\n",
      "Epoch [430/1000], Loss: 0.0690\n",
      "Epoch [431/1000], Loss: 0.0664\n",
      "Epoch [432/1000], Loss: 0.0657\n",
      "Epoch [433/1000], Loss: 0.0528\n",
      "Epoch [434/1000], Loss: 0.0560\n",
      "Epoch [435/1000], Loss: 0.0621\n",
      "Epoch [436/1000], Loss: 0.0527\n",
      "Epoch [437/1000], Loss: 0.0628\n",
      "Epoch [438/1000], Loss: 0.0585\n",
      "Epoch [439/1000], Loss: 0.0581\n",
      "Epoch [440/1000], Loss: 0.0504\n",
      "Epoch [441/1000], Loss: 0.0610\n",
      "Epoch [442/1000], Loss: 0.0782\n",
      "Epoch [443/1000], Loss: 0.0627\n",
      "Epoch [444/1000], Loss: 0.0478\n",
      "Epoch [445/1000], Loss: 0.0646\n",
      "Epoch [446/1000], Loss: 0.0549\n",
      "Epoch [447/1000], Loss: 0.0557\n",
      "Epoch [448/1000], Loss: 0.0466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [449/1000], Loss: 0.0395\n",
      "Epoch [450/1000], Loss: 0.0566\n",
      "Epoch [451/1000], Loss: 0.0452\n",
      "Epoch [452/1000], Loss: 0.0510\n",
      "Epoch [453/1000], Loss: 0.0481\n",
      "Epoch [454/1000], Loss: 0.0452\n",
      "Epoch [455/1000], Loss: 0.0614\n",
      "Epoch [456/1000], Loss: 0.0467\n",
      "Epoch [457/1000], Loss: 0.0449\n",
      "Epoch [458/1000], Loss: 0.0404\n",
      "Epoch [459/1000], Loss: 0.0388\n",
      "Epoch [460/1000], Loss: 0.0467\n",
      "Epoch [461/1000], Loss: 0.0357\n",
      "Epoch [462/1000], Loss: 0.1494\n",
      "Epoch [463/1000], Loss: 0.1471\n",
      "Epoch [464/1000], Loss: 0.1387\n",
      "Epoch [465/1000], Loss: 0.1267\n",
      "Epoch [466/1000], Loss: 0.1142\n",
      "Epoch [467/1000], Loss: 0.1597\n",
      "Epoch [468/1000], Loss: 0.1131\n",
      "Epoch [469/1000], Loss: 0.1128\n",
      "Epoch [470/1000], Loss: 0.1186\n",
      "Epoch [471/1000], Loss: 0.1746\n",
      "Epoch [472/1000], Loss: 0.1539\n",
      "Epoch [473/1000], Loss: 0.1130\n",
      "Epoch [474/1000], Loss: 0.0980\n",
      "Epoch [475/1000], Loss: 0.1045\n",
      "Epoch [476/1000], Loss: 0.1224\n",
      "Epoch [477/1000], Loss: 0.1136\n",
      "Epoch [478/1000], Loss: 0.1228\n",
      "Epoch [479/1000], Loss: 0.1001\n",
      "Epoch [480/1000], Loss: 0.1233\n",
      "Epoch [481/1000], Loss: 0.1041\n",
      "Epoch [482/1000], Loss: 0.1171\n",
      "Epoch [483/1000], Loss: 0.0811\n",
      "Epoch [484/1000], Loss: 0.0857\n",
      "Epoch [485/1000], Loss: 0.1207\n",
      "Epoch [486/1000], Loss: 0.1337\n",
      "Epoch [487/1000], Loss: 0.1255\n",
      "Epoch [488/1000], Loss: 0.1142\n",
      "Epoch [489/1000], Loss: 0.1795\n",
      "Epoch [490/1000], Loss: 0.1538\n",
      "Epoch [491/1000], Loss: 0.1076\n",
      "Epoch [492/1000], Loss: 0.0840\n",
      "Epoch [493/1000], Loss: 0.0800\n",
      "Epoch [494/1000], Loss: 0.1102\n",
      "Epoch [495/1000], Loss: 0.1670\n",
      "Epoch [496/1000], Loss: 0.1969\n",
      "Epoch [497/1000], Loss: 0.1580\n",
      "Epoch [498/1000], Loss: 0.1184\n",
      "Epoch [499/1000], Loss: 0.1054\n",
      "Epoch [500/1000], Loss: 0.1005\n",
      "Epoch [501/1000], Loss: 0.0981\n",
      "Epoch [502/1000], Loss: 0.0781\n",
      "Epoch [503/1000], Loss: 0.1542\n",
      "Epoch [504/1000], Loss: 0.1235\n",
      "Epoch [505/1000], Loss: 0.1170\n",
      "Epoch [506/1000], Loss: 0.1300\n",
      "Epoch [507/1000], Loss: 0.1088\n",
      "Epoch [508/1000], Loss: 0.0980\n",
      "Epoch [509/1000], Loss: 0.1079\n",
      "Epoch [510/1000], Loss: 0.1078\n",
      "Epoch [511/1000], Loss: 0.1380\n",
      "Epoch [512/1000], Loss: 0.0912\n",
      "Epoch [513/1000], Loss: 0.1147\n",
      "Epoch [514/1000], Loss: 0.1008\n",
      "Epoch [515/1000], Loss: 0.0967\n",
      "Epoch [516/1000], Loss: 0.0892\n",
      "Epoch [517/1000], Loss: 0.1166\n",
      "Epoch [518/1000], Loss: 0.0899\n",
      "Epoch [519/1000], Loss: 0.0846\n",
      "Epoch [520/1000], Loss: 0.1089\n",
      "Epoch [521/1000], Loss: 0.1020\n",
      "Epoch [522/1000], Loss: 0.0893\n",
      "Epoch [523/1000], Loss: 0.0871\n",
      "Epoch [524/1000], Loss: 0.0968\n",
      "Epoch [525/1000], Loss: 0.0913\n",
      "Epoch [526/1000], Loss: 0.1042\n",
      "Epoch [527/1000], Loss: 0.1706\n",
      "Epoch [528/1000], Loss: 0.1112\n",
      "Epoch [529/1000], Loss: 0.1004\n",
      "Epoch [530/1000], Loss: 0.0996\n",
      "Epoch [531/1000], Loss: 0.1234\n",
      "Epoch [532/1000], Loss: 0.0937\n",
      "Epoch [533/1000], Loss: 0.0857\n",
      "Epoch [534/1000], Loss: 0.0901\n",
      "Epoch [535/1000], Loss: 0.0838\n",
      "Epoch [536/1000], Loss: 0.0849\n",
      "Epoch [537/1000], Loss: 0.0844\n",
      "Epoch [538/1000], Loss: 0.0765\n",
      "Epoch [539/1000], Loss: 0.0816\n",
      "Epoch [540/1000], Loss: 0.0939\n",
      "Epoch [541/1000], Loss: 0.1007\n",
      "Epoch [542/1000], Loss: 0.0813\n",
      "Epoch [543/1000], Loss: 0.0853\n",
      "Epoch [544/1000], Loss: 0.0768\n",
      "Epoch [545/1000], Loss: 0.0818\n",
      "Epoch [546/1000], Loss: 0.0778\n",
      "Epoch [547/1000], Loss: 0.0893\n",
      "Epoch [548/1000], Loss: 0.0945\n",
      "Epoch [549/1000], Loss: 0.1081\n",
      "Epoch [550/1000], Loss: 0.0773\n",
      "Epoch [551/1000], Loss: 0.1120\n",
      "Epoch [552/1000], Loss: 0.0929\n",
      "Epoch [553/1000], Loss: 0.0769\n",
      "Epoch [554/1000], Loss: 0.0739\n",
      "Epoch [555/1000], Loss: 0.0765\n",
      "Epoch [556/1000], Loss: 0.1046\n",
      "Epoch [557/1000], Loss: 0.0977\n",
      "Epoch [558/1000], Loss: 0.0954\n",
      "Epoch [559/1000], Loss: 0.0763\n",
      "Epoch [560/1000], Loss: 0.0856\n",
      "Epoch [561/1000], Loss: 0.1249\n",
      "Epoch [562/1000], Loss: 0.1365\n",
      "Epoch [563/1000], Loss: 0.1319\n",
      "Epoch [564/1000], Loss: 0.1254\n",
      "Epoch [565/1000], Loss: 0.1252\n",
      "Epoch [566/1000], Loss: 0.1202\n",
      "Epoch [567/1000], Loss: 0.1203\n",
      "Epoch [568/1000], Loss: 0.1158\n",
      "Epoch [569/1000], Loss: 0.1042\n",
      "Epoch [570/1000], Loss: 0.0958\n",
      "Epoch [571/1000], Loss: 0.0934\n",
      "Epoch [572/1000], Loss: 0.0936\n",
      "Epoch [573/1000], Loss: 0.0917\n",
      "Epoch [574/1000], Loss: 0.0884\n",
      "Epoch [575/1000], Loss: 0.0825\n",
      "Epoch [576/1000], Loss: 0.0897\n",
      "Epoch [577/1000], Loss: 0.0895\n",
      "Epoch [578/1000], Loss: 0.0909\n",
      "Epoch [579/1000], Loss: 0.0822\n",
      "Epoch [580/1000], Loss: 0.0815\n",
      "Epoch [581/1000], Loss: 0.0859\n",
      "Epoch [582/1000], Loss: 0.0936\n",
      "Epoch [583/1000], Loss: 0.0863\n",
      "Epoch [584/1000], Loss: 0.0896\n",
      "Epoch [585/1000], Loss: 0.0842\n",
      "Epoch [586/1000], Loss: 0.0854\n",
      "Epoch [587/1000], Loss: 0.0822\n",
      "Epoch [588/1000], Loss: 0.0824\n",
      "Epoch [589/1000], Loss: 0.0800\n",
      "Epoch [590/1000], Loss: 0.1138\n",
      "Epoch [591/1000], Loss: 0.0819\n",
      "Epoch [592/1000], Loss: 0.0842\n",
      "Epoch [593/1000], Loss: 0.0857\n",
      "Epoch [594/1000], Loss: 0.0790\n",
      "Epoch [595/1000], Loss: 0.0996\n",
      "Epoch [596/1000], Loss: 0.0870\n",
      "Epoch [597/1000], Loss: 0.0782\n",
      "Epoch [598/1000], Loss: 0.0762\n",
      "Epoch [599/1000], Loss: 0.0852\n",
      "Epoch [600/1000], Loss: 0.0761\n",
      "Epoch [601/1000], Loss: 0.0765\n",
      "Epoch [602/1000], Loss: 0.0752\n",
      "Epoch [603/1000], Loss: 0.0767\n",
      "Epoch [604/1000], Loss: 0.0774\n",
      "Epoch [605/1000], Loss: 0.0728\n",
      "Epoch [606/1000], Loss: 0.0779\n",
      "Epoch [607/1000], Loss: 0.0780\n",
      "Epoch [608/1000], Loss: 0.0828\n",
      "Epoch [609/1000], Loss: 0.0773\n",
      "Epoch [610/1000], Loss: 0.0716\n",
      "Epoch [611/1000], Loss: 0.0957\n",
      "Epoch [612/1000], Loss: 0.0718\n",
      "Epoch [613/1000], Loss: 0.0818\n",
      "Epoch [614/1000], Loss: 0.0720\n",
      "Epoch [615/1000], Loss: 0.0673\n",
      "Epoch [616/1000], Loss: 0.0696\n",
      "Epoch [617/1000], Loss: 0.0804\n",
      "Epoch [618/1000], Loss: 0.0719\n",
      "Epoch [619/1000], Loss: 0.0654\n",
      "Epoch [620/1000], Loss: 0.0665\n",
      "Epoch [621/1000], Loss: 0.0658\n",
      "Epoch [622/1000], Loss: 0.0683\n",
      "Epoch [623/1000], Loss: 0.0663\n",
      "Epoch [624/1000], Loss: 0.0634\n",
      "Epoch [625/1000], Loss: 0.0795\n",
      "Epoch [626/1000], Loss: 0.0701\n",
      "Epoch [627/1000], Loss: 0.0978\n",
      "Epoch [628/1000], Loss: 0.0637\n",
      "Epoch [629/1000], Loss: 0.1527\n",
      "Epoch [630/1000], Loss: 0.1066\n",
      "Epoch [631/1000], Loss: 0.1305\n",
      "Epoch [632/1000], Loss: 0.0916\n",
      "Epoch [633/1000], Loss: 0.0982\n",
      "Epoch [634/1000], Loss: 0.0882\n",
      "Epoch [635/1000], Loss: 0.0919\n",
      "Epoch [636/1000], Loss: 0.0838\n",
      "Epoch [637/1000], Loss: 0.0813\n",
      "Epoch [638/1000], Loss: 0.0833\n",
      "Epoch [639/1000], Loss: 0.0830\n",
      "Epoch [640/1000], Loss: 0.0995\n",
      "Epoch [641/1000], Loss: 0.0862\n",
      "Epoch [642/1000], Loss: 0.0891\n",
      "Epoch [643/1000], Loss: 0.0973\n",
      "Epoch [644/1000], Loss: 0.1074\n",
      "Epoch [645/1000], Loss: 0.0818\n",
      "Epoch [646/1000], Loss: 0.0731\n",
      "Epoch [647/1000], Loss: 0.1809\n",
      "Epoch [648/1000], Loss: 0.1104\n",
      "Epoch [649/1000], Loss: 0.1186\n",
      "Epoch [650/1000], Loss: 0.1236\n",
      "Epoch [651/1000], Loss: 0.1106\n",
      "Epoch [652/1000], Loss: 0.1017\n",
      "Epoch [653/1000], Loss: 0.1115\n",
      "Epoch [654/1000], Loss: 0.1259\n",
      "Epoch [655/1000], Loss: 0.1005\n",
      "Epoch [656/1000], Loss: 0.0830\n",
      "Epoch [657/1000], Loss: 0.0789\n",
      "Epoch [658/1000], Loss: 0.0733\n",
      "Epoch [659/1000], Loss: 0.1269\n",
      "Epoch [660/1000], Loss: 0.1194\n",
      "Epoch [661/1000], Loss: 0.0996\n",
      "Epoch [662/1000], Loss: 0.0764\n",
      "Epoch [663/1000], Loss: 0.0732\n",
      "Epoch [664/1000], Loss: 0.0721\n",
      "Epoch [665/1000], Loss: 0.0743\n",
      "Epoch [666/1000], Loss: 0.0899\n",
      "Epoch [667/1000], Loss: 0.0672\n",
      "Epoch [668/1000], Loss: 0.0710\n",
      "Epoch [669/1000], Loss: 0.0893\n",
      "Epoch [670/1000], Loss: 0.1009\n",
      "Epoch [671/1000], Loss: 0.0611\n",
      "Epoch [672/1000], Loss: 0.0601\n",
      "Epoch [673/1000], Loss: 0.0947\n",
      "Epoch [674/1000], Loss: 0.1354\n",
      "Epoch [675/1000], Loss: 0.1000\n",
      "Epoch [676/1000], Loss: 0.0956\n",
      "Epoch [677/1000], Loss: 0.0861\n",
      "Epoch [678/1000], Loss: 0.0948\n",
      "Epoch [679/1000], Loss: 0.0768\n",
      "Epoch [680/1000], Loss: 0.0767\n",
      "Epoch [681/1000], Loss: 0.0764\n",
      "Epoch [682/1000], Loss: 0.0754\n",
      "Epoch [683/1000], Loss: 0.1069\n",
      "Epoch [684/1000], Loss: 0.1688\n",
      "Epoch [685/1000], Loss: 0.1214\n",
      "Epoch [686/1000], Loss: 0.1102\n",
      "Epoch [687/1000], Loss: 0.1051\n",
      "Epoch [688/1000], Loss: 0.1006\n",
      "Epoch [689/1000], Loss: 0.1019\n",
      "Epoch [690/1000], Loss: 0.0965\n",
      "Epoch [691/1000], Loss: 0.0951\n",
      "Epoch [692/1000], Loss: 0.0950\n",
      "Epoch [693/1000], Loss: 0.0933\n",
      "Epoch [694/1000], Loss: 0.0924\n",
      "Epoch [695/1000], Loss: 0.0935\n",
      "Epoch [696/1000], Loss: 0.0952\n",
      "Epoch [697/1000], Loss: 0.0927\n",
      "Epoch [698/1000], Loss: 0.0926\n",
      "Epoch [699/1000], Loss: 0.0887\n",
      "Epoch [700/1000], Loss: 0.0916\n",
      "Epoch [701/1000], Loss: 0.0860\n",
      "Epoch [702/1000], Loss: 0.0883\n",
      "Epoch [703/1000], Loss: 0.0849\n",
      "Epoch [704/1000], Loss: 0.0884\n",
      "Epoch [705/1000], Loss: 0.0885\n",
      "Epoch [706/1000], Loss: 0.0834\n",
      "Epoch [707/1000], Loss: 0.0879\n",
      "Epoch [708/1000], Loss: 0.0886\n",
      "Epoch [709/1000], Loss: 0.0953\n",
      "Epoch [710/1000], Loss: 0.0850\n",
      "Epoch [711/1000], Loss: 0.0874\n",
      "Epoch [712/1000], Loss: 0.0831\n",
      "Epoch [713/1000], Loss: 0.0858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [714/1000], Loss: 0.0873\n",
      "Epoch [715/1000], Loss: 0.0847\n",
      "Epoch [716/1000], Loss: 0.0887\n",
      "Epoch [717/1000], Loss: 0.0901\n",
      "Epoch [718/1000], Loss: 0.0849\n",
      "Epoch [719/1000], Loss: 0.0833\n",
      "Epoch [720/1000], Loss: 0.0899\n",
      "Epoch [721/1000], Loss: 0.0871\n",
      "Epoch [722/1000], Loss: 0.0866\n",
      "Epoch [723/1000], Loss: 0.0878\n",
      "Epoch [724/1000], Loss: 0.0826\n",
      "Epoch [725/1000], Loss: 0.0809\n",
      "Epoch [726/1000], Loss: 0.0805\n",
      "Epoch [727/1000], Loss: 0.0821\n",
      "Epoch [728/1000], Loss: 0.0827\n",
      "Epoch [729/1000], Loss: 0.0867\n",
      "Epoch [730/1000], Loss: 0.0821\n",
      "Epoch [731/1000], Loss: 0.0873\n",
      "Epoch [732/1000], Loss: 0.0842\n",
      "Epoch [733/1000], Loss: 0.0806\n",
      "Epoch [734/1000], Loss: 0.0816\n",
      "Epoch [735/1000], Loss: 0.0825\n",
      "Epoch [736/1000], Loss: 0.0807\n",
      "Epoch [737/1000], Loss: 0.0823\n",
      "Epoch [738/1000], Loss: 0.0840\n",
      "Epoch [739/1000], Loss: 0.0822\n",
      "Epoch [740/1000], Loss: 0.0777\n",
      "Epoch [741/1000], Loss: 0.0993\n",
      "Epoch [742/1000], Loss: 0.0785\n",
      "Epoch [743/1000], Loss: 0.0798\n",
      "Epoch [744/1000], Loss: 0.0787\n",
      "Epoch [745/1000], Loss: 0.0793\n",
      "Epoch [746/1000], Loss: 0.0818\n",
      "Epoch [747/1000], Loss: 0.0873\n",
      "Epoch [748/1000], Loss: 0.0801\n",
      "Epoch [749/1000], Loss: 0.0812\n",
      "Epoch [750/1000], Loss: 0.0814\n",
      "Epoch [751/1000], Loss: 0.0816\n",
      "Epoch [752/1000], Loss: 0.0767\n",
      "Epoch [753/1000], Loss: 0.0783\n",
      "Epoch [754/1000], Loss: 0.0820\n",
      "Epoch [755/1000], Loss: 0.0845\n",
      "Epoch [756/1000], Loss: 0.0767\n",
      "Epoch [757/1000], Loss: 0.0758\n",
      "Epoch [758/1000], Loss: 0.0772\n",
      "Epoch [759/1000], Loss: 0.0819\n",
      "Epoch [760/1000], Loss: 0.0741\n",
      "Epoch [761/1000], Loss: 0.0754\n",
      "Epoch [762/1000], Loss: 0.0789\n",
      "Epoch [763/1000], Loss: 0.0737\n",
      "Epoch [764/1000], Loss: 0.0723\n",
      "Epoch [765/1000], Loss: 0.0825\n",
      "Epoch [766/1000], Loss: 0.0839\n",
      "Epoch [767/1000], Loss: 0.0778\n",
      "Epoch [768/1000], Loss: 0.0808\n",
      "Epoch [769/1000], Loss: 0.0737\n",
      "Epoch [770/1000], Loss: 0.0775\n",
      "Epoch [771/1000], Loss: 0.0828\n",
      "Epoch [772/1000], Loss: 0.0776\n",
      "Epoch [773/1000], Loss: 0.0791\n",
      "Epoch [774/1000], Loss: 0.0736\n",
      "Epoch [775/1000], Loss: 0.0770\n",
      "Epoch [776/1000], Loss: 0.0792\n",
      "Epoch [777/1000], Loss: 0.0767\n",
      "Epoch [778/1000], Loss: 0.0842\n",
      "Epoch [779/1000], Loss: 0.0727\n",
      "Epoch [780/1000], Loss: 0.0716\n",
      "Epoch [781/1000], Loss: 0.0829\n",
      "Epoch [782/1000], Loss: 0.0759\n",
      "Epoch [783/1000], Loss: 0.0778\n",
      "Epoch [784/1000], Loss: 0.0754\n",
      "Epoch [785/1000], Loss: 0.0749\n",
      "Epoch [786/1000], Loss: 0.0730\n",
      "Epoch [787/1000], Loss: 0.0763\n",
      "Epoch [788/1000], Loss: 0.0764\n",
      "Epoch [789/1000], Loss: 0.0778\n",
      "Epoch [790/1000], Loss: 0.0713\n",
      "Epoch [791/1000], Loss: 0.0769\n",
      "Epoch [792/1000], Loss: 0.0737\n",
      "Epoch [793/1000], Loss: 0.0751\n",
      "Epoch [794/1000], Loss: 0.0738\n",
      "Epoch [795/1000], Loss: 0.0729\n",
      "Epoch [796/1000], Loss: 0.0719\n",
      "Epoch [797/1000], Loss: 0.0735\n",
      "Epoch [798/1000], Loss: 0.0747\n",
      "Epoch [799/1000], Loss: 0.0769\n",
      "Epoch [800/1000], Loss: 0.0726\n",
      "Epoch [801/1000], Loss: 0.0777\n",
      "Epoch [802/1000], Loss: 0.0728\n",
      "Epoch [803/1000], Loss: 0.0713\n",
      "Epoch [804/1000], Loss: 0.0755\n",
      "Epoch [805/1000], Loss: 0.0723\n",
      "Epoch [806/1000], Loss: 0.0920\n",
      "Epoch [807/1000], Loss: 0.0879\n",
      "Epoch [808/1000], Loss: 0.0755\n",
      "Epoch [809/1000], Loss: 0.0721\n",
      "Epoch [810/1000], Loss: 0.0689\n",
      "Epoch [811/1000], Loss: 0.0667\n",
      "Epoch [812/1000], Loss: 0.0761\n",
      "Epoch [813/1000], Loss: 0.0737\n",
      "Epoch [814/1000], Loss: 0.1351\n",
      "Epoch [815/1000], Loss: 0.1391\n",
      "Epoch [816/1000], Loss: 0.0745\n",
      "Epoch [817/1000], Loss: 0.0688\n",
      "Epoch [818/1000], Loss: 0.0784\n",
      "Epoch [819/1000], Loss: 0.0728\n",
      "Epoch [820/1000], Loss: 0.0745\n",
      "Epoch [821/1000], Loss: 0.0788\n",
      "Epoch [822/1000], Loss: 0.0717\n",
      "Epoch [823/1000], Loss: 0.0796\n",
      "Epoch [824/1000], Loss: 0.0705\n",
      "Epoch [825/1000], Loss: 0.0934\n",
      "Epoch [826/1000], Loss: 0.0712\n",
      "Epoch [827/1000], Loss: 0.0756\n",
      "Epoch [828/1000], Loss: 0.0782\n",
      "Epoch [829/1000], Loss: 0.0774\n",
      "Epoch [830/1000], Loss: 0.0899\n",
      "Epoch [831/1000], Loss: 0.1160\n",
      "Epoch [832/1000], Loss: 0.0734\n",
      "Epoch [833/1000], Loss: 0.0740\n",
      "Epoch [834/1000], Loss: 0.0778\n",
      "Epoch [835/1000], Loss: 0.0848\n",
      "Epoch [836/1000], Loss: 0.1376\n",
      "Epoch [837/1000], Loss: 0.0702\n",
      "Epoch [838/1000], Loss: 0.0790\n",
      "Epoch [839/1000], Loss: 0.0758\n",
      "Epoch [840/1000], Loss: 0.0719\n",
      "Epoch [841/1000], Loss: 0.0698\n",
      "Epoch [842/1000], Loss: 0.0741\n",
      "Epoch [843/1000], Loss: 0.0766\n",
      "Epoch [844/1000], Loss: 0.0710\n",
      "Epoch [845/1000], Loss: 0.0713\n",
      "Epoch [846/1000], Loss: 0.0745\n",
      "Epoch [847/1000], Loss: 0.0706\n",
      "Epoch [848/1000], Loss: 0.0642\n",
      "Epoch [849/1000], Loss: 0.0754\n",
      "Epoch [850/1000], Loss: 0.0672\n",
      "Epoch [851/1000], Loss: 0.0661\n",
      "Epoch [852/1000], Loss: 0.0701\n",
      "Epoch [853/1000], Loss: 0.0665\n",
      "Epoch [854/1000], Loss: 0.0663\n",
      "Epoch [855/1000], Loss: 0.0679\n",
      "Epoch [856/1000], Loss: 0.0679\n",
      "Epoch [857/1000], Loss: 0.0684\n",
      "Epoch [858/1000], Loss: 0.0647\n",
      "Epoch [859/1000], Loss: 0.0654\n",
      "Epoch [860/1000], Loss: 0.0712\n",
      "Epoch [861/1000], Loss: 0.0730\n",
      "Epoch [862/1000], Loss: 0.0698\n",
      "Epoch [863/1000], Loss: 0.0768\n",
      "Epoch [864/1000], Loss: 0.0691\n",
      "Epoch [865/1000], Loss: 0.0765\n",
      "Epoch [866/1000], Loss: 0.0690\n",
      "Epoch [867/1000], Loss: 0.0715\n",
      "Epoch [868/1000], Loss: 0.0668\n",
      "Epoch [869/1000], Loss: 0.0651\n",
      "Epoch [870/1000], Loss: 0.1009\n",
      "Epoch [871/1000], Loss: 0.0653\n",
      "Epoch [872/1000], Loss: 0.0690\n",
      "Epoch [873/1000], Loss: 0.0657\n",
      "Epoch [874/1000], Loss: 0.0643\n",
      "Epoch [875/1000], Loss: 0.0735\n",
      "Epoch [876/1000], Loss: 0.0678\n",
      "Epoch [877/1000], Loss: 0.0695\n",
      "Epoch [878/1000], Loss: 0.0680\n",
      "Epoch [879/1000], Loss: 0.0718\n",
      "Epoch [880/1000], Loss: 0.0639\n",
      "Epoch [881/1000], Loss: 0.0683\n",
      "Epoch [882/1000], Loss: 0.0704\n",
      "Epoch [883/1000], Loss: 0.0646\n",
      "Epoch [884/1000], Loss: 0.0591\n",
      "Epoch [885/1000], Loss: 0.0626\n",
      "Epoch [886/1000], Loss: 0.0633\n",
      "Epoch [887/1000], Loss: 0.0555\n",
      "Epoch [888/1000], Loss: 0.0601\n",
      "Epoch [889/1000], Loss: 0.0597\n",
      "Epoch [890/1000], Loss: 0.0629\n",
      "Epoch [891/1000], Loss: 0.0604\n",
      "Epoch [892/1000], Loss: 0.0686\n",
      "Epoch [893/1000], Loss: 0.0639\n",
      "Epoch [894/1000], Loss: 0.0686\n",
      "Epoch [895/1000], Loss: 0.0652\n",
      "Epoch [896/1000], Loss: 0.0782\n",
      "Epoch [897/1000], Loss: 0.0676\n",
      "Epoch [898/1000], Loss: 0.0899\n",
      "Epoch [899/1000], Loss: 0.0630\n",
      "Epoch [900/1000], Loss: 0.0673\n",
      "Epoch [901/1000], Loss: 0.0636\n",
      "Epoch [902/1000], Loss: 0.0681\n",
      "Epoch [903/1000], Loss: 0.0633\n",
      "Epoch [904/1000], Loss: 0.0596\n",
      "Epoch [905/1000], Loss: 0.0557\n",
      "Epoch [906/1000], Loss: 0.0612\n",
      "Epoch [907/1000], Loss: 0.0590\n",
      "Epoch [908/1000], Loss: 0.0585\n",
      "Epoch [909/1000], Loss: 0.0608\n",
      "Epoch [910/1000], Loss: 0.0593\n",
      "Epoch [911/1000], Loss: 0.0597\n",
      "Epoch [912/1000], Loss: 0.0567\n",
      "Epoch [913/1000], Loss: 0.0701\n",
      "Epoch [914/1000], Loss: 0.1318\n",
      "Epoch [915/1000], Loss: 0.0632\n",
      "Epoch [916/1000], Loss: 0.0586\n",
      "Epoch [917/1000], Loss: 0.0569\n",
      "Epoch [918/1000], Loss: 0.0582\n",
      "Epoch [919/1000], Loss: 0.0625\n",
      "Epoch [920/1000], Loss: 0.0670\n",
      "Epoch [921/1000], Loss: 0.0628\n",
      "Epoch [922/1000], Loss: 0.0547\n",
      "Epoch [923/1000], Loss: 0.0577\n",
      "Epoch [924/1000], Loss: 0.0672\n",
      "Epoch [925/1000], Loss: 0.0645\n",
      "Epoch [926/1000], Loss: 0.0540\n",
      "Epoch [927/1000], Loss: 0.0524\n",
      "Epoch [928/1000], Loss: 0.0642\n",
      "Epoch [929/1000], Loss: 0.0581\n",
      "Epoch [930/1000], Loss: 0.0553\n",
      "Epoch [931/1000], Loss: 0.2369\n",
      "Epoch [932/1000], Loss: 0.1590\n",
      "Epoch [933/1000], Loss: 0.1358\n",
      "Epoch [934/1000], Loss: 0.1157\n",
      "Epoch [935/1000], Loss: 0.1095\n",
      "Epoch [936/1000], Loss: 0.0958\n",
      "Epoch [937/1000], Loss: 0.0901\n",
      "Epoch [938/1000], Loss: 0.0872\n",
      "Epoch [939/1000], Loss: 0.0887\n",
      "Epoch [940/1000], Loss: 0.0876\n",
      "Epoch [941/1000], Loss: 0.0853\n",
      "Epoch [942/1000], Loss: 0.1935\n",
      "Epoch [943/1000], Loss: 0.1464\n",
      "Epoch [944/1000], Loss: 0.1025\n",
      "Epoch [945/1000], Loss: 0.0943\n",
      "Epoch [946/1000], Loss: 0.0827\n",
      "Epoch [947/1000], Loss: 0.0793\n",
      "Epoch [948/1000], Loss: 0.0795\n",
      "Epoch [949/1000], Loss: 0.0822\n",
      "Epoch [950/1000], Loss: 0.0734\n",
      "Epoch [951/1000], Loss: 0.0682\n",
      "Epoch [952/1000], Loss: 0.0528\n",
      "Epoch [953/1000], Loss: 0.0564\n",
      "Epoch [954/1000], Loss: 0.0599\n",
      "Epoch [955/1000], Loss: 0.0548\n",
      "Epoch [956/1000], Loss: 0.0644\n",
      "Epoch [957/1000], Loss: 0.0590\n",
      "Epoch [958/1000], Loss: 0.0521\n",
      "Epoch [959/1000], Loss: 0.0666\n",
      "Epoch [960/1000], Loss: 0.0526\n",
      "Epoch [961/1000], Loss: 0.0519\n",
      "Epoch [962/1000], Loss: 0.0549\n",
      "Epoch [963/1000], Loss: 0.0548\n",
      "Epoch [964/1000], Loss: 0.0493\n",
      "Epoch [965/1000], Loss: 0.0562\n",
      "Epoch [966/1000], Loss: 0.0514\n",
      "Epoch [967/1000], Loss: 0.0497\n",
      "Epoch [968/1000], Loss: 0.0476\n",
      "Epoch [969/1000], Loss: 0.0608\n",
      "Epoch [970/1000], Loss: 0.0539\n",
      "Epoch [971/1000], Loss: 0.0538\n",
      "Epoch [972/1000], Loss: 0.0485\n",
      "Epoch [973/1000], Loss: 0.0560\n",
      "Epoch [974/1000], Loss: 0.0490\n",
      "Epoch [975/1000], Loss: 0.0495\n",
      "Epoch [976/1000], Loss: 0.0483\n",
      "Epoch [977/1000], Loss: 0.0507\n",
      "Epoch [978/1000], Loss: 0.0442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [979/1000], Loss: 0.0468\n",
      "Epoch [980/1000], Loss: 0.0495\n",
      "Epoch [981/1000], Loss: 0.0507\n",
      "Epoch [982/1000], Loss: 0.0508\n",
      "Epoch [983/1000], Loss: 0.0425\n",
      "Epoch [984/1000], Loss: 0.0514\n",
      "Epoch [985/1000], Loss: 0.0451\n",
      "Epoch [986/1000], Loss: 0.0440\n",
      "Epoch [987/1000], Loss: 0.0371\n",
      "Epoch [988/1000], Loss: 0.0763\n",
      "Epoch [989/1000], Loss: 0.0392\n",
      "Epoch [990/1000], Loss: 0.0518\n",
      "Epoch [991/1000], Loss: 0.0501\n",
      "Epoch [992/1000], Loss: 0.0514\n",
      "Epoch [993/1000], Loss: 0.0471\n",
      "Epoch [994/1000], Loss: 0.2388\n",
      "Epoch [995/1000], Loss: 0.2080\n",
      "Epoch [996/1000], Loss: 0.1496\n",
      "Epoch [997/1000], Loss: 0.1179\n",
      "Epoch [998/1000], Loss: 0.1074\n",
      "Epoch [999/1000], Loss: 0.1009\n",
      "Epoch [1000/1000], Loss: 0.1019\n",
      "------- Training model with depth : 5, activation : tanh, and neurons: 10\n",
      "Epoch [1/1000], Loss: 0.2523\n",
      "Epoch [2/1000], Loss: 0.2501\n",
      "Epoch [3/1000], Loss: 0.2494\n",
      "Epoch [4/1000], Loss: 0.2491\n",
      "Epoch [5/1000], Loss: 0.2487\n",
      "Epoch [6/1000], Loss: 0.2483\n",
      "Epoch [7/1000], Loss: 0.2478\n",
      "Epoch [8/1000], Loss: 0.2471\n",
      "Epoch [9/1000], Loss: 0.2462\n",
      "Epoch [10/1000], Loss: 0.2450\n",
      "Epoch [11/1000], Loss: 0.2437\n",
      "Epoch [12/1000], Loss: 0.2422\n",
      "Epoch [13/1000], Loss: 0.2407\n",
      "Epoch [14/1000], Loss: 0.2394\n",
      "Epoch [15/1000], Loss: 0.2386\n",
      "Epoch [16/1000], Loss: 0.2380\n",
      "Epoch [17/1000], Loss: 0.2376\n",
      "Epoch [18/1000], Loss: 0.2373\n",
      "Epoch [19/1000], Loss: 0.2371\n",
      "Epoch [20/1000], Loss: 0.2369\n",
      "Epoch [21/1000], Loss: 0.2367\n",
      "Epoch [22/1000], Loss: 0.2365\n",
      "Epoch [23/1000], Loss: 0.2363\n",
      "Epoch [24/1000], Loss: 0.2361\n",
      "Epoch [25/1000], Loss: 0.2358\n",
      "Epoch [26/1000], Loss: 0.2357\n",
      "Epoch [27/1000], Loss: 0.2355\n",
      "Epoch [28/1000], Loss: 0.2353\n",
      "Epoch [29/1000], Loss: 0.2351\n",
      "Epoch [30/1000], Loss: 0.2349\n",
      "Epoch [31/1000], Loss: 0.2347\n",
      "Epoch [32/1000], Loss: 0.2345\n",
      "Epoch [33/1000], Loss: 0.2343\n",
      "Epoch [34/1000], Loss: 0.2341\n",
      "Epoch [35/1000], Loss: 0.2338\n",
      "Epoch [36/1000], Loss: 0.2336\n",
      "Epoch [37/1000], Loss: 0.2334\n",
      "Epoch [38/1000], Loss: 0.2332\n",
      "Epoch [39/1000], Loss: 0.2329\n",
      "Epoch [40/1000], Loss: 0.2328\n",
      "Epoch [41/1000], Loss: 0.2325\n",
      "Epoch [42/1000], Loss: 0.2323\n",
      "Epoch [43/1000], Loss: 0.2320\n",
      "Epoch [44/1000], Loss: 0.2318\n",
      "Epoch [45/1000], Loss: 0.2316\n",
      "Epoch [46/1000], Loss: 0.2313\n",
      "Epoch [47/1000], Loss: 0.2311\n",
      "Epoch [48/1000], Loss: 0.2308\n",
      "Epoch [49/1000], Loss: 0.2306\n",
      "Epoch [50/1000], Loss: 0.2303\n",
      "Epoch [51/1000], Loss: 0.2301\n",
      "Epoch [52/1000], Loss: 0.2298\n",
      "Epoch [53/1000], Loss: 0.2295\n",
      "Epoch [54/1000], Loss: 0.2293\n",
      "Epoch [55/1000], Loss: 0.2290\n",
      "Epoch [56/1000], Loss: 0.2287\n",
      "Epoch [57/1000], Loss: 0.2284\n",
      "Epoch [58/1000], Loss: 0.2282\n",
      "Epoch [59/1000], Loss: 0.2278\n",
      "Epoch [60/1000], Loss: 0.2276\n",
      "Epoch [61/1000], Loss: 0.2272\n",
      "Epoch [62/1000], Loss: 0.2269\n",
      "Epoch [63/1000], Loss: 0.2266\n",
      "Epoch [64/1000], Loss: 0.2262\n",
      "Epoch [65/1000], Loss: 0.2258\n",
      "Epoch [66/1000], Loss: 0.2254\n",
      "Epoch [67/1000], Loss: 0.2250\n",
      "Epoch [68/1000], Loss: 0.2246\n",
      "Epoch [69/1000], Loss: 0.2241\n",
      "Epoch [70/1000], Loss: 0.2236\n",
      "Epoch [71/1000], Loss: 0.2230\n",
      "Epoch [72/1000], Loss: 0.2224\n",
      "Epoch [73/1000], Loss: 0.2219\n",
      "Epoch [74/1000], Loss: 0.2211\n",
      "Epoch [75/1000], Loss: 0.2205\n",
      "Epoch [76/1000], Loss: 0.2197\n",
      "Epoch [77/1000], Loss: 0.2190\n",
      "Epoch [78/1000], Loss: 0.2183\n",
      "Epoch [79/1000], Loss: 0.2175\n",
      "Epoch [80/1000], Loss: 0.2167\n",
      "Epoch [81/1000], Loss: 0.2159\n",
      "Epoch [82/1000], Loss: 0.2150\n",
      "Epoch [83/1000], Loss: 0.2141\n",
      "Epoch [84/1000], Loss: 0.2131\n",
      "Epoch [85/1000], Loss: 0.2122\n",
      "Epoch [86/1000], Loss: 0.2110\n",
      "Epoch [87/1000], Loss: 0.2102\n",
      "Epoch [88/1000], Loss: 0.2090\n",
      "Epoch [89/1000], Loss: 0.2080\n",
      "Epoch [90/1000], Loss: 0.2067\n",
      "Epoch [91/1000], Loss: 0.2057\n",
      "Epoch [92/1000], Loss: 0.2041\n",
      "Epoch [93/1000], Loss: 0.2029\n",
      "Epoch [94/1000], Loss: 0.2015\n",
      "Epoch [95/1000], Loss: 0.1997\n",
      "Epoch [96/1000], Loss: 0.1984\n",
      "Epoch [97/1000], Loss: 0.1968\n",
      "Epoch [98/1000], Loss: 0.1959\n",
      "Epoch [99/1000], Loss: 0.1944\n",
      "Epoch [100/1000], Loss: 0.1932\n",
      "Epoch [101/1000], Loss: 0.1915\n",
      "Epoch [102/1000], Loss: 0.1902\n",
      "Epoch [103/1000], Loss: 0.1893\n",
      "Epoch [104/1000], Loss: 0.1881\n",
      "Epoch [105/1000], Loss: 0.1865\n",
      "Epoch [106/1000], Loss: 0.1844\n",
      "Epoch [107/1000], Loss: 0.1826\n",
      "Epoch [108/1000], Loss: 0.1801\n",
      "Epoch [109/1000], Loss: 0.1773\n",
      "Epoch [110/1000], Loss: 0.1733\n",
      "Epoch [111/1000], Loss: 0.1687\n",
      "Epoch [112/1000], Loss: 0.1628\n",
      "Epoch [113/1000], Loss: 0.1570\n",
      "Epoch [114/1000], Loss: 0.1516\n",
      "Epoch [115/1000], Loss: 0.1476\n",
      "Epoch [116/1000], Loss: 0.1441\n",
      "Epoch [117/1000], Loss: 0.1388\n",
      "Epoch [118/1000], Loss: 0.1357\n",
      "Epoch [119/1000], Loss: 0.1303\n",
      "Epoch [120/1000], Loss: 0.1244\n",
      "Epoch [121/1000], Loss: 0.1207\n",
      "Epoch [122/1000], Loss: 0.1166\n",
      "Epoch [123/1000], Loss: 0.1109\n",
      "Epoch [124/1000], Loss: 0.1082\n",
      "Epoch [125/1000], Loss: 0.1042\n",
      "Epoch [126/1000], Loss: 0.0998\n",
      "Epoch [127/1000], Loss: 0.1007\n",
      "Epoch [128/1000], Loss: 0.0959\n",
      "Epoch [129/1000], Loss: 0.0920\n",
      "Epoch [130/1000], Loss: 0.0880\n",
      "Epoch [131/1000], Loss: 0.0848\n",
      "Epoch [132/1000], Loss: 0.0755\n",
      "Epoch [133/1000], Loss: 0.0730\n",
      "Epoch [134/1000], Loss: 0.0707\n",
      "Epoch [135/1000], Loss: 0.0691\n",
      "Epoch [136/1000], Loss: 0.0690\n",
      "Epoch [137/1000], Loss: 0.0623\n",
      "Epoch [138/1000], Loss: 0.0544\n",
      "Epoch [139/1000], Loss: 0.0580\n",
      "Epoch [140/1000], Loss: 0.0554\n",
      "Epoch [141/1000], Loss: 0.0586\n",
      "Epoch [142/1000], Loss: 0.0564\n",
      "Epoch [143/1000], Loss: 0.0527\n",
      "Epoch [144/1000], Loss: 0.0548\n",
      "Epoch [145/1000], Loss: 0.0516\n",
      "Epoch [146/1000], Loss: 0.0446\n",
      "Epoch [147/1000], Loss: 0.0423\n",
      "Epoch [148/1000], Loss: 0.0483\n",
      "Epoch [149/1000], Loss: 0.0355\n",
      "Epoch [150/1000], Loss: 0.0305\n",
      "Epoch [151/1000], Loss: 0.0347\n",
      "Epoch [152/1000], Loss: 0.0347\n",
      "Epoch [153/1000], Loss: 0.0348\n",
      "Epoch [154/1000], Loss: 0.0283\n",
      "Epoch [155/1000], Loss: 0.0246\n",
      "Epoch [156/1000], Loss: 0.0198\n",
      "Epoch [157/1000], Loss: 0.0213\n",
      "Epoch [158/1000], Loss: 0.0223\n",
      "Epoch [159/1000], Loss: 0.0180\n",
      "Epoch [160/1000], Loss: 0.0179\n",
      "Epoch [161/1000], Loss: 0.0127\n",
      "Epoch [162/1000], Loss: 0.0129\n",
      "Epoch [163/1000], Loss: 0.0190\n",
      "Epoch [164/1000], Loss: 0.0128\n",
      "Epoch [165/1000], Loss: 0.0135\n",
      "Epoch [166/1000], Loss: 0.0101\n",
      "Epoch [167/1000], Loss: 0.0108\n",
      "Epoch [168/1000], Loss: 0.0091\n",
      "Epoch [169/1000], Loss: 0.0106\n",
      "Epoch [170/1000], Loss: 0.0110\n",
      "Epoch [171/1000], Loss: 0.0079\n",
      "Epoch [172/1000], Loss: 0.0068\n",
      "Epoch [173/1000], Loss: 0.0077\n",
      "Epoch [174/1000], Loss: 0.0071\n",
      "Epoch [175/1000], Loss: 0.0038\n",
      "Epoch [176/1000], Loss: 0.0050\n",
      "Epoch [177/1000], Loss: 0.0107\n",
      "Epoch [178/1000], Loss: 0.0087\n",
      "Epoch [179/1000], Loss: 0.0037\n",
      "Epoch [180/1000], Loss: 0.0051\n",
      "Epoch [181/1000], Loss: 0.0079\n",
      "Epoch [182/1000], Loss: 0.0040\n",
      "Epoch [183/1000], Loss: 0.0050\n",
      "Epoch [184/1000], Loss: 0.0040\n",
      "Epoch [185/1000], Loss: 0.0040\n",
      "Epoch [186/1000], Loss: 0.0064\n",
      "Epoch [187/1000], Loss: 0.0057\n",
      "Epoch [188/1000], Loss: 0.0046\n",
      "Epoch [189/1000], Loss: 0.0032\n",
      "Epoch [190/1000], Loss: 0.0023\n",
      "Epoch [191/1000], Loss: 0.0018\n",
      "Epoch [192/1000], Loss: 0.0019\n",
      "Epoch [193/1000], Loss: 0.0042\n",
      "Epoch [194/1000], Loss: 0.0019\n",
      "Epoch [195/1000], Loss: 0.0017\n",
      "Epoch [196/1000], Loss: 0.0016\n",
      "Epoch [197/1000], Loss: 0.0018\n",
      "Epoch [198/1000], Loss: 0.0017\n",
      "Epoch [199/1000], Loss: 0.0153\n",
      "Epoch [200/1000], Loss: 0.0020\n",
      "Epoch [201/1000], Loss: 0.0024\n",
      "Epoch [202/1000], Loss: 0.0021\n",
      "Epoch [203/1000], Loss: 0.0028\n",
      "Epoch [204/1000], Loss: 0.0064\n",
      "Epoch [205/1000], Loss: 0.0042\n",
      "Epoch [206/1000], Loss: 0.0014\n",
      "Epoch [207/1000], Loss: 0.0014\n",
      "Epoch [208/1000], Loss: 0.0017\n",
      "Epoch [209/1000], Loss: 0.0052\n",
      "Epoch [210/1000], Loss: 0.0047\n",
      "Epoch [211/1000], Loss: 0.0027\n",
      "Epoch [212/1000], Loss: 0.0020\n",
      "Epoch [213/1000], Loss: 0.0015\n",
      "Epoch [214/1000], Loss: 0.0023\n",
      "Epoch [215/1000], Loss: 0.0019\n",
      "Epoch [216/1000], Loss: 0.0015\n",
      "Epoch [217/1000], Loss: 0.0019\n",
      "Epoch [218/1000], Loss: 0.0047\n",
      "Epoch [219/1000], Loss: 0.0029\n",
      "Epoch [220/1000], Loss: 0.0016\n",
      "Epoch [221/1000], Loss: 0.0016\n",
      "Epoch [222/1000], Loss: 0.0040\n",
      "Epoch [223/1000], Loss: 0.0015\n",
      "Epoch [224/1000], Loss: 0.0012\n",
      "Epoch [225/1000], Loss: 0.0020\n",
      "Epoch [226/1000], Loss: 0.0011\n",
      "Epoch [227/1000], Loss: 0.0011\n",
      "Epoch [228/1000], Loss: 0.0010\n",
      "Epoch [229/1000], Loss: 0.0010\n",
      "Epoch [230/1000], Loss: 0.0010\n",
      "Epoch [231/1000], Loss: 0.0015\n",
      "Epoch [232/1000], Loss: 0.0011\n",
      "Epoch [233/1000], Loss: 0.0008\n",
      "No improvement for 7 epochs, stopping\n",
      "------- Training model with depth : 5, activation : tanh, and neurons: 20\n",
      "Epoch [1/1000], Loss: 0.2502\n",
      "Epoch [2/1000], Loss: 0.2482\n",
      "Epoch [3/1000], Loss: 0.2466\n",
      "Epoch [4/1000], Loss: 0.2450\n",
      "Epoch [5/1000], Loss: 0.2436\n",
      "Epoch [6/1000], Loss: 0.2424\n",
      "Epoch [7/1000], Loss: 0.2414\n",
      "Epoch [8/1000], Loss: 0.2406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/1000], Loss: 0.2400\n",
      "Epoch [10/1000], Loss: 0.2396\n",
      "Epoch [11/1000], Loss: 0.2392\n",
      "Epoch [12/1000], Loss: 0.2389\n",
      "Epoch [13/1000], Loss: 0.2387\n",
      "Epoch [14/1000], Loss: 0.2385\n",
      "Epoch [15/1000], Loss: 0.2384\n",
      "Epoch [16/1000], Loss: 0.2382\n",
      "Epoch [17/1000], Loss: 0.2380\n",
      "Epoch [18/1000], Loss: 0.2378\n",
      "Epoch [19/1000], Loss: 0.2377\n",
      "Epoch [20/1000], Loss: 0.2375\n",
      "Epoch [21/1000], Loss: 0.2373\n",
      "Epoch [22/1000], Loss: 0.2371\n",
      "Epoch [23/1000], Loss: 0.2370\n",
      "Epoch [24/1000], Loss: 0.2368\n",
      "Epoch [25/1000], Loss: 0.2366\n",
      "Epoch [26/1000], Loss: 0.2364\n",
      "Epoch [27/1000], Loss: 0.2362\n",
      "Epoch [28/1000], Loss: 0.2361\n",
      "Epoch [29/1000], Loss: 0.2358\n",
      "Epoch [30/1000], Loss: 0.2356\n",
      "Epoch [31/1000], Loss: 0.2354\n",
      "Epoch [32/1000], Loss: 0.2352\n",
      "Epoch [33/1000], Loss: 0.2350\n",
      "Epoch [34/1000], Loss: 0.2348\n",
      "Epoch [35/1000], Loss: 0.2345\n",
      "Epoch [36/1000], Loss: 0.2343\n",
      "Epoch [37/1000], Loss: 0.2340\n",
      "Epoch [38/1000], Loss: 0.2338\n",
      "Epoch [39/1000], Loss: 0.2335\n",
      "Epoch [40/1000], Loss: 0.2332\n",
      "Epoch [41/1000], Loss: 0.2329\n",
      "Epoch [42/1000], Loss: 0.2326\n",
      "Epoch [43/1000], Loss: 0.2323\n",
      "Epoch [44/1000], Loss: 0.2319\n",
      "Epoch [45/1000], Loss: 0.2316\n",
      "Epoch [46/1000], Loss: 0.2312\n",
      "Epoch [47/1000], Loss: 0.2308\n",
      "Epoch [48/1000], Loss: 0.2305\n",
      "Epoch [49/1000], Loss: 0.2300\n",
      "Epoch [50/1000], Loss: 0.2296\n",
      "Epoch [51/1000], Loss: 0.2291\n",
      "Epoch [52/1000], Loss: 0.2286\n",
      "Epoch [53/1000], Loss: 0.2280\n",
      "Epoch [54/1000], Loss: 0.2274\n",
      "Epoch [55/1000], Loss: 0.2267\n",
      "Epoch [56/1000], Loss: 0.2260\n",
      "Epoch [57/1000], Loss: 0.2252\n",
      "Epoch [58/1000], Loss: 0.2242\n",
      "Epoch [59/1000], Loss: 0.2233\n",
      "Epoch [60/1000], Loss: 0.2221\n",
      "Epoch [61/1000], Loss: 0.2209\n",
      "Epoch [62/1000], Loss: 0.2196\n",
      "Epoch [63/1000], Loss: 0.2181\n",
      "Epoch [64/1000], Loss: 0.2166\n",
      "Epoch [65/1000], Loss: 0.2149\n",
      "Epoch [66/1000], Loss: 0.2132\n",
      "Epoch [67/1000], Loss: 0.2115\n",
      "Epoch [68/1000], Loss: 0.2092\n",
      "Epoch [69/1000], Loss: 0.2070\n",
      "Epoch [70/1000], Loss: 0.2048\n",
      "Epoch [71/1000], Loss: 0.2028\n",
      "Epoch [72/1000], Loss: 0.2004\n",
      "Epoch [73/1000], Loss: 0.1968\n",
      "Epoch [74/1000], Loss: 0.1938\n",
      "Epoch [75/1000], Loss: 0.1902\n",
      "Epoch [76/1000], Loss: 0.1858\n",
      "Epoch [77/1000], Loss: 0.1804\n",
      "Epoch [78/1000], Loss: 0.1740\n",
      "Epoch [79/1000], Loss: 0.1669\n",
      "Epoch [80/1000], Loss: 0.1589\n",
      "Epoch [81/1000], Loss: 0.1522\n",
      "Epoch [82/1000], Loss: 0.1456\n",
      "Epoch [83/1000], Loss: 0.1393\n",
      "Epoch [84/1000], Loss: 0.1338\n",
      "Epoch [85/1000], Loss: 0.1271\n",
      "Epoch [86/1000], Loss: 0.1250\n",
      "Epoch [87/1000], Loss: 0.1207\n",
      "Epoch [88/1000], Loss: 0.1195\n",
      "Epoch [89/1000], Loss: 0.1170\n",
      "Epoch [90/1000], Loss: 0.1111\n",
      "Epoch [91/1000], Loss: 0.1107\n",
      "Epoch [92/1000], Loss: 0.1061\n",
      "Epoch [93/1000], Loss: 0.1055\n",
      "Epoch [94/1000], Loss: 0.1016\n",
      "Epoch [95/1000], Loss: 0.1001\n",
      "Epoch [96/1000], Loss: 0.0997\n",
      "Epoch [97/1000], Loss: 0.0971\n",
      "Epoch [98/1000], Loss: 0.0911\n",
      "Epoch [99/1000], Loss: 0.0902\n",
      "Epoch [100/1000], Loss: 0.0856\n",
      "Epoch [101/1000], Loss: 0.0864\n",
      "Epoch [102/1000], Loss: 0.0798\n",
      "Epoch [103/1000], Loss: 0.0762\n",
      "Epoch [104/1000], Loss: 0.0809\n",
      "Epoch [105/1000], Loss: 0.0751\n",
      "Epoch [106/1000], Loss: 0.0618\n",
      "Epoch [107/1000], Loss: 0.0657\n",
      "Epoch [108/1000], Loss: 0.0587\n",
      "Epoch [109/1000], Loss: 0.0599\n",
      "Epoch [110/1000], Loss: 0.0516\n",
      "Epoch [111/1000], Loss: 0.0443\n",
      "Epoch [112/1000], Loss: 0.0384\n",
      "Epoch [113/1000], Loss: 0.0400\n",
      "Epoch [114/1000], Loss: 0.0354\n",
      "Epoch [115/1000], Loss: 0.0354\n",
      "Epoch [116/1000], Loss: 0.0276\n",
      "Epoch [117/1000], Loss: 0.0306\n",
      "Epoch [118/1000], Loss: 0.0288\n",
      "Epoch [119/1000], Loss: 0.0214\n",
      "Epoch [120/1000], Loss: 0.0157\n",
      "Epoch [121/1000], Loss: 0.0254\n",
      "Epoch [122/1000], Loss: 0.0205\n",
      "Epoch [123/1000], Loss: 0.0179\n",
      "Epoch [124/1000], Loss: 0.0229\n",
      "Epoch [125/1000], Loss: 0.0152\n",
      "Epoch [126/1000], Loss: 0.0174\n",
      "Epoch [127/1000], Loss: 0.0069\n",
      "Epoch [128/1000], Loss: 0.0071\n",
      "Epoch [129/1000], Loss: 0.0125\n",
      "Epoch [130/1000], Loss: 0.0060\n",
      "Epoch [131/1000], Loss: 0.0078\n",
      "Epoch [132/1000], Loss: 0.0211\n",
      "Epoch [133/1000], Loss: 0.0056\n",
      "Epoch [134/1000], Loss: 0.0125\n",
      "Epoch [135/1000], Loss: 0.0043\n",
      "Epoch [136/1000], Loss: 0.0039\n",
      "Epoch [137/1000], Loss: 0.0170\n",
      "Epoch [138/1000], Loss: 0.0046\n",
      "Epoch [139/1000], Loss: 0.0042\n",
      "Epoch [140/1000], Loss: 0.0051\n",
      "Epoch [141/1000], Loss: 0.0019\n",
      "Epoch [142/1000], Loss: 0.0015\n",
      "Epoch [143/1000], Loss: 0.0080\n",
      "Epoch [144/1000], Loss: 0.0042\n",
      "Epoch [145/1000], Loss: 0.0041\n",
      "Epoch [146/1000], Loss: 0.0077\n",
      "Epoch [147/1000], Loss: 0.0079\n",
      "Epoch [148/1000], Loss: 0.0032\n",
      "Epoch [149/1000], Loss: 0.0121\n",
      "Epoch [150/1000], Loss: 0.0023\n",
      "Epoch [151/1000], Loss: 0.0012\n",
      "Epoch [152/1000], Loss: 0.0009\n",
      "Epoch [153/1000], Loss: 0.0010\n",
      "Epoch [154/1000], Loss: 0.0091\n",
      "Epoch [155/1000], Loss: 0.0010\n",
      "Epoch [156/1000], Loss: 0.0011\n",
      "Epoch [157/1000], Loss: 0.0011\n",
      "Epoch [158/1000], Loss: 0.0016\n",
      "Epoch [159/1000], Loss: 0.0077\n",
      "Epoch [160/1000], Loss: 0.0060\n",
      "Epoch [161/1000], Loss: 0.0011\n",
      "Epoch [162/1000], Loss: 0.0007\n",
      "Epoch [163/1000], Loss: 0.0006\n",
      "Epoch [164/1000], Loss: 0.0010\n",
      "Epoch [165/1000], Loss: 0.0006\n",
      "Epoch [166/1000], Loss: 0.0006\n",
      "Epoch [167/1000], Loss: 0.0012\n",
      "Epoch [168/1000], Loss: 0.0005\n",
      "Epoch [169/1000], Loss: 0.0008\n",
      "Epoch [170/1000], Loss: 0.0005\n",
      "Epoch [171/1000], Loss: 0.0005\n",
      "Epoch [172/1000], Loss: 0.0005\n",
      "Epoch [173/1000], Loss: 0.0005\n",
      "Epoch [174/1000], Loss: 0.0005\n",
      "Epoch [175/1000], Loss: 0.0005\n",
      "No improvement for 7 epochs, stopping\n",
      "Grid evaluation took 2367.6557989120483 sec\n"
     ]
    }
   ],
   "source": [
    "results = {\"depth\": [], \"activation\":[], \"neurons\":[], \"acc\":[], \"num_epochs\":[]}\n",
    "start_time = time.time()\n",
    "for depth in range(depth_interval[0], depth_interval[1]+1):\n",
    "    for activation in activations:\n",
    "        for neurons in neurons_numbers:\n",
    "            print(f\"------- Training model with depth : {depth}, activation : {activation}, and neurons: {neurons}\")\n",
    "            # Init model \n",
    "            model = Model(activation=activation, n_neurons=[neurons]*depth)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "            train_error, _num_epochs = train(num_epochs, batch_size, criterion, optimizer, model, training_set)\n",
    "            \n",
    "            # predict labels for validation set\n",
    "            model.eval() # set the model to test mode\n",
    "            with torch.no_grad():\n",
    "                y_pre = model(X_val).view(-1)\n",
    "                \n",
    "            acc = accuracy(y_val, y_pre)\n",
    "            \n",
    "            curr_res = {\"depth\": depth, \"activation\":activation, \"neurons\":neurons, \"acc\":acc, \"num_epochs\":_num_epochs}\n",
    "            [results[key].append(val) for key, val in curr_res.items()]\n",
    "            \n",
    "print(f\"Grid evaluation took {time.time()-start_time} sec\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame.from_dict(results)\n",
    "df_results.to_csv(\"ex1_grid_search.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2: Impact of the optimizer\n",
    "\n",
    "Retrain the model by using different parameters of the optimizer, you can change its parameter in the cell initializing it, after the definition of your model.\n",
    "\n",
    "* Use different batch size from 10 to 400\n",
    "* Try different values of the learning rate (between 0.001 and 10), and see how these impact the trainig process. Do all network architectures react the same way to different learning rates?\n",
    "* Change the duration of the training by increasing the number of epochs\n",
    "* Try other optimizers, such as [Adam](https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam) or [RMSprop](https://pytorch.org/docs/stable/optim.html?highlight=rmsprop#torch.optim.RMSprop)\n",
    "\n",
    "**Note:** These changes may interact with your previous choices of architectures, and you may need to change them as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation, depth, neurons  = \"relu\", 2, 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_list = [int(x) for x in np.linspace(10, 400, 5)]\n",
    "lr_list = np.logspace(-3, 1, 5)\n",
    "optimizer_dict = {\"Adagrad\": torch.optim.Adagrad, \"Adam\": torch.optim.Adam, \"RMSprop\": torch.optim.RMSprop, \"SGD\": torch.optim.SGD}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with batch_size: 10, lr :0.001, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.2424\n",
      "Epoch [2/1000], Loss: 0.2389\n",
      "Epoch [3/1000], Loss: 0.2379\n",
      "Epoch [4/1000], Loss: 0.2373\n",
      "Epoch [5/1000], Loss: 0.2369\n",
      "Epoch [6/1000], Loss: 0.2367\n",
      "Epoch [7/1000], Loss: 0.2365\n",
      "Epoch [8/1000], Loss: 0.2363\n",
      "Epoch [9/1000], Loss: 0.2362\n",
      "Epoch [10/1000], Loss: 0.2360\n",
      "Epoch [11/1000], Loss: 0.2359\n",
      "Epoch [12/1000], Loss: 0.2358\n",
      "Epoch [13/1000], Loss: 0.2357\n",
      "Epoch [14/1000], Loss: 0.2357\n",
      "Epoch [15/1000], Loss: 0.2356\n",
      "Epoch [16/1000], Loss: 0.2355\n",
      "Epoch [17/1000], Loss: 0.2355\n",
      "Epoch [18/1000], Loss: 0.2354\n",
      "Epoch [19/1000], Loss: 0.2353\n",
      "Epoch [20/1000], Loss: 0.2353\n",
      "Epoch [21/1000], Loss: 0.2352\n",
      "Epoch [22/1000], Loss: 0.2352\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 62.00 %\n",
      "Training model with batch_size: 10, lr :0.001, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.2377\n",
      "Epoch [2/1000], Loss: 0.2316\n",
      "Epoch [3/1000], Loss: 0.2273\n",
      "Epoch [4/1000], Loss: 0.2209\n",
      "Epoch [5/1000], Loss: 0.2095\n",
      "Epoch [6/1000], Loss: 0.1956\n",
      "Epoch [7/1000], Loss: 0.1838\n",
      "Epoch [8/1000], Loss: 0.1734\n",
      "Epoch [9/1000], Loss: 0.1645\n",
      "Epoch [10/1000], Loss: 0.1539\n",
      "Epoch [11/1000], Loss: 0.1411\n",
      "Epoch [12/1000], Loss: 0.1298\n",
      "Epoch [13/1000], Loss: 0.1213\n",
      "Epoch [14/1000], Loss: 0.1106\n",
      "Epoch [15/1000], Loss: 0.1014\n",
      "Epoch [16/1000], Loss: 0.0912\n",
      "Epoch [17/1000], Loss: 0.0828\n",
      "Epoch [18/1000], Loss: 0.0737\n",
      "Epoch [19/1000], Loss: 0.0649\n",
      "Epoch [20/1000], Loss: 0.0576\n",
      "Epoch [21/1000], Loss: 0.0502\n",
      "Epoch [22/1000], Loss: 0.0453\n",
      "Epoch [23/1000], Loss: 0.0390\n",
      "Epoch [24/1000], Loss: 0.0333\n",
      "Epoch [25/1000], Loss: 0.0277\n",
      "Epoch [26/1000], Loss: 0.0217\n",
      "Epoch [27/1000], Loss: 0.0167\n",
      "Epoch [28/1000], Loss: 0.0137\n",
      "Epoch [29/1000], Loss: 0.0114\n",
      "Epoch [30/1000], Loss: 0.0096\n",
      "Epoch [31/1000], Loss: 0.0076\n",
      "Epoch [32/1000], Loss: 0.0064\n",
      "Epoch [33/1000], Loss: 0.0052\n",
      "Epoch [34/1000], Loss: 0.0043\n",
      "Epoch [35/1000], Loss: 0.0037\n",
      "Epoch [36/1000], Loss: 0.0028\n",
      "Epoch [37/1000], Loss: 0.0025\n",
      "Epoch [38/1000], Loss: 0.0026\n",
      "Epoch [39/1000], Loss: 0.0018\n",
      "Epoch [40/1000], Loss: 0.0018\n",
      "Epoch [41/1000], Loss: 0.0014\n",
      "Epoch [42/1000], Loss: 0.0012\n",
      "Epoch [43/1000], Loss: 0.0011\n",
      "Epoch [44/1000], Loss: 0.0009\n",
      "Epoch [45/1000], Loss: 0.0008\n",
      "Epoch [46/1000], Loss: 0.0012\n",
      "Epoch [47/1000], Loss: 0.0010\n",
      "Epoch [48/1000], Loss: 0.0005\n",
      "Epoch [49/1000], Loss: 0.0005\n",
      "Epoch [50/1000], Loss: 0.0005\n",
      "Epoch [51/1000], Loss: 0.0007\n",
      "Epoch [52/1000], Loss: 0.0010\n",
      "Epoch [53/1000], Loss: 0.0003\n",
      "Epoch [54/1000], Loss: 0.0004\n",
      "Epoch [55/1000], Loss: 0.0004\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 99.90 %\n",
      "Training model with batch_size: 10, lr :0.001, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.2343\n",
      "Epoch [2/1000], Loss: 0.2225\n",
      "Epoch [3/1000], Loss: 0.2075\n",
      "Epoch [4/1000], Loss: 0.1878\n",
      "Epoch [5/1000], Loss: 0.1676\n",
      "Epoch [6/1000], Loss: 0.1471\n",
      "Epoch [7/1000], Loss: 0.1217\n",
      "Epoch [8/1000], Loss: 0.0969\n",
      "Epoch [9/1000], Loss: 0.0779\n",
      "Epoch [10/1000], Loss: 0.0630\n",
      "Epoch [11/1000], Loss: 0.0501\n",
      "Epoch [12/1000], Loss: 0.0397\n",
      "Epoch [13/1000], Loss: 0.0309\n",
      "Epoch [14/1000], Loss: 0.0236\n",
      "Epoch [15/1000], Loss: 0.0180\n",
      "Epoch [16/1000], Loss: 0.0134\n",
      "Epoch [17/1000], Loss: 0.0099\n",
      "Epoch [18/1000], Loss: 0.0076\n",
      "Epoch [19/1000], Loss: 0.0056\n",
      "Epoch [20/1000], Loss: 0.0046\n",
      "Epoch [21/1000], Loss: 0.0034\n",
      "Epoch [22/1000], Loss: 0.0026\n",
      "Epoch [23/1000], Loss: 0.0021\n",
      "Epoch [24/1000], Loss: 0.0016\n",
      "Epoch [25/1000], Loss: 0.0013\n",
      "Epoch [26/1000], Loss: 0.0012\n",
      "Epoch [27/1000], Loss: 0.0009\n",
      "Epoch [28/1000], Loss: 0.0008\n",
      "Epoch [29/1000], Loss: 0.0006\n",
      "Epoch [30/1000], Loss: 0.0006\n",
      "Epoch [31/1000], Loss: 0.0005\n",
      "Epoch [32/1000], Loss: 0.0005\n",
      "Epoch [33/1000], Loss: 0.0004\n",
      "Epoch [34/1000], Loss: 0.0004\n",
      "Epoch [35/1000], Loss: 0.0003\n",
      "Epoch [36/1000], Loss: 0.0003\n",
      "Epoch [37/1000], Loss: 0.0003\n",
      "Epoch [38/1000], Loss: 0.0002\n",
      "Epoch [39/1000], Loss: 0.0002\n",
      "Epoch [40/1000], Loss: 0.0002\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 10, lr :0.001, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2504\n",
      "Epoch [2/1000], Loss: 0.2443\n",
      "Epoch [3/1000], Loss: 0.2412\n",
      "Epoch [4/1000], Loss: 0.2394\n",
      "Epoch [5/1000], Loss: 0.2383\n",
      "Epoch [6/1000], Loss: 0.2376\n",
      "Epoch [7/1000], Loss: 0.2371\n",
      "Epoch [8/1000], Loss: 0.2367\n",
      "Epoch [9/1000], Loss: 0.2365\n",
      "Epoch [10/1000], Loss: 0.2363\n",
      "Epoch [11/1000], Loss: 0.2362\n",
      "Epoch [12/1000], Loss: 0.2360\n",
      "Epoch [13/1000], Loss: 0.2359\n",
      "Epoch [14/1000], Loss: 0.2359\n",
      "Epoch [15/1000], Loss: 0.2358\n",
      "Epoch [16/1000], Loss: 0.2357\n",
      "Epoch [17/1000], Loss: 0.2356\n",
      "Epoch [18/1000], Loss: 0.2356\n",
      "Epoch [19/1000], Loss: 0.2355\n",
      "Epoch [20/1000], Loss: 0.2354\n",
      "Epoch [21/1000], Loss: 0.2354\n",
      "Epoch [22/1000], Loss: 0.2353\n",
      "Epoch [23/1000], Loss: 0.2353\n",
      "Epoch [24/1000], Loss: 0.2352\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 65.40 %\n",
      "Training model with batch_size: 10, lr :0.01, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.2372\n",
      "Epoch [2/1000], Loss: 0.2300\n",
      "Epoch [3/1000], Loss: 0.2235\n",
      "Epoch [4/1000], Loss: 0.2164\n",
      "Epoch [5/1000], Loss: 0.2093\n",
      "Epoch [6/1000], Loss: 0.2021\n",
      "Epoch [7/1000], Loss: 0.1951\n",
      "Epoch [8/1000], Loss: 0.1886\n",
      "Epoch [9/1000], Loss: 0.1823\n",
      "Epoch [10/1000], Loss: 0.1765\n",
      "Epoch [11/1000], Loss: 0.1710\n",
      "Epoch [12/1000], Loss: 0.1656\n",
      "Epoch [13/1000], Loss: 0.1605\n",
      "Epoch [14/1000], Loss: 0.1557\n",
      "Epoch [15/1000], Loss: 0.1509\n",
      "Epoch [16/1000], Loss: 0.1458\n",
      "Epoch [17/1000], Loss: 0.1413\n",
      "Epoch [18/1000], Loss: 0.1368\n",
      "Epoch [19/1000], Loss: 0.1321\n",
      "Epoch [20/1000], Loss: 0.1274\n",
      "Epoch [21/1000], Loss: 0.1232\n",
      "Epoch [22/1000], Loss: 0.1194\n",
      "Epoch [23/1000], Loss: 0.1157\n",
      "Epoch [24/1000], Loss: 0.1121\n",
      "Epoch [25/1000], Loss: 0.1085\n",
      "Epoch [26/1000], Loss: 0.1053\n",
      "Epoch [27/1000], Loss: 0.1022\n",
      "Epoch [28/1000], Loss: 0.0989\n",
      "Epoch [29/1000], Loss: 0.0948\n",
      "Epoch [30/1000], Loss: 0.0911\n",
      "Epoch [31/1000], Loss: 0.0879\n",
      "Epoch [32/1000], Loss: 0.0851\n",
      "Epoch [33/1000], Loss: 0.0821\n",
      "Epoch [34/1000], Loss: 0.0795\n",
      "Epoch [35/1000], Loss: 0.0770\n",
      "Epoch [36/1000], Loss: 0.0745\n",
      "Epoch [37/1000], Loss: 0.0722\n",
      "Epoch [38/1000], Loss: 0.0700\n",
      "Epoch [39/1000], Loss: 0.0678\n",
      "Epoch [40/1000], Loss: 0.0658\n",
      "Epoch [41/1000], Loss: 0.0638\n",
      "Epoch [42/1000], Loss: 0.0620\n",
      "Epoch [43/1000], Loss: 0.0602\n",
      "Epoch [44/1000], Loss: 0.0585\n",
      "Epoch [45/1000], Loss: 0.0569\n",
      "Epoch [46/1000], Loss: 0.0553\n",
      "Epoch [47/1000], Loss: 0.0537\n",
      "Epoch [48/1000], Loss: 0.0523\n",
      "Epoch [49/1000], Loss: 0.0509\n",
      "Epoch [50/1000], Loss: 0.0496\n",
      "Epoch [51/1000], Loss: 0.0483\n",
      "Epoch [52/1000], Loss: 0.0470\n",
      "Epoch [53/1000], Loss: 0.0459\n",
      "Epoch [54/1000], Loss: 0.0447\n",
      "Epoch [55/1000], Loss: 0.0436\n",
      "Epoch [56/1000], Loss: 0.0425\n",
      "Epoch [57/1000], Loss: 0.0415\n",
      "Epoch [58/1000], Loss: 0.0405\n",
      "Epoch [59/1000], Loss: 0.0396\n",
      "Epoch [60/1000], Loss: 0.0387\n",
      "Epoch [61/1000], Loss: 0.0378\n",
      "Epoch [62/1000], Loss: 0.0370\n",
      "Epoch [63/1000], Loss: 0.0362\n",
      "Epoch [64/1000], Loss: 0.0353\n",
      "Epoch [65/1000], Loss: 0.0346\n",
      "Epoch [66/1000], Loss: 0.0339\n",
      "Epoch [67/1000], Loss: 0.0331\n",
      "Epoch [68/1000], Loss: 0.0325\n",
      "Epoch [69/1000], Loss: 0.0318\n",
      "Epoch [70/1000], Loss: 0.0312\n",
      "Epoch [71/1000], Loss: 0.0306\n",
      "Epoch [72/1000], Loss: 0.0300\n",
      "Epoch [73/1000], Loss: 0.0294\n",
      "Epoch [74/1000], Loss: 0.0289\n",
      "Epoch [75/1000], Loss: 0.0284\n",
      "Epoch [76/1000], Loss: 0.0278\n",
      "Epoch [77/1000], Loss: 0.0273\n",
      "Epoch [78/1000], Loss: 0.0267\n",
      "Epoch [79/1000], Loss: 0.0263\n",
      "Epoch [80/1000], Loss: 0.0258\n",
      "Epoch [81/1000], Loss: 0.0254\n",
      "Epoch [82/1000], Loss: 0.0249\n",
      "Epoch [83/1000], Loss: 0.0244\n",
      "Epoch [84/1000], Loss: 0.0241\n",
      "Epoch [85/1000], Loss: 0.0236\n",
      "Epoch [86/1000], Loss: 0.0232\n",
      "Epoch [87/1000], Loss: 0.0229\n",
      "Epoch [88/1000], Loss: 0.0225\n",
      "Epoch [89/1000], Loss: 0.0221\n",
      "Epoch [90/1000], Loss: 0.0217\n",
      "Epoch [91/1000], Loss: 0.0213\n",
      "Epoch [92/1000], Loss: 0.0210\n",
      "Epoch [93/1000], Loss: 0.0206\n",
      "Epoch [94/1000], Loss: 0.0203\n",
      "Epoch [95/1000], Loss: 0.0199\n",
      "Epoch [96/1000], Loss: 0.0195\n",
      "Epoch [97/1000], Loss: 0.0193\n",
      "Epoch [98/1000], Loss: 0.0189\n",
      "Epoch [99/1000], Loss: 0.0186\n",
      "Epoch [100/1000], Loss: 0.0183\n",
      "Epoch [101/1000], Loss: 0.0180\n",
      "Epoch [102/1000], Loss: 0.0177\n",
      "Epoch [103/1000], Loss: 0.0173\n",
      "Epoch [104/1000], Loss: 0.0170\n",
      "Epoch [105/1000], Loss: 0.0167\n",
      "Epoch [106/1000], Loss: 0.0163\n",
      "Epoch [107/1000], Loss: 0.0160\n",
      "Epoch [108/1000], Loss: 0.0157\n",
      "Epoch [109/1000], Loss: 0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [110/1000], Loss: 0.0151\n",
      "Epoch [111/1000], Loss: 0.0149\n",
      "Epoch [112/1000], Loss: 0.0146\n",
      "Epoch [113/1000], Loss: 0.0144\n",
      "Epoch [114/1000], Loss: 0.0141\n",
      "Epoch [115/1000], Loss: 0.0139\n",
      "Epoch [116/1000], Loss: 0.0136\n",
      "Epoch [117/1000], Loss: 0.0134\n",
      "Epoch [118/1000], Loss: 0.0132\n",
      "Epoch [119/1000], Loss: 0.0130\n",
      "Epoch [120/1000], Loss: 0.0128\n",
      "Epoch [121/1000], Loss: 0.0126\n",
      "Epoch [122/1000], Loss: 0.0124\n",
      "Epoch [123/1000], Loss: 0.0122\n",
      "Epoch [124/1000], Loss: 0.0120\n",
      "Epoch [125/1000], Loss: 0.0119\n",
      "Epoch [126/1000], Loss: 0.0117\n",
      "Epoch [127/1000], Loss: 0.0115\n",
      "Epoch [128/1000], Loss: 0.0114\n",
      "Epoch [129/1000], Loss: 0.0112\n",
      "Epoch [130/1000], Loss: 0.0111\n",
      "Epoch [131/1000], Loss: 0.0109\n",
      "Epoch [132/1000], Loss: 0.0108\n",
      "Epoch [133/1000], Loss: 0.0106\n",
      "Epoch [134/1000], Loss: 0.0105\n",
      "Epoch [135/1000], Loss: 0.0104\n",
      "Epoch [136/1000], Loss: 0.0103\n",
      "Epoch [137/1000], Loss: 0.0101\n",
      "Epoch [138/1000], Loss: 0.0100\n",
      "Epoch [139/1000], Loss: 0.0099\n",
      "Epoch [140/1000], Loss: 0.0098\n",
      "Epoch [141/1000], Loss: 0.0097\n",
      "Epoch [142/1000], Loss: 0.0095\n",
      "Epoch [143/1000], Loss: 0.0094\n",
      "Epoch [144/1000], Loss: 0.0093\n",
      "Epoch [145/1000], Loss: 0.0092\n",
      "Epoch [146/1000], Loss: 0.0091\n",
      "Epoch [147/1000], Loss: 0.0090\n",
      "Epoch [148/1000], Loss: 0.0089\n",
      "Epoch [149/1000], Loss: 0.0088\n",
      "Epoch [150/1000], Loss: 0.0087\n",
      "Epoch [151/1000], Loss: 0.0087\n",
      "Epoch [152/1000], Loss: 0.0086\n",
      "Epoch [153/1000], Loss: 0.0085\n",
      "Epoch [154/1000], Loss: 0.0084\n",
      "Epoch [155/1000], Loss: 0.0083\n",
      "Epoch [156/1000], Loss: 0.0082\n",
      "Epoch [157/1000], Loss: 0.0081\n",
      "Epoch [158/1000], Loss: 0.0081\n",
      "Epoch [159/1000], Loss: 0.0080\n",
      "Epoch [160/1000], Loss: 0.0079\n",
      "Epoch [161/1000], Loss: 0.0078\n",
      "Epoch [162/1000], Loss: 0.0078\n",
      "Epoch [163/1000], Loss: 0.0077\n",
      "Epoch [164/1000], Loss: 0.0076\n",
      "Epoch [165/1000], Loss: 0.0076\n",
      "Epoch [166/1000], Loss: 0.0075\n",
      "Epoch [167/1000], Loss: 0.0074\n",
      "Epoch [168/1000], Loss: 0.0073\n",
      "Epoch [169/1000], Loss: 0.0073\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 10, lr :0.01, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.2214\n",
      "Epoch [2/1000], Loss: 0.1192\n",
      "Epoch [3/1000], Loss: 0.0164\n",
      "Epoch [4/1000], Loss: 0.0038\n",
      "Epoch [5/1000], Loss: 0.0015\n",
      "Epoch [6/1000], Loss: 0.0068\n",
      "Epoch [7/1000], Loss: 0.0052\n",
      "Epoch [8/1000], Loss: 0.0116\n",
      "Epoch [9/1000], Loss: 0.0030\n",
      "Epoch [10/1000], Loss: 0.0042\n",
      "Epoch [11/1000], Loss: 0.0036\n",
      "Epoch [12/1000], Loss: 0.0009\n",
      "Epoch [13/1000], Loss: 0.0005\n",
      "Epoch [14/1000], Loss: 0.0077\n",
      "Epoch [15/1000], Loss: 0.0073\n",
      "Epoch [16/1000], Loss: 0.0009\n",
      "Epoch [17/1000], Loss: 0.0003\n",
      "Epoch [18/1000], Loss: 0.0009\n",
      "Epoch [19/1000], Loss: 0.0003\n",
      "Epoch [20/1000], Loss: 0.0091\n",
      "Epoch [21/1000], Loss: 0.0343\n",
      "Epoch [22/1000], Loss: 0.0084\n",
      "Epoch [23/1000], Loss: 0.0076\n",
      "Epoch [24/1000], Loss: 0.0088\n",
      "Epoch [25/1000], Loss: 0.0236\n",
      "Epoch [26/1000], Loss: 0.0005\n",
      "Epoch [27/1000], Loss: 0.0000\n",
      "Epoch [28/1000], Loss: 0.0001\n",
      "Epoch [29/1000], Loss: 0.0002\n",
      "Epoch [30/1000], Loss: 0.0000\n",
      "Epoch [31/1000], Loss: 0.0000\n",
      "Epoch [32/1000], Loss: 0.0000\n",
      "Epoch [33/1000], Loss: 0.0000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 10, lr :0.01, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.1974\n",
      "Epoch [2/1000], Loss: 0.0455\n",
      "Epoch [3/1000], Loss: 0.0104\n",
      "Epoch [4/1000], Loss: 0.0097\n",
      "Epoch [5/1000], Loss: 0.0045\n",
      "Epoch [6/1000], Loss: 0.0072\n",
      "Epoch [7/1000], Loss: 0.0047\n",
      "Epoch [8/1000], Loss: 0.0052\n",
      "Epoch [9/1000], Loss: 0.0037\n",
      "Epoch [10/1000], Loss: 0.0042\n",
      "Epoch [11/1000], Loss: 0.0057\n",
      "Epoch [12/1000], Loss: 0.0015\n",
      "Epoch [13/1000], Loss: 0.0122\n",
      "Epoch [14/1000], Loss: 0.0008\n",
      "Epoch [15/1000], Loss: 0.0051\n",
      "Epoch [16/1000], Loss: 0.0040\n",
      "Epoch [17/1000], Loss: 0.0008\n",
      "Epoch [18/1000], Loss: 0.0046\n",
      "Epoch [19/1000], Loss: 0.0004\n",
      "Epoch [20/1000], Loss: 0.0099\n",
      "Epoch [21/1000], Loss: 0.0051\n",
      "Epoch [22/1000], Loss: 0.0070\n",
      "Epoch [23/1000], Loss: 0.0007\n",
      "Epoch [24/1000], Loss: 0.0032\n",
      "Epoch [25/1000], Loss: 0.0005\n",
      "Epoch [26/1000], Loss: 0.0049\n",
      "Epoch [27/1000], Loss: 0.0002\n",
      "Epoch [28/1000], Loss: 0.0063\n",
      "Epoch [29/1000], Loss: 0.0017\n",
      "Epoch [30/1000], Loss: 0.0067\n",
      "Epoch [31/1000], Loss: 0.0019\n",
      "Epoch [32/1000], Loss: 0.0049\n",
      "Epoch [33/1000], Loss: 0.0007\n",
      "Epoch [34/1000], Loss: 0.0062\n",
      "Epoch [35/1000], Loss: 0.0013\n",
      "Epoch [36/1000], Loss: 0.0010\n",
      "Epoch [37/1000], Loss: 0.0036\n",
      "Epoch [38/1000], Loss: 0.0023\n",
      "Epoch [39/1000], Loss: 0.0031\n",
      "Epoch [40/1000], Loss: 0.0016\n",
      "Epoch [41/1000], Loss: 0.0068\n",
      "Epoch [42/1000], Loss: 0.0052\n",
      "Epoch [43/1000], Loss: 0.0026\n",
      "Epoch [44/1000], Loss: 0.0003\n",
      "Epoch [45/1000], Loss: 0.0102\n",
      "Epoch [46/1000], Loss: 0.0003\n",
      "Epoch [47/1000], Loss: 0.0090\n",
      "Epoch [48/1000], Loss: 0.0009\n",
      "Epoch [49/1000], Loss: 0.0057\n",
      "Epoch [50/1000], Loss: 0.0024\n",
      "Epoch [51/1000], Loss: 0.0010\n",
      "Epoch [52/1000], Loss: 0.0021\n",
      "Epoch [53/1000], Loss: 0.0028\n",
      "Epoch [54/1000], Loss: 0.0011\n",
      "Epoch [55/1000], Loss: 0.0043\n",
      "Epoch [56/1000], Loss: 0.0026\n",
      "Epoch [57/1000], Loss: 0.0008\n",
      "Epoch [58/1000], Loss: 0.0079\n",
      "Epoch [59/1000], Loss: 0.0000\n",
      "Epoch [60/1000], Loss: 0.0023\n",
      "Epoch [61/1000], Loss: 0.0045\n",
      "Epoch [62/1000], Loss: 0.0009\n",
      "Epoch [63/1000], Loss: 0.0041\n",
      "Epoch [64/1000], Loss: 0.0043\n",
      "Epoch [65/1000], Loss: 0.0012\n",
      "Epoch [66/1000], Loss: 0.0078\n",
      "Epoch [67/1000], Loss: 0.0007\n",
      "Epoch [68/1000], Loss: 0.0004\n",
      "Epoch [69/1000], Loss: 0.0054\n",
      "Epoch [70/1000], Loss: 0.0000\n",
      "Epoch [71/1000], Loss: 0.0033\n",
      "Epoch [72/1000], Loss: 0.0003\n",
      "Epoch [73/1000], Loss: 0.0000\n",
      "Epoch [74/1000], Loss: 0.0043\n",
      "Epoch [75/1000], Loss: 0.0020\n",
      "Epoch [76/1000], Loss: 0.0000\n",
      "Epoch [77/1000], Loss: 0.0000\n",
      "Epoch [78/1000], Loss: 0.0038\n",
      "Epoch [79/1000], Loss: 0.0080\n",
      "Epoch [80/1000], Loss: 0.0006\n",
      "Epoch [81/1000], Loss: 0.0036\n",
      "Epoch [82/1000], Loss: 0.0003\n",
      "Epoch [83/1000], Loss: 0.0000\n",
      "Epoch [84/1000], Loss: 0.0015\n",
      "Epoch [85/1000], Loss: 0.0028\n",
      "Epoch [86/1000], Loss: 0.0066\n",
      "Epoch [87/1000], Loss: 0.0006\n",
      "Epoch [88/1000], Loss: 0.0001\n",
      "Epoch [89/1000], Loss: 0.0047\n",
      "Epoch [90/1000], Loss: 0.0005\n",
      "Epoch [91/1000], Loss: 0.0037\n",
      "Epoch [92/1000], Loss: 0.0006\n",
      "Epoch [93/1000], Loss: 0.0039\n",
      "Epoch [94/1000], Loss: 0.0020\n",
      "Epoch [95/1000], Loss: 0.0038\n",
      "Epoch [96/1000], Loss: 0.0002\n",
      "Epoch [97/1000], Loss: 0.0000\n",
      "Epoch [98/1000], Loss: 0.0017\n",
      "Epoch [99/1000], Loss: 0.0001\n",
      "Epoch [100/1000], Loss: 0.0000\n",
      "Epoch [101/1000], Loss: 0.0000\n",
      "Epoch [102/1000], Loss: 0.0035\n",
      "Epoch [103/1000], Loss: 0.0037\n",
      "Epoch [104/1000], Loss: 0.0002\n",
      "Epoch [105/1000], Loss: 0.0063\n",
      "Epoch [106/1000], Loss: 0.0006\n",
      "Epoch [107/1000], Loss: 0.0002\n",
      "Epoch [108/1000], Loss: 0.0024\n",
      "Epoch [109/1000], Loss: 0.0022\n",
      "Epoch [110/1000], Loss: 0.0003\n",
      "Epoch [111/1000], Loss: 0.0142\n",
      "Epoch [112/1000], Loss: 0.0022\n",
      "Epoch [113/1000], Loss: 0.0046\n",
      "Epoch [114/1000], Loss: 0.0015\n",
      "Epoch [115/1000], Loss: 0.0027\n",
      "Epoch [116/1000], Loss: 0.0021\n",
      "Epoch [117/1000], Loss: 0.0012\n",
      "Epoch [118/1000], Loss: 0.0011\n",
      "Epoch [119/1000], Loss: 0.0084\n",
      "Epoch [120/1000], Loss: 0.0006\n",
      "Epoch [121/1000], Loss: 0.0044\n",
      "Epoch [122/1000], Loss: 0.0010\n",
      "Epoch [123/1000], Loss: 0.0003\n",
      "Epoch [124/1000], Loss: 0.0054\n",
      "Epoch [125/1000], Loss: 0.0016\n",
      "Epoch [126/1000], Loss: 0.0060\n",
      "Epoch [127/1000], Loss: 0.0002\n",
      "Epoch [128/1000], Loss: 0.0023\n",
      "Epoch [129/1000], Loss: 0.0031\n",
      "Epoch [130/1000], Loss: 0.0010\n",
      "Epoch [131/1000], Loss: 0.0010\n",
      "Epoch [132/1000], Loss: 0.0009\n",
      "Epoch [133/1000], Loss: 0.0001\n",
      "Epoch [134/1000], Loss: 0.0000\n",
      "Epoch [135/1000], Loss: 0.0012\n",
      "Epoch [136/1000], Loss: 0.0049\n",
      "Epoch [137/1000], Loss: 0.0051\n",
      "Epoch [138/1000], Loss: 0.0027\n",
      "Epoch [139/1000], Loss: 0.0008\n",
      "Epoch [140/1000], Loss: 0.0026\n",
      "Epoch [141/1000], Loss: 0.0012\n",
      "Epoch [142/1000], Loss: 0.0021\n",
      "Epoch [143/1000], Loss: 0.0014\n",
      "Epoch [144/1000], Loss: 0.0000\n",
      "Epoch [145/1000], Loss: 0.0000\n",
      "Epoch [146/1000], Loss: 0.0023\n",
      "Epoch [147/1000], Loss: 0.0025\n",
      "Epoch [148/1000], Loss: 0.0058\n",
      "Epoch [149/1000], Loss: 0.0018\n",
      "Epoch [150/1000], Loss: 0.0018\n",
      "Epoch [151/1000], Loss: 0.0010\n",
      "Epoch [152/1000], Loss: 0.0052\n",
      "Epoch [153/1000], Loss: 0.0019\n",
      "Epoch [154/1000], Loss: 0.0002\n",
      "Epoch [155/1000], Loss: 0.0026\n",
      "Epoch [156/1000], Loss: 0.0022\n",
      "Epoch [157/1000], Loss: 0.0043\n",
      "Epoch [158/1000], Loss: 0.0000\n",
      "Epoch [159/1000], Loss: 0.0000\n",
      "Epoch [160/1000], Loss: 0.0000\n",
      "Epoch [161/1000], Loss: 0.0000\n",
      "Epoch [162/1000], Loss: 0.0014\n",
      "Epoch [163/1000], Loss: 0.0009\n",
      "Epoch [164/1000], Loss: 0.0000\n",
      "Epoch [165/1000], Loss: 0.0000\n",
      "Epoch [166/1000], Loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [167/1000], Loss: 0.0030\n",
      "Epoch [168/1000], Loss: 0.0007\n",
      "Epoch [169/1000], Loss: 0.0035\n",
      "Epoch [170/1000], Loss: 0.0038\n",
      "Epoch [171/1000], Loss: 0.0043\n",
      "Epoch [172/1000], Loss: 0.0006\n",
      "Epoch [173/1000], Loss: 0.0002\n",
      "Epoch [174/1000], Loss: 0.0000\n",
      "Epoch [175/1000], Loss: 0.0049\n",
      "Epoch [176/1000], Loss: 0.0044\n",
      "Epoch [177/1000], Loss: 0.0037\n",
      "Epoch [178/1000], Loss: 0.0003\n",
      "Epoch [179/1000], Loss: 0.0000\n",
      "Epoch [180/1000], Loss: 0.0000\n",
      "Epoch [181/1000], Loss: 0.0011\n",
      "Epoch [182/1000], Loss: 0.0075\n",
      "Epoch [183/1000], Loss: 0.0002\n",
      "Epoch [184/1000], Loss: 0.0000\n",
      "Epoch [185/1000], Loss: 0.0012\n",
      "Epoch [186/1000], Loss: 0.0007\n",
      "Epoch [187/1000], Loss: 0.0138\n",
      "Epoch [188/1000], Loss: 0.0026\n",
      "Epoch [189/1000], Loss: 0.0006\n",
      "Epoch [190/1000], Loss: 0.0000\n",
      "Epoch [191/1000], Loss: 0.0000\n",
      "Epoch [192/1000], Loss: 0.0000\n",
      "Epoch [193/1000], Loss: 0.0059\n",
      "Epoch [194/1000], Loss: 0.0015\n",
      "Epoch [195/1000], Loss: 0.0015\n",
      "Epoch [196/1000], Loss: 0.0019\n",
      "Epoch [197/1000], Loss: 0.0008\n",
      "Epoch [198/1000], Loss: 0.0062\n",
      "Epoch [199/1000], Loss: 0.0000\n",
      "Epoch [200/1000], Loss: 0.0000\n",
      "Epoch [201/1000], Loss: 0.0000\n",
      "Epoch [202/1000], Loss: 0.0000\n",
      "Epoch [203/1000], Loss: 0.0000\n",
      "Epoch [204/1000], Loss: 0.0050\n",
      "Epoch [205/1000], Loss: 0.0090\n",
      "Epoch [206/1000], Loss: 0.0012\n",
      "Epoch [207/1000], Loss: 0.0000\n",
      "Epoch [208/1000], Loss: 0.0000\n",
      "Epoch [209/1000], Loss: 0.0056\n",
      "Epoch [210/1000], Loss: 0.0000\n",
      "Epoch [211/1000], Loss: 0.0007\n",
      "Epoch [212/1000], Loss: 0.0000\n",
      "Epoch [213/1000], Loss: 0.0000\n",
      "Epoch [214/1000], Loss: 0.0000\n",
      "Epoch [215/1000], Loss: 0.0035\n",
      "Epoch [216/1000], Loss: 0.0020\n",
      "Epoch [217/1000], Loss: 0.0015\n",
      "Epoch [218/1000], Loss: 0.0005\n",
      "Epoch [219/1000], Loss: 0.0000\n",
      "Epoch [220/1000], Loss: 0.0000\n",
      "Epoch [221/1000], Loss: 0.0000\n",
      "Epoch [222/1000], Loss: 0.0015\n",
      "Epoch [223/1000], Loss: 0.0013\n",
      "Epoch [224/1000], Loss: 0.0021\n",
      "Epoch [225/1000], Loss: 0.0004\n",
      "Epoch [226/1000], Loss: 0.0000\n",
      "Epoch [227/1000], Loss: 0.0000\n",
      "Epoch [228/1000], Loss: 0.0000\n",
      "Epoch [229/1000], Loss: 0.0000\n",
      "Epoch [230/1000], Loss: 0.0002\n",
      "Epoch [231/1000], Loss: 0.0019\n",
      "Epoch [232/1000], Loss: 0.0075\n",
      "Epoch [233/1000], Loss: 0.0003\n",
      "Epoch [234/1000], Loss: 0.0000\n",
      "Epoch [235/1000], Loss: 0.0000\n",
      "Epoch [236/1000], Loss: 0.0000\n",
      "Epoch [237/1000], Loss: 0.0037\n",
      "Epoch [238/1000], Loss: 0.0000\n",
      "Epoch [239/1000], Loss: 0.0000\n",
      "Epoch [240/1000], Loss: 0.0003\n",
      "Epoch [241/1000], Loss: 0.0071\n",
      "Epoch [242/1000], Loss: 0.0015\n",
      "Epoch [243/1000], Loss: 0.0003\n",
      "Epoch [244/1000], Loss: 0.0003\n",
      "Epoch [245/1000], Loss: 0.0000\n",
      "Epoch [246/1000], Loss: 0.0000\n",
      "Epoch [247/1000], Loss: 0.0000\n",
      "Epoch [248/1000], Loss: 0.0026\n",
      "Epoch [249/1000], Loss: 0.0032\n",
      "Epoch [250/1000], Loss: 0.0010\n",
      "Epoch [251/1000], Loss: 0.0000\n",
      "Epoch [252/1000], Loss: 0.0000\n",
      "Epoch [253/1000], Loss: 0.0000\n",
      "Epoch [254/1000], Loss: 0.0000\n",
      "Epoch [255/1000], Loss: 0.0084\n",
      "Epoch [256/1000], Loss: 0.0010\n",
      "Epoch [257/1000], Loss: 0.0048\n",
      "Epoch [258/1000], Loss: 0.0038\n",
      "Epoch [259/1000], Loss: 0.0006\n",
      "Epoch [260/1000], Loss: 0.0009\n",
      "Epoch [261/1000], Loss: 0.0000\n",
      "Epoch [262/1000], Loss: 0.0000\n",
      "Epoch [263/1000], Loss: 0.0000\n",
      "Epoch [264/1000], Loss: 0.0000\n",
      "Epoch [265/1000], Loss: 0.0117\n",
      "Epoch [266/1000], Loss: 0.0018\n",
      "Epoch [267/1000], Loss: 0.0000\n",
      "Epoch [268/1000], Loss: 0.0002\n",
      "Epoch [269/1000], Loss: 0.0019\n",
      "Epoch [270/1000], Loss: 0.0021\n",
      "Epoch [271/1000], Loss: 0.0025\n",
      "Epoch [272/1000], Loss: 0.0089\n",
      "Epoch [273/1000], Loss: 0.0067\n",
      "Epoch [274/1000], Loss: 0.0014\n",
      "Epoch [275/1000], Loss: 0.0015\n",
      "Epoch [276/1000], Loss: 0.0009\n",
      "Epoch [277/1000], Loss: 0.0030\n",
      "Epoch [278/1000], Loss: 0.0004\n",
      "Epoch [279/1000], Loss: 0.0000\n",
      "Epoch [280/1000], Loss: 0.0000\n",
      "Epoch [281/1000], Loss: 0.0000\n",
      "Epoch [282/1000], Loss: 0.0000\n",
      "Epoch [283/1000], Loss: 0.0028\n",
      "Epoch [284/1000], Loss: 0.0091\n",
      "Epoch [285/1000], Loss: 0.0048\n",
      "Epoch [286/1000], Loss: 0.0009\n",
      "Epoch [287/1000], Loss: 0.0005\n",
      "Epoch [288/1000], Loss: 0.0089\n",
      "Epoch [289/1000], Loss: 0.0000\n",
      "Epoch [290/1000], Loss: 0.0000\n",
      "Epoch [291/1000], Loss: 0.0000\n",
      "Epoch [292/1000], Loss: 0.0017\n",
      "Epoch [293/1000], Loss: 0.0002\n",
      "Epoch [294/1000], Loss: 0.0000\n",
      "Epoch [295/1000], Loss: 0.0000\n",
      "Epoch [296/1000], Loss: 0.0003\n",
      "Epoch [297/1000], Loss: 0.0041\n",
      "Epoch [298/1000], Loss: 0.0033\n",
      "Epoch [299/1000], Loss: 0.0006\n",
      "Epoch [300/1000], Loss: 0.0007\n",
      "Epoch [301/1000], Loss: 0.0020\n",
      "Epoch [302/1000], Loss: 0.0040\n",
      "Epoch [303/1000], Loss: 0.0018\n",
      "Epoch [304/1000], Loss: 0.0021\n",
      "Epoch [305/1000], Loss: 0.0000\n",
      "Epoch [306/1000], Loss: 0.0000\n",
      "Epoch [307/1000], Loss: 0.0000\n",
      "Epoch [308/1000], Loss: 0.0000\n",
      "Epoch [309/1000], Loss: 0.0000\n",
      "Epoch [310/1000], Loss: 0.0030\n",
      "Epoch [311/1000], Loss: 0.0026\n",
      "Epoch [312/1000], Loss: 0.0002\n",
      "Epoch [313/1000], Loss: 0.0000\n",
      "Epoch [314/1000], Loss: 0.0000\n",
      "Epoch [315/1000], Loss: 0.0000\n",
      "Epoch [316/1000], Loss: 0.0000\n",
      "Epoch [317/1000], Loss: 0.0000\n",
      "Epoch [318/1000], Loss: 0.0000\n",
      "Epoch [319/1000], Loss: 0.0000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 99.90 %\n",
      "Training model with batch_size: 10, lr :0.01, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2442\n",
      "Epoch [2/1000], Loss: 0.2380\n",
      "Epoch [3/1000], Loss: 0.2371\n",
      "Epoch [4/1000], Loss: 0.2366\n",
      "Epoch [5/1000], Loss: 0.2361\n",
      "Epoch [6/1000], Loss: 0.2356\n",
      "Epoch [7/1000], Loss: 0.2352\n",
      "Epoch [8/1000], Loss: 0.2348\n",
      "Epoch [9/1000], Loss: 0.2346\n",
      "Epoch [10/1000], Loss: 0.2341\n",
      "Epoch [11/1000], Loss: 0.2337\n",
      "Epoch [12/1000], Loss: 0.2335\n",
      "Epoch [13/1000], Loss: 0.2329\n",
      "Epoch [14/1000], Loss: 0.2325\n",
      "Epoch [15/1000], Loss: 0.2324\n",
      "Epoch [16/1000], Loss: 0.2319\n",
      "Epoch [17/1000], Loss: 0.2315\n",
      "Epoch [18/1000], Loss: 0.2311\n",
      "Epoch [19/1000], Loss: 0.2308\n",
      "Epoch [20/1000], Loss: 0.2304\n",
      "Epoch [21/1000], Loss: 0.2300\n",
      "Epoch [22/1000], Loss: 0.2296\n",
      "Epoch [23/1000], Loss: 0.2292\n",
      "Epoch [24/1000], Loss: 0.2288\n",
      "Epoch [25/1000], Loss: 0.2281\n",
      "Epoch [26/1000], Loss: 0.2278\n",
      "Epoch [27/1000], Loss: 0.2272\n",
      "Epoch [28/1000], Loss: 0.2263\n",
      "Epoch [29/1000], Loss: 0.2260\n",
      "Epoch [30/1000], Loss: 0.2252\n",
      "Epoch [31/1000], Loss: 0.2246\n",
      "Epoch [32/1000], Loss: 0.2238\n",
      "Epoch [33/1000], Loss: 0.2228\n",
      "Epoch [34/1000], Loss: 0.2220\n",
      "Epoch [35/1000], Loss: 0.2210\n",
      "Epoch [36/1000], Loss: 0.2196\n",
      "Epoch [37/1000], Loss: 0.2186\n",
      "Epoch [38/1000], Loss: 0.2171\n",
      "Epoch [39/1000], Loss: 0.2155\n",
      "Epoch [40/1000], Loss: 0.2137\n",
      "Epoch [41/1000], Loss: 0.2119\n",
      "Epoch [42/1000], Loss: 0.2093\n",
      "Epoch [43/1000], Loss: 0.2069\n",
      "Epoch [44/1000], Loss: 0.2039\n",
      "Epoch [45/1000], Loss: 0.2005\n",
      "Epoch [46/1000], Loss: 0.1975\n",
      "Epoch [47/1000], Loss: 0.1934\n",
      "Epoch [48/1000], Loss: 0.1891\n",
      "Epoch [49/1000], Loss: 0.1843\n",
      "Epoch [50/1000], Loss: 0.1787\n",
      "Epoch [51/1000], Loss: 0.1739\n",
      "Epoch [52/1000], Loss: 0.1679\n",
      "Epoch [53/1000], Loss: 0.1617\n",
      "Epoch [54/1000], Loss: 0.1557\n",
      "Epoch [55/1000], Loss: 0.1493\n",
      "Epoch [56/1000], Loss: 0.1433\n",
      "Epoch [57/1000], Loss: 0.1365\n",
      "Epoch [58/1000], Loss: 0.1305\n",
      "Epoch [59/1000], Loss: 0.1248\n",
      "Epoch [60/1000], Loss: 0.1191\n",
      "Epoch [61/1000], Loss: 0.1139\n",
      "Epoch [62/1000], Loss: 0.1093\n",
      "Epoch [63/1000], Loss: 0.1044\n",
      "Epoch [64/1000], Loss: 0.1006\n",
      "Epoch [65/1000], Loss: 0.0975\n",
      "Epoch [66/1000], Loss: 0.0938\n",
      "Epoch [67/1000], Loss: 0.0910\n",
      "Epoch [68/1000], Loss: 0.0885\n",
      "Epoch [69/1000], Loss: 0.0857\n",
      "Epoch [70/1000], Loss: 0.0834\n",
      "Epoch [71/1000], Loss: 0.0813\n",
      "Epoch [72/1000], Loss: 0.0792\n",
      "Epoch [73/1000], Loss: 0.0772\n",
      "Epoch [74/1000], Loss: 0.0757\n",
      "Epoch [75/1000], Loss: 0.0741\n",
      "Epoch [76/1000], Loss: 0.0725\n",
      "Epoch [77/1000], Loss: 0.0709\n",
      "Epoch [78/1000], Loss: 0.0689\n",
      "Epoch [79/1000], Loss: 0.0676\n",
      "Epoch [80/1000], Loss: 0.0647\n",
      "Epoch [81/1000], Loss: 0.0639\n",
      "Epoch [82/1000], Loss: 0.0619\n",
      "Epoch [83/1000], Loss: 0.0604\n",
      "Epoch [84/1000], Loss: 0.0597\n",
      "Epoch [85/1000], Loss: 0.0583\n",
      "Epoch [86/1000], Loss: 0.0576\n",
      "Epoch [87/1000], Loss: 0.0561\n",
      "Epoch [88/1000], Loss: 0.0551\n",
      "Epoch [89/1000], Loss: 0.0544\n",
      "Epoch [90/1000], Loss: 0.0534\n",
      "Epoch [91/1000], Loss: 0.0524\n",
      "Epoch [92/1000], Loss: 0.0515\n",
      "Epoch [93/1000], Loss: 0.0507\n",
      "Epoch [94/1000], Loss: 0.0501\n",
      "Epoch [95/1000], Loss: 0.0485\n",
      "Epoch [96/1000], Loss: 0.0479\n",
      "Epoch [97/1000], Loss: 0.0466\n",
      "Epoch [98/1000], Loss: 0.0453\n",
      "Epoch [99/1000], Loss: 0.0446\n",
      "Epoch [100/1000], Loss: 0.0438\n",
      "Epoch [101/1000], Loss: 0.0427\n",
      "Epoch [102/1000], Loss: 0.0412\n",
      "Epoch [103/1000], Loss: 0.0406\n",
      "Epoch [104/1000], Loss: 0.0394\n",
      "Epoch [105/1000], Loss: 0.0388\n",
      "Epoch [106/1000], Loss: 0.0373\n",
      "Epoch [107/1000], Loss: 0.0359\n",
      "Epoch [108/1000], Loss: 0.0352\n",
      "Epoch [109/1000], Loss: 0.0341\n",
      "Epoch [110/1000], Loss: 0.0331\n",
      "Epoch [111/1000], Loss: 0.0319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [112/1000], Loss: 0.0309\n",
      "Epoch [113/1000], Loss: 0.0299\n",
      "Epoch [114/1000], Loss: 0.0295\n",
      "Epoch [115/1000], Loss: 0.0278\n",
      "Epoch [116/1000], Loss: 0.0271\n",
      "Epoch [117/1000], Loss: 0.0255\n",
      "Epoch [118/1000], Loss: 0.0250\n",
      "Epoch [119/1000], Loss: 0.0237\n",
      "Epoch [120/1000], Loss: 0.0232\n",
      "Epoch [121/1000], Loss: 0.0219\n",
      "Epoch [122/1000], Loss: 0.0212\n",
      "Epoch [123/1000], Loss: 0.0202\n",
      "Epoch [124/1000], Loss: 0.0195\n",
      "Epoch [125/1000], Loss: 0.0191\n",
      "Epoch [126/1000], Loss: 0.0180\n",
      "Epoch [127/1000], Loss: 0.0178\n",
      "Epoch [128/1000], Loss: 0.0173\n",
      "Epoch [129/1000], Loss: 0.0159\n",
      "Epoch [130/1000], Loss: 0.0155\n",
      "Epoch [131/1000], Loss: 0.0150\n",
      "Epoch [132/1000], Loss: 0.0144\n",
      "Epoch [133/1000], Loss: 0.0136\n",
      "Epoch [134/1000], Loss: 0.0130\n",
      "Epoch [135/1000], Loss: 0.0125\n",
      "Epoch [136/1000], Loss: 0.0122\n",
      "Epoch [137/1000], Loss: 0.0114\n",
      "Epoch [138/1000], Loss: 0.0108\n",
      "Epoch [139/1000], Loss: 0.0107\n",
      "Epoch [140/1000], Loss: 0.0102\n",
      "Epoch [141/1000], Loss: 0.0097\n",
      "Epoch [142/1000], Loss: 0.0092\n",
      "Epoch [143/1000], Loss: 0.0088\n",
      "Epoch [144/1000], Loss: 0.0085\n",
      "Epoch [145/1000], Loss: 0.0081\n",
      "Epoch [146/1000], Loss: 0.0079\n",
      "Epoch [147/1000], Loss: 0.0075\n",
      "Epoch [148/1000], Loss: 0.0072\n",
      "Epoch [149/1000], Loss: 0.0070\n",
      "Epoch [150/1000], Loss: 0.0069\n",
      "Epoch [151/1000], Loss: 0.0066\n",
      "Epoch [152/1000], Loss: 0.0064\n",
      "Epoch [153/1000], Loss: 0.0062\n",
      "Epoch [154/1000], Loss: 0.0061\n",
      "Epoch [155/1000], Loss: 0.0058\n",
      "Epoch [156/1000], Loss: 0.0056\n",
      "Epoch [157/1000], Loss: 0.0055\n",
      "Epoch [158/1000], Loss: 0.0053\n",
      "Epoch [159/1000], Loss: 0.0053\n",
      "Epoch [160/1000], Loss: 0.0051\n",
      "Epoch [161/1000], Loss: 0.0050\n",
      "Epoch [162/1000], Loss: 0.0048\n",
      "Epoch [163/1000], Loss: 0.0047\n",
      "Epoch [164/1000], Loss: 0.0046\n",
      "Epoch [165/1000], Loss: 0.0045\n",
      "Epoch [166/1000], Loss: 0.0044\n",
      "Epoch [167/1000], Loss: 0.0043\n",
      "Epoch [168/1000], Loss: 0.0042\n",
      "Epoch [169/1000], Loss: 0.0041\n",
      "Epoch [170/1000], Loss: 0.0040\n",
      "Epoch [171/1000], Loss: 0.0039\n",
      "Epoch [172/1000], Loss: 0.0038\n",
      "Epoch [173/1000], Loss: 0.0038\n",
      "Epoch [174/1000], Loss: 0.0037\n",
      "Epoch [175/1000], Loss: 0.0036\n",
      "Epoch [176/1000], Loss: 0.0035\n",
      "Epoch [177/1000], Loss: 0.0034\n",
      "Epoch [178/1000], Loss: 0.0033\n",
      "Epoch [179/1000], Loss: 0.0033\n",
      "Epoch [180/1000], Loss: 0.0032\n",
      "Epoch [181/1000], Loss: 0.0032\n",
      "Epoch [182/1000], Loss: 0.0032\n",
      "Epoch [183/1000], Loss: 0.0030\n",
      "Epoch [184/1000], Loss: 0.0030\n",
      "Epoch [185/1000], Loss: 0.0030\n",
      "Epoch [186/1000], Loss: 0.0029\n",
      "Epoch [187/1000], Loss: 0.0029\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 99.90 %\n",
      "Training model with batch_size: 10, lr :0.1, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.2173\n",
      "Epoch [2/1000], Loss: 0.1016\n",
      "Epoch [3/1000], Loss: 0.0480\n",
      "Epoch [4/1000], Loss: 0.0347\n",
      "Epoch [5/1000], Loss: 0.0265\n",
      "Epoch [6/1000], Loss: 0.0185\n",
      "Epoch [7/1000], Loss: 0.0125\n",
      "Epoch [8/1000], Loss: 0.0074\n",
      "Epoch [9/1000], Loss: 0.0047\n",
      "Epoch [10/1000], Loss: 0.0036\n",
      "Epoch [11/1000], Loss: 0.0029\n",
      "Epoch [12/1000], Loss: 0.0023\n",
      "Epoch [13/1000], Loss: 0.0020\n",
      "Epoch [14/1000], Loss: 0.0017\n",
      "Epoch [15/1000], Loss: 0.0015\n",
      "Epoch [16/1000], Loss: 0.0013\n",
      "Epoch [17/1000], Loss: 0.0012\n",
      "Epoch [18/1000], Loss: 0.0011\n",
      "Epoch [19/1000], Loss: 0.0010\n",
      "Epoch [20/1000], Loss: 0.0009\n",
      "Epoch [21/1000], Loss: 0.0008\n",
      "Epoch [22/1000], Loss: 0.0008\n",
      "Epoch [23/1000], Loss: 0.0007\n",
      "Epoch [24/1000], Loss: 0.0007\n",
      "Epoch [25/1000], Loss: 0.0007\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 10, lr :0.1, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.2576\n",
      "Epoch [2/1000], Loss: 0.2519\n",
      "Epoch [3/1000], Loss: 0.2520\n",
      "Epoch [4/1000], Loss: 0.2520\n",
      "Epoch [5/1000], Loss: 0.2514\n",
      "Epoch [6/1000], Loss: 0.2515\n",
      "Epoch [7/1000], Loss: 0.2518\n",
      "Epoch [8/1000], Loss: 0.2511\n",
      "Epoch [9/1000], Loss: 0.2529\n",
      "Epoch [10/1000], Loss: 0.2517\n",
      "Epoch [11/1000], Loss: 0.2528\n",
      "Epoch [12/1000], Loss: 0.2523\n",
      "Epoch [13/1000], Loss: 0.2520\n",
      "Epoch [14/1000], Loss: 0.2517\n",
      "Epoch [15/1000], Loss: 0.2520\n",
      "Epoch [16/1000], Loss: 0.2524\n",
      "Epoch [17/1000], Loss: 0.2540\n",
      "Epoch [18/1000], Loss: 0.2513\n",
      "Epoch [19/1000], Loss: 0.2519\n",
      "Epoch [20/1000], Loss: 0.2519\n",
      "Epoch [21/1000], Loss: 0.2526\n",
      "Epoch [22/1000], Loss: 0.2514\n",
      "Epoch [23/1000], Loss: 0.2528\n",
      "Epoch [24/1000], Loss: 0.2516\n",
      "Epoch [25/1000], Loss: 0.2521\n",
      "Epoch [26/1000], Loss: 0.2516\n",
      "Epoch [27/1000], Loss: 0.2523\n",
      "Epoch [28/1000], Loss: 0.2517\n",
      "Epoch [29/1000], Loss: 0.2513\n",
      "Epoch [30/1000], Loss: 0.2527\n",
      "Epoch [31/1000], Loss: 0.2518\n",
      "Epoch [32/1000], Loss: 0.2521\n",
      "Epoch [33/1000], Loss: 0.2520\n",
      "Epoch [34/1000], Loss: 0.2529\n",
      "Epoch [35/1000], Loss: 0.2518\n",
      "Epoch [36/1000], Loss: 0.2524\n",
      "Epoch [37/1000], Loss: 0.2519\n",
      "Epoch [38/1000], Loss: 0.2527\n",
      "Epoch [39/1000], Loss: 0.2526\n",
      "Epoch [40/1000], Loss: 0.2514\n",
      "Epoch [41/1000], Loss: 0.2529\n",
      "Epoch [42/1000], Loss: 0.2531\n",
      "Epoch [43/1000], Loss: 0.2515\n",
      "Epoch [44/1000], Loss: 0.2526\n",
      "Epoch [45/1000], Loss: 0.2525\n",
      "Epoch [46/1000], Loss: 0.2521\n",
      "Epoch [47/1000], Loss: 0.2525\n",
      "Epoch [48/1000], Loss: 0.2510\n",
      "Epoch [49/1000], Loss: 0.2510\n",
      "Epoch [50/1000], Loss: 0.2529\n",
      "Epoch [51/1000], Loss: 0.2509\n",
      "Epoch [52/1000], Loss: 0.2518\n",
      "Epoch [53/1000], Loss: 0.2518\n",
      "Epoch [54/1000], Loss: 0.2518\n",
      "Epoch [55/1000], Loss: 0.2528\n",
      "Epoch [56/1000], Loss: 0.2526\n",
      "Epoch [57/1000], Loss: 0.2518\n",
      "Epoch [58/1000], Loss: 0.2521\n",
      "Epoch [59/1000], Loss: 0.2522\n",
      "Epoch [60/1000], Loss: 0.2526\n",
      "Epoch [61/1000], Loss: 0.2512\n",
      "Epoch [62/1000], Loss: 0.2512\n",
      "Epoch [63/1000], Loss: 0.2513\n",
      "Epoch [64/1000], Loss: 0.2521\n",
      "Epoch [65/1000], Loss: 0.2516\n",
      "Epoch [66/1000], Loss: 0.2520\n",
      "Epoch [67/1000], Loss: 0.2526\n",
      "Epoch [68/1000], Loss: 0.2520\n",
      "Epoch [69/1000], Loss: 0.2520\n",
      "Epoch [70/1000], Loss: 0.2526\n",
      "Epoch [71/1000], Loss: 0.2510\n",
      "Epoch [72/1000], Loss: 0.2515\n",
      "Epoch [73/1000], Loss: 0.2523\n",
      "Epoch [74/1000], Loss: 0.2522\n",
      "Epoch [75/1000], Loss: 0.2519\n",
      "Epoch [76/1000], Loss: 0.2511\n",
      "Epoch [77/1000], Loss: 0.2527\n",
      "Epoch [78/1000], Loss: 0.2511\n",
      "Epoch [79/1000], Loss: 0.2517\n",
      "Epoch [80/1000], Loss: 0.2512\n",
      "Epoch [81/1000], Loss: 0.2517\n",
      "Epoch [82/1000], Loss: 0.2511\n",
      "Epoch [83/1000], Loss: 0.2523\n",
      "Epoch [84/1000], Loss: 0.2520\n",
      "Epoch [85/1000], Loss: 0.2517\n",
      "Epoch [86/1000], Loss: 0.2520\n",
      "Epoch [87/1000], Loss: 0.2519\n",
      "Epoch [88/1000], Loss: 0.2519\n",
      "Epoch [89/1000], Loss: 0.2517\n",
      "Epoch [90/1000], Loss: 0.2524\n",
      "Epoch [91/1000], Loss: 0.2518\n",
      "Epoch [92/1000], Loss: 0.2515\n",
      "Epoch [93/1000], Loss: 0.2514\n",
      "Epoch [94/1000], Loss: 0.2521\n",
      "Epoch [95/1000], Loss: 0.2524\n",
      "Epoch [96/1000], Loss: 0.2522\n",
      "Epoch [97/1000], Loss: 0.2521\n",
      "Epoch [98/1000], Loss: 0.2534\n",
      "Epoch [99/1000], Loss: 0.2524\n",
      "Epoch [100/1000], Loss: 0.2522\n",
      "Epoch [101/1000], Loss: 0.2533\n",
      "Epoch [102/1000], Loss: 0.2519\n",
      "Epoch [103/1000], Loss: 0.2521\n",
      "Epoch [104/1000], Loss: 0.2515\n",
      "Epoch [105/1000], Loss: 0.2516\n",
      "Epoch [106/1000], Loss: 0.2533\n",
      "Epoch [107/1000], Loss: 0.2514\n",
      "Epoch [108/1000], Loss: 0.2516\n",
      "Epoch [109/1000], Loss: 0.2518\n",
      "Epoch [110/1000], Loss: 0.2526\n",
      "Epoch [111/1000], Loss: 0.2517\n",
      "Epoch [112/1000], Loss: 0.2512\n",
      "Epoch [113/1000], Loss: 0.2513\n",
      "Epoch [114/1000], Loss: 0.2516\n",
      "Epoch [115/1000], Loss: 0.2518\n",
      "Epoch [116/1000], Loss: 0.2526\n",
      "Epoch [117/1000], Loss: 0.2523\n",
      "Epoch [118/1000], Loss: 0.2514\n",
      "Epoch [119/1000], Loss: 0.2525\n",
      "Epoch [120/1000], Loss: 0.2530\n",
      "Epoch [121/1000], Loss: 0.2534\n",
      "Epoch [122/1000], Loss: 0.2528\n",
      "Epoch [123/1000], Loss: 0.2524\n",
      "Epoch [124/1000], Loss: 0.2513\n",
      "Epoch [125/1000], Loss: 0.2518\n",
      "Epoch [126/1000], Loss: 0.2521\n",
      "Epoch [127/1000], Loss: 0.2515\n",
      "Epoch [128/1000], Loss: 0.2517\n",
      "Epoch [129/1000], Loss: 0.2513\n",
      "Epoch [130/1000], Loss: 0.2509\n",
      "Epoch [131/1000], Loss: 0.2522\n",
      "Epoch [132/1000], Loss: 0.2526\n",
      "Epoch [133/1000], Loss: 0.2515\n",
      "Epoch [134/1000], Loss: 0.2514\n",
      "Epoch [135/1000], Loss: 0.2522\n",
      "Epoch [136/1000], Loss: 0.2521\n",
      "Epoch [137/1000], Loss: 0.2532\n",
      "Epoch [138/1000], Loss: 0.2519\n",
      "Epoch [139/1000], Loss: 0.2509\n",
      "Epoch [140/1000], Loss: 0.2515\n",
      "Epoch [141/1000], Loss: 0.2511\n",
      "Epoch [142/1000], Loss: 0.2516\n",
      "Epoch [143/1000], Loss: 0.2518\n",
      "Epoch [144/1000], Loss: 0.2529\n",
      "Epoch [145/1000], Loss: 0.2534\n",
      "Epoch [146/1000], Loss: 0.2523\n",
      "Epoch [147/1000], Loss: 0.2517\n",
      "Epoch [148/1000], Loss: 0.2513\n",
      "Epoch [149/1000], Loss: 0.2517\n",
      "Epoch [150/1000], Loss: 0.2514\n",
      "Epoch [151/1000], Loss: 0.2521\n",
      "Epoch [152/1000], Loss: 0.2508\n",
      "Epoch [153/1000], Loss: 0.2521\n",
      "Epoch [154/1000], Loss: 0.2527\n",
      "Epoch [155/1000], Loss: 0.2511\n",
      "Epoch [156/1000], Loss: 0.2518\n",
      "Epoch [157/1000], Loss: 0.2517\n",
      "Epoch [158/1000], Loss: 0.2516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [159/1000], Loss: 0.2528\n",
      "Epoch [160/1000], Loss: 0.2522\n",
      "Epoch [161/1000], Loss: 0.2516\n",
      "Epoch [162/1000], Loss: 0.2525\n",
      "Epoch [163/1000], Loss: 0.2520\n",
      "Epoch [164/1000], Loss: 0.2518\n",
      "Epoch [165/1000], Loss: 0.2520\n",
      "Epoch [166/1000], Loss: 0.2518\n",
      "Epoch [167/1000], Loss: 0.2518\n",
      "Epoch [168/1000], Loss: 0.2520\n",
      "Epoch [169/1000], Loss: 0.2525\n",
      "Epoch [170/1000], Loss: 0.2518\n",
      "Epoch [171/1000], Loss: 0.2523\n",
      "Epoch [172/1000], Loss: 0.2519\n",
      "Epoch [173/1000], Loss: 0.2529\n",
      "Epoch [174/1000], Loss: 0.2521\n",
      "Epoch [175/1000], Loss: 0.2520\n",
      "Epoch [176/1000], Loss: 0.2524\n",
      "Epoch [177/1000], Loss: 0.2524\n",
      "Epoch [178/1000], Loss: 0.2523\n",
      "Epoch [179/1000], Loss: 0.2514\n",
      "Epoch [180/1000], Loss: 0.2515\n",
      "Epoch [181/1000], Loss: 0.2524\n",
      "Epoch [182/1000], Loss: 0.2526\n",
      "Epoch [183/1000], Loss: 0.2522\n",
      "Epoch [184/1000], Loss: 0.2525\n",
      "Epoch [185/1000], Loss: 0.2524\n",
      "Epoch [186/1000], Loss: 0.2515\n",
      "Epoch [187/1000], Loss: 0.2525\n",
      "Epoch [188/1000], Loss: 0.2515\n",
      "Epoch [189/1000], Loss: 0.2519\n",
      "Epoch [190/1000], Loss: 0.2516\n",
      "Epoch [191/1000], Loss: 0.2513\n",
      "Epoch [192/1000], Loss: 0.2516\n",
      "Epoch [193/1000], Loss: 0.2528\n",
      "Epoch [194/1000], Loss: 0.2517\n",
      "Epoch [195/1000], Loss: 0.2512\n",
      "Epoch [196/1000], Loss: 0.2529\n",
      "Epoch [197/1000], Loss: 0.2524\n",
      "Epoch [198/1000], Loss: 0.2518\n",
      "Epoch [199/1000], Loss: 0.2516\n",
      "Epoch [200/1000], Loss: 0.2525\n",
      "Epoch [201/1000], Loss: 0.2517\n",
      "Epoch [202/1000], Loss: 0.2516\n",
      "Epoch [203/1000], Loss: 0.2514\n",
      "Epoch [204/1000], Loss: 0.2520\n",
      "Epoch [205/1000], Loss: 0.2518\n",
      "Epoch [206/1000], Loss: 0.2526\n",
      "Epoch [207/1000], Loss: 0.2503\n",
      "Epoch [208/1000], Loss: 0.2516\n",
      "Epoch [209/1000], Loss: 0.2521\n",
      "Epoch [210/1000], Loss: 0.2516\n",
      "Epoch [211/1000], Loss: 0.2526\n",
      "Epoch [212/1000], Loss: 0.2520\n",
      "Epoch [213/1000], Loss: 0.2516\n",
      "Epoch [214/1000], Loss: 0.2518\n",
      "Epoch [215/1000], Loss: 0.2531\n",
      "Epoch [216/1000], Loss: 0.2518\n",
      "Epoch [217/1000], Loss: 0.2523\n",
      "Epoch [218/1000], Loss: 0.2514\n",
      "Epoch [219/1000], Loss: 0.2520\n",
      "Epoch [220/1000], Loss: 0.2519\n",
      "Epoch [221/1000], Loss: 0.2525\n",
      "Epoch [222/1000], Loss: 0.2515\n",
      "Epoch [223/1000], Loss: 0.2519\n",
      "Epoch [224/1000], Loss: 0.2520\n",
      "Epoch [225/1000], Loss: 0.2529\n",
      "Epoch [226/1000], Loss: 0.2519\n",
      "Epoch [227/1000], Loss: 0.2514\n",
      "Epoch [228/1000], Loss: 0.2525\n",
      "Epoch [229/1000], Loss: 0.2533\n",
      "Epoch [230/1000], Loss: 0.2524\n",
      "Epoch [231/1000], Loss: 0.2531\n",
      "Epoch [232/1000], Loss: 0.2520\n",
      "Epoch [233/1000], Loss: 0.2525\n",
      "Epoch [234/1000], Loss: 0.2514\n",
      "Epoch [235/1000], Loss: 0.2527\n",
      "Epoch [236/1000], Loss: 0.2520\n",
      "Epoch [237/1000], Loss: 0.2516\n",
      "Epoch [238/1000], Loss: 0.2516\n",
      "Epoch [239/1000], Loss: 0.2515\n",
      "Epoch [240/1000], Loss: 0.2513\n",
      "Epoch [241/1000], Loss: 0.2520\n",
      "Epoch [242/1000], Loss: 0.2519\n",
      "Epoch [243/1000], Loss: 0.2524\n",
      "Epoch [244/1000], Loss: 0.2526\n",
      "Epoch [245/1000], Loss: 0.2519\n",
      "Epoch [246/1000], Loss: 0.2520\n",
      "Epoch [247/1000], Loss: 0.2516\n",
      "Epoch [248/1000], Loss: 0.2516\n",
      "Epoch [249/1000], Loss: 0.2518\n",
      "Epoch [250/1000], Loss: 0.2531\n",
      "Epoch [251/1000], Loss: 0.2518\n",
      "Epoch [252/1000], Loss: 0.2522\n",
      "Epoch [253/1000], Loss: 0.2517\n",
      "Epoch [254/1000], Loss: 0.2526\n",
      "Epoch [255/1000], Loss: 0.2513\n",
      "Epoch [256/1000], Loss: 0.2525\n",
      "Epoch [257/1000], Loss: 0.2510\n",
      "Epoch [258/1000], Loss: 0.2515\n",
      "Epoch [259/1000], Loss: 0.2520\n",
      "Epoch [260/1000], Loss: 0.2515\n",
      "Epoch [261/1000], Loss: 0.2522\n",
      "Epoch [262/1000], Loss: 0.2519\n",
      "Epoch [263/1000], Loss: 0.2526\n",
      "Epoch [264/1000], Loss: 0.2518\n",
      "Epoch [265/1000], Loss: 0.2523\n",
      "Epoch [266/1000], Loss: 0.2524\n",
      "Epoch [267/1000], Loss: 0.2519\n",
      "Epoch [268/1000], Loss: 0.2532\n",
      "Epoch [269/1000], Loss: 0.2520\n",
      "Epoch [270/1000], Loss: 0.2518\n",
      "Epoch [271/1000], Loss: 0.2525\n",
      "Epoch [272/1000], Loss: 0.2520\n",
      "Epoch [273/1000], Loss: 0.2519\n",
      "Epoch [274/1000], Loss: 0.2519\n",
      "Epoch [275/1000], Loss: 0.2518\n",
      "Epoch [276/1000], Loss: 0.2511\n",
      "Epoch [277/1000], Loss: 0.2517\n",
      "Epoch [278/1000], Loss: 0.2524\n",
      "Epoch [279/1000], Loss: 0.2526\n",
      "Epoch [280/1000], Loss: 0.2542\n",
      "Epoch [281/1000], Loss: 0.2521\n",
      "Epoch [282/1000], Loss: 0.2521\n",
      "Epoch [283/1000], Loss: 0.2512\n",
      "Epoch [284/1000], Loss: 0.2516\n",
      "Epoch [285/1000], Loss: 0.2525\n",
      "Epoch [286/1000], Loss: 0.2520\n",
      "Epoch [287/1000], Loss: 0.2521\n",
      "Epoch [288/1000], Loss: 0.2515\n",
      "Epoch [289/1000], Loss: 0.2530\n",
      "Epoch [290/1000], Loss: 0.2527\n",
      "Epoch [291/1000], Loss: 0.2517\n",
      "Epoch [292/1000], Loss: 0.2515\n",
      "Epoch [293/1000], Loss: 0.2516\n",
      "Epoch [294/1000], Loss: 0.2521\n",
      "Epoch [295/1000], Loss: 0.2520\n",
      "Epoch [296/1000], Loss: 0.2519\n",
      "Epoch [297/1000], Loss: 0.2513\n",
      "Epoch [298/1000], Loss: 0.2517\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 10, lr :0.1, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.4999\n",
      "Epoch [2/1000], Loss: 0.5000\n",
      "Epoch [3/1000], Loss: 0.5000\n",
      "Epoch [4/1000], Loss: 0.5000\n",
      "Epoch [5/1000], Loss: 0.5000\n",
      "Epoch [6/1000], Loss: 0.5000\n",
      "Epoch [7/1000], Loss: 0.5000\n",
      "Epoch [8/1000], Loss: 0.5000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 10, lr :0.1, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2380\n",
      "Epoch [2/1000], Loss: 0.2343\n",
      "Epoch [3/1000], Loss: 0.2303\n",
      "Epoch [4/1000], Loss: 0.2243\n",
      "Epoch [5/1000], Loss: 0.2107\n",
      "Epoch [6/1000], Loss: 0.1939\n",
      "Epoch [7/1000], Loss: 0.1659\n",
      "Epoch [8/1000], Loss: 0.1159\n",
      "Epoch [9/1000], Loss: 0.0722\n",
      "Epoch [10/1000], Loss: 0.0469\n",
      "Epoch [11/1000], Loss: 0.0326\n",
      "Epoch [12/1000], Loss: 0.0148\n",
      "Epoch [13/1000], Loss: 0.0119\n",
      "Epoch [14/1000], Loss: 0.0060\n",
      "Epoch [15/1000], Loss: 0.0062\n",
      "Epoch [16/1000], Loss: 0.0033\n",
      "Epoch [17/1000], Loss: 0.0102\n",
      "Epoch [18/1000], Loss: 0.0021\n",
      "Epoch [19/1000], Loss: 0.0018\n",
      "Epoch [20/1000], Loss: 0.0016\n",
      "Epoch [21/1000], Loss: 0.0013\n",
      "Epoch [22/1000], Loss: 0.0012\n",
      "Epoch [23/1000], Loss: 0.0010\n",
      "Epoch [24/1000], Loss: 0.0010\n",
      "Epoch [25/1000], Loss: 0.0009\n",
      "Epoch [26/1000], Loss: 0.0009\n",
      "Epoch [27/1000], Loss: 0.0008\n",
      "Epoch [28/1000], Loss: 0.0007\n",
      "Epoch [29/1000], Loss: 0.0008\n",
      "Epoch [30/1000], Loss: 0.0007\n",
      "Epoch [31/1000], Loss: 0.0006\n",
      "Epoch [32/1000], Loss: 0.0006\n",
      "Epoch [33/1000], Loss: 0.0005\n",
      "Epoch [34/1000], Loss: 0.0005\n",
      "Epoch [35/1000], Loss: 0.0005\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 10, lr :1.0, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.4998\n",
      "Epoch [2/1000], Loss: 0.5000\n",
      "Epoch [3/1000], Loss: 0.5000\n",
      "Epoch [4/1000], Loss: 0.5000\n",
      "Epoch [5/1000], Loss: 0.5000\n",
      "Epoch [6/1000], Loss: 0.5000\n",
      "Epoch [7/1000], Loss: 0.5000\n",
      "Epoch [8/1000], Loss: 0.5000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 10, lr :1.0, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.4999\n",
      "Epoch [2/1000], Loss: 0.5000\n",
      "Epoch [3/1000], Loss: 0.5000\n",
      "Epoch [4/1000], Loss: 0.5000\n",
      "Epoch [5/1000], Loss: 0.5000\n",
      "Epoch [6/1000], Loss: 0.5000\n",
      "Epoch [7/1000], Loss: 0.5000\n",
      "Epoch [8/1000], Loss: 0.5000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 10, lr :1.0, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.5000\n",
      "Epoch [2/1000], Loss: 0.5000\n",
      "Epoch [3/1000], Loss: 0.5000\n",
      "Epoch [4/1000], Loss: 0.5000\n",
      "Epoch [5/1000], Loss: 0.5000\n",
      "Epoch [6/1000], Loss: 0.5000\n",
      "Epoch [7/1000], Loss: 0.5000\n",
      "Epoch [8/1000], Loss: 0.5000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 10, lr :1.0, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2353\n",
      "Epoch [2/1000], Loss: 0.1821\n",
      "Epoch [3/1000], Loss: 0.1598\n",
      "Epoch [4/1000], Loss: 0.1786\n",
      "Epoch [5/1000], Loss: 0.2078\n",
      "Epoch [6/1000], Loss: 0.1963\n",
      "Epoch [7/1000], Loss: 0.1766\n",
      "Epoch [8/1000], Loss: 0.1589\n",
      "Epoch [9/1000], Loss: 0.1767\n",
      "Epoch [10/1000], Loss: 0.1696\n",
      "Epoch [11/1000], Loss: 0.2265\n",
      "Epoch [12/1000], Loss: 0.2246\n",
      "Epoch [13/1000], Loss: 0.2222\n",
      "Epoch [14/1000], Loss: 0.2187\n",
      "Epoch [15/1000], Loss: 0.2176\n",
      "Epoch [16/1000], Loss: 0.2095\n",
      "Epoch [17/1000], Loss: 0.1865\n",
      "Epoch [18/1000], Loss: 0.1917\n",
      "Epoch [19/1000], Loss: 0.1848\n",
      "Epoch [20/1000], Loss: 0.1810\n",
      "Epoch [21/1000], Loss: 0.1855\n",
      "Epoch [22/1000], Loss: 0.1861\n",
      "Epoch [23/1000], Loss: 0.1845\n",
      "Epoch [24/1000], Loss: 0.1750\n",
      "Epoch [25/1000], Loss: 0.1631\n",
      "Epoch [26/1000], Loss: 0.1561\n",
      "Epoch [27/1000], Loss: 0.1561\n",
      "Epoch [28/1000], Loss: 0.1633\n",
      "Epoch [29/1000], Loss: 0.1888\n",
      "Epoch [30/1000], Loss: 0.1494\n",
      "Epoch [31/1000], Loss: 0.1455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/1000], Loss: 0.1383\n",
      "Epoch [33/1000], Loss: 0.2250\n",
      "Epoch [34/1000], Loss: 0.2217\n",
      "Epoch [35/1000], Loss: 0.1915\n",
      "Epoch [36/1000], Loss: 0.1809\n",
      "Epoch [37/1000], Loss: 0.1530\n",
      "Epoch [38/1000], Loss: 0.1474\n",
      "Epoch [39/1000], Loss: 0.1476\n",
      "Epoch [40/1000], Loss: 0.1429\n",
      "Epoch [41/1000], Loss: 0.1468\n",
      "Epoch [42/1000], Loss: 0.1498\n",
      "Epoch [43/1000], Loss: 0.1357\n",
      "Epoch [44/1000], Loss: 0.1333\n",
      "Epoch [45/1000], Loss: 0.1371\n",
      "Epoch [46/1000], Loss: 0.1386\n",
      "Epoch [47/1000], Loss: 0.1426\n",
      "Epoch [48/1000], Loss: 0.1907\n",
      "Epoch [49/1000], Loss: 0.2100\n",
      "Epoch [50/1000], Loss: 0.2077\n",
      "Epoch [51/1000], Loss: 0.2062\n",
      "Epoch [52/1000], Loss: 0.2058\n",
      "Epoch [53/1000], Loss: 0.2120\n",
      "Epoch [54/1000], Loss: 0.2088\n",
      "Epoch [55/1000], Loss: 0.2138\n",
      "Epoch [56/1000], Loss: 0.2070\n",
      "Epoch [57/1000], Loss: 0.2088\n",
      "Epoch [58/1000], Loss: 0.2125\n",
      "Epoch [59/1000], Loss: 0.2058\n",
      "Epoch [60/1000], Loss: 0.2078\n",
      "Epoch [61/1000], Loss: 0.2068\n",
      "Epoch [62/1000], Loss: 0.2098\n",
      "Epoch [63/1000], Loss: 0.2071\n",
      "Epoch [64/1000], Loss: 0.2079\n",
      "Epoch [65/1000], Loss: 0.2066\n",
      "Epoch [66/1000], Loss: 0.2105\n",
      "Epoch [67/1000], Loss: 0.2060\n",
      "Epoch [68/1000], Loss: 0.2073\n",
      "Epoch [69/1000], Loss: 0.2072\n",
      "Epoch [70/1000], Loss: 0.2297\n",
      "Epoch [71/1000], Loss: 0.2134\n",
      "Epoch [72/1000], Loss: 0.2106\n",
      "Epoch [73/1000], Loss: 0.2067\n",
      "Epoch [74/1000], Loss: 0.2054\n",
      "Epoch [75/1000], Loss: 0.2069\n",
      "Epoch [76/1000], Loss: 0.2077\n",
      "Epoch [77/1000], Loss: 0.2067\n",
      "Epoch [78/1000], Loss: 0.2074\n",
      "Epoch [79/1000], Loss: 0.2057\n",
      "Epoch [80/1000], Loss: 0.2052\n",
      "Epoch [81/1000], Loss: 0.2077\n",
      "Epoch [82/1000], Loss: 0.2071\n",
      "Epoch [83/1000], Loss: 0.2053\n",
      "Epoch [84/1000], Loss: 0.2079\n",
      "Epoch [85/1000], Loss: 0.2074\n",
      "Epoch [86/1000], Loss: 0.2088\n",
      "Epoch [87/1000], Loss: 0.2062\n",
      "Epoch [88/1000], Loss: 0.2057\n",
      "Epoch [89/1000], Loss: 0.2061\n",
      "Epoch [90/1000], Loss: 0.2066\n",
      "Epoch [91/1000], Loss: 0.2063\n",
      "Epoch [92/1000], Loss: 0.2053\n",
      "Epoch [93/1000], Loss: 0.2047\n",
      "Epoch [94/1000], Loss: 0.2056\n",
      "Epoch [95/1000], Loss: 0.2053\n",
      "Epoch [96/1000], Loss: 0.2049\n",
      "Epoch [97/1000], Loss: 0.2052\n",
      "Epoch [98/1000], Loss: 0.2050\n",
      "Epoch [99/1000], Loss: 0.2058\n",
      "Epoch [100/1000], Loss: 0.2059\n",
      "Epoch [101/1000], Loss: 0.2050\n",
      "Epoch [102/1000], Loss: 0.2073\n",
      "Epoch [103/1000], Loss: 0.2069\n",
      "Epoch [104/1000], Loss: 0.2056\n",
      "Epoch [105/1000], Loss: 0.2064\n",
      "Epoch [106/1000], Loss: 0.2069\n",
      "Epoch [107/1000], Loss: 0.2066\n",
      "Epoch [108/1000], Loss: 0.2067\n",
      "Epoch [109/1000], Loss: 0.2052\n",
      "Epoch [110/1000], Loss: 0.2119\n",
      "Epoch [111/1000], Loss: 0.2054\n",
      "Epoch [112/1000], Loss: 0.2056\n",
      "Epoch [113/1000], Loss: 0.2060\n",
      "Epoch [114/1000], Loss: 0.2048\n",
      "Epoch [115/1000], Loss: 0.2047\n",
      "Epoch [116/1000], Loss: 0.2049\n",
      "Epoch [117/1000], Loss: 0.2049\n",
      "Epoch [118/1000], Loss: 0.2043\n",
      "Epoch [119/1000], Loss: 0.2043\n",
      "Epoch [120/1000], Loss: 0.2044\n",
      "Epoch [121/1000], Loss: 0.2044\n",
      "Epoch [122/1000], Loss: 0.2042\n",
      "Epoch [123/1000], Loss: 0.2040\n",
      "Epoch [124/1000], Loss: 0.2044\n",
      "Epoch [125/1000], Loss: 0.2040\n",
      "Epoch [126/1000], Loss: 0.2077\n",
      "Epoch [127/1000], Loss: 0.2047\n",
      "Epoch [128/1000], Loss: 0.2060\n",
      "Epoch [129/1000], Loss: 0.2075\n",
      "Epoch [130/1000], Loss: 0.2070\n",
      "Epoch [131/1000], Loss: 0.2070\n",
      "Epoch [132/1000], Loss: 0.2066\n",
      "Epoch [133/1000], Loss: 0.2044\n",
      "Epoch [134/1000], Loss: 0.2043\n",
      "Epoch [135/1000], Loss: 0.2052\n",
      "Epoch [136/1000], Loss: 0.2050\n",
      "Epoch [137/1000], Loss: 0.2049\n",
      "Epoch [138/1000], Loss: 0.2050\n",
      "Epoch [139/1000], Loss: 0.2049\n",
      "Epoch [140/1000], Loss: 0.2054\n",
      "Epoch [141/1000], Loss: 0.2049\n",
      "Epoch [142/1000], Loss: 0.2048\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 65.70 %\n",
      "Training model with batch_size: 10, lr :10.0, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.4996\n",
      "Epoch [2/1000], Loss: 0.5000\n",
      "Epoch [3/1000], Loss: 0.5000\n",
      "Epoch [4/1000], Loss: 0.5000\n",
      "Epoch [5/1000], Loss: 0.5000\n",
      "Epoch [6/1000], Loss: 0.5000\n",
      "Epoch [7/1000], Loss: 0.5000\n",
      "Epoch [8/1000], Loss: 0.5000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 10, lr :10.0, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.5211\n",
      "Epoch [2/1000], Loss: 0.5223\n",
      "Epoch [3/1000], Loss: 0.5223\n",
      "Epoch [4/1000], Loss: 0.5223\n",
      "Epoch [5/1000], Loss: 0.5223\n",
      "Epoch [6/1000], Loss: 0.5223\n",
      "Epoch [7/1000], Loss: 0.5223\n",
      "Epoch [8/1000], Loss: 0.5223\n",
      "Epoch [9/1000], Loss: 0.5223\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 45.90 %\n",
      "Training model with batch_size: 10, lr :10.0, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.4996\n",
      "Epoch [2/1000], Loss: 0.5000\n",
      "Epoch [3/1000], Loss: 0.5000\n",
      "Epoch [4/1000], Loss: 0.5000\n",
      "Epoch [5/1000], Loss: 0.5000\n",
      "Epoch [6/1000], Loss: 0.5000\n",
      "Epoch [7/1000], Loss: 0.5000\n",
      "Epoch [8/1000], Loss: 0.5000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 10, lr :10.0, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.4987\n",
      "Epoch [2/1000], Loss: 0.4968\n",
      "Epoch [3/1000], Loss: 0.4963\n",
      "Epoch [4/1000], Loss: 0.5000\n",
      "Epoch [5/1000], Loss: 0.5000\n",
      "Epoch [6/1000], Loss: 0.5000\n",
      "Epoch [7/1000], Loss: 0.5000\n",
      "Epoch [8/1000], Loss: 0.5000\n",
      "Epoch [9/1000], Loss: 0.5000\n",
      "Epoch [10/1000], Loss: 0.5000\n",
      "Epoch [11/1000], Loss: 0.5000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 107, lr :0.001, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.2592\n",
      "Epoch [2/1000], Loss: 0.2530\n",
      "Epoch [3/1000], Loss: 0.2501\n",
      "Epoch [4/1000], Loss: 0.2477\n",
      "Epoch [5/1000], Loss: 0.2462\n",
      "Epoch [6/1000], Loss: 0.2450\n",
      "Epoch [7/1000], Loss: 0.2443\n",
      "Epoch [8/1000], Loss: 0.2434\n",
      "Epoch [9/1000], Loss: 0.2421\n",
      "Epoch [10/1000], Loss: 0.2420\n",
      "Epoch [11/1000], Loss: 0.2416\n",
      "Epoch [12/1000], Loss: 0.2415\n",
      "Epoch [13/1000], Loss: 0.2404\n",
      "Epoch [14/1000], Loss: 0.2403\n",
      "Epoch [15/1000], Loss: 0.2404\n",
      "Epoch [16/1000], Loss: 0.2405\n",
      "Epoch [17/1000], Loss: 0.2394\n",
      "Epoch [18/1000], Loss: 0.2395\n",
      "Epoch [19/1000], Loss: 0.2389\n",
      "Epoch [20/1000], Loss: 0.2391\n",
      "Epoch [21/1000], Loss: 0.2389\n",
      "Epoch [22/1000], Loss: 0.2386\n",
      "Epoch [23/1000], Loss: 0.2384\n",
      "Epoch [24/1000], Loss: 0.2385\n",
      "Epoch [25/1000], Loss: 0.2383\n",
      "Epoch [26/1000], Loss: 0.2387\n",
      "Epoch [27/1000], Loss: 0.2388\n",
      "Epoch [28/1000], Loss: 0.2383\n",
      "Epoch [29/1000], Loss: 0.2383\n",
      "Epoch [30/1000], Loss: 0.2379\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 66.90 %\n",
      "Training model with batch_size: 107, lr :0.001, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.2425\n",
      "Epoch [2/1000], Loss: 0.2387\n",
      "Epoch [3/1000], Loss: 0.2372\n",
      "Epoch [4/1000], Loss: 0.2364\n",
      "Epoch [5/1000], Loss: 0.2354\n",
      "Epoch [6/1000], Loss: 0.2328\n",
      "Epoch [7/1000], Loss: 0.2322\n",
      "Epoch [8/1000], Loss: 0.2308\n",
      "Epoch [9/1000], Loss: 0.2291\n",
      "Epoch [10/1000], Loss: 0.2276\n",
      "Epoch [11/1000], Loss: 0.2254\n",
      "Epoch [12/1000], Loss: 0.2234\n",
      "Epoch [13/1000], Loss: 0.2202\n",
      "Epoch [14/1000], Loss: 0.2174\n",
      "Epoch [15/1000], Loss: 0.2132\n",
      "Epoch [16/1000], Loss: 0.2087\n",
      "Epoch [17/1000], Loss: 0.2027\n",
      "Epoch [18/1000], Loss: 0.1935\n",
      "Epoch [19/1000], Loss: 0.1843\n",
      "Epoch [20/1000], Loss: 0.1742\n",
      "Epoch [21/1000], Loss: 0.1642\n",
      "Epoch [22/1000], Loss: 0.1539\n",
      "Epoch [23/1000], Loss: 0.1451\n",
      "Epoch [24/1000], Loss: 0.1364\n",
      "Epoch [25/1000], Loss: 0.1276\n",
      "Epoch [26/1000], Loss: 0.1187\n",
      "Epoch [27/1000], Loss: 0.1118\n",
      "Epoch [28/1000], Loss: 0.1042\n",
      "Epoch [29/1000], Loss: 0.0974\n",
      "Epoch [30/1000], Loss: 0.0907\n",
      "Epoch [31/1000], Loss: 0.0846\n",
      "Epoch [32/1000], Loss: 0.0785\n",
      "Epoch [33/1000], Loss: 0.0728\n",
      "Epoch [34/1000], Loss: 0.0677\n",
      "Epoch [35/1000], Loss: 0.0620\n",
      "Epoch [36/1000], Loss: 0.0576\n",
      "Epoch [37/1000], Loss: 0.0533\n",
      "Epoch [38/1000], Loss: 0.0496\n",
      "Epoch [39/1000], Loss: 0.0456\n",
      "Epoch [40/1000], Loss: 0.0422\n",
      "Epoch [41/1000], Loss: 0.0394\n",
      "Epoch [42/1000], Loss: 0.0358\n",
      "Epoch [43/1000], Loss: 0.0331\n",
      "Epoch [44/1000], Loss: 0.0302\n",
      "Epoch [45/1000], Loss: 0.0274\n",
      "Epoch [46/1000], Loss: 0.0252\n",
      "Epoch [47/1000], Loss: 0.0230\n",
      "Epoch [48/1000], Loss: 0.0214\n",
      "Epoch [49/1000], Loss: 0.0199\n",
      "Epoch [50/1000], Loss: 0.0183\n",
      "Epoch [51/1000], Loss: 0.0171\n",
      "Epoch [52/1000], Loss: 0.0157\n",
      "Epoch [53/1000], Loss: 0.0146\n",
      "Epoch [54/1000], Loss: 0.0135\n",
      "Epoch [55/1000], Loss: 0.0128\n",
      "Epoch [56/1000], Loss: 0.0120\n",
      "Epoch [57/1000], Loss: 0.0111\n",
      "Epoch [58/1000], Loss: 0.0106\n",
      "Epoch [59/1000], Loss: 0.0101\n",
      "Epoch [60/1000], Loss: 0.0091\n",
      "Epoch [61/1000], Loss: 0.0089\n",
      "Epoch [62/1000], Loss: 0.0081\n",
      "Epoch [63/1000], Loss: 0.0077\n",
      "Epoch [64/1000], Loss: 0.0073\n",
      "Epoch [65/1000], Loss: 0.0069\n",
      "Epoch [66/1000], Loss: 0.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/1000], Loss: 0.0061\n",
      "Epoch [68/1000], Loss: 0.0060\n",
      "Epoch [69/1000], Loss: 0.0057\n",
      "Epoch [70/1000], Loss: 0.0053\n",
      "Epoch [71/1000], Loss: 0.0051\n",
      "Epoch [72/1000], Loss: 0.0048\n",
      "Epoch [73/1000], Loss: 0.0045\n",
      "Epoch [74/1000], Loss: 0.0044\n",
      "Epoch [75/1000], Loss: 0.0042\n",
      "Epoch [76/1000], Loss: 0.0040\n",
      "Epoch [77/1000], Loss: 0.0039\n",
      "Epoch [78/1000], Loss: 0.0037\n",
      "Epoch [79/1000], Loss: 0.0035\n",
      "Epoch [80/1000], Loss: 0.0034\n",
      "Epoch [81/1000], Loss: 0.0032\n",
      "Epoch [82/1000], Loss: 0.0031\n",
      "Epoch [83/1000], Loss: 0.0030\n",
      "Epoch [84/1000], Loss: 0.0029\n",
      "Epoch [85/1000], Loss: 0.0028\n",
      "Epoch [86/1000], Loss: 0.0027\n",
      "Epoch [87/1000], Loss: 0.0026\n",
      "Epoch [88/1000], Loss: 0.0025\n",
      "Epoch [89/1000], Loss: 0.0024\n",
      "Epoch [90/1000], Loss: 0.0023\n",
      "Epoch [91/1000], Loss: 0.0022\n",
      "Epoch [92/1000], Loss: 0.0021\n",
      "Epoch [93/1000], Loss: 0.0020\n",
      "Epoch [94/1000], Loss: 0.0020\n",
      "Epoch [95/1000], Loss: 0.0019\n",
      "Epoch [96/1000], Loss: 0.0019\n",
      "Epoch [97/1000], Loss: 0.0018\n",
      "Epoch [98/1000], Loss: 0.0018\n",
      "Epoch [99/1000], Loss: 0.0017\n",
      "Epoch [100/1000], Loss: 0.0016\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 107, lr :0.001, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.2430\n",
      "Epoch [2/1000], Loss: 0.2385\n",
      "Epoch [3/1000], Loss: 0.2372\n",
      "Epoch [4/1000], Loss: 0.2353\n",
      "Epoch [5/1000], Loss: 0.2336\n",
      "Epoch [6/1000], Loss: 0.2319\n",
      "Epoch [7/1000], Loss: 0.2291\n",
      "Epoch [8/1000], Loss: 0.2269\n",
      "Epoch [9/1000], Loss: 0.2247\n",
      "Epoch [10/1000], Loss: 0.2215\n",
      "Epoch [11/1000], Loss: 0.2177\n",
      "Epoch [12/1000], Loss: 0.2147\n",
      "Epoch [13/1000], Loss: 0.2114\n",
      "Epoch [14/1000], Loss: 0.2068\n",
      "Epoch [15/1000], Loss: 0.2023\n",
      "Epoch [16/1000], Loss: 0.1983\n",
      "Epoch [17/1000], Loss: 0.1937\n",
      "Epoch [18/1000], Loss: 0.1896\n",
      "Epoch [19/1000], Loss: 0.1850\n",
      "Epoch [20/1000], Loss: 0.1806\n",
      "Epoch [21/1000], Loss: 0.1763\n",
      "Epoch [22/1000], Loss: 0.1719\n",
      "Epoch [23/1000], Loss: 0.1672\n",
      "Epoch [24/1000], Loss: 0.1623\n",
      "Epoch [25/1000], Loss: 0.1577\n",
      "Epoch [26/1000], Loss: 0.1535\n",
      "Epoch [27/1000], Loss: 0.1489\n",
      "Epoch [28/1000], Loss: 0.1436\n",
      "Epoch [29/1000], Loss: 0.1394\n",
      "Epoch [30/1000], Loss: 0.1342\n",
      "Epoch [31/1000], Loss: 0.1291\n",
      "Epoch [32/1000], Loss: 0.1247\n",
      "Epoch [33/1000], Loss: 0.1208\n",
      "Epoch [34/1000], Loss: 0.1158\n",
      "Epoch [35/1000], Loss: 0.1118\n",
      "Epoch [36/1000], Loss: 0.1069\n",
      "Epoch [37/1000], Loss: 0.1029\n",
      "Epoch [38/1000], Loss: 0.0981\n",
      "Epoch [39/1000], Loss: 0.0937\n",
      "Epoch [40/1000], Loss: 0.0897\n",
      "Epoch [41/1000], Loss: 0.0857\n",
      "Epoch [42/1000], Loss: 0.0814\n",
      "Epoch [43/1000], Loss: 0.0771\n",
      "Epoch [44/1000], Loss: 0.0738\n",
      "Epoch [45/1000], Loss: 0.0695\n",
      "Epoch [46/1000], Loss: 0.0658\n",
      "Epoch [47/1000], Loss: 0.0624\n",
      "Epoch [48/1000], Loss: 0.0590\n",
      "Epoch [49/1000], Loss: 0.0556\n",
      "Epoch [50/1000], Loss: 0.0525\n",
      "Epoch [51/1000], Loss: 0.0495\n",
      "Epoch [52/1000], Loss: 0.0467\n",
      "Epoch [53/1000], Loss: 0.0433\n",
      "Epoch [54/1000], Loss: 0.0408\n",
      "Epoch [55/1000], Loss: 0.0383\n",
      "Epoch [56/1000], Loss: 0.0353\n",
      "Epoch [57/1000], Loss: 0.0331\n",
      "Epoch [58/1000], Loss: 0.0305\n",
      "Epoch [59/1000], Loss: 0.0281\n",
      "Epoch [60/1000], Loss: 0.0259\n",
      "Epoch [61/1000], Loss: 0.0241\n",
      "Epoch [62/1000], Loss: 0.0222\n",
      "Epoch [63/1000], Loss: 0.0204\n",
      "Epoch [64/1000], Loss: 0.0186\n",
      "Epoch [65/1000], Loss: 0.0171\n",
      "Epoch [66/1000], Loss: 0.0156\n",
      "Epoch [67/1000], Loss: 0.0143\n",
      "Epoch [68/1000], Loss: 0.0128\n",
      "Epoch [69/1000], Loss: 0.0118\n",
      "Epoch [70/1000], Loss: 0.0105\n",
      "Epoch [71/1000], Loss: 0.0098\n",
      "Epoch [72/1000], Loss: 0.0087\n",
      "Epoch [73/1000], Loss: 0.0079\n",
      "Epoch [74/1000], Loss: 0.0073\n",
      "Epoch [75/1000], Loss: 0.0066\n",
      "Epoch [76/1000], Loss: 0.0060\n",
      "Epoch [77/1000], Loss: 0.0054\n",
      "Epoch [78/1000], Loss: 0.0049\n",
      "Epoch [79/1000], Loss: 0.0045\n",
      "Epoch [80/1000], Loss: 0.0042\n",
      "Epoch [81/1000], Loss: 0.0037\n",
      "Epoch [82/1000], Loss: 0.0032\n",
      "Epoch [83/1000], Loss: 0.0030\n",
      "Epoch [84/1000], Loss: 0.0029\n",
      "Epoch [85/1000], Loss: 0.0025\n",
      "Epoch [86/1000], Loss: 0.0023\n",
      "Epoch [87/1000], Loss: 0.0021\n",
      "Epoch [88/1000], Loss: 0.0020\n",
      "Epoch [89/1000], Loss: 0.0018\n",
      "Epoch [90/1000], Loss: 0.0017\n",
      "Epoch [91/1000], Loss: 0.0016\n",
      "Epoch [92/1000], Loss: 0.0014\n",
      "Epoch [93/1000], Loss: 0.0015\n",
      "Epoch [94/1000], Loss: 0.0012\n",
      "Epoch [95/1000], Loss: 0.0011\n",
      "Epoch [96/1000], Loss: 0.0011\n",
      "Epoch [97/1000], Loss: 0.0010\n",
      "Epoch [98/1000], Loss: 0.0009\n",
      "Epoch [99/1000], Loss: 0.0010\n",
      "Epoch [100/1000], Loss: 0.0008\n",
      "Epoch [101/1000], Loss: 0.0008\n",
      "Epoch [102/1000], Loss: 0.0007\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 107, lr :0.001, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2480\n",
      "Epoch [2/1000], Loss: 0.2474\n",
      "Epoch [3/1000], Loss: 0.2472\n",
      "Epoch [4/1000], Loss: 0.2471\n",
      "Epoch [5/1000], Loss: 0.2470\n",
      "Epoch [6/1000], Loss: 0.2465\n",
      "Epoch [7/1000], Loss: 0.2465\n",
      "Epoch [8/1000], Loss: 0.2460\n",
      "Epoch [9/1000], Loss: 0.2462\n",
      "Epoch [10/1000], Loss: 0.2458\n",
      "Epoch [11/1000], Loss: 0.2457\n",
      "Epoch [12/1000], Loss: 0.2456\n",
      "Epoch [13/1000], Loss: 0.2457\n",
      "Epoch [14/1000], Loss: 0.2453\n",
      "Epoch [15/1000], Loss: 0.2451\n",
      "Epoch [16/1000], Loss: 0.2450\n",
      "Epoch [17/1000], Loss: 0.2448\n",
      "Epoch [18/1000], Loss: 0.2448\n",
      "Epoch [19/1000], Loss: 0.2449\n",
      "Epoch [20/1000], Loss: 0.2449\n",
      "Epoch [21/1000], Loss: 0.2447\n",
      "Epoch [22/1000], Loss: 0.2443\n",
      "Epoch [23/1000], Loss: 0.2444\n",
      "Epoch [24/1000], Loss: 0.2443\n",
      "Epoch [25/1000], Loss: 0.2442\n",
      "Epoch [26/1000], Loss: 0.2441\n",
      "Epoch [27/1000], Loss: 0.2441\n",
      "Epoch [28/1000], Loss: 0.2441\n",
      "Epoch [29/1000], Loss: 0.2441\n",
      "Epoch [30/1000], Loss: 0.2437\n",
      "Epoch [31/1000], Loss: 0.2441\n",
      "Epoch [32/1000], Loss: 0.2438\n",
      "Epoch [33/1000], Loss: 0.2436\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 58.90 %\n",
      "Training model with batch_size: 107, lr :0.01, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.2437\n",
      "Epoch [2/1000], Loss: 0.2381\n",
      "Epoch [3/1000], Loss: 0.2363\n",
      "Epoch [4/1000], Loss: 0.2350\n",
      "Epoch [5/1000], Loss: 0.2341\n",
      "Epoch [6/1000], Loss: 0.2328\n",
      "Epoch [7/1000], Loss: 0.2312\n",
      "Epoch [8/1000], Loss: 0.2298\n",
      "Epoch [9/1000], Loss: 0.2281\n",
      "Epoch [10/1000], Loss: 0.2265\n",
      "Epoch [11/1000], Loss: 0.2247\n",
      "Epoch [12/1000], Loss: 0.2234\n",
      "Epoch [13/1000], Loss: 0.2216\n",
      "Epoch [14/1000], Loss: 0.2195\n",
      "Epoch [15/1000], Loss: 0.2183\n",
      "Epoch [16/1000], Loss: 0.2168\n",
      "Epoch [17/1000], Loss: 0.2151\n",
      "Epoch [18/1000], Loss: 0.2137\n",
      "Epoch [19/1000], Loss: 0.2118\n",
      "Epoch [20/1000], Loss: 0.2111\n",
      "Epoch [21/1000], Loss: 0.2092\n",
      "Epoch [22/1000], Loss: 0.2074\n",
      "Epoch [23/1000], Loss: 0.2059\n",
      "Epoch [24/1000], Loss: 0.2048\n",
      "Epoch [25/1000], Loss: 0.2024\n",
      "Epoch [26/1000], Loss: 0.2008\n",
      "Epoch [27/1000], Loss: 0.2000\n",
      "Epoch [28/1000], Loss: 0.1976\n",
      "Epoch [29/1000], Loss: 0.1959\n",
      "Epoch [30/1000], Loss: 0.1945\n",
      "Epoch [31/1000], Loss: 0.1927\n",
      "Epoch [32/1000], Loss: 0.1909\n",
      "Epoch [33/1000], Loss: 0.1895\n",
      "Epoch [34/1000], Loss: 0.1877\n",
      "Epoch [35/1000], Loss: 0.1862\n",
      "Epoch [36/1000], Loss: 0.1840\n",
      "Epoch [37/1000], Loss: 0.1821\n",
      "Epoch [38/1000], Loss: 0.1801\n",
      "Epoch [39/1000], Loss: 0.1780\n",
      "Epoch [40/1000], Loss: 0.1765\n",
      "Epoch [41/1000], Loss: 0.1736\n",
      "Epoch [42/1000], Loss: 0.1719\n",
      "Epoch [43/1000], Loss: 0.1698\n",
      "Epoch [44/1000], Loss: 0.1676\n",
      "Epoch [45/1000], Loss: 0.1657\n",
      "Epoch [46/1000], Loss: 0.1641\n",
      "Epoch [47/1000], Loss: 0.1616\n",
      "Epoch [48/1000], Loss: 0.1591\n",
      "Epoch [49/1000], Loss: 0.1573\n",
      "Epoch [50/1000], Loss: 0.1545\n",
      "Epoch [51/1000], Loss: 0.1520\n",
      "Epoch [52/1000], Loss: 0.1485\n",
      "Epoch [53/1000], Loss: 0.1450\n",
      "Epoch [54/1000], Loss: 0.1418\n",
      "Epoch [55/1000], Loss: 0.1398\n",
      "Epoch [56/1000], Loss: 0.1379\n",
      "Epoch [57/1000], Loss: 0.1355\n",
      "Epoch [58/1000], Loss: 0.1332\n",
      "Epoch [59/1000], Loss: 0.1312\n",
      "Epoch [60/1000], Loss: 0.1286\n",
      "Epoch [61/1000], Loss: 0.1273\n",
      "Epoch [62/1000], Loss: 0.1250\n",
      "Epoch [63/1000], Loss: 0.1226\n",
      "Epoch [64/1000], Loss: 0.1211\n",
      "Epoch [65/1000], Loss: 0.1193\n",
      "Epoch [66/1000], Loss: 0.1168\n",
      "Epoch [67/1000], Loss: 0.1149\n",
      "Epoch [68/1000], Loss: 0.1130\n",
      "Epoch [69/1000], Loss: 0.1111\n",
      "Epoch [70/1000], Loss: 0.1095\n",
      "Epoch [71/1000], Loss: 0.1077\n",
      "Epoch [72/1000], Loss: 0.1060\n",
      "Epoch [73/1000], Loss: 0.1041\n",
      "Epoch [74/1000], Loss: 0.1027\n",
      "Epoch [75/1000], Loss: 0.1008\n",
      "Epoch [76/1000], Loss: 0.0994\n",
      "Epoch [77/1000], Loss: 0.0980\n",
      "Epoch [78/1000], Loss: 0.0962\n",
      "Epoch [79/1000], Loss: 0.0949\n",
      "Epoch [80/1000], Loss: 0.0931\n",
      "Epoch [81/1000], Loss: 0.0917\n",
      "Epoch [82/1000], Loss: 0.0904\n",
      "Epoch [83/1000], Loss: 0.0887\n",
      "Epoch [84/1000], Loss: 0.0876\n",
      "Epoch [85/1000], Loss: 0.0861\n",
      "Epoch [86/1000], Loss: 0.0851\n",
      "Epoch [87/1000], Loss: 0.0840\n",
      "Epoch [88/1000], Loss: 0.0828\n",
      "Epoch [89/1000], Loss: 0.0814\n",
      "Epoch [90/1000], Loss: 0.0802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/1000], Loss: 0.0797\n",
      "Epoch [92/1000], Loss: 0.0779\n",
      "Epoch [93/1000], Loss: 0.0772\n",
      "Epoch [94/1000], Loss: 0.0758\n",
      "Epoch [95/1000], Loss: 0.0753\n",
      "Epoch [96/1000], Loss: 0.0738\n",
      "Epoch [97/1000], Loss: 0.0735\n",
      "Epoch [98/1000], Loss: 0.0719\n",
      "Epoch [99/1000], Loss: 0.0713\n",
      "Epoch [100/1000], Loss: 0.0703\n",
      "Epoch [101/1000], Loss: 0.0690\n",
      "Epoch [102/1000], Loss: 0.0677\n",
      "Epoch [103/1000], Loss: 0.0665\n",
      "Epoch [104/1000], Loss: 0.0659\n",
      "Epoch [105/1000], Loss: 0.0653\n",
      "Epoch [106/1000], Loss: 0.0641\n",
      "Epoch [107/1000], Loss: 0.0633\n",
      "Epoch [108/1000], Loss: 0.0624\n",
      "Epoch [109/1000], Loss: 0.0620\n",
      "Epoch [110/1000], Loss: 0.0612\n",
      "Epoch [111/1000], Loss: 0.0603\n",
      "Epoch [112/1000], Loss: 0.0595\n",
      "Epoch [113/1000], Loss: 0.0594\n",
      "Epoch [114/1000], Loss: 0.0584\n",
      "Epoch [115/1000], Loss: 0.0573\n",
      "Epoch [116/1000], Loss: 0.0568\n",
      "Epoch [117/1000], Loss: 0.0558\n",
      "Epoch [118/1000], Loss: 0.0558\n",
      "Epoch [119/1000], Loss: 0.0545\n",
      "Epoch [120/1000], Loss: 0.0540\n",
      "Epoch [121/1000], Loss: 0.0533\n",
      "Epoch [122/1000], Loss: 0.0529\n",
      "Epoch [123/1000], Loss: 0.0521\n",
      "Epoch [124/1000], Loss: 0.0514\n",
      "Epoch [125/1000], Loss: 0.0509\n",
      "Epoch [126/1000], Loss: 0.0502\n",
      "Epoch [127/1000], Loss: 0.0500\n",
      "Epoch [128/1000], Loss: 0.0494\n",
      "Epoch [129/1000], Loss: 0.0489\n",
      "Epoch [130/1000], Loss: 0.0481\n",
      "Epoch [131/1000], Loss: 0.0483\n",
      "Epoch [132/1000], Loss: 0.0472\n",
      "Epoch [133/1000], Loss: 0.0466\n",
      "Epoch [134/1000], Loss: 0.0462\n",
      "Epoch [135/1000], Loss: 0.0458\n",
      "Epoch [136/1000], Loss: 0.0450\n",
      "Epoch [137/1000], Loss: 0.0449\n",
      "Epoch [138/1000], Loss: 0.0442\n",
      "Epoch [139/1000], Loss: 0.0436\n",
      "Epoch [140/1000], Loss: 0.0434\n",
      "Epoch [141/1000], Loss: 0.0427\n",
      "Epoch [142/1000], Loss: 0.0422\n",
      "Epoch [143/1000], Loss: 0.0420\n",
      "Epoch [144/1000], Loss: 0.0418\n",
      "Epoch [145/1000], Loss: 0.0411\n",
      "Epoch [146/1000], Loss: 0.0405\n",
      "Epoch [147/1000], Loss: 0.0403\n",
      "Epoch [148/1000], Loss: 0.0397\n",
      "Epoch [149/1000], Loss: 0.0394\n",
      "Epoch [150/1000], Loss: 0.0393\n",
      "Epoch [151/1000], Loss: 0.0389\n",
      "Epoch [152/1000], Loss: 0.0381\n",
      "Epoch [153/1000], Loss: 0.0377\n",
      "Epoch [154/1000], Loss: 0.0374\n",
      "Epoch [155/1000], Loss: 0.0370\n",
      "Epoch [156/1000], Loss: 0.0366\n",
      "Epoch [157/1000], Loss: 0.0360\n",
      "Epoch [158/1000], Loss: 0.0360\n",
      "Epoch [159/1000], Loss: 0.0354\n",
      "Epoch [160/1000], Loss: 0.0350\n",
      "Epoch [161/1000], Loss: 0.0348\n",
      "Epoch [162/1000], Loss: 0.0343\n",
      "Epoch [163/1000], Loss: 0.0340\n",
      "Epoch [164/1000], Loss: 0.0340\n",
      "Epoch [165/1000], Loss: 0.0335\n",
      "Epoch [166/1000], Loss: 0.0332\n",
      "Epoch [167/1000], Loss: 0.0330\n",
      "Epoch [168/1000], Loss: 0.0325\n",
      "Epoch [169/1000], Loss: 0.0321\n",
      "Epoch [170/1000], Loss: 0.0319\n",
      "Epoch [171/1000], Loss: 0.0314\n",
      "Epoch [172/1000], Loss: 0.0312\n",
      "Epoch [173/1000], Loss: 0.0309\n",
      "Epoch [174/1000], Loss: 0.0307\n",
      "Epoch [175/1000], Loss: 0.0303\n",
      "Epoch [176/1000], Loss: 0.0300\n",
      "Epoch [177/1000], Loss: 0.0299\n",
      "Epoch [178/1000], Loss: 0.0294\n",
      "Epoch [179/1000], Loss: 0.0290\n",
      "Epoch [180/1000], Loss: 0.0287\n",
      "Epoch [181/1000], Loss: 0.0284\n",
      "Epoch [182/1000], Loss: 0.0281\n",
      "Epoch [183/1000], Loss: 0.0275\n",
      "Epoch [184/1000], Loss: 0.0274\n",
      "Epoch [185/1000], Loss: 0.0271\n",
      "Epoch [186/1000], Loss: 0.0268\n",
      "Epoch [187/1000], Loss: 0.0268\n",
      "Epoch [188/1000], Loss: 0.0263\n",
      "Epoch [189/1000], Loss: 0.0259\n",
      "Epoch [190/1000], Loss: 0.0256\n",
      "Epoch [191/1000], Loss: 0.0256\n",
      "Epoch [192/1000], Loss: 0.0251\n",
      "Epoch [193/1000], Loss: 0.0248\n",
      "Epoch [194/1000], Loss: 0.0246\n",
      "Epoch [195/1000], Loss: 0.0242\n",
      "Epoch [196/1000], Loss: 0.0240\n",
      "Epoch [197/1000], Loss: 0.0236\n",
      "Epoch [198/1000], Loss: 0.0234\n",
      "Epoch [199/1000], Loss: 0.0231\n",
      "Epoch [200/1000], Loss: 0.0228\n",
      "Epoch [201/1000], Loss: 0.0229\n",
      "Epoch [202/1000], Loss: 0.0222\n",
      "Epoch [203/1000], Loss: 0.0221\n",
      "Epoch [204/1000], Loss: 0.0219\n",
      "Epoch [205/1000], Loss: 0.0215\n",
      "Epoch [206/1000], Loss: 0.0214\n",
      "Epoch [207/1000], Loss: 0.0214\n",
      "Epoch [208/1000], Loss: 0.0212\n",
      "Epoch [209/1000], Loss: 0.0208\n",
      "Epoch [210/1000], Loss: 0.0206\n",
      "Epoch [211/1000], Loss: 0.0203\n",
      "Epoch [212/1000], Loss: 0.0200\n",
      "Epoch [213/1000], Loss: 0.0199\n",
      "Epoch [214/1000], Loss: 0.0198\n",
      "Epoch [215/1000], Loss: 0.0195\n",
      "Epoch [216/1000], Loss: 0.0192\n",
      "Epoch [217/1000], Loss: 0.0191\n",
      "Epoch [218/1000], Loss: 0.0188\n",
      "Epoch [219/1000], Loss: 0.0188\n",
      "Epoch [220/1000], Loss: 0.0187\n",
      "Epoch [221/1000], Loss: 0.0186\n",
      "Epoch [222/1000], Loss: 0.0183\n",
      "Epoch [223/1000], Loss: 0.0180\n",
      "Epoch [224/1000], Loss: 0.0178\n",
      "Epoch [225/1000], Loss: 0.0177\n",
      "Epoch [226/1000], Loss: 0.0175\n",
      "Epoch [227/1000], Loss: 0.0175\n",
      "Epoch [228/1000], Loss: 0.0175\n",
      "Epoch [229/1000], Loss: 0.0170\n",
      "Epoch [230/1000], Loss: 0.0168\n",
      "Epoch [231/1000], Loss: 0.0168\n",
      "Epoch [232/1000], Loss: 0.0166\n",
      "Epoch [233/1000], Loss: 0.0165\n",
      "Epoch [234/1000], Loss: 0.0164\n",
      "Epoch [235/1000], Loss: 0.0162\n",
      "Epoch [236/1000], Loss: 0.0161\n",
      "Epoch [237/1000], Loss: 0.0158\n",
      "Epoch [238/1000], Loss: 0.0156\n",
      "Epoch [239/1000], Loss: 0.0156\n",
      "Epoch [240/1000], Loss: 0.0154\n",
      "Epoch [241/1000], Loss: 0.0153\n",
      "Epoch [242/1000], Loss: 0.0151\n",
      "Epoch [243/1000], Loss: 0.0150\n",
      "Epoch [244/1000], Loss: 0.0148\n",
      "Epoch [245/1000], Loss: 0.0148\n",
      "Epoch [246/1000], Loss: 0.0146\n",
      "Epoch [247/1000], Loss: 0.0144\n",
      "Epoch [248/1000], Loss: 0.0143\n",
      "Epoch [249/1000], Loss: 0.0143\n",
      "Epoch [250/1000], Loss: 0.0141\n",
      "Epoch [251/1000], Loss: 0.0139\n",
      "Epoch [252/1000], Loss: 0.0139\n",
      "Epoch [253/1000], Loss: 0.0139\n",
      "Epoch [254/1000], Loss: 0.0136\n",
      "Epoch [255/1000], Loss: 0.0136\n",
      "Epoch [256/1000], Loss: 0.0134\n",
      "Epoch [257/1000], Loss: 0.0132\n",
      "Epoch [258/1000], Loss: 0.0133\n",
      "Epoch [259/1000], Loss: 0.0132\n",
      "Epoch [260/1000], Loss: 0.0131\n",
      "Epoch [261/1000], Loss: 0.0129\n",
      "Epoch [262/1000], Loss: 0.0127\n",
      "Epoch [263/1000], Loss: 0.0126\n",
      "Epoch [264/1000], Loss: 0.0125\n",
      "Epoch [265/1000], Loss: 0.0125\n",
      "Epoch [266/1000], Loss: 0.0124\n",
      "Epoch [267/1000], Loss: 0.0122\n",
      "Epoch [268/1000], Loss: 0.0121\n",
      "Epoch [269/1000], Loss: 0.0122\n",
      "Epoch [270/1000], Loss: 0.0120\n",
      "Epoch [271/1000], Loss: 0.0119\n",
      "Epoch [272/1000], Loss: 0.0119\n",
      "Epoch [273/1000], Loss: 0.0117\n",
      "Epoch [274/1000], Loss: 0.0116\n",
      "Epoch [275/1000], Loss: 0.0115\n",
      "Epoch [276/1000], Loss: 0.0115\n",
      "Epoch [277/1000], Loss: 0.0113\n",
      "Epoch [278/1000], Loss: 0.0113\n",
      "Epoch [279/1000], Loss: 0.0112\n",
      "Epoch [280/1000], Loss: 0.0111\n",
      "Epoch [281/1000], Loss: 0.0112\n",
      "Epoch [282/1000], Loss: 0.0109\n",
      "Epoch [283/1000], Loss: 0.0109\n",
      "Epoch [284/1000], Loss: 0.0108\n",
      "Epoch [285/1000], Loss: 0.0107\n",
      "Epoch [286/1000], Loss: 0.0107\n",
      "Epoch [287/1000], Loss: 0.0107\n",
      "Epoch [288/1000], Loss: 0.0105\n",
      "Epoch [289/1000], Loss: 0.0103\n",
      "Epoch [290/1000], Loss: 0.0103\n",
      "Epoch [291/1000], Loss: 0.0104\n",
      "Epoch [292/1000], Loss: 0.0102\n",
      "Epoch [293/1000], Loss: 0.0101\n",
      "Epoch [294/1000], Loss: 0.0101\n",
      "Epoch [295/1000], Loss: 0.0100\n",
      "Epoch [296/1000], Loss: 0.0099\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 99.90 %\n",
      "Training model with batch_size: 107, lr :0.01, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.2417\n",
      "Epoch [2/1000], Loss: 0.2337\n",
      "Epoch [3/1000], Loss: 0.2145\n",
      "Epoch [4/1000], Loss: 0.1717\n",
      "Epoch [5/1000], Loss: 0.1010\n",
      "Epoch [6/1000], Loss: 0.0321\n",
      "Epoch [7/1000], Loss: 0.0100\n",
      "Epoch [8/1000], Loss: 0.0053\n",
      "Epoch [9/1000], Loss: 0.0037\n",
      "Epoch [10/1000], Loss: 0.0029\n",
      "Epoch [11/1000], Loss: 0.0021\n",
      "Epoch [12/1000], Loss: 0.0016\n",
      "Epoch [13/1000], Loss: 0.0014\n",
      "Epoch [14/1000], Loss: 0.0012\n",
      "Epoch [15/1000], Loss: 0.0010\n",
      "Epoch [16/1000], Loss: 0.0009\n",
      "Epoch [17/1000], Loss: 0.0007\n",
      "Epoch [18/1000], Loss: 0.0006\n",
      "Epoch [19/1000], Loss: 0.0005\n",
      "Epoch [20/1000], Loss: 0.0005\n",
      "Epoch [21/1000], Loss: 0.0007\n",
      "Epoch [22/1000], Loss: 0.0004\n",
      "Epoch [23/1000], Loss: 0.0004\n",
      "Epoch [24/1000], Loss: 0.0003\n",
      "Epoch [25/1000], Loss: 0.0003\n",
      "Epoch [26/1000], Loss: 0.0003\n",
      "Epoch [27/1000], Loss: 0.0002\n",
      "Epoch [28/1000], Loss: 0.0002\n",
      "Epoch [29/1000], Loss: 0.0002\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 107, lr :0.01, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.2516\n",
      "Epoch [2/1000], Loss: 0.2272\n",
      "Epoch [3/1000], Loss: 0.1885\n",
      "Epoch [4/1000], Loss: 0.1352\n",
      "Epoch [5/1000], Loss: 0.0824\n",
      "Epoch [6/1000], Loss: 0.0446\n",
      "Epoch [7/1000], Loss: 0.0243\n",
      "Epoch [8/1000], Loss: 0.0125\n",
      "Epoch [9/1000], Loss: 0.0120\n",
      "Epoch [10/1000], Loss: 0.0054\n",
      "Epoch [11/1000], Loss: 0.0038\n",
      "Epoch [12/1000], Loss: 0.0028\n",
      "Epoch [13/1000], Loss: 0.0020\n",
      "Epoch [14/1000], Loss: 0.0014\n",
      "Epoch [15/1000], Loss: 0.0201\n",
      "Epoch [16/1000], Loss: 0.0015\n",
      "Epoch [17/1000], Loss: 0.0007\n",
      "Epoch [18/1000], Loss: 0.0006\n",
      "Epoch [19/1000], Loss: 0.0005\n",
      "Epoch [20/1000], Loss: 0.0005\n",
      "Epoch [21/1000], Loss: 0.0004\n",
      "Epoch [22/1000], Loss: 0.0219\n",
      "Epoch [23/1000], Loss: 0.0045\n",
      "Epoch [24/1000], Loss: 0.0006\n",
      "Epoch [25/1000], Loss: 0.0003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/1000], Loss: 0.0004\n",
      "Epoch [27/1000], Loss: 0.0003\n",
      "Epoch [28/1000], Loss: 0.0002\n",
      "Epoch [29/1000], Loss: 0.0002\n",
      "Epoch [30/1000], Loss: 0.0002\n",
      "Epoch [31/1000], Loss: 0.0197\n",
      "Epoch [32/1000], Loss: 0.0004\n",
      "Epoch [33/1000], Loss: 0.0003\n",
      "Epoch [34/1000], Loss: 0.0004\n",
      "Epoch [35/1000], Loss: 0.0002\n",
      "Epoch [36/1000], Loss: 0.0001\n",
      "Epoch [37/1000], Loss: 0.0001\n",
      "Epoch [38/1000], Loss: 0.0001\n",
      "Epoch [39/1000], Loss: 0.0003\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 107, lr :0.01, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2506\n",
      "Epoch [2/1000], Loss: 0.2491\n",
      "Epoch [3/1000], Loss: 0.2473\n",
      "Epoch [4/1000], Loss: 0.2461\n",
      "Epoch [5/1000], Loss: 0.2452\n",
      "Epoch [6/1000], Loss: 0.2444\n",
      "Epoch [7/1000], Loss: 0.2436\n",
      "Epoch [8/1000], Loss: 0.2430\n",
      "Epoch [9/1000], Loss: 0.2424\n",
      "Epoch [10/1000], Loss: 0.2422\n",
      "Epoch [11/1000], Loss: 0.2419\n",
      "Epoch [12/1000], Loss: 0.2417\n",
      "Epoch [13/1000], Loss: 0.2414\n",
      "Epoch [14/1000], Loss: 0.2413\n",
      "Epoch [15/1000], Loss: 0.2411\n",
      "Epoch [16/1000], Loss: 0.2412\n",
      "Epoch [17/1000], Loss: 0.2407\n",
      "Epoch [18/1000], Loss: 0.2408\n",
      "Epoch [19/1000], Loss: 0.2411\n",
      "Epoch [20/1000], Loss: 0.2407\n",
      "Epoch [21/1000], Loss: 0.2404\n",
      "Epoch [22/1000], Loss: 0.2406\n",
      "Epoch [23/1000], Loss: 0.2404\n",
      "Epoch [24/1000], Loss: 0.2404\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 61.40 %\n",
      "Training model with batch_size: 107, lr :0.1, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.2471\n",
      "Epoch [2/1000], Loss: 0.2116\n",
      "Epoch [3/1000], Loss: 0.1711\n",
      "Epoch [4/1000], Loss: 0.1287\n",
      "Epoch [5/1000], Loss: 0.0824\n",
      "Epoch [6/1000], Loss: 0.0455\n",
      "Epoch [7/1000], Loss: 0.0252\n",
      "Epoch [8/1000], Loss: 0.0146\n",
      "Epoch [9/1000], Loss: 0.0109\n",
      "Epoch [10/1000], Loss: 0.0082\n",
      "Epoch [11/1000], Loss: 0.0064\n",
      "Epoch [12/1000], Loss: 0.0052\n",
      "Epoch [13/1000], Loss: 0.0044\n",
      "Epoch [14/1000], Loss: 0.0039\n",
      "Epoch [15/1000], Loss: 0.0034\n",
      "Epoch [16/1000], Loss: 0.0031\n",
      "Epoch [17/1000], Loss: 0.0027\n",
      "Epoch [18/1000], Loss: 0.0025\n",
      "Epoch [19/1000], Loss: 0.0022\n",
      "Epoch [20/1000], Loss: 0.0021\n",
      "Epoch [21/1000], Loss: 0.0019\n",
      "Epoch [22/1000], Loss: 0.0018\n",
      "Epoch [23/1000], Loss: 0.0016\n",
      "Epoch [24/1000], Loss: 0.0015\n",
      "Epoch [25/1000], Loss: 0.0015\n",
      "Epoch [26/1000], Loss: 0.0014\n",
      "Epoch [27/1000], Loss: 0.0013\n",
      "Epoch [28/1000], Loss: 0.0012\n",
      "Epoch [29/1000], Loss: 0.0011\n",
      "Epoch [30/1000], Loss: 0.0011\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 107, lr :0.1, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.2435\n",
      "Epoch [2/1000], Loss: 0.2010\n",
      "Epoch [3/1000], Loss: 0.2056\n",
      "Epoch [4/1000], Loss: 0.2001\n",
      "Epoch [5/1000], Loss: 0.1932\n",
      "Epoch [6/1000], Loss: 0.1952\n",
      "Epoch [7/1000], Loss: 0.1805\n",
      "Epoch [8/1000], Loss: 0.1624\n",
      "Epoch [9/1000], Loss: 0.1313\n",
      "Epoch [10/1000], Loss: 0.1545\n",
      "Epoch [11/1000], Loss: 0.1300\n",
      "Epoch [12/1000], Loss: 0.1080\n",
      "Epoch [13/1000], Loss: 0.1003\n",
      "Epoch [14/1000], Loss: 0.0870\n",
      "Epoch [15/1000], Loss: 0.0820\n",
      "Epoch [16/1000], Loss: 0.1233\n",
      "Epoch [17/1000], Loss: 0.1161\n",
      "Epoch [18/1000], Loss: 0.1108\n",
      "Epoch [19/1000], Loss: 0.1371\n",
      "Epoch [20/1000], Loss: 0.0936\n",
      "Epoch [21/1000], Loss: 0.0716\n",
      "Epoch [22/1000], Loss: 0.0618\n",
      "Epoch [23/1000], Loss: 0.0873\n",
      "Epoch [24/1000], Loss: 0.1090\n",
      "Epoch [25/1000], Loss: 0.0879\n",
      "Epoch [26/1000], Loss: 0.0737\n",
      "Epoch [27/1000], Loss: 0.0652\n",
      "Epoch [28/1000], Loss: 0.0652\n",
      "Epoch [29/1000], Loss: 0.0660\n",
      "Epoch [30/1000], Loss: 0.0563\n",
      "Epoch [31/1000], Loss: 0.0282\n",
      "Epoch [32/1000], Loss: 0.0586\n",
      "Epoch [33/1000], Loss: 0.0424\n",
      "Epoch [34/1000], Loss: 0.0278\n",
      "Epoch [35/1000], Loss: 0.0306\n",
      "Epoch [36/1000], Loss: 0.0228\n",
      "Epoch [37/1000], Loss: 0.0301\n",
      "Epoch [38/1000], Loss: 0.0190\n",
      "Epoch [39/1000], Loss: 0.0343\n",
      "Epoch [40/1000], Loss: 0.0283\n",
      "Epoch [41/1000], Loss: 0.0122\n",
      "Epoch [42/1000], Loss: 0.0485\n",
      "Epoch [43/1000], Loss: 0.0480\n",
      "Epoch [44/1000], Loss: 0.0234\n",
      "Epoch [45/1000], Loss: 0.0155\n",
      "Epoch [46/1000], Loss: 0.0051\n",
      "Epoch [47/1000], Loss: 0.0020\n",
      "Epoch [48/1000], Loss: 0.0036\n",
      "Epoch [49/1000], Loss: 0.0040\n",
      "Epoch [50/1000], Loss: 0.0043\n",
      "Epoch [51/1000], Loss: 0.0268\n",
      "Epoch [52/1000], Loss: 0.0063\n",
      "Epoch [53/1000], Loss: 0.0030\n",
      "Epoch [54/1000], Loss: 0.0019\n",
      "Epoch [55/1000], Loss: 0.0023\n",
      "Epoch [56/1000], Loss: 0.0016\n",
      "Epoch [57/1000], Loss: 0.0043\n",
      "Epoch [58/1000], Loss: 0.0026\n",
      "Epoch [59/1000], Loss: 0.0010\n",
      "Epoch [60/1000], Loss: 0.0015\n",
      "Epoch [61/1000], Loss: 0.0022\n",
      "Epoch [62/1000], Loss: 0.0015\n",
      "Epoch [63/1000], Loss: 0.0021\n",
      "Epoch [64/1000], Loss: 0.0042\n",
      "Epoch [65/1000], Loss: 0.0022\n",
      "Epoch [66/1000], Loss: 0.0012\n",
      "Epoch [67/1000], Loss: 0.0024\n",
      "Epoch [68/1000], Loss: 0.0005\n",
      "Epoch [69/1000], Loss: 0.0031\n",
      "Epoch [70/1000], Loss: 0.0014\n",
      "Epoch [71/1000], Loss: 0.0058\n",
      "Epoch [72/1000], Loss: 0.0074\n",
      "Epoch [73/1000], Loss: 0.0079\n",
      "Epoch [74/1000], Loss: 0.0112\n",
      "Epoch [75/1000], Loss: 0.0056\n",
      "Epoch [76/1000], Loss: 0.0288\n",
      "Epoch [77/1000], Loss: 0.0339\n",
      "Epoch [78/1000], Loss: 0.1019\n",
      "Epoch [79/1000], Loss: 0.2051\n",
      "Epoch [80/1000], Loss: 0.1797\n",
      "Epoch [81/1000], Loss: 0.1678\n",
      "Epoch [82/1000], Loss: 0.1689\n",
      "Epoch [83/1000], Loss: 0.1697\n",
      "Epoch [84/1000], Loss: 0.1708\n",
      "Epoch [85/1000], Loss: 0.1528\n",
      "Epoch [86/1000], Loss: 0.1568\n",
      "Epoch [87/1000], Loss: 0.1496\n",
      "Epoch [88/1000], Loss: 0.1478\n",
      "Epoch [89/1000], Loss: 0.1466\n",
      "Epoch [90/1000], Loss: 0.1463\n",
      "Epoch [91/1000], Loss: 0.1460\n",
      "Epoch [92/1000], Loss: 0.1435\n",
      "Epoch [93/1000], Loss: 0.1457\n",
      "Epoch [94/1000], Loss: 0.1454\n",
      "Epoch [95/1000], Loss: 0.1429\n",
      "Epoch [96/1000], Loss: 0.1390\n",
      "Epoch [97/1000], Loss: 0.1491\n",
      "Epoch [98/1000], Loss: 0.1555\n",
      "Epoch [99/1000], Loss: 0.1560\n",
      "Epoch [100/1000], Loss: 0.1452\n",
      "Epoch [101/1000], Loss: 0.1457\n",
      "Epoch [102/1000], Loss: 0.1480\n",
      "Epoch [103/1000], Loss: 0.1432\n",
      "Epoch [104/1000], Loss: 0.1387\n",
      "Epoch [105/1000], Loss: 0.1446\n",
      "Epoch [106/1000], Loss: 0.1532\n",
      "Epoch [107/1000], Loss: 0.1528\n",
      "Epoch [108/1000], Loss: 0.1246\n",
      "Epoch [109/1000], Loss: 0.1290\n",
      "Epoch [110/1000], Loss: 0.1452\n",
      "Epoch [111/1000], Loss: 0.1435\n",
      "Epoch [112/1000], Loss: 0.1549\n",
      "Epoch [113/1000], Loss: 0.1421\n",
      "Epoch [114/1000], Loss: 0.1319\n",
      "Epoch [115/1000], Loss: 0.1205\n",
      "Epoch [116/1000], Loss: 0.1268\n",
      "Epoch [117/1000], Loss: 0.1357\n",
      "Epoch [118/1000], Loss: 0.1236\n",
      "Epoch [119/1000], Loss: 0.1447\n",
      "Epoch [120/1000], Loss: 0.1303\n",
      "Epoch [121/1000], Loss: 0.1198\n",
      "Epoch [122/1000], Loss: 0.1547\n",
      "Epoch [123/1000], Loss: 0.0995\n",
      "Epoch [124/1000], Loss: 0.0694\n",
      "Epoch [125/1000], Loss: 0.0678\n",
      "Epoch [126/1000], Loss: 0.0700\n",
      "Epoch [127/1000], Loss: 0.0562\n",
      "Epoch [128/1000], Loss: 0.0708\n",
      "Epoch [129/1000], Loss: 0.0517\n",
      "Epoch [130/1000], Loss: 0.0518\n",
      "Epoch [131/1000], Loss: 0.0412\n",
      "Epoch [132/1000], Loss: 0.0420\n",
      "Epoch [133/1000], Loss: 0.0355\n",
      "Epoch [134/1000], Loss: 0.0531\n",
      "Epoch [135/1000], Loss: 0.0347\n",
      "Epoch [136/1000], Loss: 0.0356\n",
      "Epoch [137/1000], Loss: 0.0511\n",
      "Epoch [138/1000], Loss: 0.0429\n",
      "Epoch [139/1000], Loss: 0.0870\n",
      "Epoch [140/1000], Loss: 0.0865\n",
      "Epoch [141/1000], Loss: 0.0880\n",
      "Epoch [142/1000], Loss: 0.1089\n",
      "Epoch [143/1000], Loss: 0.0832\n",
      "Epoch [144/1000], Loss: 0.0807\n",
      "Epoch [145/1000], Loss: 0.1080\n",
      "Epoch [146/1000], Loss: 0.0922\n",
      "Epoch [147/1000], Loss: 0.1305\n",
      "Epoch [148/1000], Loss: 0.1494\n",
      "Epoch [149/1000], Loss: 0.1612\n",
      "Epoch [150/1000], Loss: 0.2832\n",
      "Epoch [151/1000], Loss: 0.2117\n",
      "Epoch [152/1000], Loss: 0.1688\n",
      "Epoch [153/1000], Loss: 0.1622\n",
      "Epoch [154/1000], Loss: 0.1613\n",
      "Epoch [155/1000], Loss: 0.1636\n",
      "Epoch [156/1000], Loss: 0.1604\n",
      "Epoch [157/1000], Loss: 0.1702\n",
      "Epoch [158/1000], Loss: 0.1553\n",
      "Epoch [159/1000], Loss: 0.1552\n",
      "Epoch [160/1000], Loss: 0.1807\n",
      "Epoch [161/1000], Loss: 0.1998\n",
      "Epoch [162/1000], Loss: 0.1869\n",
      "Epoch [163/1000], Loss: 0.1765\n",
      "Epoch [164/1000], Loss: 0.1762\n",
      "Epoch [165/1000], Loss: 0.1759\n",
      "Epoch [166/1000], Loss: 0.1752\n",
      "Epoch [167/1000], Loss: 0.1752\n",
      "Epoch [168/1000], Loss: 0.1803\n",
      "Epoch [169/1000], Loss: 0.1810\n",
      "Epoch [170/1000], Loss: 0.1817\n",
      "Epoch [171/1000], Loss: 0.1759\n",
      "Epoch [172/1000], Loss: 0.1742\n",
      "Epoch [173/1000], Loss: 0.1745\n",
      "Epoch [174/1000], Loss: 0.1774\n",
      "Epoch [175/1000], Loss: 0.1771\n",
      "Epoch [176/1000], Loss: 0.1773\n",
      "Epoch [177/1000], Loss: 0.1866\n",
      "Epoch [178/1000], Loss: 0.1854\n",
      "Epoch [179/1000], Loss: 0.1798\n",
      "Epoch [180/1000], Loss: 0.1884\n",
      "Epoch [181/1000], Loss: 0.1926\n",
      "Epoch [182/1000], Loss: 0.2085\n",
      "Epoch [183/1000], Loss: 0.2387\n",
      "Epoch [184/1000], Loss: 0.2143\n",
      "Epoch [185/1000], Loss: 0.1578\n",
      "Epoch [186/1000], Loss: 0.1947\n",
      "Epoch [187/1000], Loss: 0.1823\n",
      "Epoch [188/1000], Loss: 0.1824\n",
      "Epoch [189/1000], Loss: 0.2157\n",
      "Epoch [190/1000], Loss: 0.1763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [191/1000], Loss: 0.1527\n",
      "Epoch [192/1000], Loss: 0.1552\n",
      "Epoch [193/1000], Loss: 0.1443\n",
      "Epoch [194/1000], Loss: 0.1473\n",
      "Epoch [195/1000], Loss: 0.1470\n",
      "Epoch [196/1000], Loss: 0.1910\n",
      "Epoch [197/1000], Loss: 0.2587\n",
      "Epoch [198/1000], Loss: 0.2592\n",
      "Epoch [199/1000], Loss: 0.2281\n",
      "Epoch [200/1000], Loss: 0.1734\n",
      "Epoch [201/1000], Loss: 0.1347\n",
      "Epoch [202/1000], Loss: 0.1468\n",
      "Epoch [203/1000], Loss: 0.1583\n",
      "Epoch [204/1000], Loss: 0.1288\n",
      "Epoch [205/1000], Loss: 0.1652\n",
      "Epoch [206/1000], Loss: 0.1262\n",
      "Epoch [207/1000], Loss: 0.1726\n",
      "Epoch [208/1000], Loss: 0.1865\n",
      "Epoch [209/1000], Loss: 0.1572\n",
      "Epoch [210/1000], Loss: 0.1475\n",
      "Epoch [211/1000], Loss: 0.1384\n",
      "Epoch [212/1000], Loss: 0.1305\n",
      "Epoch [213/1000], Loss: 0.1582\n",
      "Epoch [214/1000], Loss: 0.2291\n",
      "Epoch [215/1000], Loss: 0.1637\n",
      "Epoch [216/1000], Loss: 0.1571\n",
      "Epoch [217/1000], Loss: 0.1827\n",
      "Epoch [218/1000], Loss: 0.1975\n",
      "Epoch [219/1000], Loss: 0.1428\n",
      "Epoch [220/1000], Loss: 0.1258\n",
      "Epoch [221/1000], Loss: 0.1402\n",
      "Epoch [222/1000], Loss: 0.1370\n",
      "Epoch [223/1000], Loss: 0.1329\n",
      "Epoch [224/1000], Loss: 0.1291\n",
      "Epoch [225/1000], Loss: 0.1317\n",
      "Epoch [226/1000], Loss: 0.1324\n",
      "Epoch [227/1000], Loss: 0.1455\n",
      "Epoch [228/1000], Loss: 0.1608\n",
      "Epoch [229/1000], Loss: 0.1488\n",
      "Epoch [230/1000], Loss: 0.1521\n",
      "Epoch [231/1000], Loss: 0.1547\n",
      "Epoch [232/1000], Loss: 0.1389\n",
      "Epoch [233/1000], Loss: 0.1335\n",
      "Epoch [234/1000], Loss: 0.1329\n",
      "Epoch [235/1000], Loss: 0.1348\n",
      "Epoch [236/1000], Loss: 0.1253\n",
      "Epoch [237/1000], Loss: 0.1282\n",
      "Epoch [238/1000], Loss: 0.1306\n",
      "Epoch [239/1000], Loss: 0.1290\n",
      "Epoch [240/1000], Loss: 0.1317\n",
      "Epoch [241/1000], Loss: 0.1312\n",
      "Epoch [242/1000], Loss: 0.1283\n",
      "Epoch [243/1000], Loss: 0.1245\n",
      "Epoch [244/1000], Loss: 0.1336\n",
      "Epoch [245/1000], Loss: 0.1469\n",
      "Epoch [246/1000], Loss: 0.1222\n",
      "Epoch [247/1000], Loss: 0.1528\n",
      "Epoch [248/1000], Loss: 0.1633\n",
      "Epoch [249/1000], Loss: 0.1360\n",
      "Epoch [250/1000], Loss: 0.1240\n",
      "Epoch [251/1000], Loss: 0.1156\n",
      "Epoch [252/1000], Loss: 0.1035\n",
      "Epoch [253/1000], Loss: 0.1058\n",
      "Epoch [254/1000], Loss: 0.1031\n",
      "Epoch [255/1000], Loss: 0.1031\n",
      "Epoch [256/1000], Loss: 0.0996\n",
      "Epoch [257/1000], Loss: 0.0967\n",
      "Epoch [258/1000], Loss: 0.0976\n",
      "Epoch [259/1000], Loss: 0.1010\n",
      "Epoch [260/1000], Loss: 0.1058\n",
      "Epoch [261/1000], Loss: 0.1047\n",
      "Epoch [262/1000], Loss: 0.1074\n",
      "Epoch [263/1000], Loss: 0.1492\n",
      "Epoch [264/1000], Loss: 0.1948\n",
      "Epoch [265/1000], Loss: 0.1924\n",
      "Epoch [266/1000], Loss: 0.1926\n",
      "Epoch [267/1000], Loss: 0.2028\n",
      "Epoch [268/1000], Loss: 0.2606\n",
      "Epoch [269/1000], Loss: 0.2231\n",
      "Epoch [270/1000], Loss: 0.1892\n",
      "Epoch [271/1000], Loss: 0.1929\n",
      "Epoch [272/1000], Loss: 0.1910\n",
      "Epoch [273/1000], Loss: 0.1899\n",
      "Epoch [274/1000], Loss: 0.1885\n",
      "Epoch [275/1000], Loss: 0.1905\n",
      "Epoch [276/1000], Loss: 0.1908\n",
      "Epoch [277/1000], Loss: 0.1895\n",
      "Epoch [278/1000], Loss: 0.1849\n",
      "Epoch [279/1000], Loss: 0.1927\n",
      "Epoch [280/1000], Loss: 0.1888\n",
      "Epoch [281/1000], Loss: 0.1822\n",
      "Epoch [282/1000], Loss: 0.1691\n",
      "Epoch [283/1000], Loss: 0.1707\n",
      "Epoch [284/1000], Loss: 0.1518\n",
      "Epoch [285/1000], Loss: 0.1191\n",
      "Epoch [286/1000], Loss: 0.1185\n",
      "Epoch [287/1000], Loss: 0.1203\n",
      "Epoch [288/1000], Loss: 0.1599\n",
      "Epoch [289/1000], Loss: 0.2592\n",
      "Epoch [290/1000], Loss: 0.2604\n",
      "Epoch [291/1000], Loss: 0.2653\n",
      "Epoch [292/1000], Loss: 0.2475\n",
      "Epoch [293/1000], Loss: 0.2457\n",
      "Epoch [294/1000], Loss: 0.1978\n",
      "Epoch [295/1000], Loss: 0.2201\n",
      "Epoch [296/1000], Loss: 0.2336\n",
      "Epoch [297/1000], Loss: 0.1758\n",
      "Epoch [298/1000], Loss: 0.1668\n",
      "Epoch [299/1000], Loss: 0.1431\n",
      "Epoch [300/1000], Loss: 0.1394\n",
      "Epoch [301/1000], Loss: 0.1640\n",
      "Epoch [302/1000], Loss: 0.2127\n",
      "Epoch [303/1000], Loss: 0.2785\n",
      "Epoch [304/1000], Loss: 0.3099\n",
      "Epoch [305/1000], Loss: 0.2785\n",
      "Epoch [306/1000], Loss: 0.2259\n",
      "Epoch [307/1000], Loss: 0.2215\n",
      "Epoch [308/1000], Loss: 0.1876\n",
      "Epoch [309/1000], Loss: 0.1817\n",
      "Epoch [310/1000], Loss: 0.1805\n",
      "Epoch [311/1000], Loss: 0.1720\n",
      "Epoch [312/1000], Loss: 0.1529\n",
      "Epoch [313/1000], Loss: 0.1854\n",
      "Epoch [314/1000], Loss: 0.1897\n",
      "Epoch [315/1000], Loss: 0.1857\n",
      "Epoch [316/1000], Loss: 0.1935\n",
      "Epoch [317/1000], Loss: 0.1887\n",
      "Epoch [318/1000], Loss: 0.1868\n",
      "Epoch [319/1000], Loss: 0.1830\n",
      "Epoch [320/1000], Loss: 0.1696\n",
      "Epoch [321/1000], Loss: 0.1698\n",
      "Epoch [322/1000], Loss: 0.1675\n",
      "Epoch [323/1000], Loss: 0.1676\n",
      "Epoch [324/1000], Loss: 0.1574\n",
      "Epoch [325/1000], Loss: 0.1455\n",
      "Epoch [326/1000], Loss: 0.1470\n",
      "Epoch [327/1000], Loss: 0.1474\n",
      "Epoch [328/1000], Loss: 0.1431\n",
      "Epoch [329/1000], Loss: 0.1388\n",
      "Epoch [330/1000], Loss: 0.1504\n",
      "Epoch [331/1000], Loss: 0.1912\n",
      "Epoch [332/1000], Loss: 0.1854\n",
      "Epoch [333/1000], Loss: 0.2001\n",
      "Epoch [334/1000], Loss: 0.2217\n",
      "Epoch [335/1000], Loss: 0.1844\n",
      "Epoch [336/1000], Loss: 0.2078\n",
      "Epoch [337/1000], Loss: 0.1963\n",
      "Epoch [338/1000], Loss: 0.1938\n",
      "Epoch [339/1000], Loss: 0.2141\n",
      "Epoch [340/1000], Loss: 0.2202\n",
      "Epoch [341/1000], Loss: 0.1828\n",
      "Epoch [342/1000], Loss: 0.1653\n",
      "Epoch [343/1000], Loss: 0.1643\n",
      "Epoch [344/1000], Loss: 0.1273\n",
      "Epoch [345/1000], Loss: 0.1155\n",
      "Epoch [346/1000], Loss: 0.1062\n",
      "Epoch [347/1000], Loss: 0.1107\n",
      "Epoch [348/1000], Loss: 0.1139\n",
      "Epoch [349/1000], Loss: 0.1150\n",
      "Epoch [350/1000], Loss: 0.1432\n",
      "Epoch [351/1000], Loss: 0.1726\n",
      "Epoch [352/1000], Loss: 0.1567\n",
      "Epoch [353/1000], Loss: 0.1701\n",
      "Epoch [354/1000], Loss: 0.1703\n",
      "Epoch [355/1000], Loss: 0.1338\n",
      "Epoch [356/1000], Loss: 0.1264\n",
      "Epoch [357/1000], Loss: 0.1218\n",
      "Epoch [358/1000], Loss: 0.1160\n",
      "Epoch [359/1000], Loss: 0.1149\n",
      "Epoch [360/1000], Loss: 0.1151\n",
      "Epoch [361/1000], Loss: 0.1296\n",
      "Epoch [362/1000], Loss: 0.1403\n",
      "Epoch [363/1000], Loss: 0.1318\n",
      "Epoch [364/1000], Loss: 0.1132\n",
      "Epoch [365/1000], Loss: 0.1050\n",
      "Epoch [366/1000], Loss: 0.1029\n",
      "Epoch [367/1000], Loss: 0.1022\n",
      "Epoch [368/1000], Loss: 0.1038\n",
      "Epoch [369/1000], Loss: 0.1021\n",
      "Epoch [370/1000], Loss: 0.1030\n",
      "Epoch [371/1000], Loss: 0.1001\n",
      "Epoch [372/1000], Loss: 0.1436\n",
      "Epoch [373/1000], Loss: 0.1690\n",
      "Epoch [374/1000], Loss: 0.1644\n",
      "Epoch [375/1000], Loss: 0.1656\n",
      "Epoch [376/1000], Loss: 0.1647\n",
      "Epoch [377/1000], Loss: 0.1627\n",
      "Epoch [378/1000], Loss: 0.1551\n",
      "Epoch [379/1000], Loss: 0.1462\n",
      "Epoch [380/1000], Loss: 0.1426\n",
      "Epoch [381/1000], Loss: 0.1375\n",
      "Epoch [382/1000], Loss: 0.1377\n",
      "Epoch [383/1000], Loss: 0.1423\n",
      "Epoch [384/1000], Loss: 0.1309\n",
      "Epoch [385/1000], Loss: 0.1250\n",
      "Epoch [386/1000], Loss: 0.1218\n",
      "Epoch [387/1000], Loss: 0.1191\n",
      "Epoch [388/1000], Loss: 0.1307\n",
      "Epoch [389/1000], Loss: 0.1171\n",
      "Epoch [390/1000], Loss: 0.1278\n",
      "Epoch [391/1000], Loss: 0.1427\n",
      "Epoch [392/1000], Loss: 0.1375\n",
      "Epoch [393/1000], Loss: 0.1388\n",
      "Epoch [394/1000], Loss: 0.1417\n",
      "Epoch [395/1000], Loss: 0.1323\n",
      "Epoch [396/1000], Loss: 0.1135\n",
      "Epoch [397/1000], Loss: 0.1128\n",
      "Epoch [398/1000], Loss: 0.1120\n",
      "Epoch [399/1000], Loss: 0.1115\n",
      "Epoch [400/1000], Loss: 0.1144\n",
      "Epoch [401/1000], Loss: 0.1135\n",
      "Epoch [402/1000], Loss: 0.1133\n",
      "Epoch [403/1000], Loss: 0.1137\n",
      "Epoch [404/1000], Loss: 0.1125\n",
      "Epoch [405/1000], Loss: 0.1128\n",
      "Epoch [406/1000], Loss: 0.1129\n",
      "Epoch [407/1000], Loss: 0.1132\n",
      "Epoch [408/1000], Loss: 0.1131\n",
      "Epoch [409/1000], Loss: 0.1130\n",
      "Epoch [410/1000], Loss: 0.1112\n",
      "Epoch [411/1000], Loss: 0.1133\n",
      "Epoch [412/1000], Loss: 0.1127\n",
      "Epoch [413/1000], Loss: 0.1128\n",
      "Epoch [414/1000], Loss: 0.1131\n",
      "Epoch [415/1000], Loss: 0.1138\n",
      "Epoch [416/1000], Loss: 0.1131\n",
      "Epoch [417/1000], Loss: 0.1141\n",
      "Epoch [418/1000], Loss: 0.1128\n",
      "Epoch [419/1000], Loss: 0.1127\n",
      "Epoch [420/1000], Loss: 0.1138\n",
      "Epoch [421/1000], Loss: 0.1136\n",
      "Epoch [422/1000], Loss: 0.1122\n",
      "Epoch [423/1000], Loss: 0.1132\n",
      "Epoch [424/1000], Loss: 0.1126\n",
      "Epoch [425/1000], Loss: 0.1124\n",
      "Epoch [426/1000], Loss: 0.1136\n",
      "Epoch [427/1000], Loss: 0.1132\n",
      "Epoch [428/1000], Loss: 0.1123\n",
      "Epoch [429/1000], Loss: 0.1135\n",
      "Epoch [430/1000], Loss: 0.1130\n",
      "Epoch [431/1000], Loss: 0.1131\n",
      "Epoch [432/1000], Loss: 0.1129\n",
      "Epoch [433/1000], Loss: 0.1130\n",
      "Epoch [434/1000], Loss: 0.1136\n",
      "Epoch [435/1000], Loss: 0.1133\n",
      "Epoch [436/1000], Loss: 0.1131\n",
      "Epoch [437/1000], Loss: 0.1133\n",
      "Epoch [438/1000], Loss: 0.1138\n",
      "Epoch [439/1000], Loss: 0.1127\n",
      "Epoch [440/1000], Loss: 0.1121\n",
      "Epoch [441/1000], Loss: 0.1132\n",
      "Epoch [442/1000], Loss: 0.1120\n",
      "Epoch [443/1000], Loss: 0.1130\n",
      "Epoch [444/1000], Loss: 0.1130\n",
      "Epoch [445/1000], Loss: 0.1130\n",
      "Epoch [446/1000], Loss: 0.1118\n",
      "Epoch [447/1000], Loss: 0.1128\n",
      "Epoch [448/1000], Loss: 0.1139\n",
      "Epoch [449/1000], Loss: 0.1131\n",
      "Epoch [450/1000], Loss: 0.1123\n",
      "Epoch [451/1000], Loss: 0.1120\n",
      "Epoch [452/1000], Loss: 0.1129\n",
      "Epoch [453/1000], Loss: 0.1126\n",
      "Epoch [454/1000], Loss: 0.1135\n",
      "Epoch [455/1000], Loss: 0.1128\n",
      "Epoch [456/1000], Loss: 0.1124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [457/1000], Loss: 0.1124\n",
      "Epoch [458/1000], Loss: 0.1122\n",
      "Epoch [459/1000], Loss: 0.1121\n",
      "Epoch [460/1000], Loss: 0.1138\n",
      "Epoch [461/1000], Loss: 0.1146\n",
      "Epoch [462/1000], Loss: 0.1127\n",
      "Epoch [463/1000], Loss: 0.1126\n",
      "Epoch [464/1000], Loss: 0.1139\n",
      "Epoch [465/1000], Loss: 0.1130\n",
      "Epoch [466/1000], Loss: 0.1125\n",
      "Epoch [467/1000], Loss: 0.1131\n",
      "Epoch [468/1000], Loss: 0.1125\n",
      "Epoch [469/1000], Loss: 0.1126\n",
      "Epoch [470/1000], Loss: 0.1126\n",
      "Epoch [471/1000], Loss: 0.1120\n",
      "Epoch [472/1000], Loss: 0.1135\n",
      "Epoch [473/1000], Loss: 0.1131\n",
      "Epoch [474/1000], Loss: 0.1128\n",
      "Epoch [475/1000], Loss: 0.1120\n",
      "Epoch [476/1000], Loss: 0.1124\n",
      "Epoch [477/1000], Loss: 0.1140\n",
      "Epoch [478/1000], Loss: 0.1136\n",
      "Epoch [479/1000], Loss: 0.1133\n",
      "Epoch [480/1000], Loss: 0.1120\n",
      "Epoch [481/1000], Loss: 0.1137\n",
      "Epoch [482/1000], Loss: 0.1130\n",
      "Epoch [483/1000], Loss: 0.1132\n",
      "Epoch [484/1000], Loss: 0.1120\n",
      "Epoch [485/1000], Loss: 0.1122\n",
      "Epoch [486/1000], Loss: 0.1124\n",
      "Epoch [487/1000], Loss: 0.1120\n",
      "Epoch [488/1000], Loss: 0.1131\n",
      "Epoch [489/1000], Loss: 0.1137\n",
      "Epoch [490/1000], Loss: 0.1131\n",
      "Epoch [491/1000], Loss: 0.1123\n",
      "Epoch [492/1000], Loss: 0.1121\n",
      "Epoch [493/1000], Loss: 0.1119\n",
      "Epoch [494/1000], Loss: 0.1122\n",
      "Epoch [495/1000], Loss: 0.1115\n",
      "Epoch [496/1000], Loss: 0.1128\n",
      "Epoch [497/1000], Loss: 0.1135\n",
      "Epoch [498/1000], Loss: 0.1134\n",
      "Epoch [499/1000], Loss: 0.1135\n",
      "Epoch [500/1000], Loss: 0.1124\n",
      "Epoch [501/1000], Loss: 0.1141\n",
      "Epoch [502/1000], Loss: 0.1133\n",
      "Epoch [503/1000], Loss: 0.1135\n",
      "Epoch [504/1000], Loss: 0.1135\n",
      "Epoch [505/1000], Loss: 0.1125\n",
      "Epoch [506/1000], Loss: 0.1133\n",
      "Epoch [507/1000], Loss: 0.1131\n",
      "Epoch [508/1000], Loss: 0.1131\n",
      "Epoch [509/1000], Loss: 0.1128\n",
      "Epoch [510/1000], Loss: 0.1126\n",
      "Epoch [511/1000], Loss: 0.1135\n",
      "Epoch [512/1000], Loss: 0.1141\n",
      "Epoch [513/1000], Loss: 0.1123\n",
      "Epoch [514/1000], Loss: 0.1130\n",
      "Epoch [515/1000], Loss: 0.1132\n",
      "Epoch [516/1000], Loss: 0.1135\n",
      "Epoch [517/1000], Loss: 0.1127\n",
      "Epoch [518/1000], Loss: 0.1135\n",
      "Epoch [519/1000], Loss: 0.1119\n",
      "Epoch [520/1000], Loss: 0.1124\n",
      "Epoch [521/1000], Loss: 0.1127\n",
      "Epoch [522/1000], Loss: 0.1132\n",
      "Epoch [523/1000], Loss: 0.1138\n",
      "Epoch [524/1000], Loss: 0.1137\n",
      "Epoch [525/1000], Loss: 0.1127\n",
      "Epoch [526/1000], Loss: 0.1126\n",
      "Epoch [527/1000], Loss: 0.1126\n",
      "Epoch [528/1000], Loss: 0.1122\n",
      "Epoch [529/1000], Loss: 0.1125\n",
      "Epoch [530/1000], Loss: 0.1122\n",
      "Epoch [531/1000], Loss: 0.1126\n",
      "Epoch [532/1000], Loss: 0.1132\n",
      "Epoch [533/1000], Loss: 0.1135\n",
      "Epoch [534/1000], Loss: 0.1125\n",
      "Epoch [535/1000], Loss: 0.1130\n",
      "Epoch [536/1000], Loss: 0.1132\n",
      "Epoch [537/1000], Loss: 0.1132\n",
      "Epoch [538/1000], Loss: 0.1126\n",
      "Epoch [539/1000], Loss: 0.1122\n",
      "Epoch [540/1000], Loss: 0.1131\n",
      "Epoch [541/1000], Loss: 0.1126\n",
      "Epoch [542/1000], Loss: 0.1125\n",
      "Epoch [543/1000], Loss: 0.1137\n",
      "Epoch [544/1000], Loss: 0.1127\n",
      "Epoch [545/1000], Loss: 0.1117\n",
      "Epoch [546/1000], Loss: 0.1130\n",
      "Epoch [547/1000], Loss: 0.1127\n",
      "Epoch [548/1000], Loss: 0.1128\n",
      "Epoch [549/1000], Loss: 0.1125\n",
      "Epoch [550/1000], Loss: 0.1123\n",
      "Epoch [551/1000], Loss: 0.1121\n",
      "Epoch [552/1000], Loss: 0.1119\n",
      "Epoch [553/1000], Loss: 0.1128\n",
      "Epoch [554/1000], Loss: 0.1135\n",
      "Epoch [555/1000], Loss: 0.1116\n",
      "Epoch [556/1000], Loss: 0.1137\n",
      "Epoch [557/1000], Loss: 0.1135\n",
      "Epoch [558/1000], Loss: 0.1124\n",
      "Epoch [559/1000], Loss: 0.1123\n",
      "Epoch [560/1000], Loss: 0.1135\n",
      "Epoch [561/1000], Loss: 0.1126\n",
      "Epoch [562/1000], Loss: 0.1129\n",
      "Epoch [563/1000], Loss: 0.1129\n",
      "Epoch [564/1000], Loss: 0.1132\n",
      "Epoch [565/1000], Loss: 0.1129\n",
      "Epoch [566/1000], Loss: 0.1124\n",
      "Epoch [567/1000], Loss: 0.1130\n",
      "Epoch [568/1000], Loss: 0.1135\n",
      "Epoch [569/1000], Loss: 0.1130\n",
      "Epoch [570/1000], Loss: 0.1133\n",
      "Epoch [571/1000], Loss: 0.1126\n",
      "Epoch [572/1000], Loss: 0.1127\n",
      "Epoch [573/1000], Loss: 0.1120\n",
      "Epoch [574/1000], Loss: 0.1134\n",
      "Epoch [575/1000], Loss: 0.1125\n",
      "Epoch [576/1000], Loss: 0.1125\n",
      "Epoch [577/1000], Loss: 0.1138\n",
      "Epoch [578/1000], Loss: 0.1130\n",
      "Epoch [579/1000], Loss: 0.1136\n",
      "Epoch [580/1000], Loss: 0.1126\n",
      "Epoch [581/1000], Loss: 0.1137\n",
      "Epoch [582/1000], Loss: 0.1130\n",
      "Epoch [583/1000], Loss: 0.1126\n",
      "Epoch [584/1000], Loss: 0.1126\n",
      "Epoch [585/1000], Loss: 0.1135\n",
      "Epoch [586/1000], Loss: 0.1127\n",
      "Epoch [587/1000], Loss: 0.1142\n",
      "Epoch [588/1000], Loss: 0.1131\n",
      "Epoch [589/1000], Loss: 0.1122\n",
      "Epoch [590/1000], Loss: 0.1132\n",
      "Epoch [591/1000], Loss: 0.1127\n",
      "Epoch [592/1000], Loss: 0.1129\n",
      "Epoch [593/1000], Loss: 0.1126\n",
      "Epoch [594/1000], Loss: 0.1130\n",
      "Epoch [595/1000], Loss: 0.1133\n",
      "Epoch [596/1000], Loss: 0.1134\n",
      "Epoch [597/1000], Loss: 0.1124\n",
      "Epoch [598/1000], Loss: 0.1126\n",
      "Epoch [599/1000], Loss: 0.1130\n",
      "Epoch [600/1000], Loss: 0.1125\n",
      "Epoch [601/1000], Loss: 0.1129\n",
      "Epoch [602/1000], Loss: 0.1127\n",
      "Epoch [603/1000], Loss: 0.1131\n",
      "Epoch [604/1000], Loss: 0.1121\n",
      "Epoch [605/1000], Loss: 0.1120\n",
      "Epoch [606/1000], Loss: 0.1135\n",
      "Epoch [607/1000], Loss: 0.1123\n",
      "Epoch [608/1000], Loss: 0.1130\n",
      "Epoch [609/1000], Loss: 0.1126\n",
      "Epoch [610/1000], Loss: 0.1129\n",
      "Epoch [611/1000], Loss: 0.1144\n",
      "Epoch [612/1000], Loss: 0.1125\n",
      "Epoch [613/1000], Loss: 0.1123\n",
      "Epoch [614/1000], Loss: 0.1263\n",
      "Epoch [615/1000], Loss: 0.2052\n",
      "Epoch [616/1000], Loss: 0.3272\n",
      "Epoch [617/1000], Loss: 0.3642\n",
      "Epoch [618/1000], Loss: 0.3612\n",
      "Epoch [619/1000], Loss: 0.3773\n",
      "Epoch [620/1000], Loss: 0.3759\n",
      "Epoch [621/1000], Loss: 0.3576\n",
      "Epoch [622/1000], Loss: 0.3546\n",
      "Epoch [623/1000], Loss: 0.3521\n",
      "Epoch [624/1000], Loss: 0.3519\n",
      "Epoch [625/1000], Loss: 0.3481\n",
      "Epoch [626/1000], Loss: 0.3494\n",
      "Epoch [627/1000], Loss: 0.3419\n",
      "Epoch [628/1000], Loss: 0.3403\n",
      "Epoch [629/1000], Loss: 0.3416\n",
      "Epoch [630/1000], Loss: 0.3456\n",
      "Epoch [631/1000], Loss: 0.3455\n",
      "Epoch [632/1000], Loss: 0.3691\n",
      "Epoch [633/1000], Loss: 0.3697\n",
      "Epoch [634/1000], Loss: 0.3420\n",
      "Epoch [635/1000], Loss: 0.3418\n",
      "Epoch [636/1000], Loss: 0.3303\n",
      "Epoch [637/1000], Loss: 0.3266\n",
      "Epoch [638/1000], Loss: 0.3214\n",
      "Epoch [639/1000], Loss: 0.3210\n",
      "Epoch [640/1000], Loss: 0.3196\n",
      "Epoch [641/1000], Loss: 0.3223\n",
      "Epoch [642/1000], Loss: 0.3191\n",
      "Epoch [643/1000], Loss: 0.3189\n",
      "Epoch [644/1000], Loss: 0.3222\n",
      "Epoch [645/1000], Loss: 0.3447\n",
      "Epoch [646/1000], Loss: 0.3463\n",
      "Epoch [647/1000], Loss: 0.3466\n",
      "Epoch [648/1000], Loss: 0.3480\n",
      "Epoch [649/1000], Loss: 0.3489\n",
      "Epoch [650/1000], Loss: 0.3466\n",
      "Epoch [651/1000], Loss: 0.3439\n",
      "Epoch [652/1000], Loss: 0.3289\n",
      "Epoch [653/1000], Loss: 0.3268\n",
      "Epoch [654/1000], Loss: 0.3325\n",
      "Epoch [655/1000], Loss: 0.3347\n",
      "Epoch [656/1000], Loss: 0.3313\n",
      "Epoch [657/1000], Loss: 0.3309\n",
      "Epoch [658/1000], Loss: 0.3297\n",
      "Epoch [659/1000], Loss: 0.3281\n",
      "Epoch [660/1000], Loss: 0.3239\n",
      "Epoch [661/1000], Loss: 0.3245\n",
      "Epoch [662/1000], Loss: 0.3245\n",
      "Epoch [663/1000], Loss: 0.3258\n",
      "Epoch [664/1000], Loss: 0.3228\n",
      "Epoch [665/1000], Loss: 0.3223\n",
      "Epoch [666/1000], Loss: 0.3250\n",
      "Epoch [667/1000], Loss: 0.3261\n",
      "Epoch [668/1000], Loss: 0.3236\n",
      "Epoch [669/1000], Loss: 0.3225\n",
      "Epoch [670/1000], Loss: 0.3243\n",
      "Epoch [671/1000], Loss: 0.3226\n",
      "Epoch [672/1000], Loss: 0.3267\n",
      "Epoch [673/1000], Loss: 0.3240\n",
      "Epoch [674/1000], Loss: 0.3249\n",
      "Epoch [675/1000], Loss: 0.3240\n",
      "Epoch [676/1000], Loss: 0.3232\n",
      "Epoch [677/1000], Loss: 0.3245\n",
      "Epoch [678/1000], Loss: 0.3243\n",
      "Epoch [679/1000], Loss: 0.3239\n",
      "Epoch [680/1000], Loss: 0.3235\n",
      "Epoch [681/1000], Loss: 0.3250\n",
      "Epoch [682/1000], Loss: 0.3244\n",
      "Epoch [683/1000], Loss: 0.3248\n",
      "Epoch [684/1000], Loss: 0.3242\n",
      "Epoch [685/1000], Loss: 0.3249\n",
      "Epoch [686/1000], Loss: 0.3258\n",
      "Epoch [687/1000], Loss: 0.3254\n",
      "Epoch [688/1000], Loss: 0.3256\n",
      "Epoch [689/1000], Loss: 0.3241\n",
      "Epoch [690/1000], Loss: 0.3253\n",
      "Epoch [691/1000], Loss: 0.3231\n",
      "Epoch [692/1000], Loss: 0.3258\n",
      "Epoch [693/1000], Loss: 0.3241\n",
      "Epoch [694/1000], Loss: 0.3248\n",
      "Epoch [695/1000], Loss: 0.3239\n",
      "Epoch [696/1000], Loss: 0.3215\n",
      "Epoch [697/1000], Loss: 0.3237\n",
      "Epoch [698/1000], Loss: 0.3237\n",
      "Epoch [699/1000], Loss: 0.3232\n",
      "Epoch [700/1000], Loss: 0.3240\n",
      "Epoch [701/1000], Loss: 0.3244\n",
      "Epoch [702/1000], Loss: 0.3243\n",
      "Epoch [703/1000], Loss: 0.3236\n",
      "Epoch [704/1000], Loss: 0.3243\n",
      "Epoch [705/1000], Loss: 0.3232\n",
      "Epoch [706/1000], Loss: 0.3242\n",
      "Epoch [707/1000], Loss: 0.3254\n",
      "Epoch [708/1000], Loss: 0.3249\n",
      "Epoch [709/1000], Loss: 0.3239\n",
      "Epoch [710/1000], Loss: 0.3240\n",
      "Epoch [711/1000], Loss: 0.3227\n",
      "Epoch [712/1000], Loss: 0.3239\n",
      "Epoch [713/1000], Loss: 0.3255\n",
      "Epoch [714/1000], Loss: 0.3222\n",
      "Epoch [715/1000], Loss: 0.3261\n",
      "Epoch [716/1000], Loss: 0.3222\n",
      "Epoch [717/1000], Loss: 0.3250\n",
      "Epoch [718/1000], Loss: 0.3250\n",
      "Epoch [719/1000], Loss: 0.3246\n",
      "Epoch [720/1000], Loss: 0.3247\n",
      "Epoch [721/1000], Loss: 0.3249\n",
      "Epoch [722/1000], Loss: 0.3240\n",
      "Epoch [723/1000], Loss: 0.3263\n",
      "Epoch [724/1000], Loss: 0.3247\n",
      "Epoch [725/1000], Loss: 0.3244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [726/1000], Loss: 0.3273\n",
      "Epoch [727/1000], Loss: 0.3246\n",
      "Epoch [728/1000], Loss: 0.3235\n",
      "Epoch [729/1000], Loss: 0.3228\n",
      "Epoch [730/1000], Loss: 0.3261\n",
      "Epoch [731/1000], Loss: 0.3256\n",
      "Epoch [732/1000], Loss: 0.3255\n",
      "Epoch [733/1000], Loss: 0.3259\n",
      "Epoch [734/1000], Loss: 0.3252\n",
      "Epoch [735/1000], Loss: 0.3230\n",
      "Epoch [736/1000], Loss: 0.3216\n",
      "Epoch [737/1000], Loss: 0.3260\n",
      "Epoch [738/1000], Loss: 0.3243\n",
      "Epoch [739/1000], Loss: 0.3253\n",
      "Epoch [740/1000], Loss: 0.3258\n",
      "Epoch [741/1000], Loss: 0.3244\n",
      "Epoch [742/1000], Loss: 0.3251\n",
      "Epoch [743/1000], Loss: 0.3232\n",
      "Epoch [744/1000], Loss: 0.3238\n",
      "Epoch [745/1000], Loss: 0.3227\n",
      "Epoch [746/1000], Loss: 0.3238\n",
      "Epoch [747/1000], Loss: 0.3246\n",
      "Epoch [748/1000], Loss: 0.3239\n",
      "Epoch [749/1000], Loss: 0.3243\n",
      "Epoch [750/1000], Loss: 0.3258\n",
      "Epoch [751/1000], Loss: 0.3241\n",
      "Epoch [752/1000], Loss: 0.3248\n",
      "Epoch [753/1000], Loss: 0.3240\n",
      "Epoch [754/1000], Loss: 0.3245\n",
      "Epoch [755/1000], Loss: 0.3235\n",
      "Epoch [756/1000], Loss: 0.3253\n",
      "Epoch [757/1000], Loss: 0.3244\n",
      "Epoch [758/1000], Loss: 0.3238\n",
      "Epoch [759/1000], Loss: 0.3243\n",
      "Epoch [760/1000], Loss: 0.3257\n",
      "Epoch [761/1000], Loss: 0.3259\n",
      "Epoch [762/1000], Loss: 0.3246\n",
      "Epoch [763/1000], Loss: 0.3246\n",
      "Epoch [764/1000], Loss: 0.3250\n",
      "Epoch [765/1000], Loss: 0.3235\n",
      "Epoch [766/1000], Loss: 0.3242\n",
      "Epoch [767/1000], Loss: 0.3234\n",
      "Epoch [768/1000], Loss: 0.3228\n",
      "Epoch [769/1000], Loss: 0.3261\n",
      "Epoch [770/1000], Loss: 0.3252\n",
      "Epoch [771/1000], Loss: 0.3263\n",
      "Epoch [772/1000], Loss: 0.3236\n",
      "Epoch [773/1000], Loss: 0.3264\n",
      "Epoch [774/1000], Loss: 0.3248\n",
      "Epoch [775/1000], Loss: 0.3263\n",
      "Epoch [776/1000], Loss: 0.3245\n",
      "Epoch [777/1000], Loss: 0.3264\n",
      "Epoch [778/1000], Loss: 0.3257\n",
      "Epoch [779/1000], Loss: 0.3224\n",
      "Epoch [780/1000], Loss: 0.3248\n",
      "Epoch [781/1000], Loss: 0.3238\n",
      "Epoch [782/1000], Loss: 0.3246\n",
      "Epoch [783/1000], Loss: 0.3245\n",
      "Epoch [784/1000], Loss: 0.3251\n",
      "Epoch [785/1000], Loss: 0.3235\n",
      "Epoch [786/1000], Loss: 0.3258\n",
      "Epoch [787/1000], Loss: 0.3245\n",
      "Epoch [788/1000], Loss: 0.3222\n",
      "Epoch [789/1000], Loss: 0.3226\n",
      "Epoch [790/1000], Loss: 0.3230\n",
      "Epoch [791/1000], Loss: 0.3236\n",
      "Epoch [792/1000], Loss: 0.3236\n",
      "Epoch [793/1000], Loss: 0.3241\n",
      "Epoch [794/1000], Loss: 0.3230\n",
      "Epoch [795/1000], Loss: 0.3235\n",
      "Epoch [796/1000], Loss: 0.3247\n",
      "Epoch [797/1000], Loss: 0.3261\n",
      "Epoch [798/1000], Loss: 0.3237\n",
      "Epoch [799/1000], Loss: 0.3222\n",
      "Epoch [800/1000], Loss: 0.3264\n",
      "Epoch [801/1000], Loss: 0.3220\n",
      "Epoch [802/1000], Loss: 0.3242\n",
      "Epoch [803/1000], Loss: 0.3223\n",
      "Epoch [804/1000], Loss: 0.3252\n",
      "Epoch [805/1000], Loss: 0.3262\n",
      "Epoch [806/1000], Loss: 0.3239\n",
      "Epoch [807/1000], Loss: 0.3258\n",
      "Epoch [808/1000], Loss: 0.3254\n",
      "Epoch [809/1000], Loss: 0.3227\n",
      "Epoch [810/1000], Loss: 0.3225\n",
      "Epoch [811/1000], Loss: 0.3249\n",
      "Epoch [812/1000], Loss: 0.3254\n",
      "Epoch [813/1000], Loss: 0.3254\n",
      "Epoch [814/1000], Loss: 0.3225\n",
      "Epoch [815/1000], Loss: 0.3248\n",
      "Epoch [816/1000], Loss: 0.3258\n",
      "Epoch [817/1000], Loss: 0.3246\n",
      "Epoch [818/1000], Loss: 0.3230\n",
      "Epoch [819/1000], Loss: 0.3253\n",
      "Epoch [820/1000], Loss: 0.3228\n",
      "Epoch [821/1000], Loss: 0.3252\n",
      "Epoch [822/1000], Loss: 0.3240\n",
      "Epoch [823/1000], Loss: 0.3234\n",
      "Epoch [824/1000], Loss: 0.3237\n",
      "Epoch [825/1000], Loss: 0.3243\n",
      "Epoch [826/1000], Loss: 0.3235\n",
      "Epoch [827/1000], Loss: 0.3253\n",
      "Epoch [828/1000], Loss: 0.3243\n",
      "Epoch [829/1000], Loss: 0.3240\n",
      "Epoch [830/1000], Loss: 0.3250\n",
      "Epoch [831/1000], Loss: 0.3230\n",
      "Epoch [832/1000], Loss: 0.3250\n",
      "Epoch [833/1000], Loss: 0.3242\n",
      "Epoch [834/1000], Loss: 0.3233\n",
      "Epoch [835/1000], Loss: 0.3232\n",
      "Epoch [836/1000], Loss: 0.3227\n",
      "Epoch [837/1000], Loss: 0.3257\n",
      "Epoch [838/1000], Loss: 0.3251\n",
      "Epoch [839/1000], Loss: 0.3263\n",
      "Epoch [840/1000], Loss: 0.3250\n",
      "Epoch [841/1000], Loss: 0.3264\n",
      "Epoch [842/1000], Loss: 0.3247\n",
      "Epoch [843/1000], Loss: 0.3246\n",
      "Epoch [844/1000], Loss: 0.3261\n",
      "Epoch [845/1000], Loss: 0.3252\n",
      "Epoch [846/1000], Loss: 0.3256\n",
      "Epoch [847/1000], Loss: 0.3280\n",
      "Epoch [848/1000], Loss: 0.3260\n",
      "Epoch [849/1000], Loss: 0.3258\n",
      "Epoch [850/1000], Loss: 0.3247\n",
      "Epoch [851/1000], Loss: 0.3259\n",
      "Epoch [852/1000], Loss: 0.3227\n",
      "Epoch [853/1000], Loss: 0.3247\n",
      "Epoch [854/1000], Loss: 0.3244\n",
      "Epoch [855/1000], Loss: 0.3251\n",
      "Epoch [856/1000], Loss: 0.3243\n",
      "Epoch [857/1000], Loss: 0.3240\n",
      "Epoch [858/1000], Loss: 0.3231\n",
      "Epoch [859/1000], Loss: 0.3269\n",
      "Epoch [860/1000], Loss: 0.3251\n",
      "Epoch [861/1000], Loss: 0.3238\n",
      "Epoch [862/1000], Loss: 0.3233\n",
      "Epoch [863/1000], Loss: 0.3238\n",
      "Epoch [864/1000], Loss: 0.3252\n",
      "Epoch [865/1000], Loss: 0.3256\n",
      "Epoch [866/1000], Loss: 0.3256\n",
      "Epoch [867/1000], Loss: 0.3217\n",
      "Epoch [868/1000], Loss: 0.3259\n",
      "Epoch [869/1000], Loss: 0.3243\n",
      "Epoch [870/1000], Loss: 0.3261\n",
      "Epoch [871/1000], Loss: 0.3242\n",
      "Epoch [872/1000], Loss: 0.3243\n",
      "Epoch [873/1000], Loss: 0.3251\n",
      "Epoch [874/1000], Loss: 0.3236\n",
      "Epoch [875/1000], Loss: 0.3239\n",
      "Epoch [876/1000], Loss: 0.3240\n",
      "Epoch [877/1000], Loss: 0.3249\n",
      "Epoch [878/1000], Loss: 0.3246\n",
      "Epoch [879/1000], Loss: 0.3238\n",
      "Epoch [880/1000], Loss: 0.3230\n",
      "Epoch [881/1000], Loss: 0.3256\n",
      "Epoch [882/1000], Loss: 0.3240\n",
      "Epoch [883/1000], Loss: 0.3263\n",
      "Epoch [884/1000], Loss: 0.3235\n",
      "Epoch [885/1000], Loss: 0.3240\n",
      "Epoch [886/1000], Loss: 0.3229\n",
      "Epoch [887/1000], Loss: 0.3237\n",
      "Epoch [888/1000], Loss: 0.3269\n",
      "Epoch [889/1000], Loss: 0.3233\n",
      "Epoch [890/1000], Loss: 0.3241\n",
      "Epoch [891/1000], Loss: 0.3240\n",
      "Epoch [892/1000], Loss: 0.3235\n",
      "Epoch [893/1000], Loss: 0.3233\n",
      "Epoch [894/1000], Loss: 0.3246\n",
      "Epoch [895/1000], Loss: 0.3221\n",
      "Epoch [896/1000], Loss: 0.3264\n",
      "Epoch [897/1000], Loss: 0.3245\n",
      "Epoch [898/1000], Loss: 0.3229\n",
      "Epoch [899/1000], Loss: 0.3246\n",
      "Epoch [900/1000], Loss: 0.3236\n",
      "Epoch [901/1000], Loss: 0.3248\n",
      "Epoch [902/1000], Loss: 0.3228\n",
      "Epoch [903/1000], Loss: 0.3236\n",
      "Epoch [904/1000], Loss: 0.3250\n",
      "Epoch [905/1000], Loss: 0.3247\n",
      "Epoch [906/1000], Loss: 0.3222\n",
      "Epoch [907/1000], Loss: 0.3225\n",
      "Epoch [908/1000], Loss: 0.3238\n",
      "Epoch [909/1000], Loss: 0.3234\n",
      "Epoch [910/1000], Loss: 0.3227\n",
      "Epoch [911/1000], Loss: 0.3252\n",
      "Epoch [912/1000], Loss: 0.3254\n",
      "Epoch [913/1000], Loss: 0.3247\n",
      "Epoch [914/1000], Loss: 0.3257\n",
      "Epoch [915/1000], Loss: 0.3242\n",
      "Epoch [916/1000], Loss: 0.3261\n",
      "Epoch [917/1000], Loss: 0.3235\n",
      "Epoch [918/1000], Loss: 0.3225\n",
      "Epoch [919/1000], Loss: 0.3240\n",
      "Epoch [920/1000], Loss: 0.3241\n",
      "Epoch [921/1000], Loss: 0.3237\n",
      "Epoch [922/1000], Loss: 0.3258\n",
      "Epoch [923/1000], Loss: 0.3246\n",
      "Epoch [924/1000], Loss: 0.3243\n",
      "Epoch [925/1000], Loss: 0.3226\n",
      "Epoch [926/1000], Loss: 0.3253\n",
      "Epoch [927/1000], Loss: 0.3231\n",
      "Epoch [928/1000], Loss: 0.3240\n",
      "Epoch [929/1000], Loss: 0.3264\n",
      "Epoch [930/1000], Loss: 0.3238\n",
      "Epoch [931/1000], Loss: 0.3245\n",
      "Epoch [932/1000], Loss: 0.3236\n",
      "Epoch [933/1000], Loss: 0.3259\n",
      "Epoch [934/1000], Loss: 0.3264\n",
      "Epoch [935/1000], Loss: 0.3244\n",
      "Epoch [936/1000], Loss: 0.3234\n",
      "Epoch [937/1000], Loss: 0.3250\n",
      "Epoch [938/1000], Loss: 0.3249\n",
      "Epoch [939/1000], Loss: 0.3246\n",
      "Epoch [940/1000], Loss: 0.3264\n",
      "Epoch [941/1000], Loss: 0.3249\n",
      "Epoch [942/1000], Loss: 0.3238\n",
      "Epoch [943/1000], Loss: 0.3242\n",
      "Epoch [944/1000], Loss: 0.3239\n",
      "Epoch [945/1000], Loss: 0.3248\n",
      "Epoch [946/1000], Loss: 0.3243\n",
      "Epoch [947/1000], Loss: 0.3251\n",
      "Epoch [948/1000], Loss: 0.3241\n",
      "Epoch [949/1000], Loss: 0.3243\n",
      "Epoch [950/1000], Loss: 0.3262\n",
      "Epoch [951/1000], Loss: 0.3244\n",
      "Epoch [952/1000], Loss: 0.3223\n",
      "Epoch [953/1000], Loss: 0.3247\n",
      "Epoch [954/1000], Loss: 0.3235\n",
      "Epoch [955/1000], Loss: 0.3264\n",
      "Epoch [956/1000], Loss: 0.3248\n",
      "Epoch [957/1000], Loss: 0.3237\n",
      "Epoch [958/1000], Loss: 0.3250\n",
      "Epoch [959/1000], Loss: 0.3245\n",
      "Epoch [960/1000], Loss: 0.3253\n",
      "Epoch [961/1000], Loss: 0.3231\n",
      "Epoch [962/1000], Loss: 0.3255\n",
      "Epoch [963/1000], Loss: 0.3257\n",
      "Epoch [964/1000], Loss: 0.3270\n",
      "Epoch [965/1000], Loss: 0.3242\n",
      "Epoch [966/1000], Loss: 0.3244\n",
      "Epoch [967/1000], Loss: 0.3238\n",
      "Epoch [968/1000], Loss: 0.3237\n",
      "Epoch [969/1000], Loss: 0.3242\n",
      "Epoch [970/1000], Loss: 0.3252\n",
      "Epoch [971/1000], Loss: 0.3233\n",
      "Epoch [972/1000], Loss: 0.3247\n",
      "Epoch [973/1000], Loss: 0.3235\n",
      "Epoch [974/1000], Loss: 0.3250\n",
      "Epoch [975/1000], Loss: 0.3261\n",
      "Epoch [976/1000], Loss: 0.3249\n",
      "Epoch [977/1000], Loss: 0.3254\n",
      "Epoch [978/1000], Loss: 0.3243\n",
      "Epoch [979/1000], Loss: 0.3225\n",
      "Epoch [980/1000], Loss: 0.3263\n",
      "Epoch [981/1000], Loss: 0.3237\n",
      "Epoch [982/1000], Loss: 0.3236\n",
      "Epoch [983/1000], Loss: 0.3257\n",
      "Epoch [984/1000], Loss: 0.3233\n",
      "Epoch [985/1000], Loss: 0.3237\n",
      "Epoch [986/1000], Loss: 0.3251\n",
      "Epoch [987/1000], Loss: 0.3266\n",
      "Epoch [988/1000], Loss: 0.3267\n",
      "Epoch [989/1000], Loss: 0.3250\n",
      "Epoch [990/1000], Loss: 0.3228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [991/1000], Loss: 0.3269\n",
      "Epoch [992/1000], Loss: 0.3262\n",
      "Epoch [993/1000], Loss: 0.3246\n",
      "Epoch [994/1000], Loss: 0.3230\n",
      "Epoch [995/1000], Loss: 0.3250\n",
      "Epoch [996/1000], Loss: 0.3247\n",
      "Epoch [997/1000], Loss: 0.3244\n",
      "Epoch [998/1000], Loss: 0.3254\n",
      "Epoch [999/1000], Loss: 0.3226\n",
      "Epoch [1000/1000], Loss: 0.3230\n",
      "Accuracy of the network on the 1000 validation data: 65.70 %\n",
      "Training model with batch_size: 107, lr :0.1, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.4314\n",
      "Epoch [2/1000], Loss: 0.4091\n",
      "Epoch [3/1000], Loss: 0.4913\n",
      "Epoch [4/1000], Loss: 0.5072\n",
      "Epoch [5/1000], Loss: 0.5101\n",
      "Epoch [6/1000], Loss: 0.5093\n",
      "Epoch [7/1000], Loss: 0.5080\n",
      "Epoch [8/1000], Loss: 0.5105\n",
      "Epoch [9/1000], Loss: 0.5093\n",
      "Epoch [10/1000], Loss: 0.5105\n",
      "Epoch [11/1000], Loss: 0.5089\n",
      "Epoch [12/1000], Loss: 0.5064\n",
      "Epoch [13/1000], Loss: 0.5076\n",
      "Epoch [14/1000], Loss: 0.5093\n",
      "Epoch [15/1000], Loss: 0.5056\n",
      "Epoch [16/1000], Loss: 0.5080\n",
      "Epoch [17/1000], Loss: 0.5076\n",
      "Epoch [18/1000], Loss: 0.5085\n",
      "Epoch [19/1000], Loss: 0.5097\n",
      "Epoch [20/1000], Loss: 0.5080\n",
      "Epoch [21/1000], Loss: 0.5080\n",
      "Epoch [22/1000], Loss: 0.5068\n",
      "Epoch [23/1000], Loss: 0.5080\n",
      "Epoch [24/1000], Loss: 0.5109\n",
      "Epoch [25/1000], Loss: 0.5097\n",
      "Epoch [26/1000], Loss: 0.5076\n",
      "Epoch [27/1000], Loss: 0.5068\n",
      "Epoch [28/1000], Loss: 0.5085\n",
      "Epoch [29/1000], Loss: 0.5068\n",
      "Epoch [30/1000], Loss: 0.5085\n",
      "Epoch [31/1000], Loss: 0.5085\n",
      "Epoch [32/1000], Loss: 0.5076\n",
      "Epoch [33/1000], Loss: 0.5076\n",
      "Epoch [34/1000], Loss: 0.5085\n",
      "Epoch [35/1000], Loss: 0.5080\n",
      "Epoch [36/1000], Loss: 0.5056\n",
      "Epoch [37/1000], Loss: 0.5080\n",
      "Epoch [38/1000], Loss: 0.5080\n",
      "Epoch [39/1000], Loss: 0.5080\n",
      "Epoch [40/1000], Loss: 0.5076\n",
      "Epoch [41/1000], Loss: 0.5085\n",
      "Epoch [42/1000], Loss: 0.5113\n",
      "Epoch [43/1000], Loss: 0.5060\n",
      "Epoch [44/1000], Loss: 0.5093\n",
      "Epoch [45/1000], Loss: 0.5080\n",
      "Epoch [46/1000], Loss: 0.5060\n",
      "Epoch [47/1000], Loss: 0.5072\n",
      "Epoch [48/1000], Loss: 0.5089\n",
      "Epoch [49/1000], Loss: 0.5072\n",
      "Epoch [50/1000], Loss: 0.5085\n",
      "Epoch [51/1000], Loss: 0.5072\n",
      "Epoch [52/1000], Loss: 0.5089\n",
      "Epoch [53/1000], Loss: 0.5101\n",
      "Epoch [54/1000], Loss: 0.5080\n",
      "Epoch [55/1000], Loss: 0.5093\n",
      "Epoch [56/1000], Loss: 0.5089\n",
      "Epoch [57/1000], Loss: 0.5105\n",
      "Epoch [58/1000], Loss: 0.5093\n",
      "Epoch [59/1000], Loss: 0.5080\n",
      "Epoch [60/1000], Loss: 0.5101\n",
      "Epoch [61/1000], Loss: 0.5097\n",
      "Epoch [62/1000], Loss: 0.5072\n",
      "Epoch [63/1000], Loss: 0.5072\n",
      "Epoch [64/1000], Loss: 0.5101\n",
      "Epoch [65/1000], Loss: 0.5085\n",
      "Epoch [66/1000], Loss: 0.5085\n",
      "Epoch [67/1000], Loss: 0.5085\n",
      "Epoch [68/1000], Loss: 0.5076\n",
      "Epoch [69/1000], Loss: 0.5085\n",
      "Epoch [70/1000], Loss: 0.5076\n",
      "Epoch [71/1000], Loss: 0.5076\n",
      "Epoch [72/1000], Loss: 0.5085\n",
      "Epoch [73/1000], Loss: 0.5085\n",
      "Epoch [74/1000], Loss: 0.5097\n",
      "Epoch [75/1000], Loss: 0.5101\n",
      "Epoch [76/1000], Loss: 0.5072\n",
      "Epoch [77/1000], Loss: 0.5076\n",
      "Epoch [78/1000], Loss: 0.5085\n",
      "Epoch [79/1000], Loss: 0.5093\n",
      "Epoch [80/1000], Loss: 0.5109\n",
      "Epoch [81/1000], Loss: 0.5072\n",
      "Epoch [82/1000], Loss: 0.5097\n",
      "Epoch [83/1000], Loss: 0.5109\n",
      "Epoch [84/1000], Loss: 0.5072\n",
      "Epoch [85/1000], Loss: 0.5097\n",
      "Epoch [86/1000], Loss: 0.5072\n",
      "Epoch [87/1000], Loss: 0.5080\n",
      "Epoch [88/1000], Loss: 0.5097\n",
      "Epoch [89/1000], Loss: 0.5085\n",
      "Epoch [90/1000], Loss: 0.5085\n",
      "Epoch [91/1000], Loss: 0.5072\n",
      "Epoch [92/1000], Loss: 0.5072\n",
      "Epoch [93/1000], Loss: 0.5085\n",
      "Epoch [94/1000], Loss: 0.5080\n",
      "Epoch [95/1000], Loss: 0.5076\n",
      "Epoch [96/1000], Loss: 0.5089\n",
      "Epoch [97/1000], Loss: 0.5080\n",
      "Epoch [98/1000], Loss: 0.5068\n",
      "Epoch [99/1000], Loss: 0.5101\n",
      "Epoch [100/1000], Loss: 0.5089\n",
      "Epoch [101/1000], Loss: 0.5064\n",
      "Epoch [102/1000], Loss: 0.5064\n",
      "Epoch [103/1000], Loss: 0.5080\n",
      "Epoch [104/1000], Loss: 0.5072\n",
      "Epoch [105/1000], Loss: 0.5044\n",
      "Epoch [106/1000], Loss: 0.5093\n",
      "Epoch [107/1000], Loss: 0.5072\n",
      "Epoch [108/1000], Loss: 0.5064\n",
      "Epoch [109/1000], Loss: 0.5101\n",
      "Epoch [110/1000], Loss: 0.5093\n",
      "Epoch [111/1000], Loss: 0.5080\n",
      "Epoch [112/1000], Loss: 0.5080\n",
      "Epoch [113/1000], Loss: 0.5093\n",
      "Epoch [114/1000], Loss: 0.5080\n",
      "Epoch [115/1000], Loss: 0.5060\n",
      "Epoch [116/1000], Loss: 0.5080\n",
      "Epoch [117/1000], Loss: 0.5080\n",
      "Epoch [118/1000], Loss: 0.5076\n",
      "Epoch [119/1000], Loss: 0.5072\n",
      "Epoch [120/1000], Loss: 0.5080\n",
      "Epoch [121/1000], Loss: 0.5093\n",
      "Epoch [122/1000], Loss: 0.5089\n",
      "Epoch [123/1000], Loss: 0.5064\n",
      "Epoch [124/1000], Loss: 0.5085\n",
      "Epoch [125/1000], Loss: 0.5089\n",
      "Epoch [126/1000], Loss: 0.5089\n",
      "Epoch [127/1000], Loss: 0.5097\n",
      "Epoch [128/1000], Loss: 0.5072\n",
      "Epoch [129/1000], Loss: 0.5093\n",
      "Epoch [130/1000], Loss: 0.5080\n",
      "Epoch [131/1000], Loss: 0.5080\n",
      "Epoch [132/1000], Loss: 0.5105\n",
      "Epoch [133/1000], Loss: 0.5072\n",
      "Epoch [134/1000], Loss: 0.5093\n",
      "Epoch [135/1000], Loss: 0.5085\n",
      "Epoch [136/1000], Loss: 0.5089\n",
      "Epoch [137/1000], Loss: 0.5068\n",
      "Epoch [138/1000], Loss: 0.5093\n",
      "Epoch [139/1000], Loss: 0.5101\n",
      "Epoch [140/1000], Loss: 0.5076\n",
      "Epoch [141/1000], Loss: 0.5056\n",
      "Epoch [142/1000], Loss: 0.5085\n",
      "Epoch [143/1000], Loss: 0.5089\n",
      "Epoch [144/1000], Loss: 0.5101\n",
      "Epoch [145/1000], Loss: 0.5076\n",
      "Epoch [146/1000], Loss: 0.5068\n",
      "Epoch [147/1000], Loss: 0.5080\n",
      "Epoch [148/1000], Loss: 0.5089\n",
      "Epoch [149/1000], Loss: 0.5068\n",
      "Epoch [150/1000], Loss: 0.5072\n",
      "Epoch [151/1000], Loss: 0.5089\n",
      "Epoch [152/1000], Loss: 0.5068\n",
      "Epoch [153/1000], Loss: 0.5089\n",
      "Epoch [154/1000], Loss: 0.5080\n",
      "Epoch [155/1000], Loss: 0.5101\n",
      "Epoch [156/1000], Loss: 0.5085\n",
      "Epoch [157/1000], Loss: 0.5080\n",
      "Epoch [158/1000], Loss: 0.5085\n",
      "Epoch [159/1000], Loss: 0.5089\n",
      "Epoch [160/1000], Loss: 0.5060\n",
      "Epoch [161/1000], Loss: 0.5072\n",
      "Epoch [162/1000], Loss: 0.5072\n",
      "Epoch [163/1000], Loss: 0.5089\n",
      "Epoch [164/1000], Loss: 0.5085\n",
      "Epoch [165/1000], Loss: 0.5064\n",
      "Epoch [166/1000], Loss: 0.5089\n",
      "Epoch [167/1000], Loss: 0.5080\n",
      "Epoch [168/1000], Loss: 0.5089\n",
      "Epoch [169/1000], Loss: 0.5072\n",
      "Epoch [170/1000], Loss: 0.5072\n",
      "Epoch [171/1000], Loss: 0.5080\n",
      "Epoch [172/1000], Loss: 0.5085\n",
      "Epoch [173/1000], Loss: 0.5080\n",
      "Epoch [174/1000], Loss: 0.5105\n",
      "Epoch [175/1000], Loss: 0.5093\n",
      "Epoch [176/1000], Loss: 0.5085\n",
      "Epoch [177/1000], Loss: 0.5048\n",
      "Epoch [178/1000], Loss: 0.5093\n",
      "Epoch [179/1000], Loss: 0.5076\n",
      "Epoch [180/1000], Loss: 0.5072\n",
      "Epoch [181/1000], Loss: 0.5089\n",
      "Epoch [182/1000], Loss: 0.5080\n",
      "Epoch [183/1000], Loss: 0.5105\n",
      "Epoch [184/1000], Loss: 0.5076\n",
      "Epoch [185/1000], Loss: 0.5089\n",
      "Epoch [186/1000], Loss: 0.5076\n",
      "Epoch [187/1000], Loss: 0.5068\n",
      "Epoch [188/1000], Loss: 0.5052\n",
      "Epoch [189/1000], Loss: 0.5089\n",
      "Epoch [190/1000], Loss: 0.5093\n",
      "Epoch [191/1000], Loss: 0.5101\n",
      "Epoch [192/1000], Loss: 0.5097\n",
      "Epoch [193/1000], Loss: 0.5085\n",
      "Epoch [194/1000], Loss: 0.5064\n",
      "Epoch [195/1000], Loss: 0.5109\n",
      "Epoch [196/1000], Loss: 0.5085\n",
      "Epoch [197/1000], Loss: 0.5068\n",
      "Epoch [198/1000], Loss: 0.5101\n",
      "Epoch [199/1000], Loss: 0.5085\n",
      "Epoch [200/1000], Loss: 0.5072\n",
      "Epoch [201/1000], Loss: 0.5080\n",
      "Epoch [202/1000], Loss: 0.5076\n",
      "Epoch [203/1000], Loss: 0.5105\n",
      "Epoch [204/1000], Loss: 0.5068\n",
      "Epoch [205/1000], Loss: 0.5064\n",
      "Epoch [206/1000], Loss: 0.5080\n",
      "Epoch [207/1000], Loss: 0.5097\n",
      "Epoch [208/1000], Loss: 0.5080\n",
      "Epoch [209/1000], Loss: 0.5080\n",
      "Epoch [210/1000], Loss: 0.5093\n",
      "Epoch [211/1000], Loss: 0.5085\n",
      "Epoch [212/1000], Loss: 0.5068\n",
      "Epoch [213/1000], Loss: 0.5072\n",
      "Epoch [214/1000], Loss: 0.5072\n",
      "Epoch [215/1000], Loss: 0.5089\n",
      "Epoch [216/1000], Loss: 0.5072\n",
      "Epoch [217/1000], Loss: 0.5109\n",
      "Epoch [218/1000], Loss: 0.5072\n",
      "Epoch [219/1000], Loss: 0.5080\n",
      "Epoch [220/1000], Loss: 0.5080\n",
      "Epoch [221/1000], Loss: 0.5093\n",
      "Epoch [222/1000], Loss: 0.5085\n",
      "Epoch [223/1000], Loss: 0.5097\n",
      "Epoch [224/1000], Loss: 0.5089\n",
      "Epoch [225/1000], Loss: 0.5080\n",
      "Epoch [226/1000], Loss: 0.5080\n",
      "Epoch [227/1000], Loss: 0.5101\n",
      "Epoch [228/1000], Loss: 0.5085\n",
      "Epoch [229/1000], Loss: 0.5052\n",
      "Epoch [230/1000], Loss: 0.5089\n",
      "Epoch [231/1000], Loss: 0.5101\n",
      "Epoch [232/1000], Loss: 0.5064\n",
      "Epoch [233/1000], Loss: 0.5093\n",
      "Epoch [234/1000], Loss: 0.5097\n",
      "Epoch [235/1000], Loss: 0.5097\n",
      "Epoch [236/1000], Loss: 0.5056\n",
      "Epoch [237/1000], Loss: 0.5060\n",
      "Epoch [238/1000], Loss: 0.5097\n",
      "Epoch [239/1000], Loss: 0.5080\n",
      "Epoch [240/1000], Loss: 0.5085\n",
      "Epoch [241/1000], Loss: 0.5076\n",
      "Epoch [242/1000], Loss: 0.5076\n",
      "Epoch [243/1000], Loss: 0.5089\n",
      "Epoch [244/1000], Loss: 0.5097\n",
      "Epoch [245/1000], Loss: 0.5101\n",
      "Epoch [246/1000], Loss: 0.5068\n",
      "Epoch [247/1000], Loss: 0.5072\n",
      "Epoch [248/1000], Loss: 0.5068\n",
      "Epoch [249/1000], Loss: 0.5056\n",
      "Epoch [250/1000], Loss: 0.5076\n",
      "Epoch [251/1000], Loss: 0.5080\n",
      "Epoch [252/1000], Loss: 0.5085\n",
      "Epoch [253/1000], Loss: 0.5097\n",
      "Epoch [254/1000], Loss: 0.5052\n",
      "Epoch [255/1000], Loss: 0.5076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [256/1000], Loss: 0.5093\n",
      "Epoch [257/1000], Loss: 0.5076\n",
      "Epoch [258/1000], Loss: 0.5052\n",
      "Epoch [259/1000], Loss: 0.5072\n",
      "Epoch [260/1000], Loss: 0.5080\n",
      "Epoch [261/1000], Loss: 0.5097\n",
      "Epoch [262/1000], Loss: 0.5085\n",
      "Epoch [263/1000], Loss: 0.5056\n",
      "Epoch [264/1000], Loss: 0.5076\n",
      "Epoch [265/1000], Loss: 0.5093\n",
      "Epoch [266/1000], Loss: 0.5093\n",
      "Epoch [267/1000], Loss: 0.5068\n",
      "Epoch [268/1000], Loss: 0.5064\n",
      "Epoch [269/1000], Loss: 0.5076\n",
      "Epoch [270/1000], Loss: 0.5085\n",
      "Epoch [271/1000], Loss: 0.5064\n",
      "Epoch [272/1000], Loss: 0.5113\n",
      "Epoch [273/1000], Loss: 0.5080\n",
      "Epoch [274/1000], Loss: 0.5101\n",
      "Epoch [275/1000], Loss: 0.5101\n",
      "Epoch [276/1000], Loss: 0.5085\n",
      "Epoch [277/1000], Loss: 0.5064\n",
      "Epoch [278/1000], Loss: 0.5105\n",
      "Epoch [279/1000], Loss: 0.5085\n",
      "Epoch [280/1000], Loss: 0.5052\n",
      "Epoch [281/1000], Loss: 0.5117\n",
      "Epoch [282/1000], Loss: 0.5105\n",
      "Epoch [283/1000], Loss: 0.5076\n",
      "Epoch [284/1000], Loss: 0.5093\n",
      "Epoch [285/1000], Loss: 0.5085\n",
      "Epoch [286/1000], Loss: 0.5080\n",
      "Epoch [287/1000], Loss: 0.5076\n",
      "Epoch [288/1000], Loss: 0.5089\n",
      "Epoch [289/1000], Loss: 0.5101\n",
      "Epoch [290/1000], Loss: 0.5080\n",
      "Epoch [291/1000], Loss: 0.5072\n",
      "Epoch [292/1000], Loss: 0.5076\n",
      "Epoch [293/1000], Loss: 0.5064\n",
      "Epoch [294/1000], Loss: 0.5064\n",
      "Epoch [295/1000], Loss: 0.5097\n",
      "Epoch [296/1000], Loss: 0.5085\n",
      "Epoch [297/1000], Loss: 0.5101\n",
      "Epoch [298/1000], Loss: 0.5032\n",
      "Epoch [299/1000], Loss: 0.5068\n",
      "Epoch [300/1000], Loss: 0.5044\n",
      "Epoch [301/1000], Loss: 0.5076\n",
      "Epoch [302/1000], Loss: 0.5085\n",
      "Epoch [303/1000], Loss: 0.5072\n",
      "Epoch [304/1000], Loss: 0.5072\n",
      "Epoch [305/1000], Loss: 0.5072\n",
      "Epoch [306/1000], Loss: 0.5068\n",
      "Epoch [307/1000], Loss: 0.5076\n",
      "Epoch [308/1000], Loss: 0.5097\n",
      "Epoch [309/1000], Loss: 0.5085\n",
      "Epoch [310/1000], Loss: 0.5072\n",
      "Epoch [311/1000], Loss: 0.5085\n",
      "Epoch [312/1000], Loss: 0.5085\n",
      "Epoch [313/1000], Loss: 0.5085\n",
      "Epoch [314/1000], Loss: 0.5076\n",
      "Epoch [315/1000], Loss: 0.5068\n",
      "Epoch [316/1000], Loss: 0.5097\n",
      "Epoch [317/1000], Loss: 0.5085\n",
      "Epoch [318/1000], Loss: 0.5076\n",
      "Epoch [319/1000], Loss: 0.5097\n",
      "Epoch [320/1000], Loss: 0.5072\n",
      "Epoch [321/1000], Loss: 0.5052\n",
      "Epoch [322/1000], Loss: 0.5072\n",
      "Epoch [323/1000], Loss: 0.5076\n",
      "Epoch [324/1000], Loss: 0.5085\n",
      "Epoch [325/1000], Loss: 0.5093\n",
      "Epoch [326/1000], Loss: 0.5064\n",
      "Epoch [327/1000], Loss: 0.5085\n",
      "Epoch [328/1000], Loss: 0.5080\n",
      "Epoch [329/1000], Loss: 0.5089\n",
      "Epoch [330/1000], Loss: 0.5085\n",
      "Epoch [331/1000], Loss: 0.5056\n",
      "Epoch [332/1000], Loss: 0.5085\n",
      "Epoch [333/1000], Loss: 0.5097\n",
      "Epoch [334/1000], Loss: 0.5085\n",
      "Epoch [335/1000], Loss: 0.5093\n",
      "Epoch [336/1000], Loss: 0.5076\n",
      "Epoch [337/1000], Loss: 0.5076\n",
      "Epoch [338/1000], Loss: 0.5101\n",
      "Epoch [339/1000], Loss: 0.5076\n",
      "Epoch [340/1000], Loss: 0.5121\n",
      "Epoch [341/1000], Loss: 0.5060\n",
      "Epoch [342/1000], Loss: 0.5068\n",
      "Epoch [343/1000], Loss: 0.5093\n",
      "Epoch [344/1000], Loss: 0.5097\n",
      "Epoch [345/1000], Loss: 0.5076\n",
      "Epoch [346/1000], Loss: 0.5080\n",
      "Epoch [347/1000], Loss: 0.5080\n",
      "Epoch [348/1000], Loss: 0.5085\n",
      "Epoch [349/1000], Loss: 0.5068\n",
      "Epoch [350/1000], Loss: 0.5085\n",
      "Epoch [351/1000], Loss: 0.5093\n",
      "Epoch [352/1000], Loss: 0.5072\n",
      "Epoch [353/1000], Loss: 0.5101\n",
      "Epoch [354/1000], Loss: 0.5060\n",
      "Epoch [355/1000], Loss: 0.5076\n",
      "Epoch [356/1000], Loss: 0.5068\n",
      "Epoch [357/1000], Loss: 0.5093\n",
      "Epoch [358/1000], Loss: 0.5101\n",
      "Epoch [359/1000], Loss: 0.5072\n",
      "Epoch [360/1000], Loss: 0.5093\n",
      "Epoch [361/1000], Loss: 0.5089\n",
      "Epoch [362/1000], Loss: 0.5076\n",
      "Epoch [363/1000], Loss: 0.5068\n",
      "Epoch [364/1000], Loss: 0.5080\n",
      "Epoch [365/1000], Loss: 0.5080\n",
      "Epoch [366/1000], Loss: 0.5085\n",
      "Epoch [367/1000], Loss: 0.5080\n",
      "Epoch [368/1000], Loss: 0.5080\n",
      "Epoch [369/1000], Loss: 0.5093\n",
      "Epoch [370/1000], Loss: 0.5097\n",
      "Epoch [371/1000], Loss: 0.5089\n",
      "Epoch [372/1000], Loss: 0.5089\n",
      "Epoch [373/1000], Loss: 0.5089\n",
      "Epoch [374/1000], Loss: 0.5101\n",
      "Epoch [375/1000], Loss: 0.5080\n",
      "Epoch [376/1000], Loss: 0.5085\n",
      "Epoch [377/1000], Loss: 0.5085\n",
      "Epoch [378/1000], Loss: 0.5089\n",
      "Epoch [379/1000], Loss: 0.5056\n",
      "Epoch [380/1000], Loss: 0.5101\n",
      "Epoch [381/1000], Loss: 0.5085\n",
      "Epoch [382/1000], Loss: 0.5097\n",
      "Epoch [383/1000], Loss: 0.5076\n",
      "Epoch [384/1000], Loss: 0.5060\n",
      "Epoch [385/1000], Loss: 0.5105\n",
      "Epoch [386/1000], Loss: 0.5072\n",
      "Epoch [387/1000], Loss: 0.5093\n",
      "Epoch [388/1000], Loss: 0.5068\n",
      "Epoch [389/1000], Loss: 0.5076\n",
      "Epoch [390/1000], Loss: 0.5097\n",
      "Epoch [391/1000], Loss: 0.5068\n",
      "Epoch [392/1000], Loss: 0.5076\n",
      "Epoch [393/1000], Loss: 0.5060\n",
      "Epoch [394/1000], Loss: 0.5097\n",
      "Epoch [395/1000], Loss: 0.5052\n",
      "Epoch [396/1000], Loss: 0.5105\n",
      "Epoch [397/1000], Loss: 0.5101\n",
      "Epoch [398/1000], Loss: 0.5068\n",
      "Epoch [399/1000], Loss: 0.5089\n",
      "Epoch [400/1000], Loss: 0.5072\n",
      "Epoch [401/1000], Loss: 0.5109\n",
      "Epoch [402/1000], Loss: 0.5105\n",
      "Epoch [403/1000], Loss: 0.5093\n",
      "Epoch [404/1000], Loss: 0.5085\n",
      "Epoch [405/1000], Loss: 0.5093\n",
      "Epoch [406/1000], Loss: 0.5068\n",
      "Epoch [407/1000], Loss: 0.5089\n",
      "Epoch [408/1000], Loss: 0.5076\n",
      "Epoch [409/1000], Loss: 0.5076\n",
      "Epoch [410/1000], Loss: 0.5064\n",
      "Epoch [411/1000], Loss: 0.5089\n",
      "Epoch [412/1000], Loss: 0.5097\n",
      "Epoch [413/1000], Loss: 0.5089\n",
      "Epoch [414/1000], Loss: 0.5085\n",
      "Epoch [415/1000], Loss: 0.5080\n",
      "Epoch [416/1000], Loss: 0.5068\n",
      "Epoch [417/1000], Loss: 0.5109\n",
      "Epoch [418/1000], Loss: 0.5076\n",
      "Epoch [419/1000], Loss: 0.5093\n",
      "Epoch [420/1000], Loss: 0.5068\n",
      "Epoch [421/1000], Loss: 0.5080\n",
      "Epoch [422/1000], Loss: 0.5076\n",
      "Epoch [423/1000], Loss: 0.5056\n",
      "Epoch [424/1000], Loss: 0.5089\n",
      "Epoch [425/1000], Loss: 0.5109\n",
      "Epoch [426/1000], Loss: 0.5068\n",
      "Epoch [427/1000], Loss: 0.5060\n",
      "Epoch [428/1000], Loss: 0.5076\n",
      "Epoch [429/1000], Loss: 0.5064\n",
      "Epoch [430/1000], Loss: 0.5085\n",
      "Epoch [431/1000], Loss: 0.5080\n",
      "Epoch [432/1000], Loss: 0.5085\n",
      "Epoch [433/1000], Loss: 0.5105\n",
      "Epoch [434/1000], Loss: 0.5109\n",
      "Epoch [435/1000], Loss: 0.5089\n",
      "Epoch [436/1000], Loss: 0.5076\n",
      "Epoch [437/1000], Loss: 0.5101\n",
      "Epoch [438/1000], Loss: 0.5076\n",
      "Epoch [439/1000], Loss: 0.5097\n",
      "Epoch [440/1000], Loss: 0.5093\n",
      "Epoch [441/1000], Loss: 0.5085\n",
      "Epoch [442/1000], Loss: 0.5064\n",
      "Epoch [443/1000], Loss: 0.5097\n",
      "Epoch [444/1000], Loss: 0.5093\n",
      "Epoch [445/1000], Loss: 0.5101\n",
      "Epoch [446/1000], Loss: 0.5076\n",
      "Epoch [447/1000], Loss: 0.5080\n",
      "Epoch [448/1000], Loss: 0.5085\n",
      "Epoch [449/1000], Loss: 0.5072\n",
      "Epoch [450/1000], Loss: 0.5080\n",
      "Epoch [451/1000], Loss: 0.5089\n",
      "Epoch [452/1000], Loss: 0.5072\n",
      "Epoch [453/1000], Loss: 0.5068\n",
      "Epoch [454/1000], Loss: 0.5064\n",
      "Epoch [455/1000], Loss: 0.5072\n",
      "Epoch [456/1000], Loss: 0.5072\n",
      "Epoch [457/1000], Loss: 0.5080\n",
      "Epoch [458/1000], Loss: 0.5093\n",
      "Epoch [459/1000], Loss: 0.5085\n",
      "Epoch [460/1000], Loss: 0.5064\n",
      "Epoch [461/1000], Loss: 0.5076\n",
      "Epoch [462/1000], Loss: 0.5093\n",
      "Epoch [463/1000], Loss: 0.5064\n",
      "Epoch [464/1000], Loss: 0.5089\n",
      "Epoch [465/1000], Loss: 0.5072\n",
      "Epoch [466/1000], Loss: 0.5097\n",
      "Epoch [467/1000], Loss: 0.5076\n",
      "Epoch [468/1000], Loss: 0.5089\n",
      "Epoch [469/1000], Loss: 0.5080\n",
      "Epoch [470/1000], Loss: 0.5072\n",
      "Epoch [471/1000], Loss: 0.5072\n",
      "Epoch [472/1000], Loss: 0.5101\n",
      "Epoch [473/1000], Loss: 0.5089\n",
      "Epoch [474/1000], Loss: 0.5072\n",
      "Epoch [475/1000], Loss: 0.5048\n",
      "Epoch [476/1000], Loss: 0.5068\n",
      "Epoch [477/1000], Loss: 0.5076\n",
      "Epoch [478/1000], Loss: 0.5089\n",
      "Epoch [479/1000], Loss: 0.5076\n",
      "Epoch [480/1000], Loss: 0.5064\n",
      "Epoch [481/1000], Loss: 0.5076\n",
      "Epoch [482/1000], Loss: 0.5089\n",
      "Epoch [483/1000], Loss: 0.5085\n",
      "Epoch [484/1000], Loss: 0.5080\n",
      "Epoch [485/1000], Loss: 0.5089\n",
      "Epoch [486/1000], Loss: 0.5080\n",
      "Epoch [487/1000], Loss: 0.5097\n",
      "Epoch [488/1000], Loss: 0.5076\n",
      "Epoch [489/1000], Loss: 0.5089\n",
      "Epoch [490/1000], Loss: 0.5085\n",
      "Epoch [491/1000], Loss: 0.5105\n",
      "Epoch [492/1000], Loss: 0.5085\n",
      "Epoch [493/1000], Loss: 0.5093\n",
      "Epoch [494/1000], Loss: 0.5101\n",
      "Epoch [495/1000], Loss: 0.5076\n",
      "Epoch [496/1000], Loss: 0.5068\n",
      "Epoch [497/1000], Loss: 0.5089\n",
      "Epoch [498/1000], Loss: 0.5076\n",
      "Epoch [499/1000], Loss: 0.5117\n",
      "Epoch [500/1000], Loss: 0.5060\n",
      "Epoch [501/1000], Loss: 0.5060\n",
      "Epoch [502/1000], Loss: 0.5085\n",
      "Epoch [503/1000], Loss: 0.5085\n",
      "Epoch [504/1000], Loss: 0.5064\n",
      "Epoch [505/1000], Loss: 0.5076\n",
      "Epoch [506/1000], Loss: 0.5080\n",
      "Epoch [507/1000], Loss: 0.5076\n",
      "Epoch [508/1000], Loss: 0.5089\n",
      "Epoch [509/1000], Loss: 0.5072\n",
      "Epoch [510/1000], Loss: 0.5085\n",
      "Epoch [511/1000], Loss: 0.5093\n",
      "Epoch [512/1000], Loss: 0.5085\n",
      "Epoch [513/1000], Loss: 0.5068\n",
      "Epoch [514/1000], Loss: 0.5072\n",
      "Epoch [515/1000], Loss: 0.5076\n",
      "Epoch [516/1000], Loss: 0.5072\n",
      "Epoch [517/1000], Loss: 0.5097\n",
      "Epoch [518/1000], Loss: 0.5052\n",
      "Epoch [519/1000], Loss: 0.5072\n",
      "Epoch [520/1000], Loss: 0.5093\n",
      "Epoch [521/1000], Loss: 0.5085\n",
      "Epoch [522/1000], Loss: 0.5093\n",
      "Epoch [523/1000], Loss: 0.5093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [524/1000], Loss: 0.5093\n",
      "Epoch [525/1000], Loss: 0.5085\n",
      "Epoch [526/1000], Loss: 0.5064\n",
      "Epoch [527/1000], Loss: 0.5085\n",
      "Epoch [528/1000], Loss: 0.5072\n",
      "Epoch [529/1000], Loss: 0.5068\n",
      "Epoch [530/1000], Loss: 0.5089\n",
      "Epoch [531/1000], Loss: 0.5093\n",
      "Epoch [532/1000], Loss: 0.5080\n",
      "Epoch [533/1000], Loss: 0.5085\n",
      "Epoch [534/1000], Loss: 0.5085\n",
      "Epoch [535/1000], Loss: 0.5044\n",
      "Epoch [536/1000], Loss: 0.5085\n",
      "Epoch [537/1000], Loss: 0.5068\n",
      "Epoch [538/1000], Loss: 0.5072\n",
      "Epoch [539/1000], Loss: 0.5080\n",
      "Epoch [540/1000], Loss: 0.5068\n",
      "Epoch [541/1000], Loss: 0.5060\n",
      "Epoch [542/1000], Loss: 0.5093\n",
      "Epoch [543/1000], Loss: 0.5068\n",
      "Epoch [544/1000], Loss: 0.5048\n",
      "Epoch [545/1000], Loss: 0.5089\n",
      "Epoch [546/1000], Loss: 0.5101\n",
      "Epoch [547/1000], Loss: 0.5064\n",
      "Epoch [548/1000], Loss: 0.5089\n",
      "Epoch [549/1000], Loss: 0.5093\n",
      "Epoch [550/1000], Loss: 0.5068\n",
      "Epoch [551/1000], Loss: 0.5093\n",
      "Epoch [552/1000], Loss: 0.5093\n",
      "Epoch [553/1000], Loss: 0.5113\n",
      "Epoch [554/1000], Loss: 0.5089\n",
      "Epoch [555/1000], Loss: 0.5072\n",
      "Epoch [556/1000], Loss: 0.5072\n",
      "Epoch [557/1000], Loss: 0.5076\n",
      "Epoch [558/1000], Loss: 0.5068\n",
      "Epoch [559/1000], Loss: 0.5089\n",
      "Epoch [560/1000], Loss: 0.5068\n",
      "Epoch [561/1000], Loss: 0.5085\n",
      "Epoch [562/1000], Loss: 0.5085\n",
      "Epoch [563/1000], Loss: 0.5064\n",
      "Epoch [564/1000], Loss: 0.5101\n",
      "Epoch [565/1000], Loss: 0.5080\n",
      "Epoch [566/1000], Loss: 0.5076\n",
      "Epoch [567/1000], Loss: 0.5101\n",
      "Epoch [568/1000], Loss: 0.5080\n",
      "Epoch [569/1000], Loss: 0.5089\n",
      "Epoch [570/1000], Loss: 0.5068\n",
      "Epoch [571/1000], Loss: 0.5064\n",
      "Epoch [572/1000], Loss: 0.5080\n",
      "Epoch [573/1000], Loss: 0.5093\n",
      "Epoch [574/1000], Loss: 0.5101\n",
      "Epoch [575/1000], Loss: 0.5064\n",
      "Epoch [576/1000], Loss: 0.5097\n",
      "Epoch [577/1000], Loss: 0.5109\n",
      "Epoch [578/1000], Loss: 0.5089\n",
      "Epoch [579/1000], Loss: 0.5109\n",
      "Epoch [580/1000], Loss: 0.5080\n",
      "Epoch [581/1000], Loss: 0.5109\n",
      "Epoch [582/1000], Loss: 0.5072\n",
      "Epoch [583/1000], Loss: 0.5093\n",
      "Epoch [584/1000], Loss: 0.5097\n",
      "Epoch [585/1000], Loss: 0.5080\n",
      "Epoch [586/1000], Loss: 0.5109\n",
      "Epoch [587/1000], Loss: 0.5089\n",
      "Epoch [588/1000], Loss: 0.5080\n",
      "Epoch [589/1000], Loss: 0.5089\n",
      "Epoch [590/1000], Loss: 0.5089\n",
      "Epoch [591/1000], Loss: 0.5076\n",
      "Epoch [592/1000], Loss: 0.5097\n",
      "Epoch [593/1000], Loss: 0.5076\n",
      "Epoch [594/1000], Loss: 0.5080\n",
      "Epoch [595/1000], Loss: 0.5105\n",
      "Epoch [596/1000], Loss: 0.5080\n",
      "Epoch [597/1000], Loss: 0.5085\n",
      "Epoch [598/1000], Loss: 0.5101\n",
      "Epoch [599/1000], Loss: 0.5113\n",
      "Epoch [600/1000], Loss: 0.5072\n",
      "Epoch [601/1000], Loss: 0.5085\n",
      "Epoch [602/1000], Loss: 0.5068\n",
      "Epoch [603/1000], Loss: 0.5085\n",
      "Epoch [604/1000], Loss: 0.5105\n",
      "Epoch [605/1000], Loss: 0.5060\n",
      "Epoch [606/1000], Loss: 0.5085\n",
      "Epoch [607/1000], Loss: 0.5089\n",
      "Epoch [608/1000], Loss: 0.5097\n",
      "Epoch [609/1000], Loss: 0.5093\n",
      "Epoch [610/1000], Loss: 0.5085\n",
      "Epoch [611/1000], Loss: 0.5101\n",
      "Epoch [612/1000], Loss: 0.5093\n",
      "Epoch [613/1000], Loss: 0.5072\n",
      "Epoch [614/1000], Loss: 0.5064\n",
      "Epoch [615/1000], Loss: 0.5101\n",
      "Epoch [616/1000], Loss: 0.5064\n",
      "Epoch [617/1000], Loss: 0.5085\n",
      "Epoch [618/1000], Loss: 0.5080\n",
      "Epoch [619/1000], Loss: 0.5076\n",
      "Epoch [620/1000], Loss: 0.5080\n",
      "Epoch [621/1000], Loss: 0.5089\n",
      "Epoch [622/1000], Loss: 0.5085\n",
      "Epoch [623/1000], Loss: 0.5080\n",
      "Epoch [624/1000], Loss: 0.5089\n",
      "Epoch [625/1000], Loss: 0.5101\n",
      "Epoch [626/1000], Loss: 0.5076\n",
      "Epoch [627/1000], Loss: 0.5072\n",
      "Epoch [628/1000], Loss: 0.5060\n",
      "Epoch [629/1000], Loss: 0.5068\n",
      "Epoch [630/1000], Loss: 0.5060\n",
      "Epoch [631/1000], Loss: 0.5093\n",
      "Epoch [632/1000], Loss: 0.5109\n",
      "Epoch [633/1000], Loss: 0.5089\n",
      "Epoch [634/1000], Loss: 0.5064\n",
      "Epoch [635/1000], Loss: 0.5072\n",
      "Epoch [636/1000], Loss: 0.5085\n",
      "Epoch [637/1000], Loss: 0.5089\n",
      "Epoch [638/1000], Loss: 0.5060\n",
      "Epoch [639/1000], Loss: 0.5085\n",
      "Epoch [640/1000], Loss: 0.5097\n",
      "Epoch [641/1000], Loss: 0.5093\n",
      "Epoch [642/1000], Loss: 0.5097\n",
      "Epoch [643/1000], Loss: 0.5093\n",
      "Epoch [644/1000], Loss: 0.5093\n",
      "Epoch [645/1000], Loss: 0.5064\n",
      "Epoch [646/1000], Loss: 0.5080\n",
      "Epoch [647/1000], Loss: 0.5085\n",
      "Epoch [648/1000], Loss: 0.5097\n",
      "Epoch [649/1000], Loss: 0.5076\n",
      "Epoch [650/1000], Loss: 0.5068\n",
      "Epoch [651/1000], Loss: 0.5072\n",
      "Epoch [652/1000], Loss: 0.5060\n",
      "Epoch [653/1000], Loss: 0.5109\n",
      "Epoch [654/1000], Loss: 0.5064\n",
      "Epoch [655/1000], Loss: 0.5068\n",
      "Epoch [656/1000], Loss: 0.5056\n",
      "Epoch [657/1000], Loss: 0.5068\n",
      "Epoch [658/1000], Loss: 0.5093\n",
      "Epoch [659/1000], Loss: 0.5064\n",
      "Epoch [660/1000], Loss: 0.5085\n",
      "Epoch [661/1000], Loss: 0.5093\n",
      "Epoch [662/1000], Loss: 0.5072\n",
      "Epoch [663/1000], Loss: 0.5052\n",
      "Epoch [664/1000], Loss: 0.5080\n",
      "Epoch [665/1000], Loss: 0.5089\n",
      "Epoch [666/1000], Loss: 0.5056\n",
      "Epoch [667/1000], Loss: 0.5093\n",
      "Epoch [668/1000], Loss: 0.5072\n",
      "Epoch [669/1000], Loss: 0.5089\n",
      "Epoch [670/1000], Loss: 0.5076\n",
      "Epoch [671/1000], Loss: 0.5076\n",
      "Epoch [672/1000], Loss: 0.5101\n",
      "Epoch [673/1000], Loss: 0.5072\n",
      "Epoch [674/1000], Loss: 0.5101\n",
      "Epoch [675/1000], Loss: 0.5093\n",
      "Epoch [676/1000], Loss: 0.5080\n",
      "Epoch [677/1000], Loss: 0.5080\n",
      "Epoch [678/1000], Loss: 0.5085\n",
      "Epoch [679/1000], Loss: 0.5093\n",
      "Epoch [680/1000], Loss: 0.5085\n",
      "Epoch [681/1000], Loss: 0.5068\n",
      "Epoch [682/1000], Loss: 0.5060\n",
      "Epoch [683/1000], Loss: 0.5072\n",
      "Epoch [684/1000], Loss: 0.5068\n",
      "Epoch [685/1000], Loss: 0.5072\n",
      "Epoch [686/1000], Loss: 0.5085\n",
      "Epoch [687/1000], Loss: 0.5068\n",
      "Epoch [688/1000], Loss: 0.5076\n",
      "Epoch [689/1000], Loss: 0.5101\n",
      "Epoch [690/1000], Loss: 0.5068\n",
      "Epoch [691/1000], Loss: 0.5076\n",
      "Epoch [692/1000], Loss: 0.5085\n",
      "Epoch [693/1000], Loss: 0.5068\n",
      "Epoch [694/1000], Loss: 0.5064\n",
      "Epoch [695/1000], Loss: 0.5085\n",
      "Epoch [696/1000], Loss: 0.5097\n",
      "Epoch [697/1000], Loss: 0.5080\n",
      "Epoch [698/1000], Loss: 0.5060\n",
      "Epoch [699/1000], Loss: 0.5089\n",
      "Epoch [700/1000], Loss: 0.5113\n",
      "Epoch [701/1000], Loss: 0.5089\n",
      "Epoch [702/1000], Loss: 0.5076\n",
      "Epoch [703/1000], Loss: 0.5076\n",
      "Epoch [704/1000], Loss: 0.5085\n",
      "Epoch [705/1000], Loss: 0.5089\n",
      "Epoch [706/1000], Loss: 0.5068\n",
      "Epoch [707/1000], Loss: 0.5076\n",
      "Epoch [708/1000], Loss: 0.5072\n",
      "Epoch [709/1000], Loss: 0.5080\n",
      "Epoch [710/1000], Loss: 0.5080\n",
      "Epoch [711/1000], Loss: 0.5085\n",
      "Epoch [712/1000], Loss: 0.5072\n",
      "Epoch [713/1000], Loss: 0.5080\n",
      "Epoch [714/1000], Loss: 0.5085\n",
      "Epoch [715/1000], Loss: 0.5105\n",
      "Epoch [716/1000], Loss: 0.5105\n",
      "Epoch [717/1000], Loss: 0.5064\n",
      "Epoch [718/1000], Loss: 0.5097\n",
      "Epoch [719/1000], Loss: 0.5093\n",
      "Epoch [720/1000], Loss: 0.5089\n",
      "Epoch [721/1000], Loss: 0.5080\n",
      "Epoch [722/1000], Loss: 0.5060\n",
      "Epoch [723/1000], Loss: 0.5080\n",
      "Epoch [724/1000], Loss: 0.5076\n",
      "Epoch [725/1000], Loss: 0.5097\n",
      "Epoch [726/1000], Loss: 0.5076\n",
      "Epoch [727/1000], Loss: 0.5060\n",
      "Epoch [728/1000], Loss: 0.5080\n",
      "Epoch [729/1000], Loss: 0.5076\n",
      "Epoch [730/1000], Loss: 0.5089\n",
      "Epoch [731/1000], Loss: 0.5072\n",
      "Epoch [732/1000], Loss: 0.5121\n",
      "Epoch [733/1000], Loss: 0.5089\n",
      "Epoch [734/1000], Loss: 0.5080\n",
      "Epoch [735/1000], Loss: 0.5076\n",
      "Epoch [736/1000], Loss: 0.5101\n",
      "Epoch [737/1000], Loss: 0.5085\n",
      "Epoch [738/1000], Loss: 0.5080\n",
      "Epoch [739/1000], Loss: 0.5072\n",
      "Epoch [740/1000], Loss: 0.5072\n",
      "Epoch [741/1000], Loss: 0.5076\n",
      "Epoch [742/1000], Loss: 0.5089\n",
      "Epoch [743/1000], Loss: 0.5080\n",
      "Epoch [744/1000], Loss: 0.5093\n",
      "Epoch [745/1000], Loss: 0.5101\n",
      "Epoch [746/1000], Loss: 0.5101\n",
      "Epoch [747/1000], Loss: 0.5093\n",
      "Epoch [748/1000], Loss: 0.5101\n",
      "Epoch [749/1000], Loss: 0.5080\n",
      "Epoch [750/1000], Loss: 0.5101\n",
      "Epoch [751/1000], Loss: 0.5072\n",
      "Epoch [752/1000], Loss: 0.5072\n",
      "Epoch [753/1000], Loss: 0.5085\n",
      "Epoch [754/1000], Loss: 0.5101\n",
      "Epoch [755/1000], Loss: 0.5068\n",
      "Epoch [756/1000], Loss: 0.5109\n",
      "Epoch [757/1000], Loss: 0.5089\n",
      "Epoch [758/1000], Loss: 0.5101\n",
      "Epoch [759/1000], Loss: 0.5101\n",
      "Epoch [760/1000], Loss: 0.5085\n",
      "Epoch [761/1000], Loss: 0.5109\n",
      "Epoch [762/1000], Loss: 0.5072\n",
      "Epoch [763/1000], Loss: 0.5093\n",
      "Epoch [764/1000], Loss: 0.5085\n",
      "Epoch [765/1000], Loss: 0.5080\n",
      "Epoch [766/1000], Loss: 0.5060\n",
      "Epoch [767/1000], Loss: 0.5085\n",
      "Epoch [768/1000], Loss: 0.5089\n",
      "Epoch [769/1000], Loss: 0.5068\n",
      "Epoch [770/1000], Loss: 0.5076\n",
      "Epoch [771/1000], Loss: 0.5060\n",
      "Epoch [772/1000], Loss: 0.5089\n",
      "Epoch [773/1000], Loss: 0.5109\n",
      "Epoch [774/1000], Loss: 0.5085\n",
      "Epoch [775/1000], Loss: 0.5093\n",
      "Epoch [776/1000], Loss: 0.5068\n",
      "Epoch [777/1000], Loss: 0.5060\n",
      "Epoch [778/1000], Loss: 0.5085\n",
      "Epoch [779/1000], Loss: 0.5097\n",
      "Epoch [780/1000], Loss: 0.5085\n",
      "Epoch [781/1000], Loss: 0.5121\n",
      "Epoch [782/1000], Loss: 0.5064\n",
      "Epoch [783/1000], Loss: 0.5076\n",
      "Epoch [784/1000], Loss: 0.5089\n",
      "Epoch [785/1000], Loss: 0.5089\n",
      "Epoch [786/1000], Loss: 0.5089\n",
      "Epoch [787/1000], Loss: 0.5085\n",
      "Epoch [788/1000], Loss: 0.5064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [789/1000], Loss: 0.5097\n",
      "Epoch [790/1000], Loss: 0.5089\n",
      "Epoch [791/1000], Loss: 0.5076\n",
      "Epoch [792/1000], Loss: 0.5109\n",
      "Epoch [793/1000], Loss: 0.5089\n",
      "Epoch [794/1000], Loss: 0.5101\n",
      "Epoch [795/1000], Loss: 0.5072\n",
      "Epoch [796/1000], Loss: 0.5097\n",
      "Epoch [797/1000], Loss: 0.5097\n",
      "Epoch [798/1000], Loss: 0.5076\n",
      "Epoch [799/1000], Loss: 0.5089\n",
      "Epoch [800/1000], Loss: 0.5080\n",
      "Epoch [801/1000], Loss: 0.5080\n",
      "Epoch [802/1000], Loss: 0.5068\n",
      "Epoch [803/1000], Loss: 0.5076\n",
      "Epoch [804/1000], Loss: 0.5097\n",
      "Epoch [805/1000], Loss: 0.5076\n",
      "Epoch [806/1000], Loss: 0.5085\n",
      "Epoch [807/1000], Loss: 0.5085\n",
      "Epoch [808/1000], Loss: 0.5056\n",
      "Epoch [809/1000], Loss: 0.5097\n",
      "Epoch [810/1000], Loss: 0.5085\n",
      "Epoch [811/1000], Loss: 0.5068\n",
      "Epoch [812/1000], Loss: 0.5080\n",
      "Epoch [813/1000], Loss: 0.5080\n",
      "Epoch [814/1000], Loss: 0.5085\n",
      "Epoch [815/1000], Loss: 0.5105\n",
      "Epoch [816/1000], Loss: 0.5089\n",
      "Epoch [817/1000], Loss: 0.5101\n",
      "Epoch [818/1000], Loss: 0.5064\n",
      "Epoch [819/1000], Loss: 0.5080\n",
      "Epoch [820/1000], Loss: 0.5085\n",
      "Epoch [821/1000], Loss: 0.5085\n",
      "Epoch [822/1000], Loss: 0.5060\n",
      "Epoch [823/1000], Loss: 0.5089\n",
      "Epoch [824/1000], Loss: 0.5085\n",
      "Epoch [825/1000], Loss: 0.5093\n",
      "Epoch [826/1000], Loss: 0.5072\n",
      "Epoch [827/1000], Loss: 0.5093\n",
      "Epoch [828/1000], Loss: 0.5080\n",
      "Epoch [829/1000], Loss: 0.5072\n",
      "Epoch [830/1000], Loss: 0.5085\n",
      "Epoch [831/1000], Loss: 0.5085\n",
      "Epoch [832/1000], Loss: 0.5076\n",
      "Epoch [833/1000], Loss: 0.5080\n",
      "Epoch [834/1000], Loss: 0.5101\n",
      "Epoch [835/1000], Loss: 0.5076\n",
      "Epoch [836/1000], Loss: 0.5085\n",
      "Epoch [837/1000], Loss: 0.5064\n",
      "Epoch [838/1000], Loss: 0.5056\n",
      "Epoch [839/1000], Loss: 0.5085\n",
      "Epoch [840/1000], Loss: 0.5093\n",
      "Epoch [841/1000], Loss: 0.5109\n",
      "Epoch [842/1000], Loss: 0.5076\n",
      "Epoch [843/1000], Loss: 0.5101\n",
      "Epoch [844/1000], Loss: 0.5093\n",
      "Epoch [845/1000], Loss: 0.5089\n",
      "Epoch [846/1000], Loss: 0.5089\n",
      "Epoch [847/1000], Loss: 0.5101\n",
      "Epoch [848/1000], Loss: 0.5101\n",
      "Epoch [849/1000], Loss: 0.5080\n",
      "Epoch [850/1000], Loss: 0.5072\n",
      "Epoch [851/1000], Loss: 0.5093\n",
      "Epoch [852/1000], Loss: 0.5089\n",
      "Epoch [853/1000], Loss: 0.5064\n",
      "Epoch [854/1000], Loss: 0.5076\n",
      "Epoch [855/1000], Loss: 0.5068\n",
      "Epoch [856/1000], Loss: 0.5072\n",
      "Epoch [857/1000], Loss: 0.5060\n",
      "Epoch [858/1000], Loss: 0.5089\n",
      "Epoch [859/1000], Loss: 0.5060\n",
      "Epoch [860/1000], Loss: 0.5085\n",
      "Epoch [861/1000], Loss: 0.5097\n",
      "Epoch [862/1000], Loss: 0.5085\n",
      "Epoch [863/1000], Loss: 0.5085\n",
      "Epoch [864/1000], Loss: 0.5089\n",
      "Epoch [865/1000], Loss: 0.5080\n",
      "Epoch [866/1000], Loss: 0.5089\n",
      "Epoch [867/1000], Loss: 0.5093\n",
      "Epoch [868/1000], Loss: 0.5068\n",
      "Epoch [869/1000], Loss: 0.5076\n",
      "Epoch [870/1000], Loss: 0.5080\n",
      "Epoch [871/1000], Loss: 0.5052\n",
      "Epoch [872/1000], Loss: 0.5080\n",
      "Epoch [873/1000], Loss: 0.5068\n",
      "Epoch [874/1000], Loss: 0.5076\n",
      "Epoch [875/1000], Loss: 0.5085\n",
      "Epoch [876/1000], Loss: 0.5072\n",
      "Epoch [877/1000], Loss: 0.5080\n",
      "Epoch [878/1000], Loss: 0.5085\n",
      "Epoch [879/1000], Loss: 0.5076\n",
      "Epoch [880/1000], Loss: 0.5080\n",
      "Epoch [881/1000], Loss: 0.5093\n",
      "Epoch [882/1000], Loss: 0.5097\n",
      "Epoch [883/1000], Loss: 0.5117\n",
      "Epoch [884/1000], Loss: 0.5068\n",
      "Epoch [885/1000], Loss: 0.5085\n",
      "Epoch [886/1000], Loss: 0.5044\n",
      "Epoch [887/1000], Loss: 0.5068\n",
      "Epoch [888/1000], Loss: 0.5085\n",
      "Epoch [889/1000], Loss: 0.5093\n",
      "Epoch [890/1000], Loss: 0.5097\n",
      "Epoch [891/1000], Loss: 0.5089\n",
      "Epoch [892/1000], Loss: 0.5097\n",
      "Epoch [893/1000], Loss: 0.5085\n",
      "Epoch [894/1000], Loss: 0.5080\n",
      "Epoch [895/1000], Loss: 0.5097\n",
      "Epoch [896/1000], Loss: 0.5085\n",
      "Epoch [897/1000], Loss: 0.5085\n",
      "Epoch [898/1000], Loss: 0.5080\n",
      "Epoch [899/1000], Loss: 0.5080\n",
      "Epoch [900/1000], Loss: 0.5076\n",
      "Epoch [901/1000], Loss: 0.5072\n",
      "Epoch [902/1000], Loss: 0.5093\n",
      "Epoch [903/1000], Loss: 0.5064\n",
      "Epoch [904/1000], Loss: 0.5093\n",
      "Epoch [905/1000], Loss: 0.5085\n",
      "Epoch [906/1000], Loss: 0.5089\n",
      "Epoch [907/1000], Loss: 0.5085\n",
      "Epoch [908/1000], Loss: 0.5076\n",
      "Epoch [909/1000], Loss: 0.5101\n",
      "Epoch [910/1000], Loss: 0.5089\n",
      "Epoch [911/1000], Loss: 0.5060\n",
      "Epoch [912/1000], Loss: 0.5101\n",
      "Epoch [913/1000], Loss: 0.5080\n",
      "Epoch [914/1000], Loss: 0.5085\n",
      "Epoch [915/1000], Loss: 0.5097\n",
      "Epoch [916/1000], Loss: 0.5080\n",
      "Epoch [917/1000], Loss: 0.5097\n",
      "Epoch [918/1000], Loss: 0.5097\n",
      "Epoch [919/1000], Loss: 0.5093\n",
      "Epoch [920/1000], Loss: 0.5080\n",
      "Epoch [921/1000], Loss: 0.5076\n",
      "Epoch [922/1000], Loss: 0.5072\n",
      "Epoch [923/1000], Loss: 0.5101\n",
      "Epoch [924/1000], Loss: 0.5076\n",
      "Epoch [925/1000], Loss: 0.5085\n",
      "Epoch [926/1000], Loss: 0.5068\n",
      "Epoch [927/1000], Loss: 0.5089\n",
      "Epoch [928/1000], Loss: 0.5068\n",
      "Epoch [929/1000], Loss: 0.5080\n",
      "Epoch [930/1000], Loss: 0.5085\n",
      "Epoch [931/1000], Loss: 0.5093\n",
      "Epoch [932/1000], Loss: 0.5113\n",
      "Epoch [933/1000], Loss: 0.5076\n",
      "Epoch [934/1000], Loss: 0.5072\n",
      "Epoch [935/1000], Loss: 0.5076\n",
      "Epoch [936/1000], Loss: 0.5089\n",
      "Epoch [937/1000], Loss: 0.5097\n",
      "Epoch [938/1000], Loss: 0.5064\n",
      "Epoch [939/1000], Loss: 0.5080\n",
      "Epoch [940/1000], Loss: 0.5089\n",
      "Epoch [941/1000], Loss: 0.5072\n",
      "Epoch [942/1000], Loss: 0.5080\n",
      "Epoch [943/1000], Loss: 0.5068\n",
      "Epoch [944/1000], Loss: 0.5093\n",
      "Epoch [945/1000], Loss: 0.5097\n",
      "Epoch [946/1000], Loss: 0.5080\n",
      "Epoch [947/1000], Loss: 0.5097\n",
      "Epoch [948/1000], Loss: 0.5101\n",
      "Epoch [949/1000], Loss: 0.5076\n",
      "Epoch [950/1000], Loss: 0.5101\n",
      "Epoch [951/1000], Loss: 0.5101\n",
      "Epoch [952/1000], Loss: 0.5080\n",
      "Epoch [953/1000], Loss: 0.5089\n",
      "Epoch [954/1000], Loss: 0.5080\n",
      "Epoch [955/1000], Loss: 0.5089\n",
      "Epoch [956/1000], Loss: 0.5109\n",
      "Epoch [957/1000], Loss: 0.5080\n",
      "Epoch [958/1000], Loss: 0.5080\n",
      "Epoch [959/1000], Loss: 0.5076\n",
      "Epoch [960/1000], Loss: 0.5097\n",
      "Epoch [961/1000], Loss: 0.5080\n",
      "Epoch [962/1000], Loss: 0.5093\n",
      "Epoch [963/1000], Loss: 0.5085\n",
      "Epoch [964/1000], Loss: 0.5072\n",
      "Epoch [965/1000], Loss: 0.5076\n",
      "Epoch [966/1000], Loss: 0.5060\n",
      "Epoch [967/1000], Loss: 0.5093\n",
      "Epoch [968/1000], Loss: 0.5076\n",
      "Epoch [969/1000], Loss: 0.5101\n",
      "Epoch [970/1000], Loss: 0.5056\n",
      "Epoch [971/1000], Loss: 0.5101\n",
      "Epoch [972/1000], Loss: 0.5097\n",
      "Epoch [973/1000], Loss: 0.5089\n",
      "Epoch [974/1000], Loss: 0.5072\n",
      "Epoch [975/1000], Loss: 0.5072\n",
      "Epoch [976/1000], Loss: 0.5085\n",
      "Epoch [977/1000], Loss: 0.5121\n",
      "Epoch [978/1000], Loss: 0.5085\n",
      "Epoch [979/1000], Loss: 0.5093\n",
      "Epoch [980/1000], Loss: 0.5072\n",
      "Epoch [981/1000], Loss: 0.5097\n",
      "Epoch [982/1000], Loss: 0.5064\n",
      "Epoch [983/1000], Loss: 0.5089\n",
      "Epoch [984/1000], Loss: 0.5068\n",
      "Epoch [985/1000], Loss: 0.5080\n",
      "Epoch [986/1000], Loss: 0.5093\n",
      "Epoch [987/1000], Loss: 0.5089\n",
      "Epoch [988/1000], Loss: 0.5085\n",
      "Epoch [989/1000], Loss: 0.5056\n",
      "Epoch [990/1000], Loss: 0.5093\n",
      "Epoch [991/1000], Loss: 0.5072\n",
      "Epoch [992/1000], Loss: 0.5060\n",
      "Epoch [993/1000], Loss: 0.5085\n",
      "Epoch [994/1000], Loss: 0.5080\n",
      "Epoch [995/1000], Loss: 0.5068\n",
      "Epoch [996/1000], Loss: 0.5068\n",
      "Epoch [997/1000], Loss: 0.5093\n",
      "Epoch [998/1000], Loss: 0.5072\n",
      "Epoch [999/1000], Loss: 0.5064\n",
      "Epoch [1000/1000], Loss: 0.5085\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 107, lr :0.1, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2469\n",
      "Epoch [2/1000], Loss: 0.2399\n",
      "Epoch [3/1000], Loss: 0.2391\n",
      "Epoch [4/1000], Loss: 0.2380\n",
      "Epoch [5/1000], Loss: 0.2373\n",
      "Epoch [6/1000], Loss: 0.2370\n",
      "Epoch [7/1000], Loss: 0.2372\n",
      "Epoch [8/1000], Loss: 0.2357\n",
      "Epoch [9/1000], Loss: 0.2355\n",
      "Epoch [10/1000], Loss: 0.2347\n",
      "Epoch [11/1000], Loss: 0.2351\n",
      "Epoch [12/1000], Loss: 0.2339\n",
      "Epoch [13/1000], Loss: 0.2330\n",
      "Epoch [14/1000], Loss: 0.2324\n",
      "Epoch [15/1000], Loss: 0.2308\n",
      "Epoch [16/1000], Loss: 0.2306\n",
      "Epoch [17/1000], Loss: 0.2295\n",
      "Epoch [18/1000], Loss: 0.2286\n",
      "Epoch [19/1000], Loss: 0.2273\n",
      "Epoch [20/1000], Loss: 0.2256\n",
      "Epoch [21/1000], Loss: 0.2250\n",
      "Epoch [22/1000], Loss: 0.2240\n",
      "Epoch [23/1000], Loss: 0.2224\n",
      "Epoch [24/1000], Loss: 0.2217\n",
      "Epoch [25/1000], Loss: 0.2199\n",
      "Epoch [26/1000], Loss: 0.2188\n",
      "Epoch [27/1000], Loss: 0.2177\n",
      "Epoch [28/1000], Loss: 0.2161\n",
      "Epoch [29/1000], Loss: 0.2152\n",
      "Epoch [30/1000], Loss: 0.2139\n",
      "Epoch [31/1000], Loss: 0.2127\n",
      "Epoch [32/1000], Loss: 0.2106\n",
      "Epoch [33/1000], Loss: 0.2103\n",
      "Epoch [34/1000], Loss: 0.2090\n",
      "Epoch [35/1000], Loss: 0.2076\n",
      "Epoch [36/1000], Loss: 0.2065\n",
      "Epoch [37/1000], Loss: 0.2043\n",
      "Epoch [38/1000], Loss: 0.2036\n",
      "Epoch [39/1000], Loss: 0.2018\n",
      "Epoch [40/1000], Loss: 0.2013\n",
      "Epoch [41/1000], Loss: 0.1992\n",
      "Epoch [42/1000], Loss: 0.1974\n",
      "Epoch [43/1000], Loss: 0.1965\n",
      "Epoch [44/1000], Loss: 0.1951\n",
      "Epoch [45/1000], Loss: 0.1940\n",
      "Epoch [46/1000], Loss: 0.1917\n",
      "Epoch [47/1000], Loss: 0.1897\n",
      "Epoch [48/1000], Loss: 0.1880\n",
      "Epoch [49/1000], Loss: 0.1864\n",
      "Epoch [50/1000], Loss: 0.1842\n",
      "Epoch [51/1000], Loss: 0.1819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/1000], Loss: 0.1801\n",
      "Epoch [53/1000], Loss: 0.1768\n",
      "Epoch [54/1000], Loss: 0.1750\n",
      "Epoch [55/1000], Loss: 0.1712\n",
      "Epoch [56/1000], Loss: 0.1692\n",
      "Epoch [57/1000], Loss: 0.1656\n",
      "Epoch [58/1000], Loss: 0.1633\n",
      "Epoch [59/1000], Loss: 0.1590\n",
      "Epoch [60/1000], Loss: 0.1568\n",
      "Epoch [61/1000], Loss: 0.1541\n",
      "Epoch [62/1000], Loss: 0.1510\n",
      "Epoch [63/1000], Loss: 0.1482\n",
      "Epoch [64/1000], Loss: 0.1447\n",
      "Epoch [65/1000], Loss: 0.1423\n",
      "Epoch [66/1000], Loss: 0.1397\n",
      "Epoch [67/1000], Loss: 0.1369\n",
      "Epoch [68/1000], Loss: 0.1334\n",
      "Epoch [69/1000], Loss: 0.1300\n",
      "Epoch [70/1000], Loss: 0.1274\n",
      "Epoch [71/1000], Loss: 0.1239\n",
      "Epoch [72/1000], Loss: 0.1220\n",
      "Epoch [73/1000], Loss: 0.1192\n",
      "Epoch [74/1000], Loss: 0.1155\n",
      "Epoch [75/1000], Loss: 0.1133\n",
      "Epoch [76/1000], Loss: 0.1090\n",
      "Epoch [77/1000], Loss: 0.1055\n",
      "Epoch [78/1000], Loss: 0.1026\n",
      "Epoch [79/1000], Loss: 0.1004\n",
      "Epoch [80/1000], Loss: 0.0953\n",
      "Epoch [81/1000], Loss: 0.0923\n",
      "Epoch [82/1000], Loss: 0.0890\n",
      "Epoch [83/1000], Loss: 0.0857\n",
      "Epoch [84/1000], Loss: 0.0812\n",
      "Epoch [85/1000], Loss: 0.0765\n",
      "Epoch [86/1000], Loss: 0.0728\n",
      "Epoch [87/1000], Loss: 0.0697\n",
      "Epoch [88/1000], Loss: 0.0648\n",
      "Epoch [89/1000], Loss: 0.0608\n",
      "Epoch [90/1000], Loss: 0.0577\n",
      "Epoch [91/1000], Loss: 0.0528\n",
      "Epoch [92/1000], Loss: 0.0499\n",
      "Epoch [93/1000], Loss: 0.0473\n",
      "Epoch [94/1000], Loss: 0.0450\n",
      "Epoch [95/1000], Loss: 0.0393\n",
      "Epoch [96/1000], Loss: 0.0360\n",
      "Epoch [97/1000], Loss: 0.0340\n",
      "Epoch [98/1000], Loss: 0.0315\n",
      "Epoch [99/1000], Loss: 0.0304\n",
      "Epoch [100/1000], Loss: 0.0262\n",
      "Epoch [101/1000], Loss: 0.0267\n",
      "Epoch [102/1000], Loss: 0.0250\n",
      "Epoch [103/1000], Loss: 0.0218\n",
      "Epoch [104/1000], Loss: 0.0200\n",
      "Epoch [105/1000], Loss: 0.0186\n",
      "Epoch [106/1000], Loss: 0.0172\n",
      "Epoch [107/1000], Loss: 0.0172\n",
      "Epoch [108/1000], Loss: 0.0149\n",
      "Epoch [109/1000], Loss: 0.0142\n",
      "Epoch [110/1000], Loss: 0.0137\n",
      "Epoch [111/1000], Loss: 0.0128\n",
      "Epoch [112/1000], Loss: 0.0121\n",
      "Epoch [113/1000], Loss: 0.0116\n",
      "Epoch [114/1000], Loss: 0.0111\n",
      "Epoch [115/1000], Loss: 0.0108\n",
      "Epoch [116/1000], Loss: 0.0099\n",
      "Epoch [117/1000], Loss: 0.0094\n",
      "Epoch [118/1000], Loss: 0.0092\n",
      "Epoch [119/1000], Loss: 0.0088\n",
      "Epoch [120/1000], Loss: 0.0083\n",
      "Epoch [121/1000], Loss: 0.0081\n",
      "Epoch [122/1000], Loss: 0.0078\n",
      "Epoch [123/1000], Loss: 0.0076\n",
      "Epoch [124/1000], Loss: 0.0073\n",
      "Epoch [125/1000], Loss: 0.0071\n",
      "Epoch [126/1000], Loss: 0.0067\n",
      "Epoch [127/1000], Loss: 0.0067\n",
      "Epoch [128/1000], Loss: 0.0064\n",
      "Epoch [129/1000], Loss: 0.0061\n",
      "Epoch [130/1000], Loss: 0.0059\n",
      "Epoch [131/1000], Loss: 0.0058\n",
      "Epoch [132/1000], Loss: 0.0056\n",
      "Epoch [133/1000], Loss: 0.0053\n",
      "Epoch [134/1000], Loss: 0.0053\n",
      "Epoch [135/1000], Loss: 0.0052\n",
      "Epoch [136/1000], Loss: 0.0049\n",
      "Epoch [137/1000], Loss: 0.0048\n",
      "Epoch [138/1000], Loss: 0.0048\n",
      "Epoch [139/1000], Loss: 0.0046\n",
      "Epoch [140/1000], Loss: 0.0045\n",
      "Epoch [141/1000], Loss: 0.0044\n",
      "Epoch [142/1000], Loss: 0.0043\n",
      "Epoch [143/1000], Loss: 0.0042\n",
      "Epoch [144/1000], Loss: 0.0040\n",
      "Epoch [145/1000], Loss: 0.0039\n",
      "Epoch [146/1000], Loss: 0.0038\n",
      "Epoch [147/1000], Loss: 0.0038\n",
      "Epoch [148/1000], Loss: 0.0037\n",
      "Epoch [149/1000], Loss: 0.0036\n",
      "Epoch [150/1000], Loss: 0.0035\n",
      "Epoch [151/1000], Loss: 0.0035\n",
      "Epoch [152/1000], Loss: 0.0034\n",
      "Epoch [153/1000], Loss: 0.0034\n",
      "Epoch [154/1000], Loss: 0.0032\n",
      "Epoch [155/1000], Loss: 0.0032\n",
      "Epoch [156/1000], Loss: 0.0032\n",
      "Epoch [157/1000], Loss: 0.0031\n",
      "Epoch [158/1000], Loss: 0.0030\n",
      "Epoch [159/1000], Loss: 0.0030\n",
      "Epoch [160/1000], Loss: 0.0030\n",
      "Epoch [161/1000], Loss: 0.0028\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 107, lr :1.0, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.5033\n",
      "Epoch [2/1000], Loss: 0.5072\n",
      "Epoch [3/1000], Loss: 0.5068\n",
      "Epoch [4/1000], Loss: 0.5076\n",
      "Epoch [5/1000], Loss: 0.5089\n",
      "Epoch [6/1000], Loss: 0.5076\n",
      "Epoch [7/1000], Loss: 0.5125\n",
      "Epoch [8/1000], Loss: 0.5080\n",
      "Epoch [9/1000], Loss: 0.5056\n",
      "Epoch [10/1000], Loss: 0.5093\n",
      "Epoch [11/1000], Loss: 0.5080\n",
      "Epoch [12/1000], Loss: 0.5105\n",
      "Epoch [13/1000], Loss: 0.5056\n",
      "Epoch [14/1000], Loss: 0.5080\n",
      "Epoch [15/1000], Loss: 0.5105\n",
      "Epoch [16/1000], Loss: 0.5072\n",
      "Epoch [17/1000], Loss: 0.5072\n",
      "Epoch [18/1000], Loss: 0.5101\n",
      "Epoch [19/1000], Loss: 0.5048\n",
      "Epoch [20/1000], Loss: 0.5085\n",
      "Epoch [21/1000], Loss: 0.5093\n",
      "Epoch [22/1000], Loss: 0.5056\n",
      "Epoch [23/1000], Loss: 0.5097\n",
      "Epoch [24/1000], Loss: 0.5076\n",
      "Epoch [25/1000], Loss: 0.5064\n",
      "Epoch [26/1000], Loss: 0.5097\n",
      "Epoch [27/1000], Loss: 0.5080\n",
      "Epoch [28/1000], Loss: 0.5068\n",
      "Epoch [29/1000], Loss: 0.5072\n",
      "Epoch [30/1000], Loss: 0.5080\n",
      "Epoch [31/1000], Loss: 0.5064\n",
      "Epoch [32/1000], Loss: 0.5097\n",
      "Epoch [33/1000], Loss: 0.5080\n",
      "Epoch [34/1000], Loss: 0.5085\n",
      "Epoch [35/1000], Loss: 0.5080\n",
      "Epoch [36/1000], Loss: 0.5097\n",
      "Epoch [37/1000], Loss: 0.5113\n",
      "Epoch [38/1000], Loss: 0.5085\n",
      "Epoch [39/1000], Loss: 0.5056\n",
      "Epoch [40/1000], Loss: 0.5105\n",
      "Epoch [41/1000], Loss: 0.5093\n",
      "Epoch [42/1000], Loss: 0.5101\n",
      "Epoch [43/1000], Loss: 0.5085\n",
      "Epoch [44/1000], Loss: 0.5097\n",
      "Epoch [45/1000], Loss: 0.5085\n",
      "Epoch [46/1000], Loss: 0.5080\n",
      "Epoch [47/1000], Loss: 0.5076\n",
      "Epoch [48/1000], Loss: 0.5089\n",
      "Epoch [49/1000], Loss: 0.5089\n",
      "Epoch [50/1000], Loss: 0.5089\n",
      "Epoch [51/1000], Loss: 0.5093\n",
      "Epoch [52/1000], Loss: 0.5097\n",
      "Epoch [53/1000], Loss: 0.5085\n",
      "Epoch [54/1000], Loss: 0.5085\n",
      "Epoch [55/1000], Loss: 0.5089\n",
      "Epoch [56/1000], Loss: 0.5068\n",
      "Epoch [57/1000], Loss: 0.5080\n",
      "Epoch [58/1000], Loss: 0.5101\n",
      "Epoch [59/1000], Loss: 0.5076\n",
      "Epoch [60/1000], Loss: 0.5072\n",
      "Epoch [61/1000], Loss: 0.5076\n",
      "Epoch [62/1000], Loss: 0.5076\n",
      "Epoch [63/1000], Loss: 0.5089\n",
      "Epoch [64/1000], Loss: 0.5076\n",
      "Epoch [65/1000], Loss: 0.5089\n",
      "Epoch [66/1000], Loss: 0.5072\n",
      "Epoch [67/1000], Loss: 0.5085\n",
      "Epoch [68/1000], Loss: 0.5080\n",
      "Epoch [69/1000], Loss: 0.5076\n",
      "Epoch [70/1000], Loss: 0.5085\n",
      "Epoch [71/1000], Loss: 0.5085\n",
      "Epoch [72/1000], Loss: 0.5085\n",
      "Epoch [73/1000], Loss: 0.5072\n",
      "Epoch [74/1000], Loss: 0.5064\n",
      "Epoch [75/1000], Loss: 0.5113\n",
      "Epoch [76/1000], Loss: 0.5105\n",
      "Epoch [77/1000], Loss: 0.5080\n",
      "Epoch [78/1000], Loss: 0.5068\n",
      "Epoch [79/1000], Loss: 0.5089\n",
      "Epoch [80/1000], Loss: 0.5085\n",
      "Epoch [81/1000], Loss: 0.5076\n",
      "Epoch [82/1000], Loss: 0.5076\n",
      "Epoch [83/1000], Loss: 0.5080\n",
      "Epoch [84/1000], Loss: 0.5093\n",
      "Epoch [85/1000], Loss: 0.5076\n",
      "Epoch [86/1000], Loss: 0.5076\n",
      "Epoch [87/1000], Loss: 0.5076\n",
      "Epoch [88/1000], Loss: 0.5097\n",
      "Epoch [89/1000], Loss: 0.5101\n",
      "Epoch [90/1000], Loss: 0.5076\n",
      "Epoch [91/1000], Loss: 0.5089\n",
      "Epoch [92/1000], Loss: 0.5064\n",
      "Epoch [93/1000], Loss: 0.5068\n",
      "Epoch [94/1000], Loss: 0.5089\n",
      "Epoch [95/1000], Loss: 0.5080\n",
      "Epoch [96/1000], Loss: 0.5097\n",
      "Epoch [97/1000], Loss: 0.5097\n",
      "Epoch [98/1000], Loss: 0.5089\n",
      "Epoch [99/1000], Loss: 0.5072\n",
      "Epoch [100/1000], Loss: 0.5080\n",
      "Epoch [101/1000], Loss: 0.5080\n",
      "Epoch [102/1000], Loss: 0.5064\n",
      "Epoch [103/1000], Loss: 0.5085\n",
      "Epoch [104/1000], Loss: 0.5068\n",
      "Epoch [105/1000], Loss: 0.5064\n",
      "Epoch [106/1000], Loss: 0.5068\n",
      "Epoch [107/1000], Loss: 0.5089\n",
      "Epoch [108/1000], Loss: 0.5068\n",
      "Epoch [109/1000], Loss: 0.5072\n",
      "Epoch [110/1000], Loss: 0.5080\n",
      "Epoch [111/1000], Loss: 0.5097\n",
      "Epoch [112/1000], Loss: 0.5093\n",
      "Epoch [113/1000], Loss: 0.5085\n",
      "Epoch [114/1000], Loss: 0.5085\n",
      "Epoch [115/1000], Loss: 0.5113\n",
      "Epoch [116/1000], Loss: 0.5097\n",
      "Epoch [117/1000], Loss: 0.5080\n",
      "Epoch [118/1000], Loss: 0.5089\n",
      "Epoch [119/1000], Loss: 0.5060\n",
      "Epoch [120/1000], Loss: 0.5076\n",
      "Epoch [121/1000], Loss: 0.5085\n",
      "Epoch [122/1000], Loss: 0.5085\n",
      "Epoch [123/1000], Loss: 0.5080\n",
      "Epoch [124/1000], Loss: 0.5080\n",
      "Epoch [125/1000], Loss: 0.5072\n",
      "Epoch [126/1000], Loss: 0.5093\n",
      "Epoch [127/1000], Loss: 0.5085\n",
      "Epoch [128/1000], Loss: 0.5076\n",
      "Epoch [129/1000], Loss: 0.5076\n",
      "Epoch [130/1000], Loss: 0.5085\n",
      "Epoch [131/1000], Loss: 0.5080\n",
      "Epoch [132/1000], Loss: 0.5060\n",
      "Epoch [133/1000], Loss: 0.5089\n",
      "Epoch [134/1000], Loss: 0.5080\n",
      "Epoch [135/1000], Loss: 0.5101\n",
      "Epoch [136/1000], Loss: 0.5089\n",
      "Epoch [137/1000], Loss: 0.5097\n",
      "Epoch [138/1000], Loss: 0.5068\n",
      "Epoch [139/1000], Loss: 0.5089\n",
      "Epoch [140/1000], Loss: 0.5089\n",
      "Epoch [141/1000], Loss: 0.5072\n",
      "Epoch [142/1000], Loss: 0.5080\n",
      "Epoch [143/1000], Loss: 0.5097\n",
      "Epoch [144/1000], Loss: 0.5089\n",
      "Epoch [145/1000], Loss: 0.5076\n",
      "Epoch [146/1000], Loss: 0.5097\n",
      "Epoch [147/1000], Loss: 0.5060\n",
      "Epoch [148/1000], Loss: 0.5072\n",
      "Epoch [149/1000], Loss: 0.5105\n",
      "Epoch [150/1000], Loss: 0.5076\n",
      "Epoch [151/1000], Loss: 0.5085\n",
      "Epoch [152/1000], Loss: 0.5064\n",
      "Epoch [153/1000], Loss: 0.5080\n",
      "Epoch [154/1000], Loss: 0.5097\n",
      "Epoch [155/1000], Loss: 0.5085\n",
      "Epoch [156/1000], Loss: 0.5060\n",
      "Epoch [157/1000], Loss: 0.5097\n",
      "Epoch [158/1000], Loss: 0.5076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [159/1000], Loss: 0.5064\n",
      "Epoch [160/1000], Loss: 0.5101\n",
      "Epoch [161/1000], Loss: 0.5076\n",
      "Epoch [162/1000], Loss: 0.5093\n",
      "Epoch [163/1000], Loss: 0.5085\n",
      "Epoch [164/1000], Loss: 0.5101\n",
      "Epoch [165/1000], Loss: 0.5085\n",
      "Epoch [166/1000], Loss: 0.5076\n",
      "Epoch [167/1000], Loss: 0.5072\n",
      "Epoch [168/1000], Loss: 0.5060\n",
      "Epoch [169/1000], Loss: 0.5076\n",
      "Epoch [170/1000], Loss: 0.5076\n",
      "Epoch [171/1000], Loss: 0.5101\n",
      "Epoch [172/1000], Loss: 0.5076\n",
      "Epoch [173/1000], Loss: 0.5093\n",
      "Epoch [174/1000], Loss: 0.5085\n",
      "Epoch [175/1000], Loss: 0.5093\n",
      "Epoch [176/1000], Loss: 0.5072\n",
      "Epoch [177/1000], Loss: 0.5089\n",
      "Epoch [178/1000], Loss: 0.5080\n",
      "Epoch [179/1000], Loss: 0.5080\n",
      "Epoch [180/1000], Loss: 0.5080\n",
      "Epoch [181/1000], Loss: 0.5085\n",
      "Epoch [182/1000], Loss: 0.5101\n",
      "Epoch [183/1000], Loss: 0.5068\n",
      "Epoch [184/1000], Loss: 0.5068\n",
      "Epoch [185/1000], Loss: 0.5093\n",
      "Epoch [186/1000], Loss: 0.5080\n",
      "Epoch [187/1000], Loss: 0.5068\n",
      "Epoch [188/1000], Loss: 0.5085\n",
      "Epoch [189/1000], Loss: 0.5080\n",
      "Epoch [190/1000], Loss: 0.5076\n",
      "Epoch [191/1000], Loss: 0.5072\n",
      "Epoch [192/1000], Loss: 0.5076\n",
      "Epoch [193/1000], Loss: 0.5089\n",
      "Epoch [194/1000], Loss: 0.5064\n",
      "Epoch [195/1000], Loss: 0.5076\n",
      "Epoch [196/1000], Loss: 0.5085\n",
      "Epoch [197/1000], Loss: 0.5101\n",
      "Epoch [198/1000], Loss: 0.5080\n",
      "Epoch [199/1000], Loss: 0.5080\n",
      "Epoch [200/1000], Loss: 0.5093\n",
      "Epoch [201/1000], Loss: 0.5052\n",
      "Epoch [202/1000], Loss: 0.5089\n",
      "Epoch [203/1000], Loss: 0.5101\n",
      "Epoch [204/1000], Loss: 0.5085\n",
      "Epoch [205/1000], Loss: 0.5101\n",
      "Epoch [206/1000], Loss: 0.5064\n",
      "Epoch [207/1000], Loss: 0.5085\n",
      "Epoch [208/1000], Loss: 0.5064\n",
      "Epoch [209/1000], Loss: 0.5093\n",
      "Epoch [210/1000], Loss: 0.5080\n",
      "Epoch [211/1000], Loss: 0.5080\n",
      "Epoch [212/1000], Loss: 0.5076\n",
      "Epoch [213/1000], Loss: 0.5085\n",
      "Epoch [214/1000], Loss: 0.5072\n",
      "Epoch [215/1000], Loss: 0.5089\n",
      "Epoch [216/1000], Loss: 0.5080\n",
      "Epoch [217/1000], Loss: 0.5080\n",
      "Epoch [218/1000], Loss: 0.5064\n",
      "Epoch [219/1000], Loss: 0.5089\n",
      "Epoch [220/1000], Loss: 0.5080\n",
      "Epoch [221/1000], Loss: 0.5064\n",
      "Epoch [222/1000], Loss: 0.5068\n",
      "Epoch [223/1000], Loss: 0.5080\n",
      "Epoch [224/1000], Loss: 0.5076\n",
      "Epoch [225/1000], Loss: 0.5105\n",
      "Epoch [226/1000], Loss: 0.5085\n",
      "Epoch [227/1000], Loss: 0.5076\n",
      "Epoch [228/1000], Loss: 0.5105\n",
      "Epoch [229/1000], Loss: 0.5093\n",
      "Epoch [230/1000], Loss: 0.5080\n",
      "Epoch [231/1000], Loss: 0.5080\n",
      "Epoch [232/1000], Loss: 0.5085\n",
      "Epoch [233/1000], Loss: 0.5093\n",
      "Epoch [234/1000], Loss: 0.5089\n",
      "Epoch [235/1000], Loss: 0.5105\n",
      "Epoch [236/1000], Loss: 0.5076\n",
      "Epoch [237/1000], Loss: 0.5072\n",
      "Epoch [238/1000], Loss: 0.5101\n",
      "Epoch [239/1000], Loss: 0.5101\n",
      "Epoch [240/1000], Loss: 0.5076\n",
      "Epoch [241/1000], Loss: 0.5076\n",
      "Epoch [242/1000], Loss: 0.5080\n",
      "Epoch [243/1000], Loss: 0.5097\n",
      "Epoch [244/1000], Loss: 0.5072\n",
      "Epoch [245/1000], Loss: 0.5089\n",
      "Epoch [246/1000], Loss: 0.5064\n",
      "Epoch [247/1000], Loss: 0.5076\n",
      "Epoch [248/1000], Loss: 0.5093\n",
      "Epoch [249/1000], Loss: 0.5109\n",
      "Epoch [250/1000], Loss: 0.5089\n",
      "Epoch [251/1000], Loss: 0.5085\n",
      "Epoch [252/1000], Loss: 0.5080\n",
      "Epoch [253/1000], Loss: 0.5076\n",
      "Epoch [254/1000], Loss: 0.5093\n",
      "Epoch [255/1000], Loss: 0.5101\n",
      "Epoch [256/1000], Loss: 0.5064\n",
      "Epoch [257/1000], Loss: 0.5093\n",
      "Epoch [258/1000], Loss: 0.5056\n",
      "Epoch [259/1000], Loss: 0.5068\n",
      "Epoch [260/1000], Loss: 0.5076\n",
      "Epoch [261/1000], Loss: 0.5080\n",
      "Epoch [262/1000], Loss: 0.5064\n",
      "Epoch [263/1000], Loss: 0.5089\n",
      "Epoch [264/1000], Loss: 0.5093\n",
      "Epoch [265/1000], Loss: 0.5080\n",
      "Epoch [266/1000], Loss: 0.5076\n",
      "Epoch [267/1000], Loss: 0.5093\n",
      "Epoch [268/1000], Loss: 0.5089\n",
      "Epoch [269/1000], Loss: 0.5097\n",
      "Epoch [270/1000], Loss: 0.5089\n",
      "Epoch [271/1000], Loss: 0.5085\n",
      "Epoch [272/1000], Loss: 0.5060\n",
      "Epoch [273/1000], Loss: 0.5085\n",
      "Epoch [274/1000], Loss: 0.5101\n",
      "Epoch [275/1000], Loss: 0.5076\n",
      "Epoch [276/1000], Loss: 0.5101\n",
      "Epoch [277/1000], Loss: 0.5080\n",
      "Epoch [278/1000], Loss: 0.5097\n",
      "Epoch [279/1000], Loss: 0.5068\n",
      "Epoch [280/1000], Loss: 0.5080\n",
      "Epoch [281/1000], Loss: 0.5068\n",
      "Epoch [282/1000], Loss: 0.5101\n",
      "Epoch [283/1000], Loss: 0.5093\n",
      "Epoch [284/1000], Loss: 0.5085\n",
      "Epoch [285/1000], Loss: 0.5089\n",
      "Epoch [286/1000], Loss: 0.5089\n",
      "Epoch [287/1000], Loss: 0.5089\n",
      "Epoch [288/1000], Loss: 0.5097\n",
      "Epoch [289/1000], Loss: 0.5080\n",
      "Epoch [290/1000], Loss: 0.5085\n",
      "Epoch [291/1000], Loss: 0.5085\n",
      "Epoch [292/1000], Loss: 0.5085\n",
      "Epoch [293/1000], Loss: 0.5080\n",
      "Epoch [294/1000], Loss: 0.5080\n",
      "Epoch [295/1000], Loss: 0.5089\n",
      "Epoch [296/1000], Loss: 0.5080\n",
      "Epoch [297/1000], Loss: 0.5076\n",
      "Epoch [298/1000], Loss: 0.5101\n",
      "Epoch [299/1000], Loss: 0.5093\n",
      "Epoch [300/1000], Loss: 0.5068\n",
      "Epoch [301/1000], Loss: 0.5072\n",
      "Epoch [302/1000], Loss: 0.5093\n",
      "Epoch [303/1000], Loss: 0.5089\n",
      "Epoch [304/1000], Loss: 0.5080\n",
      "Epoch [305/1000], Loss: 0.5093\n",
      "Epoch [306/1000], Loss: 0.5076\n",
      "Epoch [307/1000], Loss: 0.5085\n",
      "Epoch [308/1000], Loss: 0.5076\n",
      "Epoch [309/1000], Loss: 0.5093\n",
      "Epoch [310/1000], Loss: 0.5072\n",
      "Epoch [311/1000], Loss: 0.5085\n",
      "Epoch [312/1000], Loss: 0.5093\n",
      "Epoch [313/1000], Loss: 0.5105\n",
      "Epoch [314/1000], Loss: 0.5076\n",
      "Epoch [315/1000], Loss: 0.5093\n",
      "Epoch [316/1000], Loss: 0.5068\n",
      "Epoch [317/1000], Loss: 0.5072\n",
      "Epoch [318/1000], Loss: 0.5068\n",
      "Epoch [319/1000], Loss: 0.5097\n",
      "Epoch [320/1000], Loss: 0.5072\n",
      "Epoch [321/1000], Loss: 0.5080\n",
      "Epoch [322/1000], Loss: 0.5085\n",
      "Epoch [323/1000], Loss: 0.5076\n",
      "Epoch [324/1000], Loss: 0.5068\n",
      "Epoch [325/1000], Loss: 0.5101\n",
      "Epoch [326/1000], Loss: 0.5080\n",
      "Epoch [327/1000], Loss: 0.5089\n",
      "Epoch [328/1000], Loss: 0.5085\n",
      "Epoch [329/1000], Loss: 0.5072\n",
      "Epoch [330/1000], Loss: 0.5064\n",
      "Epoch [331/1000], Loss: 0.5072\n",
      "Epoch [332/1000], Loss: 0.5080\n",
      "Epoch [333/1000], Loss: 0.5072\n",
      "Epoch [334/1000], Loss: 0.5076\n",
      "Epoch [335/1000], Loss: 0.5076\n",
      "Epoch [336/1000], Loss: 0.5076\n",
      "Epoch [337/1000], Loss: 0.5080\n",
      "Epoch [338/1000], Loss: 0.5085\n",
      "Epoch [339/1000], Loss: 0.5072\n",
      "Epoch [340/1000], Loss: 0.5072\n",
      "Epoch [341/1000], Loss: 0.5093\n",
      "Epoch [342/1000], Loss: 0.5109\n",
      "Epoch [343/1000], Loss: 0.5068\n",
      "Epoch [344/1000], Loss: 0.5089\n",
      "Epoch [345/1000], Loss: 0.5089\n",
      "Epoch [346/1000], Loss: 0.5117\n",
      "Epoch [347/1000], Loss: 0.5097\n",
      "Epoch [348/1000], Loss: 0.5117\n",
      "Epoch [349/1000], Loss: 0.5105\n",
      "Epoch [350/1000], Loss: 0.5072\n",
      "Epoch [351/1000], Loss: 0.5093\n",
      "Epoch [352/1000], Loss: 0.5072\n",
      "Epoch [353/1000], Loss: 0.5085\n",
      "Epoch [354/1000], Loss: 0.5080\n",
      "Epoch [355/1000], Loss: 0.5097\n",
      "Epoch [356/1000], Loss: 0.5068\n",
      "Epoch [357/1000], Loss: 0.5080\n",
      "Epoch [358/1000], Loss: 0.5089\n",
      "Epoch [359/1000], Loss: 0.5085\n",
      "Epoch [360/1000], Loss: 0.5109\n",
      "Epoch [361/1000], Loss: 0.5080\n",
      "Epoch [362/1000], Loss: 0.5080\n",
      "Epoch [363/1000], Loss: 0.5085\n",
      "Epoch [364/1000], Loss: 0.5093\n",
      "Epoch [365/1000], Loss: 0.5068\n",
      "Epoch [366/1000], Loss: 0.5076\n",
      "Epoch [367/1000], Loss: 0.5093\n",
      "Epoch [368/1000], Loss: 0.5076\n",
      "Epoch [369/1000], Loss: 0.5076\n",
      "Epoch [370/1000], Loss: 0.5064\n",
      "Epoch [371/1000], Loss: 0.5080\n",
      "Epoch [372/1000], Loss: 0.5085\n",
      "Epoch [373/1000], Loss: 0.5113\n",
      "Epoch [374/1000], Loss: 0.5089\n",
      "Epoch [375/1000], Loss: 0.5109\n",
      "Epoch [376/1000], Loss: 0.5060\n",
      "Epoch [377/1000], Loss: 0.5085\n",
      "Epoch [378/1000], Loss: 0.5072\n",
      "Epoch [379/1000], Loss: 0.5089\n",
      "Epoch [380/1000], Loss: 0.5068\n",
      "Epoch [381/1000], Loss: 0.5068\n",
      "Epoch [382/1000], Loss: 0.5068\n",
      "Epoch [383/1000], Loss: 0.5093\n",
      "Epoch [384/1000], Loss: 0.5093\n",
      "Epoch [385/1000], Loss: 0.5060\n",
      "Epoch [386/1000], Loss: 0.5097\n",
      "Epoch [387/1000], Loss: 0.5085\n",
      "Epoch [388/1000], Loss: 0.5089\n",
      "Epoch [389/1000], Loss: 0.5076\n",
      "Epoch [390/1000], Loss: 0.5076\n",
      "Epoch [391/1000], Loss: 0.5076\n",
      "Epoch [392/1000], Loss: 0.5060\n",
      "Epoch [393/1000], Loss: 0.5105\n",
      "Epoch [394/1000], Loss: 0.5080\n",
      "Epoch [395/1000], Loss: 0.5085\n",
      "Epoch [396/1000], Loss: 0.5097\n",
      "Epoch [397/1000], Loss: 0.5060\n",
      "Epoch [398/1000], Loss: 0.5105\n",
      "Epoch [399/1000], Loss: 0.5089\n",
      "Epoch [400/1000], Loss: 0.5093\n",
      "Epoch [401/1000], Loss: 0.5089\n",
      "Epoch [402/1000], Loss: 0.5093\n",
      "Epoch [403/1000], Loss: 0.5072\n",
      "Epoch [404/1000], Loss: 0.5085\n",
      "Epoch [405/1000], Loss: 0.5085\n",
      "Epoch [406/1000], Loss: 0.5089\n",
      "Epoch [407/1000], Loss: 0.5076\n",
      "Epoch [408/1000], Loss: 0.5101\n",
      "Epoch [409/1000], Loss: 0.5076\n",
      "Epoch [410/1000], Loss: 0.5109\n",
      "Epoch [411/1000], Loss: 0.5085\n",
      "Epoch [412/1000], Loss: 0.5080\n",
      "Epoch [413/1000], Loss: 0.5089\n",
      "Epoch [414/1000], Loss: 0.5109\n",
      "Epoch [415/1000], Loss: 0.5056\n",
      "Epoch [416/1000], Loss: 0.5064\n",
      "Epoch [417/1000], Loss: 0.5101\n",
      "Epoch [418/1000], Loss: 0.5068\n",
      "Epoch [419/1000], Loss: 0.5089\n",
      "Epoch [420/1000], Loss: 0.5072\n",
      "Epoch [421/1000], Loss: 0.5064\n",
      "Epoch [422/1000], Loss: 0.5064\n",
      "Epoch [423/1000], Loss: 0.5080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [424/1000], Loss: 0.5068\n",
      "Epoch [425/1000], Loss: 0.5089\n",
      "Epoch [426/1000], Loss: 0.5076\n",
      "Epoch [427/1000], Loss: 0.5093\n",
      "Epoch [428/1000], Loss: 0.5076\n",
      "Epoch [429/1000], Loss: 0.5089\n",
      "Epoch [430/1000], Loss: 0.5072\n",
      "Epoch [431/1000], Loss: 0.5109\n",
      "Epoch [432/1000], Loss: 0.5093\n",
      "Epoch [433/1000], Loss: 0.5085\n",
      "Epoch [434/1000], Loss: 0.5064\n",
      "Epoch [435/1000], Loss: 0.5068\n",
      "Epoch [436/1000], Loss: 0.5101\n",
      "Epoch [437/1000], Loss: 0.5076\n",
      "Epoch [438/1000], Loss: 0.5072\n",
      "Epoch [439/1000], Loss: 0.5093\n",
      "Epoch [440/1000], Loss: 0.5085\n",
      "Epoch [441/1000], Loss: 0.5089\n",
      "Epoch [442/1000], Loss: 0.5080\n",
      "Epoch [443/1000], Loss: 0.5101\n",
      "Epoch [444/1000], Loss: 0.5085\n",
      "Epoch [445/1000], Loss: 0.5080\n",
      "Epoch [446/1000], Loss: 0.5089\n",
      "Epoch [447/1000], Loss: 0.5093\n",
      "Epoch [448/1000], Loss: 0.5064\n",
      "Epoch [449/1000], Loss: 0.5089\n",
      "Epoch [450/1000], Loss: 0.5076\n",
      "Epoch [451/1000], Loss: 0.5064\n",
      "Epoch [452/1000], Loss: 0.5076\n",
      "Epoch [453/1000], Loss: 0.5068\n",
      "Epoch [454/1000], Loss: 0.5089\n",
      "Epoch [455/1000], Loss: 0.5089\n",
      "Epoch [456/1000], Loss: 0.5076\n",
      "Epoch [457/1000], Loss: 0.5072\n",
      "Epoch [458/1000], Loss: 0.5080\n",
      "Epoch [459/1000], Loss: 0.5068\n",
      "Epoch [460/1000], Loss: 0.5080\n",
      "Epoch [461/1000], Loss: 0.5113\n",
      "Epoch [462/1000], Loss: 0.5068\n",
      "Epoch [463/1000], Loss: 0.5076\n",
      "Epoch [464/1000], Loss: 0.5072\n",
      "Epoch [465/1000], Loss: 0.5097\n",
      "Epoch [466/1000], Loss: 0.5093\n",
      "Epoch [467/1000], Loss: 0.5080\n",
      "Epoch [468/1000], Loss: 0.5080\n",
      "Epoch [469/1000], Loss: 0.5101\n",
      "Epoch [470/1000], Loss: 0.5093\n",
      "Epoch [471/1000], Loss: 0.5060\n",
      "Epoch [472/1000], Loss: 0.5105\n",
      "Epoch [473/1000], Loss: 0.5064\n",
      "Epoch [474/1000], Loss: 0.5068\n",
      "Epoch [475/1000], Loss: 0.5076\n",
      "Epoch [476/1000], Loss: 0.5105\n",
      "Epoch [477/1000], Loss: 0.5072\n",
      "Epoch [478/1000], Loss: 0.5101\n",
      "Epoch [479/1000], Loss: 0.5076\n",
      "Epoch [480/1000], Loss: 0.5089\n",
      "Epoch [481/1000], Loss: 0.5093\n",
      "Epoch [482/1000], Loss: 0.5093\n",
      "Epoch [483/1000], Loss: 0.5097\n",
      "Epoch [484/1000], Loss: 0.5097\n",
      "Epoch [485/1000], Loss: 0.5068\n",
      "Epoch [486/1000], Loss: 0.5056\n",
      "Epoch [487/1000], Loss: 0.5085\n",
      "Epoch [488/1000], Loss: 0.5105\n",
      "Epoch [489/1000], Loss: 0.5085\n",
      "Epoch [490/1000], Loss: 0.5089\n",
      "Epoch [491/1000], Loss: 0.5093\n",
      "Epoch [492/1000], Loss: 0.5068\n",
      "Epoch [493/1000], Loss: 0.5068\n",
      "Epoch [494/1000], Loss: 0.5085\n",
      "Epoch [495/1000], Loss: 0.5089\n",
      "Epoch [496/1000], Loss: 0.5089\n",
      "Epoch [497/1000], Loss: 0.5072\n",
      "Epoch [498/1000], Loss: 0.5089\n",
      "Epoch [499/1000], Loss: 0.5072\n",
      "Epoch [500/1000], Loss: 0.5064\n",
      "Epoch [501/1000], Loss: 0.5072\n",
      "Epoch [502/1000], Loss: 0.5085\n",
      "Epoch [503/1000], Loss: 0.5064\n",
      "Epoch [504/1000], Loss: 0.5085\n",
      "Epoch [505/1000], Loss: 0.5068\n",
      "Epoch [506/1000], Loss: 0.5076\n",
      "Epoch [507/1000], Loss: 0.5097\n",
      "Epoch [508/1000], Loss: 0.5089\n",
      "Epoch [509/1000], Loss: 0.5064\n",
      "Epoch [510/1000], Loss: 0.5072\n",
      "Epoch [511/1000], Loss: 0.5072\n",
      "Epoch [512/1000], Loss: 0.5101\n",
      "Epoch [513/1000], Loss: 0.5105\n",
      "Epoch [514/1000], Loss: 0.5080\n",
      "Epoch [515/1000], Loss: 0.5101\n",
      "Epoch [516/1000], Loss: 0.5072\n",
      "Epoch [517/1000], Loss: 0.5076\n",
      "Epoch [518/1000], Loss: 0.5060\n",
      "Epoch [519/1000], Loss: 0.5089\n",
      "Epoch [520/1000], Loss: 0.5068\n",
      "Epoch [521/1000], Loss: 0.5072\n",
      "Epoch [522/1000], Loss: 0.5076\n",
      "Epoch [523/1000], Loss: 0.5072\n",
      "Epoch [524/1000], Loss: 0.5109\n",
      "Epoch [525/1000], Loss: 0.5105\n",
      "Epoch [526/1000], Loss: 0.5105\n",
      "Epoch [527/1000], Loss: 0.5085\n",
      "Epoch [528/1000], Loss: 0.5101\n",
      "Epoch [529/1000], Loss: 0.5076\n",
      "Epoch [530/1000], Loss: 0.5080\n",
      "Epoch [531/1000], Loss: 0.5072\n",
      "Epoch [532/1000], Loss: 0.5097\n",
      "Epoch [533/1000], Loss: 0.5068\n",
      "Epoch [534/1000], Loss: 0.5076\n",
      "Epoch [535/1000], Loss: 0.5076\n",
      "Epoch [536/1000], Loss: 0.5101\n",
      "Epoch [537/1000], Loss: 0.5068\n",
      "Epoch [538/1000], Loss: 0.5089\n",
      "Epoch [539/1000], Loss: 0.5076\n",
      "Epoch [540/1000], Loss: 0.5080\n",
      "Epoch [541/1000], Loss: 0.5068\n",
      "Epoch [542/1000], Loss: 0.5076\n",
      "Epoch [543/1000], Loss: 0.5089\n",
      "Epoch [544/1000], Loss: 0.5080\n",
      "Epoch [545/1000], Loss: 0.5085\n",
      "Epoch [546/1000], Loss: 0.5072\n",
      "Epoch [547/1000], Loss: 0.5097\n",
      "Epoch [548/1000], Loss: 0.5101\n",
      "Epoch [549/1000], Loss: 0.5089\n",
      "Epoch [550/1000], Loss: 0.5072\n",
      "Epoch [551/1000], Loss: 0.5097\n",
      "Epoch [552/1000], Loss: 0.5109\n",
      "Epoch [553/1000], Loss: 0.5093\n",
      "Epoch [554/1000], Loss: 0.5097\n",
      "Epoch [555/1000], Loss: 0.5060\n",
      "Epoch [556/1000], Loss: 0.5093\n",
      "Epoch [557/1000], Loss: 0.5072\n",
      "Epoch [558/1000], Loss: 0.5068\n",
      "Epoch [559/1000], Loss: 0.5064\n",
      "Epoch [560/1000], Loss: 0.5085\n",
      "Epoch [561/1000], Loss: 0.5080\n",
      "Epoch [562/1000], Loss: 0.5076\n",
      "Epoch [563/1000], Loss: 0.5093\n",
      "Epoch [564/1000], Loss: 0.5085\n",
      "Epoch [565/1000], Loss: 0.5080\n",
      "Epoch [566/1000], Loss: 0.5072\n",
      "Epoch [567/1000], Loss: 0.5064\n",
      "Epoch [568/1000], Loss: 0.5080\n",
      "Epoch [569/1000], Loss: 0.5072\n",
      "Epoch [570/1000], Loss: 0.5089\n",
      "Epoch [571/1000], Loss: 0.5089\n",
      "Epoch [572/1000], Loss: 0.5080\n",
      "Epoch [573/1000], Loss: 0.5072\n",
      "Epoch [574/1000], Loss: 0.5101\n",
      "Epoch [575/1000], Loss: 0.5089\n",
      "Epoch [576/1000], Loss: 0.5085\n",
      "Epoch [577/1000], Loss: 0.5101\n",
      "Epoch [578/1000], Loss: 0.5068\n",
      "Epoch [579/1000], Loss: 0.5076\n",
      "Epoch [580/1000], Loss: 0.5101\n",
      "Epoch [581/1000], Loss: 0.5105\n",
      "Epoch [582/1000], Loss: 0.5080\n",
      "Epoch [583/1000], Loss: 0.5068\n",
      "Epoch [584/1000], Loss: 0.5060\n",
      "Epoch [585/1000], Loss: 0.5060\n",
      "Epoch [586/1000], Loss: 0.5093\n",
      "Epoch [587/1000], Loss: 0.5085\n",
      "Epoch [588/1000], Loss: 0.5093\n",
      "Epoch [589/1000], Loss: 0.5085\n",
      "Epoch [590/1000], Loss: 0.5121\n",
      "Epoch [591/1000], Loss: 0.5097\n",
      "Epoch [592/1000], Loss: 0.5080\n",
      "Epoch [593/1000], Loss: 0.5085\n",
      "Epoch [594/1000], Loss: 0.5093\n",
      "Epoch [595/1000], Loss: 0.5089\n",
      "Epoch [596/1000], Loss: 0.5085\n",
      "Epoch [597/1000], Loss: 0.5080\n",
      "Epoch [598/1000], Loss: 0.5068\n",
      "Epoch [599/1000], Loss: 0.5080\n",
      "Epoch [600/1000], Loss: 0.5109\n",
      "Epoch [601/1000], Loss: 0.5076\n",
      "Epoch [602/1000], Loss: 0.5072\n",
      "Epoch [603/1000], Loss: 0.5089\n",
      "Epoch [604/1000], Loss: 0.5072\n",
      "Epoch [605/1000], Loss: 0.5093\n",
      "Epoch [606/1000], Loss: 0.5076\n",
      "Epoch [607/1000], Loss: 0.5076\n",
      "Epoch [608/1000], Loss: 0.5097\n",
      "Epoch [609/1000], Loss: 0.5072\n",
      "Epoch [610/1000], Loss: 0.5101\n",
      "Epoch [611/1000], Loss: 0.5089\n",
      "Epoch [612/1000], Loss: 0.5085\n",
      "Epoch [613/1000], Loss: 0.5072\n",
      "Epoch [614/1000], Loss: 0.5085\n",
      "Epoch [615/1000], Loss: 0.5085\n",
      "Epoch [616/1000], Loss: 0.5085\n",
      "Epoch [617/1000], Loss: 0.5068\n",
      "Epoch [618/1000], Loss: 0.5085\n",
      "Epoch [619/1000], Loss: 0.5101\n",
      "Epoch [620/1000], Loss: 0.5093\n",
      "Epoch [621/1000], Loss: 0.5089\n",
      "Epoch [622/1000], Loss: 0.5089\n",
      "Epoch [623/1000], Loss: 0.5068\n",
      "Epoch [624/1000], Loss: 0.5085\n",
      "Epoch [625/1000], Loss: 0.5072\n",
      "Epoch [626/1000], Loss: 0.5093\n",
      "Epoch [627/1000], Loss: 0.5113\n",
      "Epoch [628/1000], Loss: 0.5080\n",
      "Epoch [629/1000], Loss: 0.5080\n",
      "Epoch [630/1000], Loss: 0.5089\n",
      "Epoch [631/1000], Loss: 0.5076\n",
      "Epoch [632/1000], Loss: 0.5076\n",
      "Epoch [633/1000], Loss: 0.5105\n",
      "Epoch [634/1000], Loss: 0.5064\n",
      "Epoch [635/1000], Loss: 0.5097\n",
      "Epoch [636/1000], Loss: 0.5089\n",
      "Epoch [637/1000], Loss: 0.5072\n",
      "Epoch [638/1000], Loss: 0.5093\n",
      "Epoch [639/1000], Loss: 0.5080\n",
      "Epoch [640/1000], Loss: 0.5085\n",
      "Epoch [641/1000], Loss: 0.5080\n",
      "Epoch [642/1000], Loss: 0.5060\n",
      "Epoch [643/1000], Loss: 0.5068\n",
      "Epoch [644/1000], Loss: 0.5105\n",
      "Epoch [645/1000], Loss: 0.5105\n",
      "Epoch [646/1000], Loss: 0.5060\n",
      "Epoch [647/1000], Loss: 0.5072\n",
      "Epoch [648/1000], Loss: 0.5085\n",
      "Epoch [649/1000], Loss: 0.5089\n",
      "Epoch [650/1000], Loss: 0.5093\n",
      "Epoch [651/1000], Loss: 0.5072\n",
      "Epoch [652/1000], Loss: 0.5064\n",
      "Epoch [653/1000], Loss: 0.5076\n",
      "Epoch [654/1000], Loss: 0.5064\n",
      "Epoch [655/1000], Loss: 0.5076\n",
      "Epoch [656/1000], Loss: 0.5085\n",
      "Epoch [657/1000], Loss: 0.5076\n",
      "Epoch [658/1000], Loss: 0.5072\n",
      "Epoch [659/1000], Loss: 0.5076\n",
      "Epoch [660/1000], Loss: 0.5089\n",
      "Epoch [661/1000], Loss: 0.5089\n",
      "Epoch [662/1000], Loss: 0.5117\n",
      "Epoch [663/1000], Loss: 0.5097\n",
      "Epoch [664/1000], Loss: 0.5105\n",
      "Epoch [665/1000], Loss: 0.5068\n",
      "Epoch [666/1000], Loss: 0.5068\n",
      "Epoch [667/1000], Loss: 0.5101\n",
      "Epoch [668/1000], Loss: 0.5072\n",
      "Epoch [669/1000], Loss: 0.5076\n",
      "Epoch [670/1000], Loss: 0.5076\n",
      "Epoch [671/1000], Loss: 0.5068\n",
      "Epoch [672/1000], Loss: 0.5097\n",
      "Epoch [673/1000], Loss: 0.5076\n",
      "Epoch [674/1000], Loss: 0.5064\n",
      "Epoch [675/1000], Loss: 0.5097\n",
      "Epoch [676/1000], Loss: 0.5089\n",
      "Epoch [677/1000], Loss: 0.5089\n",
      "Epoch [678/1000], Loss: 0.5064\n",
      "Epoch [679/1000], Loss: 0.5097\n",
      "Epoch [680/1000], Loss: 0.5080\n",
      "Epoch [681/1000], Loss: 0.5085\n",
      "Epoch [682/1000], Loss: 0.5072\n",
      "Epoch [683/1000], Loss: 0.5105\n",
      "Epoch [684/1000], Loss: 0.5076\n",
      "Epoch [685/1000], Loss: 0.5064\n",
      "Epoch [686/1000], Loss: 0.5093\n",
      "Epoch [687/1000], Loss: 0.5093\n",
      "Epoch [688/1000], Loss: 0.5068\n",
      "Epoch [689/1000], Loss: 0.5113\n",
      "Epoch [690/1000], Loss: 0.5076\n",
      "Epoch [691/1000], Loss: 0.5068\n",
      "Epoch [692/1000], Loss: 0.5076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [693/1000], Loss: 0.5064\n",
      "Epoch [694/1000], Loss: 0.5105\n",
      "Epoch [695/1000], Loss: 0.5076\n",
      "Epoch [696/1000], Loss: 0.5076\n",
      "Epoch [697/1000], Loss: 0.5085\n",
      "Epoch [698/1000], Loss: 0.5076\n",
      "Epoch [699/1000], Loss: 0.5068\n",
      "Epoch [700/1000], Loss: 0.5085\n",
      "Epoch [701/1000], Loss: 0.5101\n",
      "Epoch [702/1000], Loss: 0.5068\n",
      "Epoch [703/1000], Loss: 0.5064\n",
      "Epoch [704/1000], Loss: 0.5068\n",
      "Epoch [705/1000], Loss: 0.5089\n",
      "Epoch [706/1000], Loss: 0.5076\n",
      "Epoch [707/1000], Loss: 0.5076\n",
      "Epoch [708/1000], Loss: 0.5052\n",
      "Epoch [709/1000], Loss: 0.5052\n",
      "Epoch [710/1000], Loss: 0.5068\n",
      "Epoch [711/1000], Loss: 0.5089\n",
      "Epoch [712/1000], Loss: 0.5068\n",
      "Epoch [713/1000], Loss: 0.5068\n",
      "Epoch [714/1000], Loss: 0.5076\n",
      "Epoch [715/1000], Loss: 0.5093\n",
      "Epoch [716/1000], Loss: 0.5072\n",
      "Epoch [717/1000], Loss: 0.5093\n",
      "Epoch [718/1000], Loss: 0.5064\n",
      "Epoch [719/1000], Loss: 0.5101\n",
      "Epoch [720/1000], Loss: 0.5076\n",
      "Epoch [721/1000], Loss: 0.5085\n",
      "Epoch [722/1000], Loss: 0.5072\n",
      "Epoch [723/1000], Loss: 0.5093\n",
      "Epoch [724/1000], Loss: 0.5101\n",
      "Epoch [725/1000], Loss: 0.5089\n",
      "Epoch [726/1000], Loss: 0.5072\n",
      "Epoch [727/1000], Loss: 0.5089\n",
      "Epoch [728/1000], Loss: 0.5089\n",
      "Epoch [729/1000], Loss: 0.5072\n",
      "Epoch [730/1000], Loss: 0.5072\n",
      "Epoch [731/1000], Loss: 0.5085\n",
      "Epoch [732/1000], Loss: 0.5085\n",
      "Epoch [733/1000], Loss: 0.5089\n",
      "Epoch [734/1000], Loss: 0.5085\n",
      "Epoch [735/1000], Loss: 0.5093\n",
      "Epoch [736/1000], Loss: 0.5068\n",
      "Epoch [737/1000], Loss: 0.5080\n",
      "Epoch [738/1000], Loss: 0.5093\n",
      "Epoch [739/1000], Loss: 0.5076\n",
      "Epoch [740/1000], Loss: 0.5101\n",
      "Epoch [741/1000], Loss: 0.5105\n",
      "Epoch [742/1000], Loss: 0.5093\n",
      "Epoch [743/1000], Loss: 0.5085\n",
      "Epoch [744/1000], Loss: 0.5089\n",
      "Epoch [745/1000], Loss: 0.5080\n",
      "Epoch [746/1000], Loss: 0.5068\n",
      "Epoch [747/1000], Loss: 0.5085\n",
      "Epoch [748/1000], Loss: 0.5085\n",
      "Epoch [749/1000], Loss: 0.5093\n",
      "Epoch [750/1000], Loss: 0.5064\n",
      "Epoch [751/1000], Loss: 0.5076\n",
      "Epoch [752/1000], Loss: 0.5089\n",
      "Epoch [753/1000], Loss: 0.5085\n",
      "Epoch [754/1000], Loss: 0.5089\n",
      "Epoch [755/1000], Loss: 0.5097\n",
      "Epoch [756/1000], Loss: 0.5085\n",
      "Epoch [757/1000], Loss: 0.5085\n",
      "Epoch [758/1000], Loss: 0.5080\n",
      "Epoch [759/1000], Loss: 0.5072\n",
      "Epoch [760/1000], Loss: 0.5089\n",
      "Epoch [761/1000], Loss: 0.5080\n",
      "Epoch [762/1000], Loss: 0.5101\n",
      "Epoch [763/1000], Loss: 0.5089\n",
      "Epoch [764/1000], Loss: 0.5093\n",
      "Epoch [765/1000], Loss: 0.5064\n",
      "Epoch [766/1000], Loss: 0.5076\n",
      "Epoch [767/1000], Loss: 0.5101\n",
      "Epoch [768/1000], Loss: 0.5072\n",
      "Epoch [769/1000], Loss: 0.5101\n",
      "Epoch [770/1000], Loss: 0.5076\n",
      "Epoch [771/1000], Loss: 0.5056\n",
      "Epoch [772/1000], Loss: 0.5089\n",
      "Epoch [773/1000], Loss: 0.5076\n",
      "Epoch [774/1000], Loss: 0.5093\n",
      "Epoch [775/1000], Loss: 0.5080\n",
      "Epoch [776/1000], Loss: 0.5064\n",
      "Epoch [777/1000], Loss: 0.5093\n",
      "Epoch [778/1000], Loss: 0.5093\n",
      "Epoch [779/1000], Loss: 0.5068\n",
      "Epoch [780/1000], Loss: 0.5085\n",
      "Epoch [781/1000], Loss: 0.5085\n",
      "Epoch [782/1000], Loss: 0.5076\n",
      "Epoch [783/1000], Loss: 0.5080\n",
      "Epoch [784/1000], Loss: 0.5085\n",
      "Epoch [785/1000], Loss: 0.5085\n",
      "Epoch [786/1000], Loss: 0.5064\n",
      "Epoch [787/1000], Loss: 0.5072\n",
      "Epoch [788/1000], Loss: 0.5080\n",
      "Epoch [789/1000], Loss: 0.5060\n",
      "Epoch [790/1000], Loss: 0.5101\n",
      "Epoch [791/1000], Loss: 0.5080\n",
      "Epoch [792/1000], Loss: 0.5101\n",
      "Epoch [793/1000], Loss: 0.5064\n",
      "Epoch [794/1000], Loss: 0.5085\n",
      "Epoch [795/1000], Loss: 0.5101\n",
      "Epoch [796/1000], Loss: 0.5076\n",
      "Epoch [797/1000], Loss: 0.5068\n",
      "Epoch [798/1000], Loss: 0.5089\n",
      "Epoch [799/1000], Loss: 0.5080\n",
      "Epoch [800/1000], Loss: 0.5085\n",
      "Epoch [801/1000], Loss: 0.5089\n",
      "Epoch [802/1000], Loss: 0.5076\n",
      "Epoch [803/1000], Loss: 0.5068\n",
      "Epoch [804/1000], Loss: 0.5048\n",
      "Epoch [805/1000], Loss: 0.5085\n",
      "Epoch [806/1000], Loss: 0.5105\n",
      "Epoch [807/1000], Loss: 0.5076\n",
      "Epoch [808/1000], Loss: 0.5080\n",
      "Epoch [809/1000], Loss: 0.5113\n",
      "Epoch [810/1000], Loss: 0.5060\n",
      "Epoch [811/1000], Loss: 0.5089\n",
      "Epoch [812/1000], Loss: 0.5093\n",
      "Epoch [813/1000], Loss: 0.5064\n",
      "Epoch [814/1000], Loss: 0.5076\n",
      "Epoch [815/1000], Loss: 0.5105\n",
      "Epoch [816/1000], Loss: 0.5097\n",
      "Epoch [817/1000], Loss: 0.5089\n",
      "Epoch [818/1000], Loss: 0.5085\n",
      "Epoch [819/1000], Loss: 0.5105\n",
      "Epoch [820/1000], Loss: 0.5085\n",
      "Epoch [821/1000], Loss: 0.5068\n",
      "Epoch [822/1000], Loss: 0.5093\n",
      "Epoch [823/1000], Loss: 0.5080\n",
      "Epoch [824/1000], Loss: 0.5097\n",
      "Epoch [825/1000], Loss: 0.5097\n",
      "Epoch [826/1000], Loss: 0.5080\n",
      "Epoch [827/1000], Loss: 0.5097\n",
      "Epoch [828/1000], Loss: 0.5072\n",
      "Epoch [829/1000], Loss: 0.5080\n",
      "Epoch [830/1000], Loss: 0.5060\n",
      "Epoch [831/1000], Loss: 0.5072\n",
      "Epoch [832/1000], Loss: 0.5072\n",
      "Epoch [833/1000], Loss: 0.5085\n",
      "Epoch [834/1000], Loss: 0.5089\n",
      "Epoch [835/1000], Loss: 0.5089\n",
      "Epoch [836/1000], Loss: 0.5072\n",
      "Epoch [837/1000], Loss: 0.5076\n",
      "Epoch [838/1000], Loss: 0.5085\n",
      "Epoch [839/1000], Loss: 0.5068\n",
      "Epoch [840/1000], Loss: 0.5076\n",
      "Epoch [841/1000], Loss: 0.5072\n",
      "Epoch [842/1000], Loss: 0.5076\n",
      "Epoch [843/1000], Loss: 0.5080\n",
      "Epoch [844/1000], Loss: 0.5089\n",
      "Epoch [845/1000], Loss: 0.5072\n",
      "Epoch [846/1000], Loss: 0.5072\n",
      "Epoch [847/1000], Loss: 0.5093\n",
      "Epoch [848/1000], Loss: 0.5093\n",
      "Epoch [849/1000], Loss: 0.5080\n",
      "Epoch [850/1000], Loss: 0.5044\n",
      "Epoch [851/1000], Loss: 0.5068\n",
      "Epoch [852/1000], Loss: 0.5080\n",
      "Epoch [853/1000], Loss: 0.5085\n",
      "Epoch [854/1000], Loss: 0.5097\n",
      "Epoch [855/1000], Loss: 0.5101\n",
      "Epoch [856/1000], Loss: 0.5064\n",
      "Epoch [857/1000], Loss: 0.5080\n",
      "Epoch [858/1000], Loss: 0.5105\n",
      "Epoch [859/1000], Loss: 0.5080\n",
      "Epoch [860/1000], Loss: 0.5093\n",
      "Epoch [861/1000], Loss: 0.5097\n",
      "Epoch [862/1000], Loss: 0.5089\n",
      "Epoch [863/1000], Loss: 0.5072\n",
      "Epoch [864/1000], Loss: 0.5097\n",
      "Epoch [865/1000], Loss: 0.5101\n",
      "Epoch [866/1000], Loss: 0.5085\n",
      "Epoch [867/1000], Loss: 0.5085\n",
      "Epoch [868/1000], Loss: 0.5068\n",
      "Epoch [869/1000], Loss: 0.5068\n",
      "Epoch [870/1000], Loss: 0.5093\n",
      "Epoch [871/1000], Loss: 0.5089\n",
      "Epoch [872/1000], Loss: 0.5089\n",
      "Epoch [873/1000], Loss: 0.5040\n",
      "Epoch [874/1000], Loss: 0.5093\n",
      "Epoch [875/1000], Loss: 0.5060\n",
      "Epoch [876/1000], Loss: 0.5093\n",
      "Epoch [877/1000], Loss: 0.5085\n",
      "Epoch [878/1000], Loss: 0.5076\n",
      "Epoch [879/1000], Loss: 0.5080\n",
      "Epoch [880/1000], Loss: 0.5101\n",
      "Epoch [881/1000], Loss: 0.5089\n",
      "Epoch [882/1000], Loss: 0.5089\n",
      "Epoch [883/1000], Loss: 0.5076\n",
      "Epoch [884/1000], Loss: 0.5072\n",
      "Epoch [885/1000], Loss: 0.5101\n",
      "Epoch [886/1000], Loss: 0.5076\n",
      "Epoch [887/1000], Loss: 0.5072\n",
      "Epoch [888/1000], Loss: 0.5060\n",
      "Epoch [889/1000], Loss: 0.5089\n",
      "Epoch [890/1000], Loss: 0.5085\n",
      "Epoch [891/1000], Loss: 0.5068\n",
      "Epoch [892/1000], Loss: 0.5097\n",
      "Epoch [893/1000], Loss: 0.5093\n",
      "Epoch [894/1000], Loss: 0.5072\n",
      "Epoch [895/1000], Loss: 0.5072\n",
      "Epoch [896/1000], Loss: 0.5080\n",
      "Epoch [897/1000], Loss: 0.5068\n",
      "Epoch [898/1000], Loss: 0.5113\n",
      "Epoch [899/1000], Loss: 0.5064\n",
      "Epoch [900/1000], Loss: 0.5093\n",
      "Epoch [901/1000], Loss: 0.5089\n",
      "Epoch [902/1000], Loss: 0.5076\n",
      "Epoch [903/1000], Loss: 0.5089\n",
      "Epoch [904/1000], Loss: 0.5080\n",
      "Epoch [905/1000], Loss: 0.5068\n",
      "Epoch [906/1000], Loss: 0.5105\n",
      "Epoch [907/1000], Loss: 0.5076\n",
      "Epoch [908/1000], Loss: 0.5072\n",
      "Epoch [909/1000], Loss: 0.5072\n",
      "Epoch [910/1000], Loss: 0.5072\n",
      "Epoch [911/1000], Loss: 0.5085\n",
      "Epoch [912/1000], Loss: 0.5076\n",
      "Epoch [913/1000], Loss: 0.5105\n",
      "Epoch [914/1000], Loss: 0.5093\n",
      "Epoch [915/1000], Loss: 0.5093\n",
      "Epoch [916/1000], Loss: 0.5080\n",
      "Epoch [917/1000], Loss: 0.5113\n",
      "Epoch [918/1000], Loss: 0.5109\n",
      "Epoch [919/1000], Loss: 0.5056\n",
      "Epoch [920/1000], Loss: 0.5093\n",
      "Epoch [921/1000], Loss: 0.5060\n",
      "Epoch [922/1000], Loss: 0.5080\n",
      "Epoch [923/1000], Loss: 0.5089\n",
      "Epoch [924/1000], Loss: 0.5101\n",
      "Epoch [925/1000], Loss: 0.5089\n",
      "Epoch [926/1000], Loss: 0.5093\n",
      "Epoch [927/1000], Loss: 0.5080\n",
      "Epoch [928/1000], Loss: 0.5089\n",
      "Epoch [929/1000], Loss: 0.5072\n",
      "Epoch [930/1000], Loss: 0.5076\n",
      "Epoch [931/1000], Loss: 0.5093\n",
      "Epoch [932/1000], Loss: 0.5093\n",
      "Epoch [933/1000], Loss: 0.5085\n",
      "Epoch [934/1000], Loss: 0.5097\n",
      "Epoch [935/1000], Loss: 0.5076\n",
      "Epoch [936/1000], Loss: 0.5060\n",
      "Epoch [937/1000], Loss: 0.5089\n",
      "Epoch [938/1000], Loss: 0.5085\n",
      "Epoch [939/1000], Loss: 0.5089\n",
      "Epoch [940/1000], Loss: 0.5080\n",
      "Epoch [941/1000], Loss: 0.5064\n",
      "Epoch [942/1000], Loss: 0.5101\n",
      "Epoch [943/1000], Loss: 0.5068\n",
      "Epoch [944/1000], Loss: 0.5089\n",
      "Epoch [945/1000], Loss: 0.5068\n",
      "Epoch [946/1000], Loss: 0.5072\n",
      "Epoch [947/1000], Loss: 0.5089\n",
      "Epoch [948/1000], Loss: 0.5076\n",
      "Epoch [949/1000], Loss: 0.5089\n",
      "Epoch [950/1000], Loss: 0.5085\n",
      "Epoch [951/1000], Loss: 0.5076\n",
      "Epoch [952/1000], Loss: 0.5068\n",
      "Epoch [953/1000], Loss: 0.5068\n",
      "Epoch [954/1000], Loss: 0.5076\n",
      "Epoch [955/1000], Loss: 0.5072\n",
      "Epoch [956/1000], Loss: 0.5097\n",
      "Epoch [957/1000], Loss: 0.5068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [958/1000], Loss: 0.5089\n",
      "Epoch [959/1000], Loss: 0.5080\n",
      "Epoch [960/1000], Loss: 0.5080\n",
      "Epoch [961/1000], Loss: 0.5085\n",
      "Epoch [962/1000], Loss: 0.5076\n",
      "Epoch [963/1000], Loss: 0.5101\n",
      "Epoch [964/1000], Loss: 0.5080\n",
      "Epoch [965/1000], Loss: 0.5072\n",
      "Epoch [966/1000], Loss: 0.5080\n",
      "Epoch [967/1000], Loss: 0.5093\n",
      "Epoch [968/1000], Loss: 0.5064\n",
      "Epoch [969/1000], Loss: 0.5085\n",
      "Epoch [970/1000], Loss: 0.5080\n",
      "Epoch [971/1000], Loss: 0.5080\n",
      "Epoch [972/1000], Loss: 0.5056\n",
      "Epoch [973/1000], Loss: 0.5093\n",
      "Epoch [974/1000], Loss: 0.5076\n",
      "Epoch [975/1000], Loss: 0.5097\n",
      "Epoch [976/1000], Loss: 0.5085\n",
      "Epoch [977/1000], Loss: 0.5072\n",
      "Epoch [978/1000], Loss: 0.5093\n",
      "Epoch [979/1000], Loss: 0.5080\n",
      "Epoch [980/1000], Loss: 0.5097\n",
      "Epoch [981/1000], Loss: 0.5089\n",
      "Epoch [982/1000], Loss: 0.5101\n",
      "Epoch [983/1000], Loss: 0.5085\n",
      "Epoch [984/1000], Loss: 0.5109\n",
      "Epoch [985/1000], Loss: 0.5068\n",
      "Epoch [986/1000], Loss: 0.5093\n",
      "Epoch [987/1000], Loss: 0.5109\n",
      "Epoch [988/1000], Loss: 0.5080\n",
      "Epoch [989/1000], Loss: 0.5085\n",
      "Epoch [990/1000], Loss: 0.5097\n",
      "Epoch [991/1000], Loss: 0.5052\n",
      "Epoch [992/1000], Loss: 0.5089\n",
      "Epoch [993/1000], Loss: 0.5097\n",
      "Epoch [994/1000], Loss: 0.5080\n",
      "Epoch [995/1000], Loss: 0.5085\n",
      "Epoch [996/1000], Loss: 0.5101\n",
      "Epoch [997/1000], Loss: 0.5064\n",
      "Epoch [998/1000], Loss: 0.5056\n",
      "Epoch [999/1000], Loss: 0.5093\n",
      "Epoch [1000/1000], Loss: 0.5060\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 107, lr :1.0, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.5014\n",
      "Epoch [2/1000], Loss: 0.5093\n",
      "Epoch [3/1000], Loss: 0.5068\n",
      "Epoch [4/1000], Loss: 0.5060\n",
      "Epoch [5/1000], Loss: 0.5089\n",
      "Epoch [6/1000], Loss: 0.5072\n",
      "Epoch [7/1000], Loss: 0.5089\n",
      "Epoch [8/1000], Loss: 0.5089\n",
      "Epoch [9/1000], Loss: 0.5076\n",
      "Epoch [10/1000], Loss: 0.5076\n",
      "Epoch [11/1000], Loss: 0.5076\n",
      "Epoch [12/1000], Loss: 0.5064\n",
      "Epoch [13/1000], Loss: 0.5080\n",
      "Epoch [14/1000], Loss: 0.5072\n",
      "Epoch [15/1000], Loss: 0.5068\n",
      "Epoch [16/1000], Loss: 0.5080\n",
      "Epoch [17/1000], Loss: 0.5093\n",
      "Epoch [18/1000], Loss: 0.5064\n",
      "Epoch [19/1000], Loss: 0.5093\n",
      "Epoch [20/1000], Loss: 0.5085\n",
      "Epoch [21/1000], Loss: 0.5093\n",
      "Epoch [22/1000], Loss: 0.5085\n",
      "Epoch [23/1000], Loss: 0.5080\n",
      "Epoch [24/1000], Loss: 0.5052\n",
      "Epoch [25/1000], Loss: 0.5085\n",
      "Epoch [26/1000], Loss: 0.5093\n",
      "Epoch [27/1000], Loss: 0.5068\n",
      "Epoch [28/1000], Loss: 0.5080\n",
      "Epoch [29/1000], Loss: 0.5093\n",
      "Epoch [30/1000], Loss: 0.5076\n",
      "Epoch [31/1000], Loss: 0.5068\n",
      "Epoch [32/1000], Loss: 0.5097\n",
      "Epoch [33/1000], Loss: 0.5097\n",
      "Epoch [34/1000], Loss: 0.5089\n",
      "Epoch [35/1000], Loss: 0.5076\n",
      "Epoch [36/1000], Loss: 0.5089\n",
      "Epoch [37/1000], Loss: 0.5068\n",
      "Epoch [38/1000], Loss: 0.5089\n",
      "Epoch [39/1000], Loss: 0.5080\n",
      "Epoch [40/1000], Loss: 0.5072\n",
      "Epoch [41/1000], Loss: 0.5097\n",
      "Epoch [42/1000], Loss: 0.5093\n",
      "Epoch [43/1000], Loss: 0.5080\n",
      "Epoch [44/1000], Loss: 0.5093\n",
      "Epoch [45/1000], Loss: 0.5056\n",
      "Epoch [46/1000], Loss: 0.5072\n",
      "Epoch [47/1000], Loss: 0.5056\n",
      "Epoch [48/1000], Loss: 0.5080\n",
      "Epoch [49/1000], Loss: 0.5093\n",
      "Epoch [50/1000], Loss: 0.5076\n",
      "Epoch [51/1000], Loss: 0.5085\n",
      "Epoch [52/1000], Loss: 0.5089\n",
      "Epoch [53/1000], Loss: 0.5068\n",
      "Epoch [54/1000], Loss: 0.5089\n",
      "Epoch [55/1000], Loss: 0.5060\n",
      "Epoch [56/1000], Loss: 0.5093\n",
      "Epoch [57/1000], Loss: 0.5080\n",
      "Epoch [58/1000], Loss: 0.5076\n",
      "Epoch [59/1000], Loss: 0.5085\n",
      "Epoch [60/1000], Loss: 0.5064\n",
      "Epoch [61/1000], Loss: 0.5105\n",
      "Epoch [62/1000], Loss: 0.5072\n",
      "Epoch [63/1000], Loss: 0.5101\n",
      "Epoch [64/1000], Loss: 0.5097\n",
      "Epoch [65/1000], Loss: 0.5080\n",
      "Epoch [66/1000], Loss: 0.5064\n",
      "Epoch [67/1000], Loss: 0.5064\n",
      "Epoch [68/1000], Loss: 0.5076\n",
      "Epoch [69/1000], Loss: 0.5085\n",
      "Epoch [70/1000], Loss: 0.5080\n",
      "Epoch [71/1000], Loss: 0.5080\n",
      "Epoch [72/1000], Loss: 0.5060\n",
      "Epoch [73/1000], Loss: 0.5097\n",
      "Epoch [74/1000], Loss: 0.5072\n",
      "Epoch [75/1000], Loss: 0.5068\n",
      "Epoch [76/1000], Loss: 0.5080\n",
      "Epoch [77/1000], Loss: 0.5072\n",
      "Epoch [78/1000], Loss: 0.5097\n",
      "Epoch [79/1000], Loss: 0.5076\n",
      "Epoch [80/1000], Loss: 0.5076\n",
      "Epoch [81/1000], Loss: 0.5085\n",
      "Epoch [82/1000], Loss: 0.5068\n",
      "Epoch [83/1000], Loss: 0.5076\n",
      "Epoch [84/1000], Loss: 0.5064\n",
      "Epoch [85/1000], Loss: 0.5089\n",
      "Epoch [86/1000], Loss: 0.5089\n",
      "Epoch [87/1000], Loss: 0.5080\n",
      "Epoch [88/1000], Loss: 0.5089\n",
      "Epoch [89/1000], Loss: 0.5080\n",
      "Epoch [90/1000], Loss: 0.5060\n",
      "Epoch [91/1000], Loss: 0.5076\n",
      "Epoch [92/1000], Loss: 0.5105\n",
      "Epoch [93/1000], Loss: 0.5085\n",
      "Epoch [94/1000], Loss: 0.5076\n",
      "Epoch [95/1000], Loss: 0.5072\n",
      "Epoch [96/1000], Loss: 0.5064\n",
      "Epoch [97/1000], Loss: 0.5113\n",
      "Epoch [98/1000], Loss: 0.5064\n",
      "Epoch [99/1000], Loss: 0.5097\n",
      "Epoch [100/1000], Loss: 0.5097\n",
      "Epoch [101/1000], Loss: 0.5101\n",
      "Epoch [102/1000], Loss: 0.5080\n",
      "Epoch [103/1000], Loss: 0.5109\n",
      "Epoch [104/1000], Loss: 0.5064\n",
      "Epoch [105/1000], Loss: 0.5089\n",
      "Epoch [106/1000], Loss: 0.5109\n",
      "Epoch [107/1000], Loss: 0.5089\n",
      "Epoch [108/1000], Loss: 0.5089\n",
      "Epoch [109/1000], Loss: 0.5093\n",
      "Epoch [110/1000], Loss: 0.5076\n",
      "Epoch [111/1000], Loss: 0.5068\n",
      "Epoch [112/1000], Loss: 0.5072\n",
      "Epoch [113/1000], Loss: 0.5076\n",
      "Epoch [114/1000], Loss: 0.5080\n",
      "Epoch [115/1000], Loss: 0.5097\n",
      "Epoch [116/1000], Loss: 0.5080\n",
      "Epoch [117/1000], Loss: 0.5068\n",
      "Epoch [118/1000], Loss: 0.5105\n",
      "Epoch [119/1000], Loss: 0.5101\n",
      "Epoch [120/1000], Loss: 0.5080\n",
      "Epoch [121/1000], Loss: 0.5105\n",
      "Epoch [122/1000], Loss: 0.5068\n",
      "Epoch [123/1000], Loss: 0.5060\n",
      "Epoch [124/1000], Loss: 0.5093\n",
      "Epoch [125/1000], Loss: 0.5093\n",
      "Epoch [126/1000], Loss: 0.5072\n",
      "Epoch [127/1000], Loss: 0.5080\n",
      "Epoch [128/1000], Loss: 0.5076\n",
      "Epoch [129/1000], Loss: 0.5068\n",
      "Epoch [130/1000], Loss: 0.5060\n",
      "Epoch [131/1000], Loss: 0.5085\n",
      "Epoch [132/1000], Loss: 0.5089\n",
      "Epoch [133/1000], Loss: 0.5076\n",
      "Epoch [134/1000], Loss: 0.5085\n",
      "Epoch [135/1000], Loss: 0.5048\n",
      "Epoch [136/1000], Loss: 0.5089\n",
      "Epoch [137/1000], Loss: 0.5068\n",
      "Epoch [138/1000], Loss: 0.5060\n",
      "Epoch [139/1000], Loss: 0.5080\n",
      "Epoch [140/1000], Loss: 0.5072\n",
      "Epoch [141/1000], Loss: 0.5060\n",
      "Epoch [142/1000], Loss: 0.5080\n",
      "Epoch [143/1000], Loss: 0.5093\n",
      "Epoch [144/1000], Loss: 0.5064\n",
      "Epoch [145/1000], Loss: 0.5080\n",
      "Epoch [146/1000], Loss: 0.5080\n",
      "Epoch [147/1000], Loss: 0.5064\n",
      "Epoch [148/1000], Loss: 0.5072\n",
      "Epoch [149/1000], Loss: 0.5048\n",
      "Epoch [150/1000], Loss: 0.5085\n",
      "Epoch [151/1000], Loss: 0.5068\n",
      "Epoch [152/1000], Loss: 0.5089\n",
      "Epoch [153/1000], Loss: 0.5080\n",
      "Epoch [154/1000], Loss: 0.5101\n",
      "Epoch [155/1000], Loss: 0.5109\n",
      "Epoch [156/1000], Loss: 0.5093\n",
      "Epoch [157/1000], Loss: 0.5101\n",
      "Epoch [158/1000], Loss: 0.5080\n",
      "Epoch [159/1000], Loss: 0.5036\n",
      "Epoch [160/1000], Loss: 0.5080\n",
      "Epoch [161/1000], Loss: 0.5089\n",
      "Epoch [162/1000], Loss: 0.5076\n",
      "Epoch [163/1000], Loss: 0.5089\n",
      "Epoch [164/1000], Loss: 0.5080\n",
      "Epoch [165/1000], Loss: 0.5097\n",
      "Epoch [166/1000], Loss: 0.5076\n",
      "Epoch [167/1000], Loss: 0.5080\n",
      "Epoch [168/1000], Loss: 0.5076\n",
      "Epoch [169/1000], Loss: 0.5076\n",
      "Epoch [170/1000], Loss: 0.5089\n",
      "Epoch [171/1000], Loss: 0.5056\n",
      "Epoch [172/1000], Loss: 0.5097\n",
      "Epoch [173/1000], Loss: 0.5072\n",
      "Epoch [174/1000], Loss: 0.5089\n",
      "Epoch [175/1000], Loss: 0.5080\n",
      "Epoch [176/1000], Loss: 0.5060\n",
      "Epoch [177/1000], Loss: 0.5080\n",
      "Epoch [178/1000], Loss: 0.5064\n",
      "Epoch [179/1000], Loss: 0.5072\n",
      "Epoch [180/1000], Loss: 0.5068\n",
      "Epoch [181/1000], Loss: 0.5080\n",
      "Epoch [182/1000], Loss: 0.5076\n",
      "Epoch [183/1000], Loss: 0.5080\n",
      "Epoch [184/1000], Loss: 0.5076\n",
      "Epoch [185/1000], Loss: 0.5076\n",
      "Epoch [186/1000], Loss: 0.5076\n",
      "Epoch [187/1000], Loss: 0.5060\n",
      "Epoch [188/1000], Loss: 0.5085\n",
      "Epoch [189/1000], Loss: 0.5068\n",
      "Epoch [190/1000], Loss: 0.5085\n",
      "Epoch [191/1000], Loss: 0.5080\n",
      "Epoch [192/1000], Loss: 0.5085\n",
      "Epoch [193/1000], Loss: 0.5080\n",
      "Epoch [194/1000], Loss: 0.5060\n",
      "Epoch [195/1000], Loss: 0.5076\n",
      "Epoch [196/1000], Loss: 0.5093\n",
      "Epoch [197/1000], Loss: 0.5080\n",
      "Epoch [198/1000], Loss: 0.5080\n",
      "Epoch [199/1000], Loss: 0.5068\n",
      "Epoch [200/1000], Loss: 0.5072\n",
      "Epoch [201/1000], Loss: 0.5080\n",
      "Epoch [202/1000], Loss: 0.5085\n",
      "Epoch [203/1000], Loss: 0.5068\n",
      "Epoch [204/1000], Loss: 0.5085\n",
      "Epoch [205/1000], Loss: 0.5105\n",
      "Epoch [206/1000], Loss: 0.5085\n",
      "Epoch [207/1000], Loss: 0.5089\n",
      "Epoch [208/1000], Loss: 0.5085\n",
      "Epoch [209/1000], Loss: 0.5072\n",
      "Epoch [210/1000], Loss: 0.5068\n",
      "Epoch [211/1000], Loss: 0.5085\n",
      "Epoch [212/1000], Loss: 0.5080\n",
      "Epoch [213/1000], Loss: 0.5080\n",
      "Epoch [214/1000], Loss: 0.5085\n",
      "Epoch [215/1000], Loss: 0.5080\n",
      "Epoch [216/1000], Loss: 0.5093\n",
      "Epoch [217/1000], Loss: 0.5089\n",
      "Epoch [218/1000], Loss: 0.5085\n",
      "Epoch [219/1000], Loss: 0.5076\n",
      "Epoch [220/1000], Loss: 0.5085\n",
      "Epoch [221/1000], Loss: 0.5085\n",
      "Epoch [222/1000], Loss: 0.5101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [223/1000], Loss: 0.5085\n",
      "Epoch [224/1000], Loss: 0.5085\n",
      "Epoch [225/1000], Loss: 0.5101\n",
      "Epoch [226/1000], Loss: 0.5072\n",
      "Epoch [227/1000], Loss: 0.5072\n",
      "Epoch [228/1000], Loss: 0.5097\n",
      "Epoch [229/1000], Loss: 0.5101\n",
      "Epoch [230/1000], Loss: 0.5085\n",
      "Epoch [231/1000], Loss: 0.5076\n",
      "Epoch [232/1000], Loss: 0.5101\n",
      "Epoch [233/1000], Loss: 0.5089\n",
      "Epoch [234/1000], Loss: 0.5093\n",
      "Epoch [235/1000], Loss: 0.5072\n",
      "Epoch [236/1000], Loss: 0.5072\n",
      "Epoch [237/1000], Loss: 0.5101\n",
      "Epoch [238/1000], Loss: 0.5076\n",
      "Epoch [239/1000], Loss: 0.5089\n",
      "Epoch [240/1000], Loss: 0.5080\n",
      "Epoch [241/1000], Loss: 0.5089\n",
      "Epoch [242/1000], Loss: 0.5064\n",
      "Epoch [243/1000], Loss: 0.5072\n",
      "Epoch [244/1000], Loss: 0.5089\n",
      "Epoch [245/1000], Loss: 0.5048\n",
      "Epoch [246/1000], Loss: 0.5093\n",
      "Epoch [247/1000], Loss: 0.5080\n",
      "Epoch [248/1000], Loss: 0.5097\n",
      "Epoch [249/1000], Loss: 0.5105\n",
      "Epoch [250/1000], Loss: 0.5080\n",
      "Epoch [251/1000], Loss: 0.5072\n",
      "Epoch [252/1000], Loss: 0.5089\n",
      "Epoch [253/1000], Loss: 0.5080\n",
      "Epoch [254/1000], Loss: 0.5060\n",
      "Epoch [255/1000], Loss: 0.5085\n",
      "Epoch [256/1000], Loss: 0.5097\n",
      "Epoch [257/1000], Loss: 0.5097\n",
      "Epoch [258/1000], Loss: 0.5085\n",
      "Epoch [259/1000], Loss: 0.5080\n",
      "Epoch [260/1000], Loss: 0.5089\n",
      "Epoch [261/1000], Loss: 0.5089\n",
      "Epoch [262/1000], Loss: 0.5076\n",
      "Epoch [263/1000], Loss: 0.5093\n",
      "Epoch [264/1000], Loss: 0.5072\n",
      "Epoch [265/1000], Loss: 0.5109\n",
      "Epoch [266/1000], Loss: 0.5068\n",
      "Epoch [267/1000], Loss: 0.5089\n",
      "Epoch [268/1000], Loss: 0.5089\n",
      "Epoch [269/1000], Loss: 0.5089\n",
      "Epoch [270/1000], Loss: 0.5101\n",
      "Epoch [271/1000], Loss: 0.5080\n",
      "Epoch [272/1000], Loss: 0.5080\n",
      "Epoch [273/1000], Loss: 0.5056\n",
      "Epoch [274/1000], Loss: 0.5089\n",
      "Epoch [275/1000], Loss: 0.5093\n",
      "Epoch [276/1000], Loss: 0.5080\n",
      "Epoch [277/1000], Loss: 0.5056\n",
      "Epoch [278/1000], Loss: 0.5080\n",
      "Epoch [279/1000], Loss: 0.5076\n",
      "Epoch [280/1000], Loss: 0.5056\n",
      "Epoch [281/1000], Loss: 0.5068\n",
      "Epoch [282/1000], Loss: 0.5093\n",
      "Epoch [283/1000], Loss: 0.5085\n",
      "Epoch [284/1000], Loss: 0.5085\n",
      "Epoch [285/1000], Loss: 0.5089\n",
      "Epoch [286/1000], Loss: 0.5072\n",
      "Epoch [287/1000], Loss: 0.5076\n",
      "Epoch [288/1000], Loss: 0.5085\n",
      "Epoch [289/1000], Loss: 0.5085\n",
      "Epoch [290/1000], Loss: 0.5085\n",
      "Epoch [291/1000], Loss: 0.5101\n",
      "Epoch [292/1000], Loss: 0.5080\n",
      "Epoch [293/1000], Loss: 0.5064\n",
      "Epoch [294/1000], Loss: 0.5072\n",
      "Epoch [295/1000], Loss: 0.5093\n",
      "Epoch [296/1000], Loss: 0.5072\n",
      "Epoch [297/1000], Loss: 0.5093\n",
      "Epoch [298/1000], Loss: 0.5076\n",
      "Epoch [299/1000], Loss: 0.5085\n",
      "Epoch [300/1000], Loss: 0.5089\n",
      "Epoch [301/1000], Loss: 0.5101\n",
      "Epoch [302/1000], Loss: 0.5080\n",
      "Epoch [303/1000], Loss: 0.5076\n",
      "Epoch [304/1000], Loss: 0.5072\n",
      "Epoch [305/1000], Loss: 0.5076\n",
      "Epoch [306/1000], Loss: 0.5097\n",
      "Epoch [307/1000], Loss: 0.5064\n",
      "Epoch [308/1000], Loss: 0.5076\n",
      "Epoch [309/1000], Loss: 0.5068\n",
      "Epoch [310/1000], Loss: 0.5085\n",
      "Epoch [311/1000], Loss: 0.5076\n",
      "Epoch [312/1000], Loss: 0.5093\n",
      "Epoch [313/1000], Loss: 0.5072\n",
      "Epoch [314/1000], Loss: 0.5068\n",
      "Epoch [315/1000], Loss: 0.5080\n",
      "Epoch [316/1000], Loss: 0.5056\n",
      "Epoch [317/1000], Loss: 0.5133\n",
      "Epoch [318/1000], Loss: 0.5072\n",
      "Epoch [319/1000], Loss: 0.5097\n",
      "Epoch [320/1000], Loss: 0.5072\n",
      "Epoch [321/1000], Loss: 0.5085\n",
      "Epoch [322/1000], Loss: 0.5105\n",
      "Epoch [323/1000], Loss: 0.5076\n",
      "Epoch [324/1000], Loss: 0.5080\n",
      "Epoch [325/1000], Loss: 0.5080\n",
      "Epoch [326/1000], Loss: 0.5060\n",
      "Epoch [327/1000], Loss: 0.5072\n",
      "Epoch [328/1000], Loss: 0.5097\n",
      "Epoch [329/1000], Loss: 0.5080\n",
      "Epoch [330/1000], Loss: 0.5085\n",
      "Epoch [331/1000], Loss: 0.5076\n",
      "Epoch [332/1000], Loss: 0.5080\n",
      "Epoch [333/1000], Loss: 0.5064\n",
      "Epoch [334/1000], Loss: 0.5068\n",
      "Epoch [335/1000], Loss: 0.5085\n",
      "Epoch [336/1000], Loss: 0.5093\n",
      "Epoch [337/1000], Loss: 0.5060\n",
      "Epoch [338/1000], Loss: 0.5109\n",
      "Epoch [339/1000], Loss: 0.5072\n",
      "Epoch [340/1000], Loss: 0.5101\n",
      "Epoch [341/1000], Loss: 0.5085\n",
      "Epoch [342/1000], Loss: 0.5064\n",
      "Epoch [343/1000], Loss: 0.5076\n",
      "Epoch [344/1000], Loss: 0.5076\n",
      "Epoch [345/1000], Loss: 0.5080\n",
      "Epoch [346/1000], Loss: 0.5101\n",
      "Epoch [347/1000], Loss: 0.5085\n",
      "Epoch [348/1000], Loss: 0.5060\n",
      "Epoch [349/1000], Loss: 0.5068\n",
      "Epoch [350/1000], Loss: 0.5076\n",
      "Epoch [351/1000], Loss: 0.5093\n",
      "Epoch [352/1000], Loss: 0.5097\n",
      "Epoch [353/1000], Loss: 0.5085\n",
      "Epoch [354/1000], Loss: 0.5093\n",
      "Epoch [355/1000], Loss: 0.5085\n",
      "Epoch [356/1000], Loss: 0.5089\n",
      "Epoch [357/1000], Loss: 0.5068\n",
      "Epoch [358/1000], Loss: 0.5085\n",
      "Epoch [359/1000], Loss: 0.5089\n",
      "Epoch [360/1000], Loss: 0.5068\n",
      "Epoch [361/1000], Loss: 0.5089\n",
      "Epoch [362/1000], Loss: 0.5097\n",
      "Epoch [363/1000], Loss: 0.5068\n",
      "Epoch [364/1000], Loss: 0.5093\n",
      "Epoch [365/1000], Loss: 0.5080\n",
      "Epoch [366/1000], Loss: 0.5080\n",
      "Epoch [367/1000], Loss: 0.5097\n",
      "Epoch [368/1000], Loss: 0.5093\n",
      "Epoch [369/1000], Loss: 0.5076\n",
      "Epoch [370/1000], Loss: 0.5080\n",
      "Epoch [371/1000], Loss: 0.5080\n",
      "Epoch [372/1000], Loss: 0.5105\n",
      "Epoch [373/1000], Loss: 0.5089\n",
      "Epoch [374/1000], Loss: 0.5097\n",
      "Epoch [375/1000], Loss: 0.5093\n",
      "Epoch [376/1000], Loss: 0.5089\n",
      "Epoch [377/1000], Loss: 0.5064\n",
      "Epoch [378/1000], Loss: 0.5089\n",
      "Epoch [379/1000], Loss: 0.5085\n",
      "Epoch [380/1000], Loss: 0.5109\n",
      "Epoch [381/1000], Loss: 0.5064\n",
      "Epoch [382/1000], Loss: 0.5080\n",
      "Epoch [383/1000], Loss: 0.5093\n",
      "Epoch [384/1000], Loss: 0.5109\n",
      "Epoch [385/1000], Loss: 0.5076\n",
      "Epoch [386/1000], Loss: 0.5101\n",
      "Epoch [387/1000], Loss: 0.5101\n",
      "Epoch [388/1000], Loss: 0.5080\n",
      "Epoch [389/1000], Loss: 0.5085\n",
      "Epoch [390/1000], Loss: 0.5076\n",
      "Epoch [391/1000], Loss: 0.5072\n",
      "Epoch [392/1000], Loss: 0.5085\n",
      "Epoch [393/1000], Loss: 0.5076\n",
      "Epoch [394/1000], Loss: 0.5085\n",
      "Epoch [395/1000], Loss: 0.5085\n",
      "Epoch [396/1000], Loss: 0.5101\n",
      "Epoch [397/1000], Loss: 0.5064\n",
      "Epoch [398/1000], Loss: 0.5076\n",
      "Epoch [399/1000], Loss: 0.5101\n",
      "Epoch [400/1000], Loss: 0.5085\n",
      "Epoch [401/1000], Loss: 0.5064\n",
      "Epoch [402/1000], Loss: 0.5089\n",
      "Epoch [403/1000], Loss: 0.5080\n",
      "Epoch [404/1000], Loss: 0.5056\n",
      "Epoch [405/1000], Loss: 0.5064\n",
      "Epoch [406/1000], Loss: 0.5085\n",
      "Epoch [407/1000], Loss: 0.5093\n",
      "Epoch [408/1000], Loss: 0.5080\n",
      "Epoch [409/1000], Loss: 0.5085\n",
      "Epoch [410/1000], Loss: 0.5089\n",
      "Epoch [411/1000], Loss: 0.5076\n",
      "Epoch [412/1000], Loss: 0.5085\n",
      "Epoch [413/1000], Loss: 0.5085\n",
      "Epoch [414/1000], Loss: 0.5076\n",
      "Epoch [415/1000], Loss: 0.5076\n",
      "Epoch [416/1000], Loss: 0.5068\n",
      "Epoch [417/1000], Loss: 0.5076\n",
      "Epoch [418/1000], Loss: 0.5080\n",
      "Epoch [419/1000], Loss: 0.5101\n",
      "Epoch [420/1000], Loss: 0.5072\n",
      "Epoch [421/1000], Loss: 0.5101\n",
      "Epoch [422/1000], Loss: 0.5076\n",
      "Epoch [423/1000], Loss: 0.5080\n",
      "Epoch [424/1000], Loss: 0.5093\n",
      "Epoch [425/1000], Loss: 0.5097\n",
      "Epoch [426/1000], Loss: 0.5105\n",
      "Epoch [427/1000], Loss: 0.5068\n",
      "Epoch [428/1000], Loss: 0.5085\n",
      "Epoch [429/1000], Loss: 0.5064\n",
      "Epoch [430/1000], Loss: 0.5052\n",
      "Epoch [431/1000], Loss: 0.5056\n",
      "Epoch [432/1000], Loss: 0.5068\n",
      "Epoch [433/1000], Loss: 0.5089\n",
      "Epoch [434/1000], Loss: 0.5060\n",
      "Epoch [435/1000], Loss: 0.5105\n",
      "Epoch [436/1000], Loss: 0.5085\n",
      "Epoch [437/1000], Loss: 0.5076\n",
      "Epoch [438/1000], Loss: 0.5080\n",
      "Epoch [439/1000], Loss: 0.5064\n",
      "Epoch [440/1000], Loss: 0.5085\n",
      "Epoch [441/1000], Loss: 0.5068\n",
      "Epoch [442/1000], Loss: 0.5093\n",
      "Epoch [443/1000], Loss: 0.5068\n",
      "Epoch [444/1000], Loss: 0.5072\n",
      "Epoch [445/1000], Loss: 0.5085\n",
      "Epoch [446/1000], Loss: 0.5093\n",
      "Epoch [447/1000], Loss: 0.5093\n",
      "Epoch [448/1000], Loss: 0.5085\n",
      "Epoch [449/1000], Loss: 0.5072\n",
      "Epoch [450/1000], Loss: 0.5072\n",
      "Epoch [451/1000], Loss: 0.5080\n",
      "Epoch [452/1000], Loss: 0.5089\n",
      "Epoch [453/1000], Loss: 0.5060\n",
      "Epoch [454/1000], Loss: 0.5080\n",
      "Epoch [455/1000], Loss: 0.5064\n",
      "Epoch [456/1000], Loss: 0.5072\n",
      "Epoch [457/1000], Loss: 0.5076\n",
      "Epoch [458/1000], Loss: 0.5080\n",
      "Epoch [459/1000], Loss: 0.5080\n",
      "Epoch [460/1000], Loss: 0.5101\n",
      "Epoch [461/1000], Loss: 0.5089\n",
      "Epoch [462/1000], Loss: 0.5076\n",
      "Epoch [463/1000], Loss: 0.5097\n",
      "Epoch [464/1000], Loss: 0.5060\n",
      "Epoch [465/1000], Loss: 0.5044\n",
      "Epoch [466/1000], Loss: 0.5101\n",
      "Epoch [467/1000], Loss: 0.5060\n",
      "Epoch [468/1000], Loss: 0.5097\n",
      "Epoch [469/1000], Loss: 0.5097\n",
      "Epoch [470/1000], Loss: 0.5097\n",
      "Epoch [471/1000], Loss: 0.5080\n",
      "Epoch [472/1000], Loss: 0.5076\n",
      "Epoch [473/1000], Loss: 0.5105\n",
      "Epoch [474/1000], Loss: 0.5060\n",
      "Epoch [475/1000], Loss: 0.5072\n",
      "Epoch [476/1000], Loss: 0.5085\n",
      "Epoch [477/1000], Loss: 0.5085\n",
      "Epoch [478/1000], Loss: 0.5076\n",
      "Epoch [479/1000], Loss: 0.5064\n",
      "Epoch [480/1000], Loss: 0.5076\n",
      "Epoch [481/1000], Loss: 0.5068\n",
      "Epoch [482/1000], Loss: 0.5093\n",
      "Epoch [483/1000], Loss: 0.5060\n",
      "Epoch [484/1000], Loss: 0.5076\n",
      "Epoch [485/1000], Loss: 0.5093\n",
      "Epoch [486/1000], Loss: 0.5089\n",
      "Epoch [487/1000], Loss: 0.5080\n",
      "Epoch [488/1000], Loss: 0.5080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [489/1000], Loss: 0.5113\n",
      "Epoch [490/1000], Loss: 0.5060\n",
      "Epoch [491/1000], Loss: 0.5080\n",
      "Epoch [492/1000], Loss: 0.5072\n",
      "Epoch [493/1000], Loss: 0.5101\n",
      "Epoch [494/1000], Loss: 0.5093\n",
      "Epoch [495/1000], Loss: 0.5085\n",
      "Epoch [496/1000], Loss: 0.5089\n",
      "Epoch [497/1000], Loss: 0.5076\n",
      "Epoch [498/1000], Loss: 0.5068\n",
      "Epoch [499/1000], Loss: 0.5064\n",
      "Epoch [500/1000], Loss: 0.5093\n",
      "Epoch [501/1000], Loss: 0.5093\n",
      "Epoch [502/1000], Loss: 0.5064\n",
      "Epoch [503/1000], Loss: 0.5097\n",
      "Epoch [504/1000], Loss: 0.5089\n",
      "Epoch [505/1000], Loss: 0.5093\n",
      "Epoch [506/1000], Loss: 0.5093\n",
      "Epoch [507/1000], Loss: 0.5068\n",
      "Epoch [508/1000], Loss: 0.5072\n",
      "Epoch [509/1000], Loss: 0.5125\n",
      "Epoch [510/1000], Loss: 0.5089\n",
      "Epoch [511/1000], Loss: 0.5093\n",
      "Epoch [512/1000], Loss: 0.5105\n",
      "Epoch [513/1000], Loss: 0.5105\n",
      "Epoch [514/1000], Loss: 0.5093\n",
      "Epoch [515/1000], Loss: 0.5080\n",
      "Epoch [516/1000], Loss: 0.5085\n",
      "Epoch [517/1000], Loss: 0.5085\n",
      "Epoch [518/1000], Loss: 0.5072\n",
      "Epoch [519/1000], Loss: 0.5109\n",
      "Epoch [520/1000], Loss: 0.5076\n",
      "Epoch [521/1000], Loss: 0.5072\n",
      "Epoch [522/1000], Loss: 0.5089\n",
      "Epoch [523/1000], Loss: 0.5093\n",
      "Epoch [524/1000], Loss: 0.5085\n",
      "Epoch [525/1000], Loss: 0.5085\n",
      "Epoch [526/1000], Loss: 0.5089\n",
      "Epoch [527/1000], Loss: 0.5109\n",
      "Epoch [528/1000], Loss: 0.5089\n",
      "Epoch [529/1000], Loss: 0.5105\n",
      "Epoch [530/1000], Loss: 0.5089\n",
      "Epoch [531/1000], Loss: 0.5076\n",
      "Epoch [532/1000], Loss: 0.5089\n",
      "Epoch [533/1000], Loss: 0.5068\n",
      "Epoch [534/1000], Loss: 0.5068\n",
      "Epoch [535/1000], Loss: 0.5080\n",
      "Epoch [536/1000], Loss: 0.5097\n",
      "Epoch [537/1000], Loss: 0.5060\n",
      "Epoch [538/1000], Loss: 0.5089\n",
      "Epoch [539/1000], Loss: 0.5085\n",
      "Epoch [540/1000], Loss: 0.5101\n",
      "Epoch [541/1000], Loss: 0.5085\n",
      "Epoch [542/1000], Loss: 0.5064\n",
      "Epoch [543/1000], Loss: 0.5072\n",
      "Epoch [544/1000], Loss: 0.5085\n",
      "Epoch [545/1000], Loss: 0.5076\n",
      "Epoch [546/1000], Loss: 0.5080\n",
      "Epoch [547/1000], Loss: 0.5085\n",
      "Epoch [548/1000], Loss: 0.5080\n",
      "Epoch [549/1000], Loss: 0.5085\n",
      "Epoch [550/1000], Loss: 0.5085\n",
      "Epoch [551/1000], Loss: 0.5101\n",
      "Epoch [552/1000], Loss: 0.5080\n",
      "Epoch [553/1000], Loss: 0.5101\n",
      "Epoch [554/1000], Loss: 0.5089\n",
      "Epoch [555/1000], Loss: 0.5076\n",
      "Epoch [556/1000], Loss: 0.5076\n",
      "Epoch [557/1000], Loss: 0.5080\n",
      "Epoch [558/1000], Loss: 0.5076\n",
      "Epoch [559/1000], Loss: 0.5097\n",
      "Epoch [560/1000], Loss: 0.5113\n",
      "Epoch [561/1000], Loss: 0.5068\n",
      "Epoch [562/1000], Loss: 0.5101\n",
      "Epoch [563/1000], Loss: 0.5076\n",
      "Epoch [564/1000], Loss: 0.5072\n",
      "Epoch [565/1000], Loss: 0.5085\n",
      "Epoch [566/1000], Loss: 0.5093\n",
      "Epoch [567/1000], Loss: 0.5080\n",
      "Epoch [568/1000], Loss: 0.5089\n",
      "Epoch [569/1000], Loss: 0.5097\n",
      "Epoch [570/1000], Loss: 0.5060\n",
      "Epoch [571/1000], Loss: 0.5085\n",
      "Epoch [572/1000], Loss: 0.5064\n",
      "Epoch [573/1000], Loss: 0.5097\n",
      "Epoch [574/1000], Loss: 0.5080\n",
      "Epoch [575/1000], Loss: 0.5080\n",
      "Epoch [576/1000], Loss: 0.5089\n",
      "Epoch [577/1000], Loss: 0.5085\n",
      "Epoch [578/1000], Loss: 0.5109\n",
      "Epoch [579/1000], Loss: 0.5072\n",
      "Epoch [580/1000], Loss: 0.5089\n",
      "Epoch [581/1000], Loss: 0.5093\n",
      "Epoch [582/1000], Loss: 0.5072\n",
      "Epoch [583/1000], Loss: 0.5068\n",
      "Epoch [584/1000], Loss: 0.5101\n",
      "Epoch [585/1000], Loss: 0.5089\n",
      "Epoch [586/1000], Loss: 0.5056\n",
      "Epoch [587/1000], Loss: 0.5072\n",
      "Epoch [588/1000], Loss: 0.5109\n",
      "Epoch [589/1000], Loss: 0.5076\n",
      "Epoch [590/1000], Loss: 0.5113\n",
      "Epoch [591/1000], Loss: 0.5064\n",
      "Epoch [592/1000], Loss: 0.5080\n",
      "Epoch [593/1000], Loss: 0.5093\n",
      "Epoch [594/1000], Loss: 0.5089\n",
      "Epoch [595/1000], Loss: 0.5080\n",
      "Epoch [596/1000], Loss: 0.5064\n",
      "Epoch [597/1000], Loss: 0.5080\n",
      "Epoch [598/1000], Loss: 0.5072\n",
      "Epoch [599/1000], Loss: 0.5064\n",
      "Epoch [600/1000], Loss: 0.5080\n",
      "Epoch [601/1000], Loss: 0.5064\n",
      "Epoch [602/1000], Loss: 0.5076\n",
      "Epoch [603/1000], Loss: 0.5085\n",
      "Epoch [604/1000], Loss: 0.5080\n",
      "Epoch [605/1000], Loss: 0.5089\n",
      "Epoch [606/1000], Loss: 0.5101\n",
      "Epoch [607/1000], Loss: 0.5080\n",
      "Epoch [608/1000], Loss: 0.5072\n",
      "Epoch [609/1000], Loss: 0.5085\n",
      "Epoch [610/1000], Loss: 0.5068\n",
      "Epoch [611/1000], Loss: 0.5085\n",
      "Epoch [612/1000], Loss: 0.5064\n",
      "Epoch [613/1000], Loss: 0.5085\n",
      "Epoch [614/1000], Loss: 0.5068\n",
      "Epoch [615/1000], Loss: 0.5097\n",
      "Epoch [616/1000], Loss: 0.5068\n",
      "Epoch [617/1000], Loss: 0.5085\n",
      "Epoch [618/1000], Loss: 0.5052\n",
      "Epoch [619/1000], Loss: 0.5085\n",
      "Epoch [620/1000], Loss: 0.5085\n",
      "Epoch [621/1000], Loss: 0.5093\n",
      "Epoch [622/1000], Loss: 0.5072\n",
      "Epoch [623/1000], Loss: 0.5089\n",
      "Epoch [624/1000], Loss: 0.5080\n",
      "Epoch [625/1000], Loss: 0.5072\n",
      "Epoch [626/1000], Loss: 0.5097\n",
      "Epoch [627/1000], Loss: 0.5076\n",
      "Epoch [628/1000], Loss: 0.5101\n",
      "Epoch [629/1000], Loss: 0.5080\n",
      "Epoch [630/1000], Loss: 0.5080\n",
      "Epoch [631/1000], Loss: 0.5060\n",
      "Epoch [632/1000], Loss: 0.5089\n",
      "Epoch [633/1000], Loss: 0.5085\n",
      "Epoch [634/1000], Loss: 0.5113\n",
      "Epoch [635/1000], Loss: 0.5076\n",
      "Epoch [636/1000], Loss: 0.5097\n",
      "Epoch [637/1000], Loss: 0.5080\n",
      "Epoch [638/1000], Loss: 0.5101\n",
      "Epoch [639/1000], Loss: 0.5072\n",
      "Epoch [640/1000], Loss: 0.5072\n",
      "Epoch [641/1000], Loss: 0.5064\n",
      "Epoch [642/1000], Loss: 0.5080\n",
      "Epoch [643/1000], Loss: 0.5064\n",
      "Epoch [644/1000], Loss: 0.5060\n",
      "Epoch [645/1000], Loss: 0.5076\n",
      "Epoch [646/1000], Loss: 0.5052\n",
      "Epoch [647/1000], Loss: 0.5101\n",
      "Epoch [648/1000], Loss: 0.5076\n",
      "Epoch [649/1000], Loss: 0.5076\n",
      "Epoch [650/1000], Loss: 0.5089\n",
      "Epoch [651/1000], Loss: 0.5089\n",
      "Epoch [652/1000], Loss: 0.5052\n",
      "Epoch [653/1000], Loss: 0.5072\n",
      "Epoch [654/1000], Loss: 0.5097\n",
      "Epoch [655/1000], Loss: 0.5085\n",
      "Epoch [656/1000], Loss: 0.5097\n",
      "Epoch [657/1000], Loss: 0.5097\n",
      "Epoch [658/1000], Loss: 0.5076\n",
      "Epoch [659/1000], Loss: 0.5080\n",
      "Epoch [660/1000], Loss: 0.5072\n",
      "Epoch [661/1000], Loss: 0.5113\n",
      "Epoch [662/1000], Loss: 0.5097\n",
      "Epoch [663/1000], Loss: 0.5064\n",
      "Epoch [664/1000], Loss: 0.5080\n",
      "Epoch [665/1000], Loss: 0.5089\n",
      "Epoch [666/1000], Loss: 0.5097\n",
      "Epoch [667/1000], Loss: 0.5101\n",
      "Epoch [668/1000], Loss: 0.5080\n",
      "Epoch [669/1000], Loss: 0.5093\n",
      "Epoch [670/1000], Loss: 0.5076\n",
      "Epoch [671/1000], Loss: 0.5068\n",
      "Epoch [672/1000], Loss: 0.5093\n",
      "Epoch [673/1000], Loss: 0.5085\n",
      "Epoch [674/1000], Loss: 0.5089\n",
      "Epoch [675/1000], Loss: 0.5105\n",
      "Epoch [676/1000], Loss: 0.5089\n",
      "Epoch [677/1000], Loss: 0.5068\n",
      "Epoch [678/1000], Loss: 0.5068\n",
      "Epoch [679/1000], Loss: 0.5076\n",
      "Epoch [680/1000], Loss: 0.5085\n",
      "Epoch [681/1000], Loss: 0.5076\n",
      "Epoch [682/1000], Loss: 0.5085\n",
      "Epoch [683/1000], Loss: 0.5093\n",
      "Epoch [684/1000], Loss: 0.5109\n",
      "Epoch [685/1000], Loss: 0.5089\n",
      "Epoch [686/1000], Loss: 0.5080\n",
      "Epoch [687/1000], Loss: 0.5060\n",
      "Epoch [688/1000], Loss: 0.5093\n",
      "Epoch [689/1000], Loss: 0.5085\n",
      "Epoch [690/1000], Loss: 0.5089\n",
      "Epoch [691/1000], Loss: 0.5076\n",
      "Epoch [692/1000], Loss: 0.5101\n",
      "Epoch [693/1000], Loss: 0.5097\n",
      "Epoch [694/1000], Loss: 0.5060\n",
      "Epoch [695/1000], Loss: 0.5105\n",
      "Epoch [696/1000], Loss: 0.5076\n",
      "Epoch [697/1000], Loss: 0.5068\n",
      "Epoch [698/1000], Loss: 0.5076\n",
      "Epoch [699/1000], Loss: 0.5064\n",
      "Epoch [700/1000], Loss: 0.5076\n",
      "Epoch [701/1000], Loss: 0.5089\n",
      "Epoch [702/1000], Loss: 0.5093\n",
      "Epoch [703/1000], Loss: 0.5060\n",
      "Epoch [704/1000], Loss: 0.5085\n",
      "Epoch [705/1000], Loss: 0.5072\n",
      "Epoch [706/1000], Loss: 0.5089\n",
      "Epoch [707/1000], Loss: 0.5109\n",
      "Epoch [708/1000], Loss: 0.5093\n",
      "Epoch [709/1000], Loss: 0.5085\n",
      "Epoch [710/1000], Loss: 0.5097\n",
      "Epoch [711/1000], Loss: 0.5072\n",
      "Epoch [712/1000], Loss: 0.5064\n",
      "Epoch [713/1000], Loss: 0.5060\n",
      "Epoch [714/1000], Loss: 0.5101\n",
      "Epoch [715/1000], Loss: 0.5080\n",
      "Epoch [716/1000], Loss: 0.5072\n",
      "Epoch [717/1000], Loss: 0.5080\n",
      "Epoch [718/1000], Loss: 0.5085\n",
      "Epoch [719/1000], Loss: 0.5097\n",
      "Epoch [720/1000], Loss: 0.5068\n",
      "Epoch [721/1000], Loss: 0.5076\n",
      "Epoch [722/1000], Loss: 0.5085\n",
      "Epoch [723/1000], Loss: 0.5085\n",
      "Epoch [724/1000], Loss: 0.5105\n",
      "Epoch [725/1000], Loss: 0.5093\n",
      "Epoch [726/1000], Loss: 0.5080\n",
      "Epoch [727/1000], Loss: 0.5080\n",
      "Epoch [728/1000], Loss: 0.5068\n",
      "Epoch [729/1000], Loss: 0.5085\n",
      "Epoch [730/1000], Loss: 0.5080\n",
      "Epoch [731/1000], Loss: 0.5072\n",
      "Epoch [732/1000], Loss: 0.5089\n",
      "Epoch [733/1000], Loss: 0.5089\n",
      "Epoch [734/1000], Loss: 0.5085\n",
      "Epoch [735/1000], Loss: 0.5093\n",
      "Epoch [736/1000], Loss: 0.5097\n",
      "Epoch [737/1000], Loss: 0.5089\n",
      "Epoch [738/1000], Loss: 0.5080\n",
      "Epoch [739/1000], Loss: 0.5089\n",
      "Epoch [740/1000], Loss: 0.5056\n",
      "Epoch [741/1000], Loss: 0.5089\n",
      "Epoch [742/1000], Loss: 0.5080\n",
      "Epoch [743/1000], Loss: 0.5076\n",
      "Epoch [744/1000], Loss: 0.5097\n",
      "Epoch [745/1000], Loss: 0.5105\n",
      "Epoch [746/1000], Loss: 0.5105\n",
      "Epoch [747/1000], Loss: 0.5097\n",
      "Epoch [748/1000], Loss: 0.5076\n",
      "Epoch [749/1000], Loss: 0.5068\n",
      "Epoch [750/1000], Loss: 0.5097\n",
      "Epoch [751/1000], Loss: 0.5097\n",
      "Epoch [752/1000], Loss: 0.5076\n",
      "Epoch [753/1000], Loss: 0.5080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [754/1000], Loss: 0.5052\n",
      "Epoch [755/1000], Loss: 0.5080\n",
      "Epoch [756/1000], Loss: 0.5097\n",
      "Epoch [757/1000], Loss: 0.5064\n",
      "Epoch [758/1000], Loss: 0.5080\n",
      "Epoch [759/1000], Loss: 0.5068\n",
      "Epoch [760/1000], Loss: 0.5085\n",
      "Epoch [761/1000], Loss: 0.5072\n",
      "Epoch [762/1000], Loss: 0.5072\n",
      "Epoch [763/1000], Loss: 0.5076\n",
      "Epoch [764/1000], Loss: 0.5076\n",
      "Epoch [765/1000], Loss: 0.5080\n",
      "Epoch [766/1000], Loss: 0.5076\n",
      "Epoch [767/1000], Loss: 0.5080\n",
      "Epoch [768/1000], Loss: 0.5085\n",
      "Epoch [769/1000], Loss: 0.5076\n",
      "Epoch [770/1000], Loss: 0.5097\n",
      "Epoch [771/1000], Loss: 0.5101\n",
      "Epoch [772/1000], Loss: 0.5101\n",
      "Epoch [773/1000], Loss: 0.5089\n",
      "Epoch [774/1000], Loss: 0.5093\n",
      "Epoch [775/1000], Loss: 0.5085\n",
      "Epoch [776/1000], Loss: 0.5064\n",
      "Epoch [777/1000], Loss: 0.5085\n",
      "Epoch [778/1000], Loss: 0.5068\n",
      "Epoch [779/1000], Loss: 0.5072\n",
      "Epoch [780/1000], Loss: 0.5109\n",
      "Epoch [781/1000], Loss: 0.5093\n",
      "Epoch [782/1000], Loss: 0.5105\n",
      "Epoch [783/1000], Loss: 0.5060\n",
      "Epoch [784/1000], Loss: 0.5080\n",
      "Epoch [785/1000], Loss: 0.5097\n",
      "Epoch [786/1000], Loss: 0.5085\n",
      "Epoch [787/1000], Loss: 0.5080\n",
      "Epoch [788/1000], Loss: 0.5093\n",
      "Epoch [789/1000], Loss: 0.5080\n",
      "Epoch [790/1000], Loss: 0.5068\n",
      "Epoch [791/1000], Loss: 0.5072\n",
      "Epoch [792/1000], Loss: 0.5093\n",
      "Epoch [793/1000], Loss: 0.5064\n",
      "Epoch [794/1000], Loss: 0.5093\n",
      "Epoch [795/1000], Loss: 0.5085\n",
      "Epoch [796/1000], Loss: 0.5068\n",
      "Epoch [797/1000], Loss: 0.5089\n",
      "Epoch [798/1000], Loss: 0.5093\n",
      "Epoch [799/1000], Loss: 0.5089\n",
      "Epoch [800/1000], Loss: 0.5056\n",
      "Epoch [801/1000], Loss: 0.5080\n",
      "Epoch [802/1000], Loss: 0.5052\n",
      "Epoch [803/1000], Loss: 0.5109\n",
      "Epoch [804/1000], Loss: 0.5080\n",
      "Epoch [805/1000], Loss: 0.5097\n",
      "Epoch [806/1000], Loss: 0.5072\n",
      "Epoch [807/1000], Loss: 0.5097\n",
      "Epoch [808/1000], Loss: 0.5076\n",
      "Epoch [809/1000], Loss: 0.5097\n",
      "Epoch [810/1000], Loss: 0.5064\n",
      "Epoch [811/1000], Loss: 0.5068\n",
      "Epoch [812/1000], Loss: 0.5072\n",
      "Epoch [813/1000], Loss: 0.5072\n",
      "Epoch [814/1000], Loss: 0.5072\n",
      "Epoch [815/1000], Loss: 0.5064\n",
      "Epoch [816/1000], Loss: 0.5085\n",
      "Epoch [817/1000], Loss: 0.5093\n",
      "Epoch [818/1000], Loss: 0.5097\n",
      "Epoch [819/1000], Loss: 0.5085\n",
      "Epoch [820/1000], Loss: 0.5080\n",
      "Epoch [821/1000], Loss: 0.5101\n",
      "Epoch [822/1000], Loss: 0.5068\n",
      "Epoch [823/1000], Loss: 0.5068\n",
      "Epoch [824/1000], Loss: 0.5089\n",
      "Epoch [825/1000], Loss: 0.5064\n",
      "Epoch [826/1000], Loss: 0.5072\n",
      "Epoch [827/1000], Loss: 0.5080\n",
      "Epoch [828/1000], Loss: 0.5076\n",
      "Epoch [829/1000], Loss: 0.5109\n",
      "Epoch [830/1000], Loss: 0.5076\n",
      "Epoch [831/1000], Loss: 0.5093\n",
      "Epoch [832/1000], Loss: 0.5076\n",
      "Epoch [833/1000], Loss: 0.5080\n",
      "Epoch [834/1000], Loss: 0.5072\n",
      "Epoch [835/1000], Loss: 0.5080\n",
      "Epoch [836/1000], Loss: 0.5060\n",
      "Epoch [837/1000], Loss: 0.5097\n",
      "Epoch [838/1000], Loss: 0.5085\n",
      "Epoch [839/1000], Loss: 0.5089\n",
      "Epoch [840/1000], Loss: 0.5068\n",
      "Epoch [841/1000], Loss: 0.5085\n",
      "Epoch [842/1000], Loss: 0.5072\n",
      "Epoch [843/1000], Loss: 0.5080\n",
      "Epoch [844/1000], Loss: 0.5072\n",
      "Epoch [845/1000], Loss: 0.5101\n",
      "Epoch [846/1000], Loss: 0.5060\n",
      "Epoch [847/1000], Loss: 0.5080\n",
      "Epoch [848/1000], Loss: 0.5085\n",
      "Epoch [849/1000], Loss: 0.5068\n",
      "Epoch [850/1000], Loss: 0.5105\n",
      "Epoch [851/1000], Loss: 0.5097\n",
      "Epoch [852/1000], Loss: 0.5076\n",
      "Epoch [853/1000], Loss: 0.5072\n",
      "Epoch [854/1000], Loss: 0.5093\n",
      "Epoch [855/1000], Loss: 0.5080\n",
      "Epoch [856/1000], Loss: 0.5080\n",
      "Epoch [857/1000], Loss: 0.5105\n",
      "Epoch [858/1000], Loss: 0.5072\n",
      "Epoch [859/1000], Loss: 0.5072\n",
      "Epoch [860/1000], Loss: 0.5072\n",
      "Epoch [861/1000], Loss: 0.5064\n",
      "Epoch [862/1000], Loss: 0.5085\n",
      "Epoch [863/1000], Loss: 0.5105\n",
      "Epoch [864/1000], Loss: 0.5089\n",
      "Epoch [865/1000], Loss: 0.5060\n",
      "Epoch [866/1000], Loss: 0.5101\n",
      "Epoch [867/1000], Loss: 0.5072\n",
      "Epoch [868/1000], Loss: 0.5093\n",
      "Epoch [869/1000], Loss: 0.5089\n",
      "Epoch [870/1000], Loss: 0.5072\n",
      "Epoch [871/1000], Loss: 0.5101\n",
      "Epoch [872/1000], Loss: 0.5072\n",
      "Epoch [873/1000], Loss: 0.5072\n",
      "Epoch [874/1000], Loss: 0.5080\n",
      "Epoch [875/1000], Loss: 0.5068\n",
      "Epoch [876/1000], Loss: 0.5089\n",
      "Epoch [877/1000], Loss: 0.5076\n",
      "Epoch [878/1000], Loss: 0.5085\n",
      "Epoch [879/1000], Loss: 0.5080\n",
      "Epoch [880/1000], Loss: 0.5093\n",
      "Epoch [881/1000], Loss: 0.5072\n",
      "Epoch [882/1000], Loss: 0.5113\n",
      "Epoch [883/1000], Loss: 0.5076\n",
      "Epoch [884/1000], Loss: 0.5113\n",
      "Epoch [885/1000], Loss: 0.5072\n",
      "Epoch [886/1000], Loss: 0.5072\n",
      "Epoch [887/1000], Loss: 0.5060\n",
      "Epoch [888/1000], Loss: 0.5085\n",
      "Epoch [889/1000], Loss: 0.5101\n",
      "Epoch [890/1000], Loss: 0.5076\n",
      "Epoch [891/1000], Loss: 0.5089\n",
      "Epoch [892/1000], Loss: 0.5089\n",
      "Epoch [893/1000], Loss: 0.5093\n",
      "Epoch [894/1000], Loss: 0.5089\n",
      "Epoch [895/1000], Loss: 0.5085\n",
      "Epoch [896/1000], Loss: 0.5085\n",
      "Epoch [897/1000], Loss: 0.5085\n",
      "Epoch [898/1000], Loss: 0.5097\n",
      "Epoch [899/1000], Loss: 0.5089\n",
      "Epoch [900/1000], Loss: 0.5097\n",
      "Epoch [901/1000], Loss: 0.5109\n",
      "Epoch [902/1000], Loss: 0.5085\n",
      "Epoch [903/1000], Loss: 0.5064\n",
      "Epoch [904/1000], Loss: 0.5097\n",
      "Epoch [905/1000], Loss: 0.5076\n",
      "Epoch [906/1000], Loss: 0.5080\n",
      "Epoch [907/1000], Loss: 0.5085\n",
      "Epoch [908/1000], Loss: 0.5076\n",
      "Epoch [909/1000], Loss: 0.5101\n",
      "Epoch [910/1000], Loss: 0.5064\n",
      "Epoch [911/1000], Loss: 0.5093\n",
      "Epoch [912/1000], Loss: 0.5101\n",
      "Epoch [913/1000], Loss: 0.5072\n",
      "Epoch [914/1000], Loss: 0.5072\n",
      "Epoch [915/1000], Loss: 0.5072\n",
      "Epoch [916/1000], Loss: 0.5093\n",
      "Epoch [917/1000], Loss: 0.5085\n",
      "Epoch [918/1000], Loss: 0.5064\n",
      "Epoch [919/1000], Loss: 0.5097\n",
      "Epoch [920/1000], Loss: 0.5097\n",
      "Epoch [921/1000], Loss: 0.5064\n",
      "Epoch [922/1000], Loss: 0.5105\n",
      "Epoch [923/1000], Loss: 0.5068\n",
      "Epoch [924/1000], Loss: 0.5097\n",
      "Epoch [925/1000], Loss: 0.5085\n",
      "Epoch [926/1000], Loss: 0.5072\n",
      "Epoch [927/1000], Loss: 0.5060\n",
      "Epoch [928/1000], Loss: 0.5089\n",
      "Epoch [929/1000], Loss: 0.5097\n",
      "Epoch [930/1000], Loss: 0.5101\n",
      "Epoch [931/1000], Loss: 0.5068\n",
      "Epoch [932/1000], Loss: 0.5068\n",
      "Epoch [933/1000], Loss: 0.5076\n",
      "Epoch [934/1000], Loss: 0.5089\n",
      "Epoch [935/1000], Loss: 0.5076\n",
      "Epoch [936/1000], Loss: 0.5093\n",
      "Epoch [937/1000], Loss: 0.5072\n",
      "Epoch [938/1000], Loss: 0.5097\n",
      "Epoch [939/1000], Loss: 0.5072\n",
      "Epoch [940/1000], Loss: 0.5060\n",
      "Epoch [941/1000], Loss: 0.5080\n",
      "Epoch [942/1000], Loss: 0.5080\n",
      "Epoch [943/1000], Loss: 0.5093\n",
      "Epoch [944/1000], Loss: 0.5093\n",
      "Epoch [945/1000], Loss: 0.5056\n",
      "Epoch [946/1000], Loss: 0.5076\n",
      "Epoch [947/1000], Loss: 0.5093\n",
      "Epoch [948/1000], Loss: 0.5093\n",
      "Epoch [949/1000], Loss: 0.5068\n",
      "Epoch [950/1000], Loss: 0.5080\n",
      "Epoch [951/1000], Loss: 0.5117\n",
      "Epoch [952/1000], Loss: 0.5076\n",
      "Epoch [953/1000], Loss: 0.5085\n",
      "Epoch [954/1000], Loss: 0.5093\n",
      "Epoch [955/1000], Loss: 0.5089\n",
      "Epoch [956/1000], Loss: 0.5089\n",
      "Epoch [957/1000], Loss: 0.5089\n",
      "Epoch [958/1000], Loss: 0.5076\n",
      "Epoch [959/1000], Loss: 0.5085\n",
      "Epoch [960/1000], Loss: 0.5076\n",
      "Epoch [961/1000], Loss: 0.5085\n",
      "Epoch [962/1000], Loss: 0.5101\n",
      "Epoch [963/1000], Loss: 0.5072\n",
      "Epoch [964/1000], Loss: 0.5093\n",
      "Epoch [965/1000], Loss: 0.5085\n",
      "Epoch [966/1000], Loss: 0.5113\n",
      "Epoch [967/1000], Loss: 0.5093\n",
      "Epoch [968/1000], Loss: 0.5085\n",
      "Epoch [969/1000], Loss: 0.5080\n",
      "Epoch [970/1000], Loss: 0.5076\n",
      "Epoch [971/1000], Loss: 0.5076\n",
      "Epoch [972/1000], Loss: 0.5089\n",
      "Epoch [973/1000], Loss: 0.5076\n",
      "Epoch [974/1000], Loss: 0.5085\n",
      "Epoch [975/1000], Loss: 0.5089\n",
      "Epoch [976/1000], Loss: 0.5056\n",
      "Epoch [977/1000], Loss: 0.5101\n",
      "Epoch [978/1000], Loss: 0.5109\n",
      "Epoch [979/1000], Loss: 0.5089\n",
      "Epoch [980/1000], Loss: 0.5076\n",
      "Epoch [981/1000], Loss: 0.5068\n",
      "Epoch [982/1000], Loss: 0.5072\n",
      "Epoch [983/1000], Loss: 0.5089\n",
      "Epoch [984/1000], Loss: 0.5076\n",
      "Epoch [985/1000], Loss: 0.5085\n",
      "Epoch [986/1000], Loss: 0.5105\n",
      "Epoch [987/1000], Loss: 0.5072\n",
      "Epoch [988/1000], Loss: 0.5080\n",
      "Epoch [989/1000], Loss: 0.5076\n",
      "Epoch [990/1000], Loss: 0.5060\n",
      "Epoch [991/1000], Loss: 0.5060\n",
      "Epoch [992/1000], Loss: 0.5072\n",
      "Epoch [993/1000], Loss: 0.5068\n",
      "Epoch [994/1000], Loss: 0.5089\n",
      "Epoch [995/1000], Loss: 0.5097\n",
      "Epoch [996/1000], Loss: 0.5093\n",
      "Epoch [997/1000], Loss: 0.5056\n",
      "Epoch [998/1000], Loss: 0.5080\n",
      "Epoch [999/1000], Loss: 0.5085\n",
      "Epoch [1000/1000], Loss: 0.5080\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 107, lr :1.0, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.5113\n",
      "Epoch [2/1000], Loss: 0.5180\n",
      "Epoch [3/1000], Loss: 0.5175\n",
      "Epoch [4/1000], Loss: 0.5188\n",
      "Epoch [5/1000], Loss: 0.5167\n",
      "Epoch [6/1000], Loss: 0.5188\n",
      "Epoch [7/1000], Loss: 0.5204\n",
      "Epoch [8/1000], Loss: 0.5188\n",
      "Epoch [9/1000], Loss: 0.5192\n",
      "Epoch [10/1000], Loss: 0.5155\n",
      "Epoch [11/1000], Loss: 0.5184\n",
      "Epoch [12/1000], Loss: 0.5200\n",
      "Epoch [13/1000], Loss: 0.5188\n",
      "Epoch [14/1000], Loss: 0.5163\n",
      "Epoch [15/1000], Loss: 0.5171\n",
      "Epoch [16/1000], Loss: 0.5204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/1000], Loss: 0.5180\n",
      "Epoch [18/1000], Loss: 0.5180\n",
      "Epoch [19/1000], Loss: 0.5175\n",
      "Epoch [20/1000], Loss: 0.5155\n",
      "Epoch [21/1000], Loss: 0.5192\n",
      "Epoch [22/1000], Loss: 0.5175\n",
      "Epoch [23/1000], Loss: 0.5163\n",
      "Epoch [24/1000], Loss: 0.5192\n",
      "Epoch [25/1000], Loss: 0.5163\n",
      "Epoch [26/1000], Loss: 0.5175\n",
      "Epoch [27/1000], Loss: 0.5224\n",
      "Epoch [28/1000], Loss: 0.5175\n",
      "Epoch [29/1000], Loss: 0.5163\n",
      "Epoch [30/1000], Loss: 0.5171\n",
      "Epoch [31/1000], Loss: 0.5159\n",
      "Epoch [32/1000], Loss: 0.5175\n",
      "Epoch [33/1000], Loss: 0.5196\n",
      "Epoch [34/1000], Loss: 0.5147\n",
      "Epoch [35/1000], Loss: 0.5167\n",
      "Epoch [36/1000], Loss: 0.5188\n",
      "Epoch [37/1000], Loss: 0.5159\n",
      "Epoch [38/1000], Loss: 0.5184\n",
      "Epoch [39/1000], Loss: 0.5192\n",
      "Epoch [40/1000], Loss: 0.5175\n",
      "Epoch [41/1000], Loss: 0.5184\n",
      "Epoch [42/1000], Loss: 0.5175\n",
      "Epoch [43/1000], Loss: 0.5175\n",
      "Epoch [44/1000], Loss: 0.5175\n",
      "Epoch [45/1000], Loss: 0.5171\n",
      "Epoch [46/1000], Loss: 0.5192\n",
      "Epoch [47/1000], Loss: 0.5155\n",
      "Epoch [48/1000], Loss: 0.5175\n",
      "Epoch [49/1000], Loss: 0.5167\n",
      "Epoch [50/1000], Loss: 0.5171\n",
      "Epoch [51/1000], Loss: 0.5159\n",
      "Epoch [52/1000], Loss: 0.5184\n",
      "Epoch [53/1000], Loss: 0.5171\n",
      "Epoch [54/1000], Loss: 0.5180\n",
      "Epoch [55/1000], Loss: 0.5192\n",
      "Epoch [56/1000], Loss: 0.5175\n",
      "Epoch [57/1000], Loss: 0.5196\n",
      "Epoch [58/1000], Loss: 0.5188\n",
      "Epoch [59/1000], Loss: 0.5196\n",
      "Epoch [60/1000], Loss: 0.5180\n",
      "Epoch [61/1000], Loss: 0.5180\n",
      "Epoch [62/1000], Loss: 0.5147\n",
      "Epoch [63/1000], Loss: 0.5167\n",
      "Epoch [64/1000], Loss: 0.5188\n",
      "Epoch [65/1000], Loss: 0.5167\n",
      "Epoch [66/1000], Loss: 0.5192\n",
      "Epoch [67/1000], Loss: 0.5200\n",
      "Epoch [68/1000], Loss: 0.5171\n",
      "Epoch [69/1000], Loss: 0.5188\n",
      "Epoch [70/1000], Loss: 0.5196\n",
      "Epoch [71/1000], Loss: 0.5163\n",
      "Epoch [72/1000], Loss: 0.5171\n",
      "Epoch [73/1000], Loss: 0.5155\n",
      "Epoch [74/1000], Loss: 0.5159\n",
      "Epoch [75/1000], Loss: 0.5180\n",
      "Epoch [76/1000], Loss: 0.5188\n",
      "Epoch [77/1000], Loss: 0.5188\n",
      "Epoch [78/1000], Loss: 0.5196\n",
      "Epoch [79/1000], Loss: 0.5175\n",
      "Epoch [80/1000], Loss: 0.5192\n",
      "Epoch [81/1000], Loss: 0.5151\n",
      "Epoch [82/1000], Loss: 0.5175\n",
      "Epoch [83/1000], Loss: 0.5196\n",
      "Epoch [84/1000], Loss: 0.5167\n",
      "Epoch [85/1000], Loss: 0.5184\n",
      "Epoch [86/1000], Loss: 0.5204\n",
      "Epoch [87/1000], Loss: 0.5184\n",
      "Epoch [88/1000], Loss: 0.5180\n",
      "Epoch [89/1000], Loss: 0.5171\n",
      "Epoch [90/1000], Loss: 0.5196\n",
      "Epoch [91/1000], Loss: 0.5180\n",
      "Epoch [92/1000], Loss: 0.5192\n",
      "Epoch [93/1000], Loss: 0.5159\n",
      "Epoch [94/1000], Loss: 0.5171\n",
      "Epoch [95/1000], Loss: 0.5184\n",
      "Epoch [96/1000], Loss: 0.5200\n",
      "Epoch [97/1000], Loss: 0.5200\n",
      "Epoch [98/1000], Loss: 0.5196\n",
      "Epoch [99/1000], Loss: 0.5192\n",
      "Epoch [100/1000], Loss: 0.5171\n",
      "Epoch [101/1000], Loss: 0.5171\n",
      "Epoch [102/1000], Loss: 0.5163\n",
      "Epoch [103/1000], Loss: 0.5184\n",
      "Epoch [104/1000], Loss: 0.5208\n",
      "Epoch [105/1000], Loss: 0.5171\n",
      "Epoch [106/1000], Loss: 0.5192\n",
      "Epoch [107/1000], Loss: 0.5175\n",
      "Epoch [108/1000], Loss: 0.5192\n",
      "Epoch [109/1000], Loss: 0.5167\n",
      "Epoch [110/1000], Loss: 0.5188\n",
      "Epoch [111/1000], Loss: 0.5167\n",
      "Epoch [112/1000], Loss: 0.5175\n",
      "Epoch [113/1000], Loss: 0.5175\n",
      "Epoch [114/1000], Loss: 0.5147\n",
      "Epoch [115/1000], Loss: 0.5155\n",
      "Epoch [116/1000], Loss: 0.5188\n",
      "Epoch [117/1000], Loss: 0.5155\n",
      "Epoch [118/1000], Loss: 0.5167\n",
      "Epoch [119/1000], Loss: 0.5200\n",
      "Epoch [120/1000], Loss: 0.5188\n",
      "Epoch [121/1000], Loss: 0.5167\n",
      "Epoch [122/1000], Loss: 0.5192\n",
      "Epoch [123/1000], Loss: 0.5184\n",
      "Epoch [124/1000], Loss: 0.5188\n",
      "Epoch [125/1000], Loss: 0.5188\n",
      "Epoch [126/1000], Loss: 0.5192\n",
      "Epoch [127/1000], Loss: 0.5180\n",
      "Epoch [128/1000], Loss: 0.5171\n",
      "Epoch [129/1000], Loss: 0.5196\n",
      "Epoch [130/1000], Loss: 0.5188\n",
      "Epoch [131/1000], Loss: 0.5159\n",
      "Epoch [132/1000], Loss: 0.5155\n",
      "Epoch [133/1000], Loss: 0.5167\n",
      "Epoch [134/1000], Loss: 0.5184\n",
      "Epoch [135/1000], Loss: 0.5159\n",
      "Epoch [136/1000], Loss: 0.5175\n",
      "Epoch [137/1000], Loss: 0.5163\n",
      "Epoch [138/1000], Loss: 0.5196\n",
      "Epoch [139/1000], Loss: 0.5180\n",
      "Epoch [140/1000], Loss: 0.5163\n",
      "Epoch [141/1000], Loss: 0.5184\n",
      "Epoch [142/1000], Loss: 0.5192\n",
      "Epoch [143/1000], Loss: 0.5188\n",
      "Epoch [144/1000], Loss: 0.5175\n",
      "Epoch [145/1000], Loss: 0.5175\n",
      "Epoch [146/1000], Loss: 0.5180\n",
      "Epoch [147/1000], Loss: 0.5175\n",
      "Epoch [148/1000], Loss: 0.5200\n",
      "Epoch [149/1000], Loss: 0.5159\n",
      "Epoch [150/1000], Loss: 0.5175\n",
      "Epoch [151/1000], Loss: 0.5167\n",
      "Epoch [152/1000], Loss: 0.5184\n",
      "Epoch [153/1000], Loss: 0.5167\n",
      "Epoch [154/1000], Loss: 0.5200\n",
      "Epoch [155/1000], Loss: 0.5171\n",
      "Epoch [156/1000], Loss: 0.5196\n",
      "Epoch [157/1000], Loss: 0.5180\n",
      "Epoch [158/1000], Loss: 0.5167\n",
      "Epoch [159/1000], Loss: 0.5196\n",
      "Epoch [160/1000], Loss: 0.5171\n",
      "Epoch [161/1000], Loss: 0.5171\n",
      "Epoch [162/1000], Loss: 0.5196\n",
      "Epoch [163/1000], Loss: 0.5192\n",
      "Epoch [164/1000], Loss: 0.5175\n",
      "Epoch [165/1000], Loss: 0.5180\n",
      "Epoch [166/1000], Loss: 0.5188\n",
      "Epoch [167/1000], Loss: 0.5171\n",
      "Epoch [168/1000], Loss: 0.5200\n",
      "Epoch [169/1000], Loss: 0.5184\n",
      "Epoch [170/1000], Loss: 0.5171\n",
      "Epoch [171/1000], Loss: 0.5175\n",
      "Epoch [172/1000], Loss: 0.5171\n",
      "Epoch [173/1000], Loss: 0.5167\n",
      "Epoch [174/1000], Loss: 0.5163\n",
      "Epoch [175/1000], Loss: 0.5180\n",
      "Epoch [176/1000], Loss: 0.5192\n",
      "Epoch [177/1000], Loss: 0.5196\n",
      "Epoch [178/1000], Loss: 0.5175\n",
      "Epoch [179/1000], Loss: 0.5188\n",
      "Epoch [180/1000], Loss: 0.5188\n",
      "Epoch [181/1000], Loss: 0.5163\n",
      "Epoch [182/1000], Loss: 0.5192\n",
      "Epoch [183/1000], Loss: 0.5192\n",
      "Epoch [184/1000], Loss: 0.5171\n",
      "Epoch [185/1000], Loss: 0.5180\n",
      "Epoch [186/1000], Loss: 0.5188\n",
      "Epoch [187/1000], Loss: 0.5155\n",
      "Epoch [188/1000], Loss: 0.5175\n",
      "Epoch [189/1000], Loss: 0.5180\n",
      "Epoch [190/1000], Loss: 0.5167\n",
      "Epoch [191/1000], Loss: 0.5175\n",
      "Epoch [192/1000], Loss: 0.5188\n",
      "Epoch [193/1000], Loss: 0.5192\n",
      "Epoch [194/1000], Loss: 0.5175\n",
      "Epoch [195/1000], Loss: 0.5180\n",
      "Epoch [196/1000], Loss: 0.5200\n",
      "Epoch [197/1000], Loss: 0.5171\n",
      "Epoch [198/1000], Loss: 0.5196\n",
      "Epoch [199/1000], Loss: 0.5188\n",
      "Epoch [200/1000], Loss: 0.5192\n",
      "Epoch [201/1000], Loss: 0.5171\n",
      "Epoch [202/1000], Loss: 0.5188\n",
      "Epoch [203/1000], Loss: 0.5175\n",
      "Epoch [204/1000], Loss: 0.5180\n",
      "Epoch [205/1000], Loss: 0.5192\n",
      "Epoch [206/1000], Loss: 0.5175\n",
      "Epoch [207/1000], Loss: 0.5192\n",
      "Epoch [208/1000], Loss: 0.5167\n",
      "Epoch [209/1000], Loss: 0.5167\n",
      "Epoch [210/1000], Loss: 0.5188\n",
      "Epoch [211/1000], Loss: 0.5192\n",
      "Epoch [212/1000], Loss: 0.5180\n",
      "Epoch [213/1000], Loss: 0.5159\n",
      "Epoch [214/1000], Loss: 0.5180\n",
      "Epoch [215/1000], Loss: 0.5184\n",
      "Epoch [216/1000], Loss: 0.5196\n",
      "Epoch [217/1000], Loss: 0.5200\n",
      "Epoch [218/1000], Loss: 0.5184\n",
      "Epoch [219/1000], Loss: 0.5192\n",
      "Epoch [220/1000], Loss: 0.5171\n",
      "Epoch [221/1000], Loss: 0.5155\n",
      "Epoch [222/1000], Loss: 0.5196\n",
      "Epoch [223/1000], Loss: 0.5188\n",
      "Epoch [224/1000], Loss: 0.5163\n",
      "Epoch [225/1000], Loss: 0.5188\n",
      "Epoch [226/1000], Loss: 0.5167\n",
      "Epoch [227/1000], Loss: 0.5175\n",
      "Epoch [228/1000], Loss: 0.5163\n",
      "Epoch [229/1000], Loss: 0.5184\n",
      "Epoch [230/1000], Loss: 0.5175\n",
      "Epoch [231/1000], Loss: 0.5192\n",
      "Epoch [232/1000], Loss: 0.5180\n",
      "Epoch [233/1000], Loss: 0.5180\n",
      "Epoch [234/1000], Loss: 0.5175\n",
      "Epoch [235/1000], Loss: 0.5175\n",
      "Epoch [236/1000], Loss: 0.5200\n",
      "Epoch [237/1000], Loss: 0.5184\n",
      "Epoch [238/1000], Loss: 0.5171\n",
      "Epoch [239/1000], Loss: 0.5208\n",
      "Epoch [240/1000], Loss: 0.5171\n",
      "Epoch [241/1000], Loss: 0.5171\n",
      "Epoch [242/1000], Loss: 0.5167\n",
      "Epoch [243/1000], Loss: 0.5196\n",
      "Epoch [244/1000], Loss: 0.5204\n",
      "Epoch [245/1000], Loss: 0.5192\n",
      "Epoch [246/1000], Loss: 0.5184\n",
      "Epoch [247/1000], Loss: 0.5184\n",
      "Epoch [248/1000], Loss: 0.5204\n",
      "Epoch [249/1000], Loss: 0.5208\n",
      "Epoch [250/1000], Loss: 0.5184\n",
      "Epoch [251/1000], Loss: 0.5163\n",
      "Epoch [252/1000], Loss: 0.5171\n",
      "Epoch [253/1000], Loss: 0.5163\n",
      "Epoch [254/1000], Loss: 0.5188\n",
      "Epoch [255/1000], Loss: 0.5180\n",
      "Epoch [256/1000], Loss: 0.5196\n",
      "Epoch [257/1000], Loss: 0.5188\n",
      "Epoch [258/1000], Loss: 0.5159\n",
      "Epoch [259/1000], Loss: 0.5167\n",
      "Epoch [260/1000], Loss: 0.5188\n",
      "Epoch [261/1000], Loss: 0.5167\n",
      "Epoch [262/1000], Loss: 0.5204\n",
      "Epoch [263/1000], Loss: 0.5196\n",
      "Epoch [264/1000], Loss: 0.5192\n",
      "Epoch [265/1000], Loss: 0.5167\n",
      "Epoch [266/1000], Loss: 0.5155\n",
      "Epoch [267/1000], Loss: 0.5163\n",
      "Epoch [268/1000], Loss: 0.5188\n",
      "Epoch [269/1000], Loss: 0.5155\n",
      "Epoch [270/1000], Loss: 0.5171\n",
      "Epoch [271/1000], Loss: 0.5175\n",
      "Epoch [272/1000], Loss: 0.5171\n",
      "Epoch [273/1000], Loss: 0.5204\n",
      "Epoch [274/1000], Loss: 0.5180\n",
      "Epoch [275/1000], Loss: 0.5171\n",
      "Epoch [276/1000], Loss: 0.5184\n",
      "Epoch [277/1000], Loss: 0.5204\n",
      "Epoch [278/1000], Loss: 0.5188\n",
      "Epoch [279/1000], Loss: 0.5192\n",
      "Epoch [280/1000], Loss: 0.5184\n",
      "Epoch [281/1000], Loss: 0.5180\n",
      "Epoch [282/1000], Loss: 0.5159\n",
      "Epoch [283/1000], Loss: 0.5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [284/1000], Loss: 0.5188\n",
      "Epoch [285/1000], Loss: 0.5159\n",
      "Epoch [286/1000], Loss: 0.5192\n",
      "Epoch [287/1000], Loss: 0.5220\n",
      "Epoch [288/1000], Loss: 0.5175\n",
      "Epoch [289/1000], Loss: 0.5159\n",
      "Epoch [290/1000], Loss: 0.5163\n",
      "Epoch [291/1000], Loss: 0.5155\n",
      "Epoch [292/1000], Loss: 0.5184\n",
      "Epoch [293/1000], Loss: 0.5196\n",
      "Epoch [294/1000], Loss: 0.5175\n",
      "Epoch [295/1000], Loss: 0.5188\n",
      "Epoch [296/1000], Loss: 0.5192\n",
      "Epoch [297/1000], Loss: 0.5188\n",
      "Epoch [298/1000], Loss: 0.5175\n",
      "Epoch [299/1000], Loss: 0.5180\n",
      "Epoch [300/1000], Loss: 0.5163\n",
      "Epoch [301/1000], Loss: 0.5167\n",
      "Epoch [302/1000], Loss: 0.5171\n",
      "Epoch [303/1000], Loss: 0.5192\n",
      "Epoch [304/1000], Loss: 0.5192\n",
      "Epoch [305/1000], Loss: 0.5167\n",
      "Epoch [306/1000], Loss: 0.5159\n",
      "Epoch [307/1000], Loss: 0.5184\n",
      "Epoch [308/1000], Loss: 0.5171\n",
      "Epoch [309/1000], Loss: 0.5175\n",
      "Epoch [310/1000], Loss: 0.5184\n",
      "Epoch [311/1000], Loss: 0.5171\n",
      "Epoch [312/1000], Loss: 0.5196\n",
      "Epoch [313/1000], Loss: 0.5188\n",
      "Epoch [314/1000], Loss: 0.5171\n",
      "Epoch [315/1000], Loss: 0.5180\n",
      "Epoch [316/1000], Loss: 0.5175\n",
      "Epoch [317/1000], Loss: 0.5220\n",
      "Epoch [318/1000], Loss: 0.5159\n",
      "Epoch [319/1000], Loss: 0.5171\n",
      "Epoch [320/1000], Loss: 0.5184\n",
      "Epoch [321/1000], Loss: 0.5171\n",
      "Epoch [322/1000], Loss: 0.5175\n",
      "Epoch [323/1000], Loss: 0.5175\n",
      "Epoch [324/1000], Loss: 0.5188\n",
      "Epoch [325/1000], Loss: 0.5167\n",
      "Epoch [326/1000], Loss: 0.5167\n",
      "Epoch [327/1000], Loss: 0.5180\n",
      "Epoch [328/1000], Loss: 0.5196\n",
      "Epoch [329/1000], Loss: 0.5171\n",
      "Epoch [330/1000], Loss: 0.5196\n",
      "Epoch [331/1000], Loss: 0.5180\n",
      "Epoch [332/1000], Loss: 0.5167\n",
      "Epoch [333/1000], Loss: 0.5188\n",
      "Epoch [334/1000], Loss: 0.5192\n",
      "Epoch [335/1000], Loss: 0.5184\n",
      "Epoch [336/1000], Loss: 0.5180\n",
      "Epoch [337/1000], Loss: 0.5184\n",
      "Epoch [338/1000], Loss: 0.5175\n",
      "Epoch [339/1000], Loss: 0.5188\n",
      "Epoch [340/1000], Loss: 0.5175\n",
      "Epoch [341/1000], Loss: 0.5188\n",
      "Epoch [342/1000], Loss: 0.5171\n",
      "Epoch [343/1000], Loss: 0.5184\n",
      "Epoch [344/1000], Loss: 0.5147\n",
      "Epoch [345/1000], Loss: 0.5175\n",
      "Epoch [346/1000], Loss: 0.5163\n",
      "Epoch [347/1000], Loss: 0.5167\n",
      "Epoch [348/1000], Loss: 0.5180\n",
      "Epoch [349/1000], Loss: 0.5175\n",
      "Epoch [350/1000], Loss: 0.5171\n",
      "Epoch [351/1000], Loss: 0.5175\n",
      "Epoch [352/1000], Loss: 0.5184\n",
      "Epoch [353/1000], Loss: 0.5163\n",
      "Epoch [354/1000], Loss: 0.5192\n",
      "Epoch [355/1000], Loss: 0.5192\n",
      "Epoch [356/1000], Loss: 0.5171\n",
      "Epoch [357/1000], Loss: 0.5167\n",
      "Epoch [358/1000], Loss: 0.5184\n",
      "Epoch [359/1000], Loss: 0.5167\n",
      "Epoch [360/1000], Loss: 0.5163\n",
      "Epoch [361/1000], Loss: 0.5180\n",
      "Epoch [362/1000], Loss: 0.5175\n",
      "Epoch [363/1000], Loss: 0.5196\n",
      "Epoch [364/1000], Loss: 0.5167\n",
      "Epoch [365/1000], Loss: 0.5171\n",
      "Epoch [366/1000], Loss: 0.5159\n",
      "Epoch [367/1000], Loss: 0.5139\n",
      "Epoch [368/1000], Loss: 0.5192\n",
      "Epoch [369/1000], Loss: 0.5180\n",
      "Epoch [370/1000], Loss: 0.5184\n",
      "Epoch [371/1000], Loss: 0.5175\n",
      "Epoch [372/1000], Loss: 0.5171\n",
      "Epoch [373/1000], Loss: 0.5200\n",
      "Epoch [374/1000], Loss: 0.5159\n",
      "Epoch [375/1000], Loss: 0.5212\n",
      "Epoch [376/1000], Loss: 0.5163\n",
      "Epoch [377/1000], Loss: 0.5159\n",
      "Epoch [378/1000], Loss: 0.5184\n",
      "Epoch [379/1000], Loss: 0.5180\n",
      "Epoch [380/1000], Loss: 0.5175\n",
      "Epoch [381/1000], Loss: 0.5196\n",
      "Epoch [382/1000], Loss: 0.5184\n",
      "Epoch [383/1000], Loss: 0.5196\n",
      "Epoch [384/1000], Loss: 0.5184\n",
      "Epoch [385/1000], Loss: 0.5204\n",
      "Epoch [386/1000], Loss: 0.5188\n",
      "Epoch [387/1000], Loss: 0.5196\n",
      "Epoch [388/1000], Loss: 0.5175\n",
      "Epoch [389/1000], Loss: 0.5159\n",
      "Epoch [390/1000], Loss: 0.5180\n",
      "Epoch [391/1000], Loss: 0.5184\n",
      "Epoch [392/1000], Loss: 0.5159\n",
      "Epoch [393/1000], Loss: 0.5184\n",
      "Epoch [394/1000], Loss: 0.5159\n",
      "Epoch [395/1000], Loss: 0.5188\n",
      "Epoch [396/1000], Loss: 0.5175\n",
      "Epoch [397/1000], Loss: 0.5180\n",
      "Epoch [398/1000], Loss: 0.5175\n",
      "Epoch [399/1000], Loss: 0.5171\n",
      "Epoch [400/1000], Loss: 0.5175\n",
      "Epoch [401/1000], Loss: 0.5171\n",
      "Epoch [402/1000], Loss: 0.5184\n",
      "Epoch [403/1000], Loss: 0.5192\n",
      "Epoch [404/1000], Loss: 0.5175\n",
      "Epoch [405/1000], Loss: 0.5192\n",
      "Epoch [406/1000], Loss: 0.5167\n",
      "Epoch [407/1000], Loss: 0.5184\n",
      "Epoch [408/1000], Loss: 0.5180\n",
      "Epoch [409/1000], Loss: 0.5175\n",
      "Epoch [410/1000], Loss: 0.5163\n",
      "Epoch [411/1000], Loss: 0.5167\n",
      "Epoch [412/1000], Loss: 0.5184\n",
      "Epoch [413/1000], Loss: 0.5192\n",
      "Epoch [414/1000], Loss: 0.5200\n",
      "Epoch [415/1000], Loss: 0.5188\n",
      "Epoch [416/1000], Loss: 0.5163\n",
      "Epoch [417/1000], Loss: 0.5184\n",
      "Epoch [418/1000], Loss: 0.5175\n",
      "Epoch [419/1000], Loss: 0.5163\n",
      "Epoch [420/1000], Loss: 0.5155\n",
      "Epoch [421/1000], Loss: 0.5184\n",
      "Epoch [422/1000], Loss: 0.5188\n",
      "Epoch [423/1000], Loss: 0.5184\n",
      "Epoch [424/1000], Loss: 0.5171\n",
      "Epoch [425/1000], Loss: 0.5143\n",
      "Epoch [426/1000], Loss: 0.5196\n",
      "Epoch [427/1000], Loss: 0.5159\n",
      "Epoch [428/1000], Loss: 0.5196\n",
      "Epoch [429/1000], Loss: 0.5159\n",
      "Epoch [430/1000], Loss: 0.5192\n",
      "Epoch [431/1000], Loss: 0.5188\n",
      "Epoch [432/1000], Loss: 0.5163\n",
      "Epoch [433/1000], Loss: 0.5167\n",
      "Epoch [434/1000], Loss: 0.5175\n",
      "Epoch [435/1000], Loss: 0.5175\n",
      "Epoch [436/1000], Loss: 0.5208\n",
      "Epoch [437/1000], Loss: 0.5180\n",
      "Epoch [438/1000], Loss: 0.5200\n",
      "Epoch [439/1000], Loss: 0.5175\n",
      "Epoch [440/1000], Loss: 0.5175\n",
      "Epoch [441/1000], Loss: 0.5171\n",
      "Epoch [442/1000], Loss: 0.5192\n",
      "Epoch [443/1000], Loss: 0.5200\n",
      "Epoch [444/1000], Loss: 0.5200\n",
      "Epoch [445/1000], Loss: 0.5184\n",
      "Epoch [446/1000], Loss: 0.5188\n",
      "Epoch [447/1000], Loss: 0.5188\n",
      "Epoch [448/1000], Loss: 0.5200\n",
      "Epoch [449/1000], Loss: 0.5192\n",
      "Epoch [450/1000], Loss: 0.5184\n",
      "Epoch [451/1000], Loss: 0.5171\n",
      "Epoch [452/1000], Loss: 0.5184\n",
      "Epoch [453/1000], Loss: 0.5188\n",
      "Epoch [454/1000], Loss: 0.5212\n",
      "Epoch [455/1000], Loss: 0.5188\n",
      "Epoch [456/1000], Loss: 0.5175\n",
      "Epoch [457/1000], Loss: 0.5167\n",
      "Epoch [458/1000], Loss: 0.5192\n",
      "Epoch [459/1000], Loss: 0.5175\n",
      "Epoch [460/1000], Loss: 0.5208\n",
      "Epoch [461/1000], Loss: 0.5163\n",
      "Epoch [462/1000], Loss: 0.5163\n",
      "Epoch [463/1000], Loss: 0.5159\n",
      "Epoch [464/1000], Loss: 0.5151\n",
      "Epoch [465/1000], Loss: 0.5192\n",
      "Epoch [466/1000], Loss: 0.5180\n",
      "Epoch [467/1000], Loss: 0.5184\n",
      "Epoch [468/1000], Loss: 0.5180\n",
      "Epoch [469/1000], Loss: 0.5180\n",
      "Epoch [470/1000], Loss: 0.5200\n",
      "Epoch [471/1000], Loss: 0.5192\n",
      "Epoch [472/1000], Loss: 0.5200\n",
      "Epoch [473/1000], Loss: 0.5180\n",
      "Epoch [474/1000], Loss: 0.5151\n",
      "Epoch [475/1000], Loss: 0.5192\n",
      "Epoch [476/1000], Loss: 0.5192\n",
      "Epoch [477/1000], Loss: 0.5196\n",
      "Epoch [478/1000], Loss: 0.5163\n",
      "Epoch [479/1000], Loss: 0.5200\n",
      "Epoch [480/1000], Loss: 0.5143\n",
      "Epoch [481/1000], Loss: 0.5171\n",
      "Epoch [482/1000], Loss: 0.5192\n",
      "Epoch [483/1000], Loss: 0.5180\n",
      "Epoch [484/1000], Loss: 0.5188\n",
      "Epoch [485/1000], Loss: 0.5159\n",
      "Epoch [486/1000], Loss: 0.5188\n",
      "Epoch [487/1000], Loss: 0.5184\n",
      "Epoch [488/1000], Loss: 0.5167\n",
      "Epoch [489/1000], Loss: 0.5171\n",
      "Epoch [490/1000], Loss: 0.5188\n",
      "Epoch [491/1000], Loss: 0.5171\n",
      "Epoch [492/1000], Loss: 0.5175\n",
      "Epoch [493/1000], Loss: 0.5163\n",
      "Epoch [494/1000], Loss: 0.5171\n",
      "Epoch [495/1000], Loss: 0.5188\n",
      "Epoch [496/1000], Loss: 0.5171\n",
      "Epoch [497/1000], Loss: 0.5212\n",
      "Epoch [498/1000], Loss: 0.5184\n",
      "Epoch [499/1000], Loss: 0.5171\n",
      "Epoch [500/1000], Loss: 0.5192\n",
      "Epoch [501/1000], Loss: 0.5196\n",
      "Epoch [502/1000], Loss: 0.5175\n",
      "Epoch [503/1000], Loss: 0.5175\n",
      "Epoch [504/1000], Loss: 0.5167\n",
      "Epoch [505/1000], Loss: 0.5175\n",
      "Epoch [506/1000], Loss: 0.5147\n",
      "Epoch [507/1000], Loss: 0.5196\n",
      "Epoch [508/1000], Loss: 0.5192\n",
      "Epoch [509/1000], Loss: 0.5192\n",
      "Epoch [510/1000], Loss: 0.5167\n",
      "Epoch [511/1000], Loss: 0.5184\n",
      "Epoch [512/1000], Loss: 0.5196\n",
      "Epoch [513/1000], Loss: 0.5192\n",
      "Epoch [514/1000], Loss: 0.5192\n",
      "Epoch [515/1000], Loss: 0.5175\n",
      "Epoch [516/1000], Loss: 0.5167\n",
      "Epoch [517/1000], Loss: 0.5175\n",
      "Epoch [518/1000], Loss: 0.5188\n",
      "Epoch [519/1000], Loss: 0.5184\n",
      "Epoch [520/1000], Loss: 0.5171\n",
      "Epoch [521/1000], Loss: 0.5204\n",
      "Epoch [522/1000], Loss: 0.5175\n",
      "Epoch [523/1000], Loss: 0.5188\n",
      "Epoch [524/1000], Loss: 0.5204\n",
      "Epoch [525/1000], Loss: 0.5196\n",
      "Epoch [526/1000], Loss: 0.5180\n",
      "Epoch [527/1000], Loss: 0.5192\n",
      "Epoch [528/1000], Loss: 0.5163\n",
      "Epoch [529/1000], Loss: 0.5171\n",
      "Epoch [530/1000], Loss: 0.5192\n",
      "Epoch [531/1000], Loss: 0.5188\n",
      "Epoch [532/1000], Loss: 0.5167\n",
      "Epoch [533/1000], Loss: 0.5204\n",
      "Epoch [534/1000], Loss: 0.5167\n",
      "Epoch [535/1000], Loss: 0.5192\n",
      "Epoch [536/1000], Loss: 0.5171\n",
      "Epoch [537/1000], Loss: 0.5184\n",
      "Epoch [538/1000], Loss: 0.5175\n",
      "Epoch [539/1000], Loss: 0.5171\n",
      "Epoch [540/1000], Loss: 0.5184\n",
      "Epoch [541/1000], Loss: 0.5163\n",
      "Epoch [542/1000], Loss: 0.5175\n",
      "Epoch [543/1000], Loss: 0.5171\n",
      "Epoch [544/1000], Loss: 0.5167\n",
      "Epoch [545/1000], Loss: 0.5171\n",
      "Epoch [546/1000], Loss: 0.5184\n",
      "Epoch [547/1000], Loss: 0.5196\n",
      "Epoch [548/1000], Loss: 0.5184\n",
      "Epoch [549/1000], Loss: 0.5180\n",
      "Epoch [550/1000], Loss: 0.5171\n",
      "Epoch [551/1000], Loss: 0.5196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [552/1000], Loss: 0.5171\n",
      "Epoch [553/1000], Loss: 0.5175\n",
      "Epoch [554/1000], Loss: 0.5188\n",
      "Epoch [555/1000], Loss: 0.5196\n",
      "Epoch [556/1000], Loss: 0.5184\n",
      "Epoch [557/1000], Loss: 0.5159\n",
      "Epoch [558/1000], Loss: 0.5167\n",
      "Epoch [559/1000], Loss: 0.5167\n",
      "Epoch [560/1000], Loss: 0.5184\n",
      "Epoch [561/1000], Loss: 0.5175\n",
      "Epoch [562/1000], Loss: 0.5167\n",
      "Epoch [563/1000], Loss: 0.5184\n",
      "Epoch [564/1000], Loss: 0.5200\n",
      "Epoch [565/1000], Loss: 0.5180\n",
      "Epoch [566/1000], Loss: 0.5163\n",
      "Epoch [567/1000], Loss: 0.5180\n",
      "Epoch [568/1000], Loss: 0.5175\n",
      "Epoch [569/1000], Loss: 0.5184\n",
      "Epoch [570/1000], Loss: 0.5184\n",
      "Epoch [571/1000], Loss: 0.5180\n",
      "Epoch [572/1000], Loss: 0.5192\n",
      "Epoch [573/1000], Loss: 0.5167\n",
      "Epoch [574/1000], Loss: 0.5188\n",
      "Epoch [575/1000], Loss: 0.5171\n",
      "Epoch [576/1000], Loss: 0.5184\n",
      "Epoch [577/1000], Loss: 0.5188\n",
      "Epoch [578/1000], Loss: 0.5163\n",
      "Epoch [579/1000], Loss: 0.5180\n",
      "Epoch [580/1000], Loss: 0.5175\n",
      "Epoch [581/1000], Loss: 0.5188\n",
      "Epoch [582/1000], Loss: 0.5180\n",
      "Epoch [583/1000], Loss: 0.5212\n",
      "Epoch [584/1000], Loss: 0.5175\n",
      "Epoch [585/1000], Loss: 0.5159\n",
      "Epoch [586/1000], Loss: 0.5171\n",
      "Epoch [587/1000], Loss: 0.5188\n",
      "Epoch [588/1000], Loss: 0.5167\n",
      "Epoch [589/1000], Loss: 0.5184\n",
      "Epoch [590/1000], Loss: 0.5192\n",
      "Epoch [591/1000], Loss: 0.5163\n",
      "Epoch [592/1000], Loss: 0.5171\n",
      "Epoch [593/1000], Loss: 0.5163\n",
      "Epoch [594/1000], Loss: 0.5192\n",
      "Epoch [595/1000], Loss: 0.5171\n",
      "Epoch [596/1000], Loss: 0.5175\n",
      "Epoch [597/1000], Loss: 0.5184\n",
      "Epoch [598/1000], Loss: 0.5192\n",
      "Epoch [599/1000], Loss: 0.5175\n",
      "Epoch [600/1000], Loss: 0.5171\n",
      "Epoch [601/1000], Loss: 0.5171\n",
      "Epoch [602/1000], Loss: 0.5188\n",
      "Epoch [603/1000], Loss: 0.5180\n",
      "Epoch [604/1000], Loss: 0.5159\n",
      "Epoch [605/1000], Loss: 0.5171\n",
      "Epoch [606/1000], Loss: 0.5171\n",
      "Epoch [607/1000], Loss: 0.5163\n",
      "Epoch [608/1000], Loss: 0.5159\n",
      "Epoch [609/1000], Loss: 0.5184\n",
      "Epoch [610/1000], Loss: 0.5159\n",
      "Epoch [611/1000], Loss: 0.5188\n",
      "Epoch [612/1000], Loss: 0.5171\n",
      "Epoch [613/1000], Loss: 0.5175\n",
      "Epoch [614/1000], Loss: 0.5159\n",
      "Epoch [615/1000], Loss: 0.5171\n",
      "Epoch [616/1000], Loss: 0.5175\n",
      "Epoch [617/1000], Loss: 0.5167\n",
      "Epoch [618/1000], Loss: 0.5180\n",
      "Epoch [619/1000], Loss: 0.5180\n",
      "Epoch [620/1000], Loss: 0.5204\n",
      "Epoch [621/1000], Loss: 0.5167\n",
      "Epoch [622/1000], Loss: 0.5163\n",
      "Epoch [623/1000], Loss: 0.5175\n",
      "Epoch [624/1000], Loss: 0.5184\n",
      "Epoch [625/1000], Loss: 0.5171\n",
      "Epoch [626/1000], Loss: 0.5184\n",
      "Epoch [627/1000], Loss: 0.5200\n",
      "Epoch [628/1000], Loss: 0.5175\n",
      "Epoch [629/1000], Loss: 0.5175\n",
      "Epoch [630/1000], Loss: 0.5163\n",
      "Epoch [631/1000], Loss: 0.5184\n",
      "Epoch [632/1000], Loss: 0.5171\n",
      "Epoch [633/1000], Loss: 0.5159\n",
      "Epoch [634/1000], Loss: 0.5167\n",
      "Epoch [635/1000], Loss: 0.5171\n",
      "Epoch [636/1000], Loss: 0.5180\n",
      "Epoch [637/1000], Loss: 0.5180\n",
      "Epoch [638/1000], Loss: 0.5196\n",
      "Epoch [639/1000], Loss: 0.5204\n",
      "Epoch [640/1000], Loss: 0.5188\n",
      "Epoch [641/1000], Loss: 0.5175\n",
      "Epoch [642/1000], Loss: 0.5175\n",
      "Epoch [643/1000], Loss: 0.5204\n",
      "Epoch [644/1000], Loss: 0.5184\n",
      "Epoch [645/1000], Loss: 0.5180\n",
      "Epoch [646/1000], Loss: 0.5147\n",
      "Epoch [647/1000], Loss: 0.5167\n",
      "Epoch [648/1000], Loss: 0.5171\n",
      "Epoch [649/1000], Loss: 0.5175\n",
      "Epoch [650/1000], Loss: 0.5180\n",
      "Epoch [651/1000], Loss: 0.5188\n",
      "Epoch [652/1000], Loss: 0.5188\n",
      "Epoch [653/1000], Loss: 0.5159\n",
      "Epoch [654/1000], Loss: 0.5196\n",
      "Epoch [655/1000], Loss: 0.5192\n",
      "Epoch [656/1000], Loss: 0.5196\n",
      "Epoch [657/1000], Loss: 0.5192\n",
      "Epoch [658/1000], Loss: 0.5204\n",
      "Epoch [659/1000], Loss: 0.5171\n",
      "Epoch [660/1000], Loss: 0.5188\n",
      "Epoch [661/1000], Loss: 0.5167\n",
      "Epoch [662/1000], Loss: 0.5163\n",
      "Epoch [663/1000], Loss: 0.5167\n",
      "Epoch [664/1000], Loss: 0.5171\n",
      "Epoch [665/1000], Loss: 0.5171\n",
      "Epoch [666/1000], Loss: 0.5175\n",
      "Epoch [667/1000], Loss: 0.5175\n",
      "Epoch [668/1000], Loss: 0.5155\n",
      "Epoch [669/1000], Loss: 0.5188\n",
      "Epoch [670/1000], Loss: 0.5155\n",
      "Epoch [671/1000], Loss: 0.5171\n",
      "Epoch [672/1000], Loss: 0.5188\n",
      "Epoch [673/1000], Loss: 0.5175\n",
      "Epoch [674/1000], Loss: 0.5192\n",
      "Epoch [675/1000], Loss: 0.5196\n",
      "Epoch [676/1000], Loss: 0.5192\n",
      "Epoch [677/1000], Loss: 0.5200\n",
      "Epoch [678/1000], Loss: 0.5180\n",
      "Epoch [679/1000], Loss: 0.5163\n",
      "Epoch [680/1000], Loss: 0.5163\n",
      "Epoch [681/1000], Loss: 0.5175\n",
      "Epoch [682/1000], Loss: 0.5175\n",
      "Epoch [683/1000], Loss: 0.5180\n",
      "Epoch [684/1000], Loss: 0.5196\n",
      "Epoch [685/1000], Loss: 0.5139\n",
      "Epoch [686/1000], Loss: 0.5175\n",
      "Epoch [687/1000], Loss: 0.5151\n",
      "Epoch [688/1000], Loss: 0.5184\n",
      "Epoch [689/1000], Loss: 0.5159\n",
      "Epoch [690/1000], Loss: 0.5180\n",
      "Epoch [691/1000], Loss: 0.5180\n",
      "Epoch [692/1000], Loss: 0.5184\n",
      "Epoch [693/1000], Loss: 0.5175\n",
      "Epoch [694/1000], Loss: 0.5180\n",
      "Epoch [695/1000], Loss: 0.5180\n",
      "Epoch [696/1000], Loss: 0.5175\n",
      "Epoch [697/1000], Loss: 0.5180\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 49.40 %\n",
      "Training model with batch_size: 107, lr :1.0, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2436\n",
      "Epoch [2/1000], Loss: 0.2399\n",
      "Epoch [3/1000], Loss: 0.2362\n",
      "Epoch [4/1000], Loss: 0.2301\n",
      "Epoch [5/1000], Loss: 0.2185\n",
      "Epoch [6/1000], Loss: 0.2079\n",
      "Epoch [7/1000], Loss: 0.1990\n",
      "Epoch [8/1000], Loss: 0.1885\n",
      "Epoch [9/1000], Loss: 0.1714\n",
      "Epoch [10/1000], Loss: 0.1557\n",
      "Epoch [11/1000], Loss: 0.1475\n",
      "Epoch [12/1000], Loss: 0.1318\n",
      "Epoch [13/1000], Loss: 0.1273\n",
      "Epoch [14/1000], Loss: 0.1251\n",
      "Epoch [15/1000], Loss: 0.1181\n",
      "Epoch [16/1000], Loss: 0.0846\n",
      "Epoch [17/1000], Loss: 0.1133\n",
      "Epoch [18/1000], Loss: 0.0971\n",
      "Epoch [19/1000], Loss: 0.0970\n",
      "Epoch [20/1000], Loss: 0.0802\n",
      "Epoch [21/1000], Loss: 0.0655\n",
      "Epoch [22/1000], Loss: 0.0979\n",
      "Epoch [23/1000], Loss: 0.0731\n",
      "Epoch [24/1000], Loss: 0.0630\n",
      "Epoch [25/1000], Loss: 0.0972\n",
      "Epoch [26/1000], Loss: 0.0661\n",
      "Epoch [27/1000], Loss: 0.0787\n",
      "Epoch [28/1000], Loss: 0.0527\n",
      "Epoch [29/1000], Loss: 0.0659\n",
      "Epoch [30/1000], Loss: 0.0432\n",
      "Epoch [31/1000], Loss: 0.0791\n",
      "Epoch [32/1000], Loss: 0.0488\n",
      "Epoch [33/1000], Loss: 0.0414\n",
      "Epoch [34/1000], Loss: 0.0186\n",
      "Epoch [35/1000], Loss: 0.0250\n",
      "Epoch [36/1000], Loss: 0.0035\n",
      "Epoch [37/1000], Loss: 0.0021\n",
      "Epoch [38/1000], Loss: 0.0021\n",
      "Epoch [39/1000], Loss: 0.0010\n",
      "Epoch [40/1000], Loss: 0.0066\n",
      "Epoch [41/1000], Loss: 0.0009\n",
      "Epoch [42/1000], Loss: 0.0009\n",
      "Epoch [43/1000], Loss: 0.0009\n",
      "Epoch [44/1000], Loss: 0.0007\n",
      "Epoch [45/1000], Loss: 0.0005\n",
      "Epoch [46/1000], Loss: 0.0006\n",
      "Epoch [47/1000], Loss: 0.0006\n",
      "Epoch [48/1000], Loss: 0.0004\n",
      "Epoch [49/1000], Loss: 0.0004\n",
      "Epoch [50/1000], Loss: 0.0004\n",
      "Epoch [51/1000], Loss: 0.0003\n",
      "Epoch [52/1000], Loss: 0.0003\n",
      "Epoch [53/1000], Loss: 0.0003\n",
      "Epoch [54/1000], Loss: 0.0003\n",
      "Epoch [55/1000], Loss: 0.0003\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 107, lr :10.0, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.5015\n",
      "Epoch [2/1000], Loss: 0.5088\n",
      "Epoch [3/1000], Loss: 0.5076\n",
      "Epoch [4/1000], Loss: 0.5072\n",
      "Epoch [5/1000], Loss: 0.5100\n",
      "Epoch [6/1000], Loss: 0.5080\n",
      "Epoch [7/1000], Loss: 0.5076\n",
      "Epoch [8/1000], Loss: 0.5068\n",
      "Epoch [9/1000], Loss: 0.5104\n",
      "Epoch [10/1000], Loss: 0.5080\n",
      "Epoch [11/1000], Loss: 0.5056\n",
      "Epoch [12/1000], Loss: 0.5084\n",
      "Epoch [13/1000], Loss: 0.5076\n",
      "Epoch [14/1000], Loss: 0.5072\n",
      "Epoch [15/1000], Loss: 0.5076\n",
      "Epoch [16/1000], Loss: 0.5060\n",
      "Epoch [17/1000], Loss: 0.5096\n",
      "Epoch [18/1000], Loss: 0.5072\n",
      "Epoch [19/1000], Loss: 0.5060\n",
      "Epoch [20/1000], Loss: 0.5076\n",
      "Epoch [21/1000], Loss: 0.5080\n",
      "Epoch [22/1000], Loss: 0.5076\n",
      "Epoch [23/1000], Loss: 0.5080\n",
      "Epoch [24/1000], Loss: 0.5064\n",
      "Epoch [25/1000], Loss: 0.5072\n",
      "Epoch [26/1000], Loss: 0.5060\n",
      "Epoch [27/1000], Loss: 0.5056\n",
      "Epoch [28/1000], Loss: 0.5064\n",
      "Epoch [29/1000], Loss: 0.5076\n",
      "Epoch [30/1000], Loss: 0.5048\n",
      "Epoch [31/1000], Loss: 0.5076\n",
      "Epoch [32/1000], Loss: 0.5088\n",
      "Epoch [33/1000], Loss: 0.5072\n",
      "Epoch [34/1000], Loss: 0.5064\n",
      "Epoch [35/1000], Loss: 0.5068\n",
      "Epoch [36/1000], Loss: 0.5056\n",
      "Epoch [37/1000], Loss: 0.5088\n",
      "Epoch [38/1000], Loss: 0.5068\n",
      "Epoch [39/1000], Loss: 0.5064\n",
      "Epoch [40/1000], Loss: 0.5068\n",
      "Epoch [41/1000], Loss: 0.5056\n",
      "Epoch [42/1000], Loss: 0.5060\n",
      "Epoch [43/1000], Loss: 0.5084\n",
      "Epoch [44/1000], Loss: 0.5064\n",
      "Epoch [45/1000], Loss: 0.5072\n",
      "Epoch [46/1000], Loss: 0.5072\n",
      "Epoch [47/1000], Loss: 0.5080\n",
      "Epoch [48/1000], Loss: 0.5064\n",
      "Epoch [49/1000], Loss: 0.5068\n",
      "Epoch [50/1000], Loss: 0.5064\n",
      "Epoch [51/1000], Loss: 0.5100\n",
      "Epoch [52/1000], Loss: 0.5064\n",
      "Epoch [53/1000], Loss: 0.5064\n",
      "Epoch [54/1000], Loss: 0.5064\n",
      "Epoch [55/1000], Loss: 0.5088\n",
      "Epoch [56/1000], Loss: 0.5044\n",
      "Epoch [57/1000], Loss: 0.5068\n",
      "Epoch [58/1000], Loss: 0.5064\n",
      "Epoch [59/1000], Loss: 0.5084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/1000], Loss: 0.5068\n",
      "Epoch [61/1000], Loss: 0.5064\n",
      "Epoch [62/1000], Loss: 0.5056\n",
      "Epoch [63/1000], Loss: 0.5056\n",
      "Epoch [64/1000], Loss: 0.5064\n",
      "Epoch [65/1000], Loss: 0.5076\n",
      "Epoch [66/1000], Loss: 0.5064\n",
      "Epoch [67/1000], Loss: 0.5060\n",
      "Epoch [68/1000], Loss: 0.5072\n",
      "Epoch [69/1000], Loss: 0.5060\n",
      "Epoch [70/1000], Loss: 0.5080\n",
      "Epoch [71/1000], Loss: 0.5092\n",
      "Epoch [72/1000], Loss: 0.5076\n",
      "Epoch [73/1000], Loss: 0.5060\n",
      "Epoch [74/1000], Loss: 0.5076\n",
      "Epoch [75/1000], Loss: 0.5048\n",
      "Epoch [76/1000], Loss: 0.5084\n",
      "Epoch [77/1000], Loss: 0.5056\n",
      "Epoch [78/1000], Loss: 0.5092\n",
      "Epoch [79/1000], Loss: 0.5060\n",
      "Epoch [80/1000], Loss: 0.5068\n",
      "Epoch [81/1000], Loss: 0.5052\n",
      "Epoch [82/1000], Loss: 0.5064\n",
      "Epoch [83/1000], Loss: 0.5052\n",
      "Epoch [84/1000], Loss: 0.5076\n",
      "Epoch [85/1000], Loss: 0.5088\n",
      "Epoch [86/1000], Loss: 0.5060\n",
      "Epoch [87/1000], Loss: 0.5068\n",
      "Epoch [88/1000], Loss: 0.5080\n",
      "Epoch [89/1000], Loss: 0.5076\n",
      "Epoch [90/1000], Loss: 0.5044\n",
      "Epoch [91/1000], Loss: 0.5072\n",
      "Epoch [92/1000], Loss: 0.5064\n",
      "Epoch [93/1000], Loss: 0.5096\n",
      "Epoch [94/1000], Loss: 0.5096\n",
      "Epoch [95/1000], Loss: 0.5080\n",
      "Epoch [96/1000], Loss: 0.5064\n",
      "Epoch [97/1000], Loss: 0.5044\n",
      "Epoch [98/1000], Loss: 0.5056\n",
      "Epoch [99/1000], Loss: 0.5076\n",
      "Epoch [100/1000], Loss: 0.5080\n",
      "Epoch [101/1000], Loss: 0.5060\n",
      "Epoch [102/1000], Loss: 0.5072\n",
      "Epoch [103/1000], Loss: 0.5076\n",
      "Epoch [104/1000], Loss: 0.5068\n",
      "Epoch [105/1000], Loss: 0.5052\n",
      "Epoch [106/1000], Loss: 0.5068\n",
      "Epoch [107/1000], Loss: 0.5076\n",
      "Epoch [108/1000], Loss: 0.5096\n",
      "Epoch [109/1000], Loss: 0.5056\n",
      "Epoch [110/1000], Loss: 0.5080\n",
      "Epoch [111/1000], Loss: 0.5084\n",
      "Epoch [112/1000], Loss: 0.5060\n",
      "Epoch [113/1000], Loss: 0.5076\n",
      "Epoch [114/1000], Loss: 0.5048\n",
      "Epoch [115/1000], Loss: 0.5076\n",
      "Epoch [116/1000], Loss: 0.5052\n",
      "Epoch [117/1000], Loss: 0.5072\n",
      "Epoch [118/1000], Loss: 0.5064\n",
      "Epoch [119/1000], Loss: 0.5072\n",
      "Epoch [120/1000], Loss: 0.5100\n",
      "Epoch [121/1000], Loss: 0.5092\n",
      "Epoch [122/1000], Loss: 0.5056\n",
      "Epoch [123/1000], Loss: 0.5056\n",
      "Epoch [124/1000], Loss: 0.5064\n",
      "Epoch [125/1000], Loss: 0.5056\n",
      "Epoch [126/1000], Loss: 0.5084\n",
      "Epoch [127/1000], Loss: 0.5072\n",
      "Epoch [128/1000], Loss: 0.5056\n",
      "Epoch [129/1000], Loss: 0.5080\n",
      "Epoch [130/1000], Loss: 0.5048\n",
      "Epoch [131/1000], Loss: 0.5068\n",
      "Epoch [132/1000], Loss: 0.5060\n",
      "Epoch [133/1000], Loss: 0.5080\n",
      "Epoch [134/1000], Loss: 0.5076\n",
      "Epoch [135/1000], Loss: 0.5080\n",
      "Epoch [136/1000], Loss: 0.5080\n",
      "Epoch [137/1000], Loss: 0.5076\n",
      "Epoch [138/1000], Loss: 0.5076\n",
      "Epoch [139/1000], Loss: 0.5076\n",
      "Epoch [140/1000], Loss: 0.5052\n",
      "Epoch [141/1000], Loss: 0.5072\n",
      "Epoch [142/1000], Loss: 0.5048\n",
      "Epoch [143/1000], Loss: 0.5072\n",
      "Epoch [144/1000], Loss: 0.5084\n",
      "Epoch [145/1000], Loss: 0.5080\n",
      "Epoch [146/1000], Loss: 0.5068\n",
      "Epoch [147/1000], Loss: 0.5068\n",
      "Epoch [148/1000], Loss: 0.5064\n",
      "Epoch [149/1000], Loss: 0.5080\n",
      "Epoch [150/1000], Loss: 0.5056\n",
      "Epoch [151/1000], Loss: 0.5084\n",
      "Epoch [152/1000], Loss: 0.5080\n",
      "Epoch [153/1000], Loss: 0.5060\n",
      "Epoch [154/1000], Loss: 0.5064\n",
      "Epoch [155/1000], Loss: 0.5056\n",
      "Epoch [156/1000], Loss: 0.5080\n",
      "Epoch [157/1000], Loss: 0.5052\n",
      "Epoch [158/1000], Loss: 0.5056\n",
      "Epoch [159/1000], Loss: 0.5064\n",
      "Epoch [160/1000], Loss: 0.5060\n",
      "Epoch [161/1000], Loss: 0.5072\n",
      "Epoch [162/1000], Loss: 0.5092\n",
      "Epoch [163/1000], Loss: 0.5048\n",
      "Epoch [164/1000], Loss: 0.5064\n",
      "Epoch [165/1000], Loss: 0.5076\n",
      "Epoch [166/1000], Loss: 0.5072\n",
      "Epoch [167/1000], Loss: 0.5056\n",
      "Epoch [168/1000], Loss: 0.5076\n",
      "Epoch [169/1000], Loss: 0.5052\n",
      "Epoch [170/1000], Loss: 0.5072\n",
      "Epoch [171/1000], Loss: 0.5064\n",
      "Epoch [172/1000], Loss: 0.5080\n",
      "Epoch [173/1000], Loss: 0.5076\n",
      "Epoch [174/1000], Loss: 0.5092\n",
      "Epoch [175/1000], Loss: 0.5076\n",
      "Epoch [176/1000], Loss: 0.5080\n",
      "Epoch [177/1000], Loss: 0.5064\n",
      "Epoch [178/1000], Loss: 0.5040\n",
      "Epoch [179/1000], Loss: 0.5072\n",
      "Epoch [180/1000], Loss: 0.5080\n",
      "Epoch [181/1000], Loss: 0.5080\n",
      "Epoch [182/1000], Loss: 0.5096\n",
      "Epoch [183/1000], Loss: 0.5076\n",
      "Epoch [184/1000], Loss: 0.5084\n",
      "Epoch [185/1000], Loss: 0.5092\n",
      "Epoch [186/1000], Loss: 0.5084\n",
      "Epoch [187/1000], Loss: 0.5096\n",
      "Epoch [188/1000], Loss: 0.5076\n",
      "Epoch [189/1000], Loss: 0.5096\n",
      "Epoch [190/1000], Loss: 0.5092\n",
      "Epoch [191/1000], Loss: 0.5052\n",
      "Epoch [192/1000], Loss: 0.5092\n",
      "Epoch [193/1000], Loss: 0.5060\n",
      "Epoch [194/1000], Loss: 0.5076\n",
      "Epoch [195/1000], Loss: 0.5060\n",
      "Epoch [196/1000], Loss: 0.5076\n",
      "Epoch [197/1000], Loss: 0.5068\n",
      "Epoch [198/1000], Loss: 0.5060\n",
      "Epoch [199/1000], Loss: 0.5076\n",
      "Epoch [200/1000], Loss: 0.5056\n",
      "Epoch [201/1000], Loss: 0.5068\n",
      "Epoch [202/1000], Loss: 0.5040\n",
      "Epoch [203/1000], Loss: 0.5076\n",
      "Epoch [204/1000], Loss: 0.5104\n",
      "Epoch [205/1000], Loss: 0.5068\n",
      "Epoch [206/1000], Loss: 0.5100\n",
      "Epoch [207/1000], Loss: 0.5068\n",
      "Epoch [208/1000], Loss: 0.5072\n",
      "Epoch [209/1000], Loss: 0.5048\n",
      "Epoch [210/1000], Loss: 0.5060\n",
      "Epoch [211/1000], Loss: 0.5064\n",
      "Epoch [212/1000], Loss: 0.5060\n",
      "Epoch [213/1000], Loss: 0.5080\n",
      "Epoch [214/1000], Loss: 0.5088\n",
      "Epoch [215/1000], Loss: 0.5052\n",
      "Epoch [216/1000], Loss: 0.5084\n",
      "Epoch [217/1000], Loss: 0.5048\n",
      "Epoch [218/1000], Loss: 0.5076\n",
      "Epoch [219/1000], Loss: 0.5072\n",
      "Epoch [220/1000], Loss: 0.5068\n",
      "Epoch [221/1000], Loss: 0.5088\n",
      "Epoch [222/1000], Loss: 0.5060\n",
      "Epoch [223/1000], Loss: 0.5068\n",
      "Epoch [224/1000], Loss: 0.5080\n",
      "Epoch [225/1000], Loss: 0.5068\n",
      "Epoch [226/1000], Loss: 0.5068\n",
      "Epoch [227/1000], Loss: 0.5080\n",
      "Epoch [228/1000], Loss: 0.5048\n",
      "Epoch [229/1000], Loss: 0.5092\n",
      "Epoch [230/1000], Loss: 0.5072\n",
      "Epoch [231/1000], Loss: 0.5064\n",
      "Epoch [232/1000], Loss: 0.5072\n",
      "Epoch [233/1000], Loss: 0.5084\n",
      "Epoch [234/1000], Loss: 0.5068\n",
      "Epoch [235/1000], Loss: 0.5076\n",
      "Epoch [236/1000], Loss: 0.5076\n",
      "Epoch [237/1000], Loss: 0.5080\n",
      "Epoch [238/1000], Loss: 0.5064\n",
      "Epoch [239/1000], Loss: 0.5100\n",
      "Epoch [240/1000], Loss: 0.5068\n",
      "Epoch [241/1000], Loss: 0.5068\n",
      "Epoch [242/1000], Loss: 0.5052\n",
      "Epoch [243/1000], Loss: 0.5088\n",
      "Epoch [244/1000], Loss: 0.5060\n",
      "Epoch [245/1000], Loss: 0.5084\n",
      "Epoch [246/1000], Loss: 0.5068\n",
      "Epoch [247/1000], Loss: 0.5076\n",
      "Epoch [248/1000], Loss: 0.5048\n",
      "Epoch [249/1000], Loss: 0.5076\n",
      "Epoch [250/1000], Loss: 0.5052\n",
      "Epoch [251/1000], Loss: 0.5064\n",
      "Epoch [252/1000], Loss: 0.5060\n",
      "Epoch [253/1000], Loss: 0.5072\n",
      "Epoch [254/1000], Loss: 0.5076\n",
      "Epoch [255/1000], Loss: 0.5080\n",
      "Epoch [256/1000], Loss: 0.5056\n",
      "Epoch [257/1000], Loss: 0.5064\n",
      "Epoch [258/1000], Loss: 0.5076\n",
      "Epoch [259/1000], Loss: 0.5040\n",
      "Epoch [260/1000], Loss: 0.5076\n",
      "Epoch [261/1000], Loss: 0.5060\n",
      "Epoch [262/1000], Loss: 0.5068\n",
      "Epoch [263/1000], Loss: 0.5076\n",
      "Epoch [264/1000], Loss: 0.5068\n",
      "Epoch [265/1000], Loss: 0.5080\n",
      "Epoch [266/1000], Loss: 0.5080\n",
      "Epoch [267/1000], Loss: 0.5040\n",
      "Epoch [268/1000], Loss: 0.5064\n",
      "Epoch [269/1000], Loss: 0.5068\n",
      "Epoch [270/1000], Loss: 0.5048\n",
      "Epoch [271/1000], Loss: 0.5080\n",
      "Epoch [272/1000], Loss: 0.5072\n",
      "Epoch [273/1000], Loss: 0.5084\n",
      "Epoch [274/1000], Loss: 0.5096\n",
      "Epoch [275/1000], Loss: 0.5080\n",
      "Epoch [276/1000], Loss: 0.5076\n",
      "Epoch [277/1000], Loss: 0.5052\n",
      "Epoch [278/1000], Loss: 0.5080\n",
      "Epoch [279/1000], Loss: 0.5080\n",
      "Epoch [280/1000], Loss: 0.5064\n",
      "Epoch [281/1000], Loss: 0.5088\n",
      "Epoch [282/1000], Loss: 0.5072\n",
      "Epoch [283/1000], Loss: 0.5084\n",
      "Epoch [284/1000], Loss: 0.5080\n",
      "Epoch [285/1000], Loss: 0.5080\n",
      "Epoch [286/1000], Loss: 0.5072\n",
      "Epoch [287/1000], Loss: 0.5060\n",
      "Epoch [288/1000], Loss: 0.5064\n",
      "Epoch [289/1000], Loss: 0.5056\n",
      "Epoch [290/1000], Loss: 0.5036\n",
      "Epoch [291/1000], Loss: 0.5064\n",
      "Epoch [292/1000], Loss: 0.5064\n",
      "Epoch [293/1000], Loss: 0.5048\n",
      "Epoch [294/1000], Loss: 0.5072\n",
      "Epoch [295/1000], Loss: 0.5056\n",
      "Epoch [296/1000], Loss: 0.5064\n",
      "Epoch [297/1000], Loss: 0.5072\n",
      "Epoch [298/1000], Loss: 0.5056\n",
      "Epoch [299/1000], Loss: 0.5064\n",
      "Epoch [300/1000], Loss: 0.5092\n",
      "Epoch [301/1000], Loss: 0.5060\n",
      "Epoch [302/1000], Loss: 0.5076\n",
      "Epoch [303/1000], Loss: 0.5080\n",
      "Epoch [304/1000], Loss: 0.5060\n",
      "Epoch [305/1000], Loss: 0.5060\n",
      "Epoch [306/1000], Loss: 0.5072\n",
      "Epoch [307/1000], Loss: 0.5080\n",
      "Epoch [308/1000], Loss: 0.5080\n",
      "Epoch [309/1000], Loss: 0.5060\n",
      "Epoch [310/1000], Loss: 0.5032\n",
      "Epoch [311/1000], Loss: 0.5052\n",
      "Epoch [312/1000], Loss: 0.5072\n",
      "Epoch [313/1000], Loss: 0.5060\n",
      "Epoch [314/1000], Loss: 0.5052\n",
      "Epoch [315/1000], Loss: 0.5056\n",
      "Epoch [316/1000], Loss: 0.5056\n",
      "Epoch [317/1000], Loss: 0.5064\n",
      "Epoch [318/1000], Loss: 0.5064\n",
      "Epoch [319/1000], Loss: 0.5068\n",
      "Epoch [320/1000], Loss: 0.5076\n",
      "Epoch [321/1000], Loss: 0.5076\n",
      "Epoch [322/1000], Loss: 0.5064\n",
      "Epoch [323/1000], Loss: 0.5052\n",
      "Epoch [324/1000], Loss: 0.5088\n",
      "Epoch [325/1000], Loss: 0.5072\n",
      "Epoch [326/1000], Loss: 0.5072\n",
      "Epoch [327/1000], Loss: 0.5064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [328/1000], Loss: 0.5072\n",
      "Epoch [329/1000], Loss: 0.5052\n",
      "Epoch [330/1000], Loss: 0.5056\n",
      "Epoch [331/1000], Loss: 0.5048\n",
      "Epoch [332/1000], Loss: 0.5088\n",
      "Epoch [333/1000], Loss: 0.5076\n",
      "Epoch [334/1000], Loss: 0.5064\n",
      "Epoch [335/1000], Loss: 0.5060\n",
      "Epoch [336/1000], Loss: 0.5096\n",
      "Epoch [337/1000], Loss: 0.5068\n",
      "Epoch [338/1000], Loss: 0.5072\n",
      "Epoch [339/1000], Loss: 0.5068\n",
      "Epoch [340/1000], Loss: 0.5084\n",
      "Epoch [341/1000], Loss: 0.5056\n",
      "Epoch [342/1000], Loss: 0.5060\n",
      "Epoch [343/1000], Loss: 0.5072\n",
      "Epoch [344/1000], Loss: 0.5076\n",
      "Epoch [345/1000], Loss: 0.5052\n",
      "Epoch [346/1000], Loss: 0.5072\n",
      "Epoch [347/1000], Loss: 0.5048\n",
      "Epoch [348/1000], Loss: 0.5036\n",
      "Epoch [349/1000], Loss: 0.5064\n",
      "Epoch [350/1000], Loss: 0.5100\n",
      "Epoch [351/1000], Loss: 0.5076\n",
      "Epoch [352/1000], Loss: 0.5072\n",
      "Epoch [353/1000], Loss: 0.5056\n",
      "Epoch [354/1000], Loss: 0.5076\n",
      "Epoch [355/1000], Loss: 0.5052\n",
      "Epoch [356/1000], Loss: 0.5068\n",
      "Epoch [357/1000], Loss: 0.5064\n",
      "Epoch [358/1000], Loss: 0.5056\n",
      "Epoch [359/1000], Loss: 0.5064\n",
      "Epoch [360/1000], Loss: 0.5092\n",
      "Epoch [361/1000], Loss: 0.5052\n",
      "Epoch [362/1000], Loss: 0.5092\n",
      "Epoch [363/1000], Loss: 0.5056\n",
      "Epoch [364/1000], Loss: 0.5068\n",
      "Epoch [365/1000], Loss: 0.5044\n",
      "Epoch [366/1000], Loss: 0.5080\n",
      "Epoch [367/1000], Loss: 0.5092\n",
      "Epoch [368/1000], Loss: 0.5056\n",
      "Epoch [369/1000], Loss: 0.5052\n",
      "Epoch [370/1000], Loss: 0.5060\n",
      "Epoch [371/1000], Loss: 0.5060\n",
      "Epoch [372/1000], Loss: 0.5068\n",
      "Epoch [373/1000], Loss: 0.5068\n",
      "Epoch [374/1000], Loss: 0.5056\n",
      "Epoch [375/1000], Loss: 0.5064\n",
      "Epoch [376/1000], Loss: 0.5080\n",
      "Epoch [377/1000], Loss: 0.5084\n",
      "Epoch [378/1000], Loss: 0.5096\n",
      "Epoch [379/1000], Loss: 0.5068\n",
      "Epoch [380/1000], Loss: 0.5064\n",
      "Epoch [381/1000], Loss: 0.5060\n",
      "Epoch [382/1000], Loss: 0.5060\n",
      "Epoch [383/1000], Loss: 0.5068\n",
      "Epoch [384/1000], Loss: 0.5076\n",
      "Epoch [385/1000], Loss: 0.5072\n",
      "Epoch [386/1000], Loss: 0.5056\n",
      "Epoch [387/1000], Loss: 0.5060\n",
      "Epoch [388/1000], Loss: 0.5064\n",
      "Epoch [389/1000], Loss: 0.5088\n",
      "Epoch [390/1000], Loss: 0.5052\n",
      "Epoch [391/1000], Loss: 0.5056\n",
      "Epoch [392/1000], Loss: 0.5052\n",
      "Epoch [393/1000], Loss: 0.5084\n",
      "Epoch [394/1000], Loss: 0.5064\n",
      "Epoch [395/1000], Loss: 0.5092\n",
      "Epoch [396/1000], Loss: 0.5068\n",
      "Epoch [397/1000], Loss: 0.5068\n",
      "Epoch [398/1000], Loss: 0.5072\n",
      "Epoch [399/1000], Loss: 0.5072\n",
      "Epoch [400/1000], Loss: 0.5060\n",
      "Epoch [401/1000], Loss: 0.5052\n",
      "Epoch [402/1000], Loss: 0.5068\n",
      "Epoch [403/1000], Loss: 0.5072\n",
      "Epoch [404/1000], Loss: 0.5072\n",
      "Epoch [405/1000], Loss: 0.5060\n",
      "Epoch [406/1000], Loss: 0.5072\n",
      "Epoch [407/1000], Loss: 0.5068\n",
      "Epoch [408/1000], Loss: 0.5076\n",
      "Epoch [409/1000], Loss: 0.5064\n",
      "Epoch [410/1000], Loss: 0.5076\n",
      "Epoch [411/1000], Loss: 0.5072\n",
      "Epoch [412/1000], Loss: 0.5060\n",
      "Epoch [413/1000], Loss: 0.5072\n",
      "Epoch [414/1000], Loss: 0.5064\n",
      "Epoch [415/1000], Loss: 0.5044\n",
      "Epoch [416/1000], Loss: 0.5048\n",
      "Epoch [417/1000], Loss: 0.5072\n",
      "Epoch [418/1000], Loss: 0.5080\n",
      "Epoch [419/1000], Loss: 0.5080\n",
      "Epoch [420/1000], Loss: 0.5080\n",
      "Epoch [421/1000], Loss: 0.5084\n",
      "Epoch [422/1000], Loss: 0.5076\n",
      "Epoch [423/1000], Loss: 0.5084\n",
      "Epoch [424/1000], Loss: 0.5072\n",
      "Epoch [425/1000], Loss: 0.5088\n",
      "Epoch [426/1000], Loss: 0.5068\n",
      "Epoch [427/1000], Loss: 0.5072\n",
      "Epoch [428/1000], Loss: 0.5064\n",
      "Epoch [429/1000], Loss: 0.5092\n",
      "Epoch [430/1000], Loss: 0.5076\n",
      "Epoch [431/1000], Loss: 0.5072\n",
      "Epoch [432/1000], Loss: 0.5068\n",
      "Epoch [433/1000], Loss: 0.5060\n",
      "Epoch [434/1000], Loss: 0.5100\n",
      "Epoch [435/1000], Loss: 0.5096\n",
      "Epoch [436/1000], Loss: 0.5060\n",
      "Epoch [437/1000], Loss: 0.5040\n",
      "Epoch [438/1000], Loss: 0.5068\n",
      "Epoch [439/1000], Loss: 0.5064\n",
      "Epoch [440/1000], Loss: 0.5064\n",
      "Epoch [441/1000], Loss: 0.5060\n",
      "Epoch [442/1000], Loss: 0.5060\n",
      "Epoch [443/1000], Loss: 0.5084\n",
      "Epoch [444/1000], Loss: 0.5068\n",
      "Epoch [445/1000], Loss: 0.5068\n",
      "Epoch [446/1000], Loss: 0.5056\n",
      "Epoch [447/1000], Loss: 0.5100\n",
      "Epoch [448/1000], Loss: 0.5068\n",
      "Epoch [449/1000], Loss: 0.5068\n",
      "Epoch [450/1000], Loss: 0.5052\n",
      "Epoch [451/1000], Loss: 0.5076\n",
      "Epoch [452/1000], Loss: 0.5072\n",
      "Epoch [453/1000], Loss: 0.5048\n",
      "Epoch [454/1000], Loss: 0.5080\n",
      "Epoch [455/1000], Loss: 0.5092\n",
      "Epoch [456/1000], Loss: 0.5052\n",
      "Epoch [457/1000], Loss: 0.5064\n",
      "Epoch [458/1000], Loss: 0.5080\n",
      "Epoch [459/1000], Loss: 0.5056\n",
      "Epoch [460/1000], Loss: 0.5064\n",
      "Epoch [461/1000], Loss: 0.5068\n",
      "Epoch [462/1000], Loss: 0.5060\n",
      "Epoch [463/1000], Loss: 0.5076\n",
      "Epoch [464/1000], Loss: 0.5068\n",
      "Epoch [465/1000], Loss: 0.5064\n",
      "Epoch [466/1000], Loss: 0.5080\n",
      "Epoch [467/1000], Loss: 0.5080\n",
      "Epoch [468/1000], Loss: 0.5056\n",
      "Epoch [469/1000], Loss: 0.5064\n",
      "Epoch [470/1000], Loss: 0.5076\n",
      "Epoch [471/1000], Loss: 0.5084\n",
      "Epoch [472/1000], Loss: 0.5076\n",
      "Epoch [473/1000], Loss: 0.5076\n",
      "Epoch [474/1000], Loss: 0.5060\n",
      "Epoch [475/1000], Loss: 0.5060\n",
      "Epoch [476/1000], Loss: 0.5072\n",
      "Epoch [477/1000], Loss: 0.5060\n",
      "Epoch [478/1000], Loss: 0.5068\n",
      "Epoch [479/1000], Loss: 0.5072\n",
      "Epoch [480/1000], Loss: 0.5052\n",
      "Epoch [481/1000], Loss: 0.5068\n",
      "Epoch [482/1000], Loss: 0.5056\n",
      "Epoch [483/1000], Loss: 0.5048\n",
      "Epoch [484/1000], Loss: 0.5060\n",
      "Epoch [485/1000], Loss: 0.5084\n",
      "Epoch [486/1000], Loss: 0.5056\n",
      "Epoch [487/1000], Loss: 0.5080\n",
      "Epoch [488/1000], Loss: 0.5080\n",
      "Epoch [489/1000], Loss: 0.5044\n",
      "Epoch [490/1000], Loss: 0.5060\n",
      "Epoch [491/1000], Loss: 0.5080\n",
      "Epoch [492/1000], Loss: 0.5076\n",
      "Epoch [493/1000], Loss: 0.5048\n",
      "Epoch [494/1000], Loss: 0.5080\n",
      "Epoch [495/1000], Loss: 0.5076\n",
      "Epoch [496/1000], Loss: 0.5068\n",
      "Epoch [497/1000], Loss: 0.5068\n",
      "Epoch [498/1000], Loss: 0.5056\n",
      "Epoch [499/1000], Loss: 0.5060\n",
      "Epoch [500/1000], Loss: 0.5080\n",
      "Epoch [501/1000], Loss: 0.5072\n",
      "Epoch [502/1000], Loss: 0.5056\n",
      "Epoch [503/1000], Loss: 0.5044\n",
      "Epoch [504/1000], Loss: 0.5072\n",
      "Epoch [505/1000], Loss: 0.5092\n",
      "Epoch [506/1000], Loss: 0.5072\n",
      "Epoch [507/1000], Loss: 0.5076\n",
      "Epoch [508/1000], Loss: 0.5072\n",
      "Epoch [509/1000], Loss: 0.5064\n",
      "Epoch [510/1000], Loss: 0.5076\n",
      "Epoch [511/1000], Loss: 0.5060\n",
      "Epoch [512/1000], Loss: 0.5068\n",
      "Epoch [513/1000], Loss: 0.5056\n",
      "Epoch [514/1000], Loss: 0.5060\n",
      "Epoch [515/1000], Loss: 0.5052\n",
      "Epoch [516/1000], Loss: 0.5084\n",
      "Epoch [517/1000], Loss: 0.5076\n",
      "Epoch [518/1000], Loss: 0.5084\n",
      "Epoch [519/1000], Loss: 0.5064\n",
      "Epoch [520/1000], Loss: 0.5060\n",
      "Epoch [521/1000], Loss: 0.5076\n",
      "Epoch [522/1000], Loss: 0.5048\n",
      "Epoch [523/1000], Loss: 0.5072\n",
      "Epoch [524/1000], Loss: 0.5076\n",
      "Epoch [525/1000], Loss: 0.5064\n",
      "Epoch [526/1000], Loss: 0.5068\n",
      "Epoch [527/1000], Loss: 0.5084\n",
      "Epoch [528/1000], Loss: 0.5060\n",
      "Epoch [529/1000], Loss: 0.5080\n",
      "Epoch [530/1000], Loss: 0.5084\n",
      "Epoch [531/1000], Loss: 0.5068\n",
      "Epoch [532/1000], Loss: 0.5060\n",
      "Epoch [533/1000], Loss: 0.5052\n",
      "Epoch [534/1000], Loss: 0.5052\n",
      "Epoch [535/1000], Loss: 0.5064\n",
      "Epoch [536/1000], Loss: 0.5088\n",
      "Epoch [537/1000], Loss: 0.5068\n",
      "Epoch [538/1000], Loss: 0.5064\n",
      "Epoch [539/1000], Loss: 0.5076\n",
      "Epoch [540/1000], Loss: 0.5084\n",
      "Epoch [541/1000], Loss: 0.5068\n",
      "Epoch [542/1000], Loss: 0.5072\n",
      "Epoch [543/1000], Loss: 0.5056\n",
      "Epoch [544/1000], Loss: 0.5060\n",
      "Epoch [545/1000], Loss: 0.5076\n",
      "Epoch [546/1000], Loss: 0.5076\n",
      "Epoch [547/1000], Loss: 0.5064\n",
      "Epoch [548/1000], Loss: 0.5076\n",
      "Epoch [549/1000], Loss: 0.5064\n",
      "Epoch [550/1000], Loss: 0.5088\n",
      "Epoch [551/1000], Loss: 0.5084\n",
      "Epoch [552/1000], Loss: 0.5056\n",
      "Epoch [553/1000], Loss: 0.5072\n",
      "Epoch [554/1000], Loss: 0.5072\n",
      "Epoch [555/1000], Loss: 0.5064\n",
      "Epoch [556/1000], Loss: 0.5056\n",
      "Epoch [557/1000], Loss: 0.5060\n",
      "Epoch [558/1000], Loss: 0.5052\n",
      "Epoch [559/1000], Loss: 0.5052\n",
      "Epoch [560/1000], Loss: 0.5064\n",
      "Epoch [561/1000], Loss: 0.5084\n",
      "Epoch [562/1000], Loss: 0.5068\n",
      "Epoch [563/1000], Loss: 0.5052\n",
      "Epoch [564/1000], Loss: 0.5088\n",
      "Epoch [565/1000], Loss: 0.5068\n",
      "Epoch [566/1000], Loss: 0.5052\n",
      "Epoch [567/1000], Loss: 0.5068\n",
      "Epoch [568/1000], Loss: 0.5064\n",
      "Epoch [569/1000], Loss: 0.5056\n",
      "Epoch [570/1000], Loss: 0.5052\n",
      "Epoch [571/1000], Loss: 0.5080\n",
      "Epoch [572/1000], Loss: 0.5068\n",
      "Epoch [573/1000], Loss: 0.5084\n",
      "Epoch [574/1000], Loss: 0.5048\n",
      "Epoch [575/1000], Loss: 0.5064\n",
      "Epoch [576/1000], Loss: 0.5060\n",
      "Epoch [577/1000], Loss: 0.5060\n",
      "Epoch [578/1000], Loss: 0.5056\n",
      "Epoch [579/1000], Loss: 0.5072\n",
      "Epoch [580/1000], Loss: 0.5068\n",
      "Epoch [581/1000], Loss: 0.5076\n",
      "Epoch [582/1000], Loss: 0.5080\n",
      "Epoch [583/1000], Loss: 0.5076\n",
      "Epoch [584/1000], Loss: 0.5076\n",
      "Epoch [585/1000], Loss: 0.5080\n",
      "Epoch [586/1000], Loss: 0.5056\n",
      "Epoch [587/1000], Loss: 0.5056\n",
      "Epoch [588/1000], Loss: 0.5056\n",
      "Epoch [589/1000], Loss: 0.5080\n",
      "Epoch [590/1000], Loss: 0.5064\n",
      "Epoch [591/1000], Loss: 0.5056\n",
      "Epoch [592/1000], Loss: 0.5056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [593/1000], Loss: 0.5052\n",
      "Epoch [594/1000], Loss: 0.5088\n",
      "Epoch [595/1000], Loss: 0.5072\n",
      "Epoch [596/1000], Loss: 0.5084\n",
      "Epoch [597/1000], Loss: 0.5088\n",
      "Epoch [598/1000], Loss: 0.5064\n",
      "Epoch [599/1000], Loss: 0.5072\n",
      "Epoch [600/1000], Loss: 0.5064\n",
      "Epoch [601/1000], Loss: 0.5072\n",
      "Epoch [602/1000], Loss: 0.5068\n",
      "Epoch [603/1000], Loss: 0.5048\n",
      "Epoch [604/1000], Loss: 0.5064\n",
      "Epoch [605/1000], Loss: 0.5068\n",
      "Epoch [606/1000], Loss: 0.5084\n",
      "Epoch [607/1000], Loss: 0.5068\n",
      "Epoch [608/1000], Loss: 0.5072\n",
      "Epoch [609/1000], Loss: 0.5068\n",
      "Epoch [610/1000], Loss: 0.5080\n",
      "Epoch [611/1000], Loss: 0.5056\n",
      "Epoch [612/1000], Loss: 0.5032\n",
      "Epoch [613/1000], Loss: 0.5084\n",
      "Epoch [614/1000], Loss: 0.5072\n",
      "Epoch [615/1000], Loss: 0.5068\n",
      "Epoch [616/1000], Loss: 0.5084\n",
      "Epoch [617/1000], Loss: 0.5048\n",
      "Epoch [618/1000], Loss: 0.5056\n",
      "Epoch [619/1000], Loss: 0.5076\n",
      "Epoch [620/1000], Loss: 0.5068\n",
      "Epoch [621/1000], Loss: 0.5052\n",
      "Epoch [622/1000], Loss: 0.5060\n",
      "Epoch [623/1000], Loss: 0.5064\n",
      "Epoch [624/1000], Loss: 0.5080\n",
      "Epoch [625/1000], Loss: 0.5076\n",
      "Epoch [626/1000], Loss: 0.5060\n",
      "Epoch [627/1000], Loss: 0.5076\n",
      "Epoch [628/1000], Loss: 0.5056\n",
      "Epoch [629/1000], Loss: 0.5052\n",
      "Epoch [630/1000], Loss: 0.5068\n",
      "Epoch [631/1000], Loss: 0.5064\n",
      "Epoch [632/1000], Loss: 0.5048\n",
      "Epoch [633/1000], Loss: 0.5064\n",
      "Epoch [634/1000], Loss: 0.5044\n",
      "Epoch [635/1000], Loss: 0.5072\n",
      "Epoch [636/1000], Loss: 0.5072\n",
      "Epoch [637/1000], Loss: 0.5068\n",
      "Epoch [638/1000], Loss: 0.5096\n",
      "Epoch [639/1000], Loss: 0.5080\n",
      "Epoch [640/1000], Loss: 0.5064\n",
      "Epoch [641/1000], Loss: 0.5080\n",
      "Epoch [642/1000], Loss: 0.5064\n",
      "Epoch [643/1000], Loss: 0.5060\n",
      "Epoch [644/1000], Loss: 0.5068\n",
      "Epoch [645/1000], Loss: 0.5052\n",
      "Epoch [646/1000], Loss: 0.5068\n",
      "Epoch [647/1000], Loss: 0.5076\n",
      "Epoch [648/1000], Loss: 0.5072\n",
      "Epoch [649/1000], Loss: 0.5076\n",
      "Epoch [650/1000], Loss: 0.5064\n",
      "Epoch [651/1000], Loss: 0.5072\n",
      "Epoch [652/1000], Loss: 0.5060\n",
      "Epoch [653/1000], Loss: 0.5068\n",
      "Epoch [654/1000], Loss: 0.5064\n",
      "Epoch [655/1000], Loss: 0.5084\n",
      "Epoch [656/1000], Loss: 0.5084\n",
      "Epoch [657/1000], Loss: 0.5064\n",
      "Epoch [658/1000], Loss: 0.5088\n",
      "Epoch [659/1000], Loss: 0.5068\n",
      "Epoch [660/1000], Loss: 0.5064\n",
      "Epoch [661/1000], Loss: 0.5076\n",
      "Epoch [662/1000], Loss: 0.5088\n",
      "Epoch [663/1000], Loss: 0.5076\n",
      "Epoch [664/1000], Loss: 0.5088\n",
      "Epoch [665/1000], Loss: 0.5064\n",
      "Epoch [666/1000], Loss: 0.5060\n",
      "Epoch [667/1000], Loss: 0.5080\n",
      "Epoch [668/1000], Loss: 0.5064\n",
      "Epoch [669/1000], Loss: 0.5068\n",
      "Epoch [670/1000], Loss: 0.5072\n",
      "Epoch [671/1000], Loss: 0.5080\n",
      "Epoch [672/1000], Loss: 0.5060\n",
      "Epoch [673/1000], Loss: 0.5060\n",
      "Epoch [674/1000], Loss: 0.5080\n",
      "Epoch [675/1000], Loss: 0.5052\n",
      "Epoch [676/1000], Loss: 0.5072\n",
      "Epoch [677/1000], Loss: 0.5072\n",
      "Epoch [678/1000], Loss: 0.5056\n",
      "Epoch [679/1000], Loss: 0.5072\n",
      "Epoch [680/1000], Loss: 0.5080\n",
      "Epoch [681/1000], Loss: 0.5044\n",
      "Epoch [682/1000], Loss: 0.5080\n",
      "Epoch [683/1000], Loss: 0.5060\n",
      "Epoch [684/1000], Loss: 0.5076\n",
      "Epoch [685/1000], Loss: 0.5084\n",
      "Epoch [686/1000], Loss: 0.5052\n",
      "Epoch [687/1000], Loss: 0.5060\n",
      "Epoch [688/1000], Loss: 0.5060\n",
      "Epoch [689/1000], Loss: 0.5048\n",
      "Epoch [690/1000], Loss: 0.5080\n",
      "Epoch [691/1000], Loss: 0.5072\n",
      "Epoch [692/1000], Loss: 0.5068\n",
      "Epoch [693/1000], Loss: 0.5072\n",
      "Epoch [694/1000], Loss: 0.5048\n",
      "Epoch [695/1000], Loss: 0.5088\n",
      "Epoch [696/1000], Loss: 0.5076\n",
      "Epoch [697/1000], Loss: 0.5076\n",
      "Epoch [698/1000], Loss: 0.5080\n",
      "Epoch [699/1000], Loss: 0.5088\n",
      "Epoch [700/1000], Loss: 0.5076\n",
      "Epoch [701/1000], Loss: 0.5096\n",
      "Epoch [702/1000], Loss: 0.5076\n",
      "Epoch [703/1000], Loss: 0.5092\n",
      "Epoch [704/1000], Loss: 0.5092\n",
      "Epoch [705/1000], Loss: 0.5080\n",
      "Epoch [706/1000], Loss: 0.5072\n",
      "Epoch [707/1000], Loss: 0.5084\n",
      "Epoch [708/1000], Loss: 0.5072\n",
      "Epoch [709/1000], Loss: 0.5080\n",
      "Epoch [710/1000], Loss: 0.5072\n",
      "Epoch [711/1000], Loss: 0.5068\n",
      "Epoch [712/1000], Loss: 0.5064\n",
      "Epoch [713/1000], Loss: 0.5052\n",
      "Epoch [714/1000], Loss: 0.5084\n",
      "Epoch [715/1000], Loss: 0.5060\n",
      "Epoch [716/1000], Loss: 0.5064\n",
      "Epoch [717/1000], Loss: 0.5064\n",
      "Epoch [718/1000], Loss: 0.5060\n",
      "Epoch [719/1000], Loss: 0.5056\n",
      "Epoch [720/1000], Loss: 0.5072\n",
      "Epoch [721/1000], Loss: 0.5052\n",
      "Epoch [722/1000], Loss: 0.5068\n",
      "Epoch [723/1000], Loss: 0.5076\n",
      "Epoch [724/1000], Loss: 0.5084\n",
      "Epoch [725/1000], Loss: 0.5076\n",
      "Epoch [726/1000], Loss: 0.5084\n",
      "Epoch [727/1000], Loss: 0.5056\n",
      "Epoch [728/1000], Loss: 0.5064\n",
      "Epoch [729/1000], Loss: 0.5060\n",
      "Epoch [730/1000], Loss: 0.5060\n",
      "Epoch [731/1000], Loss: 0.5064\n",
      "Epoch [732/1000], Loss: 0.5048\n",
      "Epoch [733/1000], Loss: 0.5040\n",
      "Epoch [734/1000], Loss: 0.5080\n",
      "Epoch [735/1000], Loss: 0.5048\n",
      "Epoch [736/1000], Loss: 0.5068\n",
      "Epoch [737/1000], Loss: 0.5056\n",
      "Epoch [738/1000], Loss: 0.5064\n",
      "Epoch [739/1000], Loss: 0.5060\n",
      "Epoch [740/1000], Loss: 0.5080\n",
      "Epoch [741/1000], Loss: 0.5080\n",
      "Epoch [742/1000], Loss: 0.5064\n",
      "Epoch [743/1000], Loss: 0.5068\n",
      "Epoch [744/1000], Loss: 0.5068\n",
      "Epoch [745/1000], Loss: 0.5060\n",
      "Epoch [746/1000], Loss: 0.5084\n",
      "Epoch [747/1000], Loss: 0.5096\n",
      "Epoch [748/1000], Loss: 0.5068\n",
      "Epoch [749/1000], Loss: 0.5088\n",
      "Epoch [750/1000], Loss: 0.5076\n",
      "Epoch [751/1000], Loss: 0.5092\n",
      "Epoch [752/1000], Loss: 0.5048\n",
      "Epoch [753/1000], Loss: 0.5064\n",
      "Epoch [754/1000], Loss: 0.5072\n",
      "Epoch [755/1000], Loss: 0.5080\n",
      "Epoch [756/1000], Loss: 0.5072\n",
      "Epoch [757/1000], Loss: 0.5068\n",
      "Epoch [758/1000], Loss: 0.5096\n",
      "Epoch [759/1000], Loss: 0.5048\n",
      "Epoch [760/1000], Loss: 0.5072\n",
      "Epoch [761/1000], Loss: 0.5064\n",
      "Epoch [762/1000], Loss: 0.5080\n",
      "Epoch [763/1000], Loss: 0.5056\n",
      "Epoch [764/1000], Loss: 0.5060\n",
      "Epoch [765/1000], Loss: 0.5068\n",
      "Epoch [766/1000], Loss: 0.5064\n",
      "Epoch [767/1000], Loss: 0.5068\n",
      "Epoch [768/1000], Loss: 0.5064\n",
      "Epoch [769/1000], Loss: 0.5068\n",
      "Epoch [770/1000], Loss: 0.5060\n",
      "Epoch [771/1000], Loss: 0.5084\n",
      "Epoch [772/1000], Loss: 0.5080\n",
      "Epoch [773/1000], Loss: 0.5056\n",
      "Epoch [774/1000], Loss: 0.5048\n",
      "Epoch [775/1000], Loss: 0.5084\n",
      "Epoch [776/1000], Loss: 0.5048\n",
      "Epoch [777/1000], Loss: 0.5084\n",
      "Epoch [778/1000], Loss: 0.5048\n",
      "Epoch [779/1000], Loss: 0.5060\n",
      "Epoch [780/1000], Loss: 0.5060\n",
      "Epoch [781/1000], Loss: 0.5072\n",
      "Epoch [782/1000], Loss: 0.5044\n",
      "Epoch [783/1000], Loss: 0.5092\n",
      "Epoch [784/1000], Loss: 0.5080\n",
      "Epoch [785/1000], Loss: 0.5064\n",
      "Epoch [786/1000], Loss: 0.5080\n",
      "Epoch [787/1000], Loss: 0.5060\n",
      "Epoch [788/1000], Loss: 0.5108\n",
      "Epoch [789/1000], Loss: 0.5072\n",
      "Epoch [790/1000], Loss: 0.5068\n",
      "Epoch [791/1000], Loss: 0.5068\n",
      "Epoch [792/1000], Loss: 0.5068\n",
      "Epoch [793/1000], Loss: 0.5060\n",
      "Epoch [794/1000], Loss: 0.5092\n",
      "Epoch [795/1000], Loss: 0.5072\n",
      "Epoch [796/1000], Loss: 0.5084\n",
      "Epoch [797/1000], Loss: 0.5072\n",
      "Epoch [798/1000], Loss: 0.5060\n",
      "Epoch [799/1000], Loss: 0.5044\n",
      "Epoch [800/1000], Loss: 0.5084\n",
      "Epoch [801/1000], Loss: 0.5076\n",
      "Epoch [802/1000], Loss: 0.5060\n",
      "Epoch [803/1000], Loss: 0.5052\n",
      "Epoch [804/1000], Loss: 0.5068\n",
      "Epoch [805/1000], Loss: 0.5068\n",
      "Epoch [806/1000], Loss: 0.5076\n",
      "Epoch [807/1000], Loss: 0.5064\n",
      "Epoch [808/1000], Loss: 0.5068\n",
      "Epoch [809/1000], Loss: 0.5072\n",
      "Epoch [810/1000], Loss: 0.5064\n",
      "Epoch [811/1000], Loss: 0.5068\n",
      "Epoch [812/1000], Loss: 0.5064\n",
      "Epoch [813/1000], Loss: 0.5076\n",
      "Epoch [814/1000], Loss: 0.5076\n",
      "Epoch [815/1000], Loss: 0.5080\n",
      "Epoch [816/1000], Loss: 0.5072\n",
      "Epoch [817/1000], Loss: 0.5064\n",
      "Epoch [818/1000], Loss: 0.5056\n",
      "Epoch [819/1000], Loss: 0.5096\n",
      "Epoch [820/1000], Loss: 0.5052\n",
      "Epoch [821/1000], Loss: 0.5060\n",
      "Epoch [822/1000], Loss: 0.5096\n",
      "Epoch [823/1000], Loss: 0.5052\n",
      "Epoch [824/1000], Loss: 0.5068\n",
      "Epoch [825/1000], Loss: 0.5052\n",
      "Epoch [826/1000], Loss: 0.5064\n",
      "Epoch [827/1000], Loss: 0.5072\n",
      "Epoch [828/1000], Loss: 0.5076\n",
      "Epoch [829/1000], Loss: 0.5060\n",
      "Epoch [830/1000], Loss: 0.5072\n",
      "Epoch [831/1000], Loss: 0.5080\n",
      "Epoch [832/1000], Loss: 0.5076\n",
      "Epoch [833/1000], Loss: 0.5080\n",
      "Epoch [834/1000], Loss: 0.5048\n",
      "Epoch [835/1000], Loss: 0.5076\n",
      "Epoch [836/1000], Loss: 0.5092\n",
      "Epoch [837/1000], Loss: 0.5068\n",
      "Epoch [838/1000], Loss: 0.5084\n",
      "Epoch [839/1000], Loss: 0.5072\n",
      "Epoch [840/1000], Loss: 0.5096\n",
      "Epoch [841/1000], Loss: 0.5096\n",
      "Epoch [842/1000], Loss: 0.5044\n",
      "Epoch [843/1000], Loss: 0.5080\n",
      "Epoch [844/1000], Loss: 0.5060\n",
      "Epoch [845/1000], Loss: 0.5080\n",
      "Epoch [846/1000], Loss: 0.5056\n",
      "Epoch [847/1000], Loss: 0.5072\n",
      "Epoch [848/1000], Loss: 0.5076\n",
      "Epoch [849/1000], Loss: 0.5100\n",
      "Epoch [850/1000], Loss: 0.5068\n",
      "Epoch [851/1000], Loss: 0.5048\n",
      "Epoch [852/1000], Loss: 0.5068\n",
      "Epoch [853/1000], Loss: 0.5076\n",
      "Epoch [854/1000], Loss: 0.5060\n",
      "Epoch [855/1000], Loss: 0.5084\n",
      "Epoch [856/1000], Loss: 0.5068\n",
      "Epoch [857/1000], Loss: 0.5072\n",
      "Epoch [858/1000], Loss: 0.5056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [859/1000], Loss: 0.5076\n",
      "Epoch [860/1000], Loss: 0.5076\n",
      "Epoch [861/1000], Loss: 0.5088\n",
      "Epoch [862/1000], Loss: 0.5080\n",
      "Epoch [863/1000], Loss: 0.5072\n",
      "Epoch [864/1000], Loss: 0.5076\n",
      "Epoch [865/1000], Loss: 0.5060\n",
      "Epoch [866/1000], Loss: 0.5072\n",
      "Epoch [867/1000], Loss: 0.5048\n",
      "Epoch [868/1000], Loss: 0.5068\n",
      "Epoch [869/1000], Loss: 0.5084\n",
      "Epoch [870/1000], Loss: 0.5060\n",
      "Epoch [871/1000], Loss: 0.5044\n",
      "Epoch [872/1000], Loss: 0.5072\n",
      "Epoch [873/1000], Loss: 0.5076\n",
      "Epoch [874/1000], Loss: 0.5076\n",
      "Epoch [875/1000], Loss: 0.5056\n",
      "Epoch [876/1000], Loss: 0.5064\n",
      "Epoch [877/1000], Loss: 0.5076\n",
      "Epoch [878/1000], Loss: 0.5076\n",
      "Epoch [879/1000], Loss: 0.5072\n",
      "Epoch [880/1000], Loss: 0.5072\n",
      "Epoch [881/1000], Loss: 0.5088\n",
      "Epoch [882/1000], Loss: 0.5064\n",
      "Epoch [883/1000], Loss: 0.5072\n",
      "Epoch [884/1000], Loss: 0.5068\n",
      "Epoch [885/1000], Loss: 0.5072\n",
      "Epoch [886/1000], Loss: 0.5080\n",
      "Epoch [887/1000], Loss: 0.5084\n",
      "Epoch [888/1000], Loss: 0.5084\n",
      "Epoch [889/1000], Loss: 0.5076\n",
      "Epoch [890/1000], Loss: 0.5060\n",
      "Epoch [891/1000], Loss: 0.5056\n",
      "Epoch [892/1000], Loss: 0.5088\n",
      "Epoch [893/1000], Loss: 0.5072\n",
      "Epoch [894/1000], Loss: 0.5088\n",
      "Epoch [895/1000], Loss: 0.5072\n",
      "Epoch [896/1000], Loss: 0.5056\n",
      "Epoch [897/1000], Loss: 0.5084\n",
      "Epoch [898/1000], Loss: 0.5072\n",
      "Epoch [899/1000], Loss: 0.5060\n",
      "Epoch [900/1000], Loss: 0.5052\n",
      "Epoch [901/1000], Loss: 0.5068\n",
      "Epoch [902/1000], Loss: 0.5068\n",
      "Epoch [903/1000], Loss: 0.5080\n",
      "Epoch [904/1000], Loss: 0.5068\n",
      "Epoch [905/1000], Loss: 0.5064\n",
      "Epoch [906/1000], Loss: 0.5056\n",
      "Epoch [907/1000], Loss: 0.5044\n",
      "Epoch [908/1000], Loss: 0.5060\n",
      "Epoch [909/1000], Loss: 0.5080\n",
      "Epoch [910/1000], Loss: 0.5056\n",
      "Epoch [911/1000], Loss: 0.5072\n",
      "Epoch [912/1000], Loss: 0.5064\n",
      "Epoch [913/1000], Loss: 0.5060\n",
      "Epoch [914/1000], Loss: 0.5080\n",
      "Epoch [915/1000], Loss: 0.5064\n",
      "Epoch [916/1000], Loss: 0.5064\n",
      "Epoch [917/1000], Loss: 0.5092\n",
      "Epoch [918/1000], Loss: 0.5076\n",
      "Epoch [919/1000], Loss: 0.5072\n",
      "Epoch [920/1000], Loss: 0.5064\n",
      "Epoch [921/1000], Loss: 0.5080\n",
      "Epoch [922/1000], Loss: 0.5076\n",
      "Epoch [923/1000], Loss: 0.5092\n",
      "Epoch [924/1000], Loss: 0.5068\n",
      "Epoch [925/1000], Loss: 0.5072\n",
      "Epoch [926/1000], Loss: 0.5072\n",
      "Epoch [927/1000], Loss: 0.5056\n",
      "Epoch [928/1000], Loss: 0.5068\n",
      "Epoch [929/1000], Loss: 0.5072\n",
      "Epoch [930/1000], Loss: 0.5080\n",
      "Epoch [931/1000], Loss: 0.5084\n",
      "Epoch [932/1000], Loss: 0.5072\n",
      "Epoch [933/1000], Loss: 0.5068\n",
      "Epoch [934/1000], Loss: 0.5080\n",
      "Epoch [935/1000], Loss: 0.5060\n",
      "Epoch [936/1000], Loss: 0.5052\n",
      "Epoch [937/1000], Loss: 0.5060\n",
      "Epoch [938/1000], Loss: 0.5076\n",
      "Epoch [939/1000], Loss: 0.5060\n",
      "Epoch [940/1000], Loss: 0.5076\n",
      "Epoch [941/1000], Loss: 0.5076\n",
      "Epoch [942/1000], Loss: 0.5076\n",
      "Epoch [943/1000], Loss: 0.5060\n",
      "Epoch [944/1000], Loss: 0.5072\n",
      "Epoch [945/1000], Loss: 0.5052\n",
      "Epoch [946/1000], Loss: 0.5032\n",
      "Epoch [947/1000], Loss: 0.5080\n",
      "Epoch [948/1000], Loss: 0.5064\n",
      "Epoch [949/1000], Loss: 0.5080\n",
      "Epoch [950/1000], Loss: 0.5072\n",
      "Epoch [951/1000], Loss: 0.5084\n",
      "Epoch [952/1000], Loss: 0.5084\n",
      "Epoch [953/1000], Loss: 0.5064\n",
      "Epoch [954/1000], Loss: 0.5088\n",
      "Epoch [955/1000], Loss: 0.5052\n",
      "Epoch [956/1000], Loss: 0.5064\n",
      "Epoch [957/1000], Loss: 0.5056\n",
      "Epoch [958/1000], Loss: 0.5052\n",
      "Epoch [959/1000], Loss: 0.5068\n",
      "Epoch [960/1000], Loss: 0.5068\n",
      "Epoch [961/1000], Loss: 0.5060\n",
      "Epoch [962/1000], Loss: 0.5084\n",
      "Epoch [963/1000], Loss: 0.5064\n",
      "Epoch [964/1000], Loss: 0.5084\n",
      "Epoch [965/1000], Loss: 0.5092\n",
      "Epoch [966/1000], Loss: 0.5064\n",
      "Epoch [967/1000], Loss: 0.5060\n",
      "Epoch [968/1000], Loss: 0.5064\n",
      "Epoch [969/1000], Loss: 0.5064\n",
      "Epoch [970/1000], Loss: 0.5100\n",
      "Epoch [971/1000], Loss: 0.5088\n",
      "Epoch [972/1000], Loss: 0.5076\n",
      "Epoch [973/1000], Loss: 0.5064\n",
      "Epoch [974/1000], Loss: 0.5068\n",
      "Epoch [975/1000], Loss: 0.5060\n",
      "Epoch [976/1000], Loss: 0.5044\n",
      "Epoch [977/1000], Loss: 0.5072\n",
      "Epoch [978/1000], Loss: 0.5072\n",
      "Epoch [979/1000], Loss: 0.5072\n",
      "Epoch [980/1000], Loss: 0.5072\n",
      "Epoch [981/1000], Loss: 0.5080\n",
      "Epoch [982/1000], Loss: 0.5072\n",
      "Epoch [983/1000], Loss: 0.5052\n",
      "Epoch [984/1000], Loss: 0.5084\n",
      "Epoch [985/1000], Loss: 0.5056\n",
      "Epoch [986/1000], Loss: 0.5048\n",
      "Epoch [987/1000], Loss: 0.5080\n",
      "Epoch [988/1000], Loss: 0.5068\n",
      "Epoch [989/1000], Loss: 0.5084\n",
      "Epoch [990/1000], Loss: 0.5064\n",
      "Epoch [991/1000], Loss: 0.5084\n",
      "Epoch [992/1000], Loss: 0.5056\n",
      "Epoch [993/1000], Loss: 0.5068\n",
      "Epoch [994/1000], Loss: 0.5084\n",
      "Epoch [995/1000], Loss: 0.5076\n",
      "Epoch [996/1000], Loss: 0.5064\n",
      "Epoch [997/1000], Loss: 0.5052\n",
      "Epoch [998/1000], Loss: 0.5096\n",
      "Epoch [999/1000], Loss: 0.5088\n",
      "Epoch [1000/1000], Loss: 0.5076\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 107, lr :10.0, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.5007\n",
      "Epoch [2/1000], Loss: 0.5080\n",
      "Epoch [3/1000], Loss: 0.5064\n",
      "Epoch [4/1000], Loss: 0.5085\n",
      "Epoch [5/1000], Loss: 0.5064\n",
      "Epoch [6/1000], Loss: 0.5080\n",
      "Epoch [7/1000], Loss: 0.5097\n",
      "Epoch [8/1000], Loss: 0.5080\n",
      "Epoch [9/1000], Loss: 0.5097\n",
      "Epoch [10/1000], Loss: 0.5080\n",
      "Epoch [11/1000], Loss: 0.5056\n",
      "Epoch [12/1000], Loss: 0.5097\n",
      "Epoch [13/1000], Loss: 0.5097\n",
      "Epoch [14/1000], Loss: 0.5101\n",
      "Epoch [15/1000], Loss: 0.5089\n",
      "Epoch [16/1000], Loss: 0.5076\n",
      "Epoch [17/1000], Loss: 0.5076\n",
      "Epoch [18/1000], Loss: 0.5072\n",
      "Epoch [19/1000], Loss: 0.5085\n",
      "Epoch [20/1000], Loss: 0.5064\n",
      "Epoch [21/1000], Loss: 0.5080\n",
      "Epoch [22/1000], Loss: 0.5072\n",
      "Epoch [23/1000], Loss: 0.5085\n",
      "Epoch [24/1000], Loss: 0.5072\n",
      "Epoch [25/1000], Loss: 0.5101\n",
      "Epoch [26/1000], Loss: 0.5109\n",
      "Epoch [27/1000], Loss: 0.5044\n",
      "Epoch [28/1000], Loss: 0.5064\n",
      "Epoch [29/1000], Loss: 0.5076\n",
      "Epoch [30/1000], Loss: 0.5076\n",
      "Epoch [31/1000], Loss: 0.5097\n",
      "Epoch [32/1000], Loss: 0.5085\n",
      "Epoch [33/1000], Loss: 0.5064\n",
      "Epoch [34/1000], Loss: 0.5089\n",
      "Epoch [35/1000], Loss: 0.5068\n",
      "Epoch [36/1000], Loss: 0.5093\n",
      "Epoch [37/1000], Loss: 0.5076\n",
      "Epoch [38/1000], Loss: 0.5093\n",
      "Epoch [39/1000], Loss: 0.5085\n",
      "Epoch [40/1000], Loss: 0.5076\n",
      "Epoch [41/1000], Loss: 0.5076\n",
      "Epoch [42/1000], Loss: 0.5085\n",
      "Epoch [43/1000], Loss: 0.5076\n",
      "Epoch [44/1000], Loss: 0.5109\n",
      "Epoch [45/1000], Loss: 0.5072\n",
      "Epoch [46/1000], Loss: 0.5101\n",
      "Epoch [47/1000], Loss: 0.5089\n",
      "Epoch [48/1000], Loss: 0.5072\n",
      "Epoch [49/1000], Loss: 0.5068\n",
      "Epoch [50/1000], Loss: 0.5068\n",
      "Epoch [51/1000], Loss: 0.5080\n",
      "Epoch [52/1000], Loss: 0.5089\n",
      "Epoch [53/1000], Loss: 0.5076\n",
      "Epoch [54/1000], Loss: 0.5105\n",
      "Epoch [55/1000], Loss: 0.5085\n",
      "Epoch [56/1000], Loss: 0.5080\n",
      "Epoch [57/1000], Loss: 0.5093\n",
      "Epoch [58/1000], Loss: 0.5085\n",
      "Epoch [59/1000], Loss: 0.5089\n",
      "Epoch [60/1000], Loss: 0.5072\n",
      "Epoch [61/1000], Loss: 0.5097\n",
      "Epoch [62/1000], Loss: 0.5056\n",
      "Epoch [63/1000], Loss: 0.5085\n",
      "Epoch [64/1000], Loss: 0.5085\n",
      "Epoch [65/1000], Loss: 0.5064\n",
      "Epoch [66/1000], Loss: 0.5097\n",
      "Epoch [67/1000], Loss: 0.5105\n",
      "Epoch [68/1000], Loss: 0.5072\n",
      "Epoch [69/1000], Loss: 0.5064\n",
      "Epoch [70/1000], Loss: 0.5089\n",
      "Epoch [71/1000], Loss: 0.5064\n",
      "Epoch [72/1000], Loss: 0.5101\n",
      "Epoch [73/1000], Loss: 0.5076\n",
      "Epoch [74/1000], Loss: 0.5068\n",
      "Epoch [75/1000], Loss: 0.5076\n",
      "Epoch [76/1000], Loss: 0.5097\n",
      "Epoch [77/1000], Loss: 0.5068\n",
      "Epoch [78/1000], Loss: 0.5076\n",
      "Epoch [79/1000], Loss: 0.5060\n",
      "Epoch [80/1000], Loss: 0.5089\n",
      "Epoch [81/1000], Loss: 0.5056\n",
      "Epoch [82/1000], Loss: 0.5080\n",
      "Epoch [83/1000], Loss: 0.5093\n",
      "Epoch [84/1000], Loss: 0.5085\n",
      "Epoch [85/1000], Loss: 0.5060\n",
      "Epoch [86/1000], Loss: 0.5093\n",
      "Epoch [87/1000], Loss: 0.5085\n",
      "Epoch [88/1000], Loss: 0.5089\n",
      "Epoch [89/1000], Loss: 0.5064\n",
      "Epoch [90/1000], Loss: 0.5076\n",
      "Epoch [91/1000], Loss: 0.5089\n",
      "Epoch [92/1000], Loss: 0.5085\n",
      "Epoch [93/1000], Loss: 0.5072\n",
      "Epoch [94/1000], Loss: 0.5085\n",
      "Epoch [95/1000], Loss: 0.5080\n",
      "Epoch [96/1000], Loss: 0.5093\n",
      "Epoch [97/1000], Loss: 0.5076\n",
      "Epoch [98/1000], Loss: 0.5064\n",
      "Epoch [99/1000], Loss: 0.5101\n",
      "Epoch [100/1000], Loss: 0.5089\n",
      "Epoch [101/1000], Loss: 0.5072\n",
      "Epoch [102/1000], Loss: 0.5085\n",
      "Epoch [103/1000], Loss: 0.5064\n",
      "Epoch [104/1000], Loss: 0.5089\n",
      "Epoch [105/1000], Loss: 0.5060\n",
      "Epoch [106/1000], Loss: 0.5080\n",
      "Epoch [107/1000], Loss: 0.5093\n",
      "Epoch [108/1000], Loss: 0.5052\n",
      "Epoch [109/1000], Loss: 0.5085\n",
      "Epoch [110/1000], Loss: 0.5072\n",
      "Epoch [111/1000], Loss: 0.5080\n",
      "Epoch [112/1000], Loss: 0.5089\n",
      "Epoch [113/1000], Loss: 0.5072\n",
      "Epoch [114/1000], Loss: 0.5064\n",
      "Epoch [115/1000], Loss: 0.5097\n",
      "Epoch [116/1000], Loss: 0.5093\n",
      "Epoch [117/1000], Loss: 0.5072\n",
      "Epoch [118/1000], Loss: 0.5076\n",
      "Epoch [119/1000], Loss: 0.5093\n",
      "Epoch [120/1000], Loss: 0.5068\n",
      "Epoch [121/1000], Loss: 0.5089\n",
      "Epoch [122/1000], Loss: 0.5076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [123/1000], Loss: 0.5080\n",
      "Epoch [124/1000], Loss: 0.5101\n",
      "Epoch [125/1000], Loss: 0.5085\n",
      "Epoch [126/1000], Loss: 0.5064\n",
      "Epoch [127/1000], Loss: 0.5068\n",
      "Epoch [128/1000], Loss: 0.5076\n",
      "Epoch [129/1000], Loss: 0.5085\n",
      "Epoch [130/1000], Loss: 0.5072\n",
      "Epoch [131/1000], Loss: 0.5085\n",
      "Epoch [132/1000], Loss: 0.5068\n",
      "Epoch [133/1000], Loss: 0.5076\n",
      "Epoch [134/1000], Loss: 0.5105\n",
      "Epoch [135/1000], Loss: 0.5097\n",
      "Epoch [136/1000], Loss: 0.5101\n",
      "Epoch [137/1000], Loss: 0.5076\n",
      "Epoch [138/1000], Loss: 0.5048\n",
      "Epoch [139/1000], Loss: 0.5085\n",
      "Epoch [140/1000], Loss: 0.5105\n",
      "Epoch [141/1000], Loss: 0.5089\n",
      "Epoch [142/1000], Loss: 0.5080\n",
      "Epoch [143/1000], Loss: 0.5076\n",
      "Epoch [144/1000], Loss: 0.5097\n",
      "Epoch [145/1000], Loss: 0.5080\n",
      "Epoch [146/1000], Loss: 0.5080\n",
      "Epoch [147/1000], Loss: 0.5085\n",
      "Epoch [148/1000], Loss: 0.5072\n",
      "Epoch [149/1000], Loss: 0.5097\n",
      "Epoch [150/1000], Loss: 0.5089\n",
      "Epoch [151/1000], Loss: 0.5068\n",
      "Epoch [152/1000], Loss: 0.5093\n",
      "Epoch [153/1000], Loss: 0.5085\n",
      "Epoch [154/1000], Loss: 0.5085\n",
      "Epoch [155/1000], Loss: 0.5076\n",
      "Epoch [156/1000], Loss: 0.5068\n",
      "Epoch [157/1000], Loss: 0.5093\n",
      "Epoch [158/1000], Loss: 0.5085\n",
      "Epoch [159/1000], Loss: 0.5085\n",
      "Epoch [160/1000], Loss: 0.5085\n",
      "Epoch [161/1000], Loss: 0.5076\n",
      "Epoch [162/1000], Loss: 0.5085\n",
      "Epoch [163/1000], Loss: 0.5097\n",
      "Epoch [164/1000], Loss: 0.5076\n",
      "Epoch [165/1000], Loss: 0.5093\n",
      "Epoch [166/1000], Loss: 0.5080\n",
      "Epoch [167/1000], Loss: 0.5080\n",
      "Epoch [168/1000], Loss: 0.5093\n",
      "Epoch [169/1000], Loss: 0.5089\n",
      "Epoch [170/1000], Loss: 0.5072\n",
      "Epoch [171/1000], Loss: 0.5101\n",
      "Epoch [172/1000], Loss: 0.5097\n",
      "Epoch [173/1000], Loss: 0.5072\n",
      "Epoch [174/1000], Loss: 0.5085\n",
      "Epoch [175/1000], Loss: 0.5093\n",
      "Epoch [176/1000], Loss: 0.5080\n",
      "Epoch [177/1000], Loss: 0.5076\n",
      "Epoch [178/1000], Loss: 0.5085\n",
      "Epoch [179/1000], Loss: 0.5097\n",
      "Epoch [180/1000], Loss: 0.5085\n",
      "Epoch [181/1000], Loss: 0.5109\n",
      "Epoch [182/1000], Loss: 0.5093\n",
      "Epoch [183/1000], Loss: 0.5089\n",
      "Epoch [184/1000], Loss: 0.5072\n",
      "Epoch [185/1000], Loss: 0.5097\n",
      "Epoch [186/1000], Loss: 0.5080\n",
      "Epoch [187/1000], Loss: 0.5105\n",
      "Epoch [188/1000], Loss: 0.5089\n",
      "Epoch [189/1000], Loss: 0.5089\n",
      "Epoch [190/1000], Loss: 0.5072\n",
      "Epoch [191/1000], Loss: 0.5093\n",
      "Epoch [192/1000], Loss: 0.5076\n",
      "Epoch [193/1000], Loss: 0.5085\n",
      "Epoch [194/1000], Loss: 0.5093\n",
      "Epoch [195/1000], Loss: 0.5093\n",
      "Epoch [196/1000], Loss: 0.5064\n",
      "Epoch [197/1000], Loss: 0.5089\n",
      "Epoch [198/1000], Loss: 0.5076\n",
      "Epoch [199/1000], Loss: 0.5076\n",
      "Epoch [200/1000], Loss: 0.5080\n",
      "Epoch [201/1000], Loss: 0.5080\n",
      "Epoch [202/1000], Loss: 0.5068\n",
      "Epoch [203/1000], Loss: 0.5101\n",
      "Epoch [204/1000], Loss: 0.5093\n",
      "Epoch [205/1000], Loss: 0.5097\n",
      "Epoch [206/1000], Loss: 0.5072\n",
      "Epoch [207/1000], Loss: 0.5068\n",
      "Epoch [208/1000], Loss: 0.5072\n",
      "Epoch [209/1000], Loss: 0.5080\n",
      "Epoch [210/1000], Loss: 0.5105\n",
      "Epoch [211/1000], Loss: 0.5076\n",
      "Epoch [212/1000], Loss: 0.5076\n",
      "Epoch [213/1000], Loss: 0.5085\n",
      "Epoch [214/1000], Loss: 0.5076\n",
      "Epoch [215/1000], Loss: 0.5072\n",
      "Epoch [216/1000], Loss: 0.5080\n",
      "Epoch [217/1000], Loss: 0.5076\n",
      "Epoch [218/1000], Loss: 0.5076\n",
      "Epoch [219/1000], Loss: 0.5068\n",
      "Epoch [220/1000], Loss: 0.5085\n",
      "Epoch [221/1000], Loss: 0.5109\n",
      "Epoch [222/1000], Loss: 0.5101\n",
      "Epoch [223/1000], Loss: 0.5097\n",
      "Epoch [224/1000], Loss: 0.5089\n",
      "Epoch [225/1000], Loss: 0.5068\n",
      "Epoch [226/1000], Loss: 0.5085\n",
      "Epoch [227/1000], Loss: 0.5097\n",
      "Epoch [228/1000], Loss: 0.5076\n",
      "Epoch [229/1000], Loss: 0.5089\n",
      "Epoch [230/1000], Loss: 0.5080\n",
      "Epoch [231/1000], Loss: 0.5085\n",
      "Epoch [232/1000], Loss: 0.5076\n",
      "Epoch [233/1000], Loss: 0.5093\n",
      "Epoch [234/1000], Loss: 0.5076\n",
      "Epoch [235/1000], Loss: 0.5068\n",
      "Epoch [236/1000], Loss: 0.5060\n",
      "Epoch [237/1000], Loss: 0.5097\n",
      "Epoch [238/1000], Loss: 0.5109\n",
      "Epoch [239/1000], Loss: 0.5089\n",
      "Epoch [240/1000], Loss: 0.5089\n",
      "Epoch [241/1000], Loss: 0.5093\n",
      "Epoch [242/1000], Loss: 0.5097\n",
      "Epoch [243/1000], Loss: 0.5097\n",
      "Epoch [244/1000], Loss: 0.5097\n",
      "Epoch [245/1000], Loss: 0.5080\n",
      "Epoch [246/1000], Loss: 0.5105\n",
      "Epoch [247/1000], Loss: 0.5060\n",
      "Epoch [248/1000], Loss: 0.5089\n",
      "Epoch [249/1000], Loss: 0.5097\n",
      "Epoch [250/1000], Loss: 0.5064\n",
      "Epoch [251/1000], Loss: 0.5076\n",
      "Epoch [252/1000], Loss: 0.5060\n",
      "Epoch [253/1000], Loss: 0.5076\n",
      "Epoch [254/1000], Loss: 0.5085\n",
      "Epoch [255/1000], Loss: 0.5080\n",
      "Epoch [256/1000], Loss: 0.5072\n",
      "Epoch [257/1000], Loss: 0.5072\n",
      "Epoch [258/1000], Loss: 0.5085\n",
      "Epoch [259/1000], Loss: 0.5080\n",
      "Epoch [260/1000], Loss: 0.5109\n",
      "Epoch [261/1000], Loss: 0.5076\n",
      "Epoch [262/1000], Loss: 0.5085\n",
      "Epoch [263/1000], Loss: 0.5064\n",
      "Epoch [264/1000], Loss: 0.5089\n",
      "Epoch [265/1000], Loss: 0.5072\n",
      "Epoch [266/1000], Loss: 0.5068\n",
      "Epoch [267/1000], Loss: 0.5072\n",
      "Epoch [268/1000], Loss: 0.5093\n",
      "Epoch [269/1000], Loss: 0.5089\n",
      "Epoch [270/1000], Loss: 0.5080\n",
      "Epoch [271/1000], Loss: 0.5089\n",
      "Epoch [272/1000], Loss: 0.5064\n",
      "Epoch [273/1000], Loss: 0.5080\n",
      "Epoch [274/1000], Loss: 0.5076\n",
      "Epoch [275/1000], Loss: 0.5068\n",
      "Epoch [276/1000], Loss: 0.5125\n",
      "Epoch [277/1000], Loss: 0.5101\n",
      "Epoch [278/1000], Loss: 0.5080\n",
      "Epoch [279/1000], Loss: 0.5072\n",
      "Epoch [280/1000], Loss: 0.5080\n",
      "Epoch [281/1000], Loss: 0.5064\n",
      "Epoch [282/1000], Loss: 0.5085\n",
      "Epoch [283/1000], Loss: 0.5085\n",
      "Epoch [284/1000], Loss: 0.5097\n",
      "Epoch [285/1000], Loss: 0.5085\n",
      "Epoch [286/1000], Loss: 0.5072\n",
      "Epoch [287/1000], Loss: 0.5076\n",
      "Epoch [288/1000], Loss: 0.5064\n",
      "Epoch [289/1000], Loss: 0.5097\n",
      "Epoch [290/1000], Loss: 0.5080\n",
      "Epoch [291/1000], Loss: 0.5085\n",
      "Epoch [292/1000], Loss: 0.5068\n",
      "Epoch [293/1000], Loss: 0.5089\n",
      "Epoch [294/1000], Loss: 0.5101\n",
      "Epoch [295/1000], Loss: 0.5089\n",
      "Epoch [296/1000], Loss: 0.5076\n",
      "Epoch [297/1000], Loss: 0.5072\n",
      "Epoch [298/1000], Loss: 0.5085\n",
      "Epoch [299/1000], Loss: 0.5072\n",
      "Epoch [300/1000], Loss: 0.5093\n",
      "Epoch [301/1000], Loss: 0.5064\n",
      "Epoch [302/1000], Loss: 0.5097\n",
      "Epoch [303/1000], Loss: 0.5076\n",
      "Epoch [304/1000], Loss: 0.5044\n",
      "Epoch [305/1000], Loss: 0.5089\n",
      "Epoch [306/1000], Loss: 0.5093\n",
      "Epoch [307/1000], Loss: 0.5089\n",
      "Epoch [308/1000], Loss: 0.5068\n",
      "Epoch [309/1000], Loss: 0.5080\n",
      "Epoch [310/1000], Loss: 0.5093\n",
      "Epoch [311/1000], Loss: 0.5089\n",
      "Epoch [312/1000], Loss: 0.5089\n",
      "Epoch [313/1000], Loss: 0.5089\n",
      "Epoch [314/1000], Loss: 0.5052\n",
      "Epoch [315/1000], Loss: 0.5076\n",
      "Epoch [316/1000], Loss: 0.5105\n",
      "Epoch [317/1000], Loss: 0.5085\n",
      "Epoch [318/1000], Loss: 0.5076\n",
      "Epoch [319/1000], Loss: 0.5080\n",
      "Epoch [320/1000], Loss: 0.5085\n",
      "Epoch [321/1000], Loss: 0.5085\n",
      "Epoch [322/1000], Loss: 0.5072\n",
      "Epoch [323/1000], Loss: 0.5080\n",
      "Epoch [324/1000], Loss: 0.5076\n",
      "Epoch [325/1000], Loss: 0.5080\n",
      "Epoch [326/1000], Loss: 0.5060\n",
      "Epoch [327/1000], Loss: 0.5076\n",
      "Epoch [328/1000], Loss: 0.5093\n",
      "Epoch [329/1000], Loss: 0.5080\n",
      "Epoch [330/1000], Loss: 0.5072\n",
      "Epoch [331/1000], Loss: 0.5089\n",
      "Epoch [332/1000], Loss: 0.5105\n",
      "Epoch [333/1000], Loss: 0.5085\n",
      "Epoch [334/1000], Loss: 0.5080\n",
      "Epoch [335/1000], Loss: 0.5089\n",
      "Epoch [336/1000], Loss: 0.5076\n",
      "Epoch [337/1000], Loss: 0.5089\n",
      "Epoch [338/1000], Loss: 0.5072\n",
      "Epoch [339/1000], Loss: 0.5085\n",
      "Epoch [340/1000], Loss: 0.5076\n",
      "Epoch [341/1000], Loss: 0.5076\n",
      "Epoch [342/1000], Loss: 0.5080\n",
      "Epoch [343/1000], Loss: 0.5064\n",
      "Epoch [344/1000], Loss: 0.5060\n",
      "Epoch [345/1000], Loss: 0.5072\n",
      "Epoch [346/1000], Loss: 0.5093\n",
      "Epoch [347/1000], Loss: 0.5072\n",
      "Epoch [348/1000], Loss: 0.5080\n",
      "Epoch [349/1000], Loss: 0.5064\n",
      "Epoch [350/1000], Loss: 0.5072\n",
      "Epoch [351/1000], Loss: 0.5064\n",
      "Epoch [352/1000], Loss: 0.5093\n",
      "Epoch [353/1000], Loss: 0.5089\n",
      "Epoch [354/1000], Loss: 0.5085\n",
      "Epoch [355/1000], Loss: 0.5101\n",
      "Epoch [356/1000], Loss: 0.5076\n",
      "Epoch [357/1000], Loss: 0.5076\n",
      "Epoch [358/1000], Loss: 0.5064\n",
      "Epoch [359/1000], Loss: 0.5080\n",
      "Epoch [360/1000], Loss: 0.5064\n",
      "Epoch [361/1000], Loss: 0.5080\n",
      "Epoch [362/1000], Loss: 0.5076\n",
      "Epoch [363/1000], Loss: 0.5080\n",
      "Epoch [364/1000], Loss: 0.5093\n",
      "Epoch [365/1000], Loss: 0.5097\n",
      "Epoch [366/1000], Loss: 0.5072\n",
      "Epoch [367/1000], Loss: 0.5085\n",
      "Epoch [368/1000], Loss: 0.5101\n",
      "Epoch [369/1000], Loss: 0.5093\n",
      "Epoch [370/1000], Loss: 0.5093\n",
      "Epoch [371/1000], Loss: 0.5076\n",
      "Epoch [372/1000], Loss: 0.5089\n",
      "Epoch [373/1000], Loss: 0.5085\n",
      "Epoch [374/1000], Loss: 0.5097\n",
      "Epoch [375/1000], Loss: 0.5101\n",
      "Epoch [376/1000], Loss: 0.5085\n",
      "Epoch [377/1000], Loss: 0.5089\n",
      "Epoch [378/1000], Loss: 0.5089\n",
      "Epoch [379/1000], Loss: 0.5080\n",
      "Epoch [380/1000], Loss: 0.5064\n",
      "Epoch [381/1000], Loss: 0.5080\n",
      "Epoch [382/1000], Loss: 0.5113\n",
      "Epoch [383/1000], Loss: 0.5072\n",
      "Epoch [384/1000], Loss: 0.5089\n",
      "Epoch [385/1000], Loss: 0.5072\n",
      "Epoch [386/1000], Loss: 0.5072\n",
      "Epoch [387/1000], Loss: 0.5089\n",
      "Epoch [388/1000], Loss: 0.5089\n",
      "Epoch [389/1000], Loss: 0.5076\n",
      "Epoch [390/1000], Loss: 0.5076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [391/1000], Loss: 0.5085\n",
      "Epoch [392/1000], Loss: 0.5085\n",
      "Epoch [393/1000], Loss: 0.5085\n",
      "Epoch [394/1000], Loss: 0.5080\n",
      "Epoch [395/1000], Loss: 0.5097\n",
      "Epoch [396/1000], Loss: 0.5076\n",
      "Epoch [397/1000], Loss: 0.5076\n",
      "Epoch [398/1000], Loss: 0.5076\n",
      "Epoch [399/1000], Loss: 0.5076\n",
      "Epoch [400/1000], Loss: 0.5085\n",
      "Epoch [401/1000], Loss: 0.5056\n",
      "Epoch [402/1000], Loss: 0.5117\n",
      "Epoch [403/1000], Loss: 0.5072\n",
      "Epoch [404/1000], Loss: 0.5097\n",
      "Epoch [405/1000], Loss: 0.5101\n",
      "Epoch [406/1000], Loss: 0.5080\n",
      "Epoch [407/1000], Loss: 0.5076\n",
      "Epoch [408/1000], Loss: 0.5080\n",
      "Epoch [409/1000], Loss: 0.5076\n",
      "Epoch [410/1000], Loss: 0.5068\n",
      "Epoch [411/1000], Loss: 0.5080\n",
      "Epoch [412/1000], Loss: 0.5089\n",
      "Epoch [413/1000], Loss: 0.5080\n",
      "Epoch [414/1000], Loss: 0.5052\n",
      "Epoch [415/1000], Loss: 0.5060\n",
      "Epoch [416/1000], Loss: 0.5068\n",
      "Epoch [417/1000], Loss: 0.5113\n",
      "Epoch [418/1000], Loss: 0.5076\n",
      "Epoch [419/1000], Loss: 0.5072\n",
      "Epoch [420/1000], Loss: 0.5085\n",
      "Epoch [421/1000], Loss: 0.5105\n",
      "Epoch [422/1000], Loss: 0.5101\n",
      "Epoch [423/1000], Loss: 0.5085\n",
      "Epoch [424/1000], Loss: 0.5068\n",
      "Epoch [425/1000], Loss: 0.5060\n",
      "Epoch [426/1000], Loss: 0.5089\n",
      "Epoch [427/1000], Loss: 0.5105\n",
      "Epoch [428/1000], Loss: 0.5085\n",
      "Epoch [429/1000], Loss: 0.5064\n",
      "Epoch [430/1000], Loss: 0.5089\n",
      "Epoch [431/1000], Loss: 0.5097\n",
      "Epoch [432/1000], Loss: 0.5093\n",
      "Epoch [433/1000], Loss: 0.5089\n",
      "Epoch [434/1000], Loss: 0.5080\n",
      "Epoch [435/1000], Loss: 0.5089\n",
      "Epoch [436/1000], Loss: 0.5076\n",
      "Epoch [437/1000], Loss: 0.5085\n",
      "Epoch [438/1000], Loss: 0.5093\n",
      "Epoch [439/1000], Loss: 0.5068\n",
      "Epoch [440/1000], Loss: 0.5072\n",
      "Epoch [441/1000], Loss: 0.5113\n",
      "Epoch [442/1000], Loss: 0.5068\n",
      "Epoch [443/1000], Loss: 0.5097\n",
      "Epoch [444/1000], Loss: 0.5085\n",
      "Epoch [445/1000], Loss: 0.5085\n",
      "Epoch [446/1000], Loss: 0.5109\n",
      "Epoch [447/1000], Loss: 0.5097\n",
      "Epoch [448/1000], Loss: 0.5093\n",
      "Epoch [449/1000], Loss: 0.5072\n",
      "Epoch [450/1000], Loss: 0.5097\n",
      "Epoch [451/1000], Loss: 0.5089\n",
      "Epoch [452/1000], Loss: 0.5064\n",
      "Epoch [453/1000], Loss: 0.5060\n",
      "Epoch [454/1000], Loss: 0.5093\n",
      "Epoch [455/1000], Loss: 0.5101\n",
      "Epoch [456/1000], Loss: 0.5076\n",
      "Epoch [457/1000], Loss: 0.5076\n",
      "Epoch [458/1000], Loss: 0.5048\n",
      "Epoch [459/1000], Loss: 0.5064\n",
      "Epoch [460/1000], Loss: 0.5064\n",
      "Epoch [461/1000], Loss: 0.5060\n",
      "Epoch [462/1000], Loss: 0.5097\n",
      "Epoch [463/1000], Loss: 0.5089\n",
      "Epoch [464/1000], Loss: 0.5080\n",
      "Epoch [465/1000], Loss: 0.5072\n",
      "Epoch [466/1000], Loss: 0.5072\n",
      "Epoch [467/1000], Loss: 0.5080\n",
      "Epoch [468/1000], Loss: 0.5068\n",
      "Epoch [469/1000], Loss: 0.5093\n",
      "Epoch [470/1000], Loss: 0.5085\n",
      "Epoch [471/1000], Loss: 0.5080\n",
      "Epoch [472/1000], Loss: 0.5068\n",
      "Epoch [473/1000], Loss: 0.5072\n",
      "Epoch [474/1000], Loss: 0.5089\n",
      "Epoch [475/1000], Loss: 0.5068\n",
      "Epoch [476/1000], Loss: 0.5072\n",
      "Epoch [477/1000], Loss: 0.5068\n",
      "Epoch [478/1000], Loss: 0.5093\n",
      "Epoch [479/1000], Loss: 0.5109\n",
      "Epoch [480/1000], Loss: 0.5064\n",
      "Epoch [481/1000], Loss: 0.5093\n",
      "Epoch [482/1000], Loss: 0.5072\n",
      "Epoch [483/1000], Loss: 0.5089\n",
      "Epoch [484/1000], Loss: 0.5076\n",
      "Epoch [485/1000], Loss: 0.5080\n",
      "Epoch [486/1000], Loss: 0.5093\n",
      "Epoch [487/1000], Loss: 0.5085\n",
      "Epoch [488/1000], Loss: 0.5068\n",
      "Epoch [489/1000], Loss: 0.5068\n",
      "Epoch [490/1000], Loss: 0.5080\n",
      "Epoch [491/1000], Loss: 0.5052\n",
      "Epoch [492/1000], Loss: 0.5085\n",
      "Epoch [493/1000], Loss: 0.5097\n",
      "Epoch [494/1000], Loss: 0.5085\n",
      "Epoch [495/1000], Loss: 0.5072\n",
      "Epoch [496/1000], Loss: 0.5072\n",
      "Epoch [497/1000], Loss: 0.5089\n",
      "Epoch [498/1000], Loss: 0.5072\n",
      "Epoch [499/1000], Loss: 0.5068\n",
      "Epoch [500/1000], Loss: 0.5080\n",
      "Epoch [501/1000], Loss: 0.5089\n",
      "Epoch [502/1000], Loss: 0.5056\n",
      "Epoch [503/1000], Loss: 0.5085\n",
      "Epoch [504/1000], Loss: 0.5068\n",
      "Epoch [505/1000], Loss: 0.5093\n",
      "Epoch [506/1000], Loss: 0.5080\n",
      "Epoch [507/1000], Loss: 0.5080\n",
      "Epoch [508/1000], Loss: 0.5101\n",
      "Epoch [509/1000], Loss: 0.5085\n",
      "Epoch [510/1000], Loss: 0.5064\n",
      "Epoch [511/1000], Loss: 0.5089\n",
      "Epoch [512/1000], Loss: 0.5089\n",
      "Epoch [513/1000], Loss: 0.5072\n",
      "Epoch [514/1000], Loss: 0.5064\n",
      "Epoch [515/1000], Loss: 0.5085\n",
      "Epoch [516/1000], Loss: 0.5085\n",
      "Epoch [517/1000], Loss: 0.5093\n",
      "Epoch [518/1000], Loss: 0.5085\n",
      "Epoch [519/1000], Loss: 0.5093\n",
      "Epoch [520/1000], Loss: 0.5080\n",
      "Epoch [521/1000], Loss: 0.5109\n",
      "Epoch [522/1000], Loss: 0.5080\n",
      "Epoch [523/1000], Loss: 0.5080\n",
      "Epoch [524/1000], Loss: 0.5097\n",
      "Epoch [525/1000], Loss: 0.5072\n",
      "Epoch [526/1000], Loss: 0.5085\n",
      "Epoch [527/1000], Loss: 0.5085\n",
      "Epoch [528/1000], Loss: 0.5097\n",
      "Epoch [529/1000], Loss: 0.5076\n",
      "Epoch [530/1000], Loss: 0.5085\n",
      "Epoch [531/1000], Loss: 0.5089\n",
      "Epoch [532/1000], Loss: 0.5076\n",
      "Epoch [533/1000], Loss: 0.5076\n",
      "Epoch [534/1000], Loss: 0.5068\n",
      "Epoch [535/1000], Loss: 0.5072\n",
      "Epoch [536/1000], Loss: 0.5093\n",
      "Epoch [537/1000], Loss: 0.5060\n",
      "Epoch [538/1000], Loss: 0.5093\n",
      "Epoch [539/1000], Loss: 0.5093\n",
      "Epoch [540/1000], Loss: 0.5072\n",
      "Epoch [541/1000], Loss: 0.5056\n",
      "Epoch [542/1000], Loss: 0.5080\n",
      "Epoch [543/1000], Loss: 0.5089\n",
      "Epoch [544/1000], Loss: 0.5076\n",
      "Epoch [545/1000], Loss: 0.5072\n",
      "Epoch [546/1000], Loss: 0.5064\n",
      "Epoch [547/1000], Loss: 0.5072\n",
      "Epoch [548/1000], Loss: 0.5085\n",
      "Epoch [549/1000], Loss: 0.5048\n",
      "Epoch [550/1000], Loss: 0.5093\n",
      "Epoch [551/1000], Loss: 0.5089\n",
      "Epoch [552/1000], Loss: 0.5089\n",
      "Epoch [553/1000], Loss: 0.5076\n",
      "Epoch [554/1000], Loss: 0.5068\n",
      "Epoch [555/1000], Loss: 0.5068\n",
      "Epoch [556/1000], Loss: 0.5089\n",
      "Epoch [557/1000], Loss: 0.5064\n",
      "Epoch [558/1000], Loss: 0.5093\n",
      "Epoch [559/1000], Loss: 0.5089\n",
      "Epoch [560/1000], Loss: 0.5101\n",
      "Epoch [561/1000], Loss: 0.5093\n",
      "Epoch [562/1000], Loss: 0.5089\n",
      "Epoch [563/1000], Loss: 0.5068\n",
      "Epoch [564/1000], Loss: 0.5097\n",
      "Epoch [565/1000], Loss: 0.5093\n",
      "Epoch [566/1000], Loss: 0.5089\n",
      "Epoch [567/1000], Loss: 0.5101\n",
      "Epoch [568/1000], Loss: 0.5076\n",
      "Epoch [569/1000], Loss: 0.5072\n",
      "Epoch [570/1000], Loss: 0.5072\n",
      "Epoch [571/1000], Loss: 0.5076\n",
      "Epoch [572/1000], Loss: 0.5101\n",
      "Epoch [573/1000], Loss: 0.5097\n",
      "Epoch [574/1000], Loss: 0.5097\n",
      "Epoch [575/1000], Loss: 0.5097\n",
      "Epoch [576/1000], Loss: 0.5076\n",
      "Epoch [577/1000], Loss: 0.5068\n",
      "Epoch [578/1000], Loss: 0.5097\n",
      "Epoch [579/1000], Loss: 0.5109\n",
      "Epoch [580/1000], Loss: 0.5072\n",
      "Epoch [581/1000], Loss: 0.5101\n",
      "Epoch [582/1000], Loss: 0.5072\n",
      "Epoch [583/1000], Loss: 0.5097\n",
      "Epoch [584/1000], Loss: 0.5101\n",
      "Epoch [585/1000], Loss: 0.5105\n",
      "Epoch [586/1000], Loss: 0.5089\n",
      "Epoch [587/1000], Loss: 0.5097\n",
      "Epoch [588/1000], Loss: 0.5085\n",
      "Epoch [589/1000], Loss: 0.5109\n",
      "Epoch [590/1000], Loss: 0.5080\n",
      "Epoch [591/1000], Loss: 0.5085\n",
      "Epoch [592/1000], Loss: 0.5064\n",
      "Epoch [593/1000], Loss: 0.5089\n",
      "Epoch [594/1000], Loss: 0.5076\n",
      "Epoch [595/1000], Loss: 0.5085\n",
      "Epoch [596/1000], Loss: 0.5093\n",
      "Epoch [597/1000], Loss: 0.5072\n",
      "Epoch [598/1000], Loss: 0.5068\n",
      "Epoch [599/1000], Loss: 0.5085\n",
      "Epoch [600/1000], Loss: 0.5085\n",
      "Epoch [601/1000], Loss: 0.5089\n",
      "Epoch [602/1000], Loss: 0.5076\n",
      "Epoch [603/1000], Loss: 0.5060\n",
      "Epoch [604/1000], Loss: 0.5089\n",
      "Epoch [605/1000], Loss: 0.5060\n",
      "Epoch [606/1000], Loss: 0.5064\n",
      "Epoch [607/1000], Loss: 0.5064\n",
      "Epoch [608/1000], Loss: 0.5072\n",
      "Epoch [609/1000], Loss: 0.5101\n",
      "Epoch [610/1000], Loss: 0.5093\n",
      "Epoch [611/1000], Loss: 0.5072\n",
      "Epoch [612/1000], Loss: 0.5101\n",
      "Epoch [613/1000], Loss: 0.5089\n",
      "Epoch [614/1000], Loss: 0.5093\n",
      "Epoch [615/1000], Loss: 0.5072\n",
      "Epoch [616/1000], Loss: 0.5113\n",
      "Epoch [617/1000], Loss: 0.5068\n",
      "Epoch [618/1000], Loss: 0.5093\n",
      "Epoch [619/1000], Loss: 0.5093\n",
      "Epoch [620/1000], Loss: 0.5048\n",
      "Epoch [621/1000], Loss: 0.5097\n",
      "Epoch [622/1000], Loss: 0.5097\n",
      "Epoch [623/1000], Loss: 0.5089\n",
      "Epoch [624/1000], Loss: 0.5113\n",
      "Epoch [625/1000], Loss: 0.5097\n",
      "Epoch [626/1000], Loss: 0.5072\n",
      "Epoch [627/1000], Loss: 0.5052\n",
      "Epoch [628/1000], Loss: 0.5097\n",
      "Epoch [629/1000], Loss: 0.5085\n",
      "Epoch [630/1000], Loss: 0.5080\n",
      "Epoch [631/1000], Loss: 0.5064\n",
      "Epoch [632/1000], Loss: 0.5064\n",
      "Epoch [633/1000], Loss: 0.5085\n",
      "Epoch [634/1000], Loss: 0.5072\n",
      "Epoch [635/1000], Loss: 0.5089\n",
      "Epoch [636/1000], Loss: 0.5076\n",
      "Epoch [637/1000], Loss: 0.5080\n",
      "Epoch [638/1000], Loss: 0.5113\n",
      "Epoch [639/1000], Loss: 0.5085\n",
      "Epoch [640/1000], Loss: 0.5089\n",
      "Epoch [641/1000], Loss: 0.5085\n",
      "Epoch [642/1000], Loss: 0.5080\n",
      "Epoch [643/1000], Loss: 0.5076\n",
      "Epoch [644/1000], Loss: 0.5085\n",
      "Epoch [645/1000], Loss: 0.5080\n",
      "Epoch [646/1000], Loss: 0.5105\n",
      "Epoch [647/1000], Loss: 0.5109\n",
      "Epoch [648/1000], Loss: 0.5080\n",
      "Epoch [649/1000], Loss: 0.5085\n",
      "Epoch [650/1000], Loss: 0.5064\n",
      "Epoch [651/1000], Loss: 0.5089\n",
      "Epoch [652/1000], Loss: 0.5093\n",
      "Epoch [653/1000], Loss: 0.5072\n",
      "Epoch [654/1000], Loss: 0.5105\n",
      "Epoch [655/1000], Loss: 0.5068\n",
      "Epoch [656/1000], Loss: 0.5101\n",
      "Epoch [657/1000], Loss: 0.5105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [658/1000], Loss: 0.5072\n",
      "Epoch [659/1000], Loss: 0.5093\n",
      "Epoch [660/1000], Loss: 0.5093\n",
      "Epoch [661/1000], Loss: 0.5068\n",
      "Epoch [662/1000], Loss: 0.5085\n",
      "Epoch [663/1000], Loss: 0.5068\n",
      "Epoch [664/1000], Loss: 0.5089\n",
      "Epoch [665/1000], Loss: 0.5080\n",
      "Epoch [666/1000], Loss: 0.5097\n",
      "Epoch [667/1000], Loss: 0.5064\n",
      "Epoch [668/1000], Loss: 0.5072\n",
      "Epoch [669/1000], Loss: 0.5089\n",
      "Epoch [670/1000], Loss: 0.5089\n",
      "Epoch [671/1000], Loss: 0.5105\n",
      "Epoch [672/1000], Loss: 0.5068\n",
      "Epoch [673/1000], Loss: 0.5080\n",
      "Epoch [674/1000], Loss: 0.5076\n",
      "Epoch [675/1000], Loss: 0.5093\n",
      "Epoch [676/1000], Loss: 0.5089\n",
      "Epoch [677/1000], Loss: 0.5056\n",
      "Epoch [678/1000], Loss: 0.5085\n",
      "Epoch [679/1000], Loss: 0.5076\n",
      "Epoch [680/1000], Loss: 0.5064\n",
      "Epoch [681/1000], Loss: 0.5101\n",
      "Epoch [682/1000], Loss: 0.5085\n",
      "Epoch [683/1000], Loss: 0.5109\n",
      "Epoch [684/1000], Loss: 0.5097\n",
      "Epoch [685/1000], Loss: 0.5089\n",
      "Epoch [686/1000], Loss: 0.5101\n",
      "Epoch [687/1000], Loss: 0.5089\n",
      "Epoch [688/1000], Loss: 0.5089\n",
      "Epoch [689/1000], Loss: 0.5080\n",
      "Epoch [690/1000], Loss: 0.5068\n",
      "Epoch [691/1000], Loss: 0.5089\n",
      "Epoch [692/1000], Loss: 0.5085\n",
      "Epoch [693/1000], Loss: 0.5072\n",
      "Epoch [694/1000], Loss: 0.5093\n",
      "Epoch [695/1000], Loss: 0.5076\n",
      "Epoch [696/1000], Loss: 0.5089\n",
      "Epoch [697/1000], Loss: 0.5101\n",
      "Epoch [698/1000], Loss: 0.5085\n",
      "Epoch [699/1000], Loss: 0.5097\n",
      "Epoch [700/1000], Loss: 0.5085\n",
      "Epoch [701/1000], Loss: 0.5089\n",
      "Epoch [702/1000], Loss: 0.5101\n",
      "Epoch [703/1000], Loss: 0.5089\n",
      "Epoch [704/1000], Loss: 0.5080\n",
      "Epoch [705/1000], Loss: 0.5089\n",
      "Epoch [706/1000], Loss: 0.5089\n",
      "Epoch [707/1000], Loss: 0.5076\n",
      "Epoch [708/1000], Loss: 0.5072\n",
      "Epoch [709/1000], Loss: 0.5105\n",
      "Epoch [710/1000], Loss: 0.5064\n",
      "Epoch [711/1000], Loss: 0.5080\n",
      "Epoch [712/1000], Loss: 0.5089\n",
      "Epoch [713/1000], Loss: 0.5068\n",
      "Epoch [714/1000], Loss: 0.5076\n",
      "Epoch [715/1000], Loss: 0.5105\n",
      "Epoch [716/1000], Loss: 0.5072\n",
      "Epoch [717/1000], Loss: 0.5056\n",
      "Epoch [718/1000], Loss: 0.5076\n",
      "Epoch [719/1000], Loss: 0.5085\n",
      "Epoch [720/1000], Loss: 0.5101\n",
      "Epoch [721/1000], Loss: 0.5085\n",
      "Epoch [722/1000], Loss: 0.5076\n",
      "Epoch [723/1000], Loss: 0.5109\n",
      "Epoch [724/1000], Loss: 0.5080\n",
      "Epoch [725/1000], Loss: 0.5117\n",
      "Epoch [726/1000], Loss: 0.5080\n",
      "Epoch [727/1000], Loss: 0.5101\n",
      "Epoch [728/1000], Loss: 0.5085\n",
      "Epoch [729/1000], Loss: 0.5080\n",
      "Epoch [730/1000], Loss: 0.5072\n",
      "Epoch [731/1000], Loss: 0.5064\n",
      "Epoch [732/1000], Loss: 0.5068\n",
      "Epoch [733/1000], Loss: 0.5093\n",
      "Epoch [734/1000], Loss: 0.5097\n",
      "Epoch [735/1000], Loss: 0.5089\n",
      "Epoch [736/1000], Loss: 0.5064\n",
      "Epoch [737/1000], Loss: 0.5093\n",
      "Epoch [738/1000], Loss: 0.5080\n",
      "Epoch [739/1000], Loss: 0.5097\n",
      "Epoch [740/1000], Loss: 0.5076\n",
      "Epoch [741/1000], Loss: 0.5101\n",
      "Epoch [742/1000], Loss: 0.5060\n",
      "Epoch [743/1000], Loss: 0.5093\n",
      "Epoch [744/1000], Loss: 0.5068\n",
      "Epoch [745/1000], Loss: 0.5064\n",
      "Epoch [746/1000], Loss: 0.5093\n",
      "Epoch [747/1000], Loss: 0.5080\n",
      "Epoch [748/1000], Loss: 0.5101\n",
      "Epoch [749/1000], Loss: 0.5097\n",
      "Epoch [750/1000], Loss: 0.5076\n",
      "Epoch [751/1000], Loss: 0.5072\n",
      "Epoch [752/1000], Loss: 0.5072\n",
      "Epoch [753/1000], Loss: 0.5085\n",
      "Epoch [754/1000], Loss: 0.5076\n",
      "Epoch [755/1000], Loss: 0.5085\n",
      "Epoch [756/1000], Loss: 0.5097\n",
      "Epoch [757/1000], Loss: 0.5068\n",
      "Epoch [758/1000], Loss: 0.5080\n",
      "Epoch [759/1000], Loss: 0.5101\n",
      "Epoch [760/1000], Loss: 0.5093\n",
      "Epoch [761/1000], Loss: 0.5064\n",
      "Epoch [762/1000], Loss: 0.5052\n",
      "Epoch [763/1000], Loss: 0.5085\n",
      "Epoch [764/1000], Loss: 0.5101\n",
      "Epoch [765/1000], Loss: 0.5109\n",
      "Epoch [766/1000], Loss: 0.5072\n",
      "Epoch [767/1000], Loss: 0.5076\n",
      "Epoch [768/1000], Loss: 0.5101\n",
      "Epoch [769/1000], Loss: 0.5080\n",
      "Epoch [770/1000], Loss: 0.5089\n",
      "Epoch [771/1000], Loss: 0.5089\n",
      "Epoch [772/1000], Loss: 0.5072\n",
      "Epoch [773/1000], Loss: 0.5089\n",
      "Epoch [774/1000], Loss: 0.5089\n",
      "Epoch [775/1000], Loss: 0.5080\n",
      "Epoch [776/1000], Loss: 0.5089\n",
      "Epoch [777/1000], Loss: 0.5105\n",
      "Epoch [778/1000], Loss: 0.5085\n",
      "Epoch [779/1000], Loss: 0.5060\n",
      "Epoch [780/1000], Loss: 0.5097\n",
      "Epoch [781/1000], Loss: 0.5048\n",
      "Epoch [782/1000], Loss: 0.5105\n",
      "Epoch [783/1000], Loss: 0.5093\n",
      "Epoch [784/1000], Loss: 0.5064\n",
      "Epoch [785/1000], Loss: 0.5097\n",
      "Epoch [786/1000], Loss: 0.5072\n",
      "Epoch [787/1000], Loss: 0.5076\n",
      "Epoch [788/1000], Loss: 0.5093\n",
      "Epoch [789/1000], Loss: 0.5080\n",
      "Epoch [790/1000], Loss: 0.5101\n",
      "Epoch [791/1000], Loss: 0.5080\n",
      "Epoch [792/1000], Loss: 0.5089\n",
      "Epoch [793/1000], Loss: 0.5097\n",
      "Epoch [794/1000], Loss: 0.5089\n",
      "Epoch [795/1000], Loss: 0.5097\n",
      "Epoch [796/1000], Loss: 0.5113\n",
      "Epoch [797/1000], Loss: 0.5072\n",
      "Epoch [798/1000], Loss: 0.5089\n",
      "Epoch [799/1000], Loss: 0.5089\n",
      "Epoch [800/1000], Loss: 0.5072\n",
      "Epoch [801/1000], Loss: 0.5101\n",
      "Epoch [802/1000], Loss: 0.5117\n",
      "Epoch [803/1000], Loss: 0.5097\n",
      "Epoch [804/1000], Loss: 0.5068\n",
      "Epoch [805/1000], Loss: 0.5076\n",
      "Epoch [806/1000], Loss: 0.5085\n",
      "Epoch [807/1000], Loss: 0.5076\n",
      "Epoch [808/1000], Loss: 0.5076\n",
      "Epoch [809/1000], Loss: 0.5080\n",
      "Epoch [810/1000], Loss: 0.5089\n",
      "Epoch [811/1000], Loss: 0.5064\n",
      "Epoch [812/1000], Loss: 0.5101\n",
      "Epoch [813/1000], Loss: 0.5072\n",
      "Epoch [814/1000], Loss: 0.5076\n",
      "Epoch [815/1000], Loss: 0.5072\n",
      "Epoch [816/1000], Loss: 0.5072\n",
      "Epoch [817/1000], Loss: 0.5080\n",
      "Epoch [818/1000], Loss: 0.5056\n",
      "Epoch [819/1000], Loss: 0.5089\n",
      "Epoch [820/1000], Loss: 0.5093\n",
      "Epoch [821/1000], Loss: 0.5085\n",
      "Epoch [822/1000], Loss: 0.5080\n",
      "Epoch [823/1000], Loss: 0.5072\n",
      "Epoch [824/1000], Loss: 0.5080\n",
      "Epoch [825/1000], Loss: 0.5080\n",
      "Epoch [826/1000], Loss: 0.5085\n",
      "Epoch [827/1000], Loss: 0.5068\n",
      "Epoch [828/1000], Loss: 0.5085\n",
      "Epoch [829/1000], Loss: 0.5113\n",
      "Epoch [830/1000], Loss: 0.5089\n",
      "Epoch [831/1000], Loss: 0.5076\n",
      "Epoch [832/1000], Loss: 0.5089\n",
      "Epoch [833/1000], Loss: 0.5072\n",
      "Epoch [834/1000], Loss: 0.5068\n",
      "Epoch [835/1000], Loss: 0.5060\n",
      "Epoch [836/1000], Loss: 0.5089\n",
      "Epoch [837/1000], Loss: 0.5089\n",
      "Epoch [838/1000], Loss: 0.5097\n",
      "Epoch [839/1000], Loss: 0.5076\n",
      "Epoch [840/1000], Loss: 0.5068\n",
      "Epoch [841/1000], Loss: 0.5076\n",
      "Epoch [842/1000], Loss: 0.5093\n",
      "Epoch [843/1000], Loss: 0.5097\n",
      "Epoch [844/1000], Loss: 0.5072\n",
      "Epoch [845/1000], Loss: 0.5080\n",
      "Epoch [846/1000], Loss: 0.5097\n",
      "Epoch [847/1000], Loss: 0.5060\n",
      "Epoch [848/1000], Loss: 0.5089\n",
      "Epoch [849/1000], Loss: 0.5093\n",
      "Epoch [850/1000], Loss: 0.5056\n",
      "Epoch [851/1000], Loss: 0.5068\n",
      "Epoch [852/1000], Loss: 0.5072\n",
      "Epoch [853/1000], Loss: 0.5085\n",
      "Epoch [854/1000], Loss: 0.5056\n",
      "Epoch [855/1000], Loss: 0.5076\n",
      "Epoch [856/1000], Loss: 0.5085\n",
      "Epoch [857/1000], Loss: 0.5080\n",
      "Epoch [858/1000], Loss: 0.5097\n",
      "Epoch [859/1000], Loss: 0.5101\n",
      "Epoch [860/1000], Loss: 0.5097\n",
      "Epoch [861/1000], Loss: 0.5072\n",
      "Epoch [862/1000], Loss: 0.5101\n",
      "Epoch [863/1000], Loss: 0.5093\n",
      "Epoch [864/1000], Loss: 0.5089\n",
      "Epoch [865/1000], Loss: 0.5076\n",
      "Epoch [866/1000], Loss: 0.5072\n",
      "Epoch [867/1000], Loss: 0.5105\n",
      "Epoch [868/1000], Loss: 0.5097\n",
      "Epoch [869/1000], Loss: 0.5076\n",
      "Epoch [870/1000], Loss: 0.5056\n",
      "Epoch [871/1000], Loss: 0.5085\n",
      "Epoch [872/1000], Loss: 0.5080\n",
      "Epoch [873/1000], Loss: 0.5101\n",
      "Epoch [874/1000], Loss: 0.5076\n",
      "Epoch [875/1000], Loss: 0.5085\n",
      "Epoch [876/1000], Loss: 0.5080\n",
      "Epoch [877/1000], Loss: 0.5093\n",
      "Epoch [878/1000], Loss: 0.5060\n",
      "Epoch [879/1000], Loss: 0.5089\n",
      "Epoch [880/1000], Loss: 0.5072\n",
      "Epoch [881/1000], Loss: 0.5093\n",
      "Epoch [882/1000], Loss: 0.5060\n",
      "Epoch [883/1000], Loss: 0.5097\n",
      "Epoch [884/1000], Loss: 0.5085\n",
      "Epoch [885/1000], Loss: 0.5085\n",
      "Epoch [886/1000], Loss: 0.5060\n",
      "Epoch [887/1000], Loss: 0.5089\n",
      "Epoch [888/1000], Loss: 0.5093\n",
      "Epoch [889/1000], Loss: 0.5085\n",
      "Epoch [890/1000], Loss: 0.5072\n",
      "Epoch [891/1000], Loss: 0.5097\n",
      "Epoch [892/1000], Loss: 0.5085\n",
      "Epoch [893/1000], Loss: 0.5093\n",
      "Epoch [894/1000], Loss: 0.5072\n",
      "Epoch [895/1000], Loss: 0.5080\n",
      "Epoch [896/1000], Loss: 0.5072\n",
      "Epoch [897/1000], Loss: 0.5068\n",
      "Epoch [898/1000], Loss: 0.5076\n",
      "Epoch [899/1000], Loss: 0.5068\n",
      "Epoch [900/1000], Loss: 0.5080\n",
      "Epoch [901/1000], Loss: 0.5064\n",
      "Epoch [902/1000], Loss: 0.5068\n",
      "Epoch [903/1000], Loss: 0.5076\n",
      "Epoch [904/1000], Loss: 0.5064\n",
      "Epoch [905/1000], Loss: 0.5085\n",
      "Epoch [906/1000], Loss: 0.5097\n",
      "Epoch [907/1000], Loss: 0.5068\n",
      "Epoch [908/1000], Loss: 0.5068\n",
      "Epoch [909/1000], Loss: 0.5097\n",
      "Epoch [910/1000], Loss: 0.5080\n",
      "Epoch [911/1000], Loss: 0.5093\n",
      "Epoch [912/1000], Loss: 0.5072\n",
      "Epoch [913/1000], Loss: 0.5072\n",
      "Epoch [914/1000], Loss: 0.5093\n",
      "Epoch [915/1000], Loss: 0.5109\n",
      "Epoch [916/1000], Loss: 0.5105\n",
      "Epoch [917/1000], Loss: 0.5085\n",
      "Epoch [918/1000], Loss: 0.5072\n",
      "Epoch [919/1000], Loss: 0.5089\n",
      "Epoch [920/1000], Loss: 0.5097\n",
      "Epoch [921/1000], Loss: 0.5105\n",
      "Epoch [922/1000], Loss: 0.5068\n",
      "Epoch [923/1000], Loss: 0.5085\n",
      "Epoch [924/1000], Loss: 0.5068\n",
      "Epoch [925/1000], Loss: 0.5085\n",
      "Epoch [926/1000], Loss: 0.5068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [927/1000], Loss: 0.5089\n",
      "Epoch [928/1000], Loss: 0.5068\n",
      "Epoch [929/1000], Loss: 0.5072\n",
      "Epoch [930/1000], Loss: 0.5080\n",
      "Epoch [931/1000], Loss: 0.5076\n",
      "Epoch [932/1000], Loss: 0.5101\n",
      "Epoch [933/1000], Loss: 0.5097\n",
      "Epoch [934/1000], Loss: 0.5068\n",
      "Epoch [935/1000], Loss: 0.5093\n",
      "Epoch [936/1000], Loss: 0.5093\n",
      "Epoch [937/1000], Loss: 0.5089\n",
      "Epoch [938/1000], Loss: 0.5089\n",
      "Epoch [939/1000], Loss: 0.5072\n",
      "Epoch [940/1000], Loss: 0.5072\n",
      "Epoch [941/1000], Loss: 0.5085\n",
      "Epoch [942/1000], Loss: 0.5076\n",
      "Epoch [943/1000], Loss: 0.5097\n",
      "Epoch [944/1000], Loss: 0.5080\n",
      "Epoch [945/1000], Loss: 0.5072\n",
      "Epoch [946/1000], Loss: 0.5085\n",
      "Epoch [947/1000], Loss: 0.5097\n",
      "Epoch [948/1000], Loss: 0.5085\n",
      "Epoch [949/1000], Loss: 0.5064\n",
      "Epoch [950/1000], Loss: 0.5076\n",
      "Epoch [951/1000], Loss: 0.5097\n",
      "Epoch [952/1000], Loss: 0.5060\n",
      "Epoch [953/1000], Loss: 0.5076\n",
      "Epoch [954/1000], Loss: 0.5076\n",
      "Epoch [955/1000], Loss: 0.5089\n",
      "Epoch [956/1000], Loss: 0.5056\n",
      "Epoch [957/1000], Loss: 0.5101\n",
      "Epoch [958/1000], Loss: 0.5076\n",
      "Epoch [959/1000], Loss: 0.5068\n",
      "Epoch [960/1000], Loss: 0.5076\n",
      "Epoch [961/1000], Loss: 0.5093\n",
      "Epoch [962/1000], Loss: 0.5076\n",
      "Epoch [963/1000], Loss: 0.5101\n",
      "Epoch [964/1000], Loss: 0.5109\n",
      "Epoch [965/1000], Loss: 0.5101\n",
      "Epoch [966/1000], Loss: 0.5089\n",
      "Epoch [967/1000], Loss: 0.5093\n",
      "Epoch [968/1000], Loss: 0.5085\n",
      "Epoch [969/1000], Loss: 0.5068\n",
      "Epoch [970/1000], Loss: 0.5076\n",
      "Epoch [971/1000], Loss: 0.5085\n",
      "Epoch [972/1000], Loss: 0.5089\n",
      "Epoch [973/1000], Loss: 0.5080\n",
      "Epoch [974/1000], Loss: 0.5072\n",
      "Epoch [975/1000], Loss: 0.5068\n",
      "Epoch [976/1000], Loss: 0.5064\n",
      "Epoch [977/1000], Loss: 0.5080\n",
      "Epoch [978/1000], Loss: 0.5076\n",
      "Epoch [979/1000], Loss: 0.5076\n",
      "Epoch [980/1000], Loss: 0.5064\n",
      "Epoch [981/1000], Loss: 0.5101\n",
      "Epoch [982/1000], Loss: 0.5093\n",
      "Epoch [983/1000], Loss: 0.5097\n",
      "Epoch [984/1000], Loss: 0.5060\n",
      "Epoch [985/1000], Loss: 0.5072\n",
      "Epoch [986/1000], Loss: 0.5101\n",
      "Epoch [987/1000], Loss: 0.5080\n",
      "Epoch [988/1000], Loss: 0.5101\n",
      "Epoch [989/1000], Loss: 0.5076\n",
      "Epoch [990/1000], Loss: 0.5105\n",
      "Epoch [991/1000], Loss: 0.5068\n",
      "Epoch [992/1000], Loss: 0.5097\n",
      "Epoch [993/1000], Loss: 0.5068\n",
      "Epoch [994/1000], Loss: 0.5101\n",
      "Epoch [995/1000], Loss: 0.5076\n",
      "Epoch [996/1000], Loss: 0.5097\n",
      "Epoch [997/1000], Loss: 0.5085\n",
      "Epoch [998/1000], Loss: 0.5089\n",
      "Epoch [999/1000], Loss: 0.5072\n",
      "Epoch [1000/1000], Loss: 0.5080\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 107, lr :10.0, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.5032\n",
      "Epoch [2/1000], Loss: 0.5085\n",
      "Epoch [3/1000], Loss: 0.5101\n",
      "Epoch [4/1000], Loss: 0.5056\n",
      "Epoch [5/1000], Loss: 0.5085\n",
      "Epoch [6/1000], Loss: 0.5072\n",
      "Epoch [7/1000], Loss: 0.5076\n",
      "Epoch [8/1000], Loss: 0.5072\n",
      "Epoch [9/1000], Loss: 0.5080\n",
      "Epoch [10/1000], Loss: 0.5093\n",
      "Epoch [11/1000], Loss: 0.5076\n",
      "Epoch [12/1000], Loss: 0.5097\n",
      "Epoch [13/1000], Loss: 0.5085\n",
      "Epoch [14/1000], Loss: 0.5060\n",
      "Epoch [15/1000], Loss: 0.5080\n",
      "Epoch [16/1000], Loss: 0.5060\n",
      "Epoch [17/1000], Loss: 0.5089\n",
      "Epoch [18/1000], Loss: 0.5080\n",
      "Epoch [19/1000], Loss: 0.5085\n",
      "Epoch [20/1000], Loss: 0.5105\n",
      "Epoch [21/1000], Loss: 0.5089\n",
      "Epoch [22/1000], Loss: 0.5089\n",
      "Epoch [23/1000], Loss: 0.5076\n",
      "Epoch [24/1000], Loss: 0.5097\n",
      "Epoch [25/1000], Loss: 0.5089\n",
      "Epoch [26/1000], Loss: 0.5097\n",
      "Epoch [27/1000], Loss: 0.5076\n",
      "Epoch [28/1000], Loss: 0.5068\n",
      "Epoch [29/1000], Loss: 0.5089\n",
      "Epoch [30/1000], Loss: 0.5076\n",
      "Epoch [31/1000], Loss: 0.5080\n",
      "Epoch [32/1000], Loss: 0.5093\n",
      "Epoch [33/1000], Loss: 0.5089\n",
      "Epoch [34/1000], Loss: 0.5093\n",
      "Epoch [35/1000], Loss: 0.5080\n",
      "Epoch [36/1000], Loss: 0.5089\n",
      "Epoch [37/1000], Loss: 0.5085\n",
      "Epoch [38/1000], Loss: 0.5080\n",
      "Epoch [39/1000], Loss: 0.5109\n",
      "Epoch [40/1000], Loss: 0.5085\n",
      "Epoch [41/1000], Loss: 0.5085\n",
      "Epoch [42/1000], Loss: 0.5085\n",
      "Epoch [43/1000], Loss: 0.5080\n",
      "Epoch [44/1000], Loss: 0.5076\n",
      "Epoch [45/1000], Loss: 0.5072\n",
      "Epoch [46/1000], Loss: 0.5085\n",
      "Epoch [47/1000], Loss: 0.5093\n",
      "Epoch [48/1000], Loss: 0.5105\n",
      "Epoch [49/1000], Loss: 0.5089\n",
      "Epoch [50/1000], Loss: 0.5060\n",
      "Epoch [51/1000], Loss: 0.5068\n",
      "Epoch [52/1000], Loss: 0.5101\n",
      "Epoch [53/1000], Loss: 0.5072\n",
      "Epoch [54/1000], Loss: 0.5064\n",
      "Epoch [55/1000], Loss: 0.5076\n",
      "Epoch [56/1000], Loss: 0.5072\n",
      "Epoch [57/1000], Loss: 0.5101\n",
      "Epoch [58/1000], Loss: 0.5080\n",
      "Epoch [59/1000], Loss: 0.5097\n",
      "Epoch [60/1000], Loss: 0.5080\n",
      "Epoch [61/1000], Loss: 0.5093\n",
      "Epoch [62/1000], Loss: 0.5080\n",
      "Epoch [63/1000], Loss: 0.5109\n",
      "Epoch [64/1000], Loss: 0.5068\n",
      "Epoch [65/1000], Loss: 0.5089\n",
      "Epoch [66/1000], Loss: 0.5085\n",
      "Epoch [67/1000], Loss: 0.5085\n",
      "Epoch [68/1000], Loss: 0.5076\n",
      "Epoch [69/1000], Loss: 0.5068\n",
      "Epoch [70/1000], Loss: 0.5076\n",
      "Epoch [71/1000], Loss: 0.5048\n",
      "Epoch [72/1000], Loss: 0.5080\n",
      "Epoch [73/1000], Loss: 0.5072\n",
      "Epoch [74/1000], Loss: 0.5072\n",
      "Epoch [75/1000], Loss: 0.5093\n",
      "Epoch [76/1000], Loss: 0.5097\n",
      "Epoch [77/1000], Loss: 0.5076\n",
      "Epoch [78/1000], Loss: 0.5089\n",
      "Epoch [79/1000], Loss: 0.5068\n",
      "Epoch [80/1000], Loss: 0.5105\n",
      "Epoch [81/1000], Loss: 0.5093\n",
      "Epoch [82/1000], Loss: 0.5093\n",
      "Epoch [83/1000], Loss: 0.5068\n",
      "Epoch [84/1000], Loss: 0.5068\n",
      "Epoch [85/1000], Loss: 0.5068\n",
      "Epoch [86/1000], Loss: 0.5109\n",
      "Epoch [87/1000], Loss: 0.5080\n",
      "Epoch [88/1000], Loss: 0.5089\n",
      "Epoch [89/1000], Loss: 0.5093\n",
      "Epoch [90/1000], Loss: 0.5072\n",
      "Epoch [91/1000], Loss: 0.5064\n",
      "Epoch [92/1000], Loss: 0.5097\n",
      "Epoch [93/1000], Loss: 0.5085\n",
      "Epoch [94/1000], Loss: 0.5056\n",
      "Epoch [95/1000], Loss: 0.5072\n",
      "Epoch [96/1000], Loss: 0.5085\n",
      "Epoch [97/1000], Loss: 0.5085\n",
      "Epoch [98/1000], Loss: 0.5076\n",
      "Epoch [99/1000], Loss: 0.5089\n",
      "Epoch [100/1000], Loss: 0.5105\n",
      "Epoch [101/1000], Loss: 0.5085\n",
      "Epoch [102/1000], Loss: 0.5076\n",
      "Epoch [103/1000], Loss: 0.5085\n",
      "Epoch [104/1000], Loss: 0.5097\n",
      "Epoch [105/1000], Loss: 0.5101\n",
      "Epoch [106/1000], Loss: 0.5085\n",
      "Epoch [107/1000], Loss: 0.5097\n",
      "Epoch [108/1000], Loss: 0.5056\n",
      "Epoch [109/1000], Loss: 0.5068\n",
      "Epoch [110/1000], Loss: 0.5085\n",
      "Epoch [111/1000], Loss: 0.5101\n",
      "Epoch [112/1000], Loss: 0.5072\n",
      "Epoch [113/1000], Loss: 0.5068\n",
      "Epoch [114/1000], Loss: 0.5056\n",
      "Epoch [115/1000], Loss: 0.5060\n",
      "Epoch [116/1000], Loss: 0.5085\n",
      "Epoch [117/1000], Loss: 0.5068\n",
      "Epoch [118/1000], Loss: 0.5068\n",
      "Epoch [119/1000], Loss: 0.5064\n",
      "Epoch [120/1000], Loss: 0.5101\n",
      "Epoch [121/1000], Loss: 0.5060\n",
      "Epoch [122/1000], Loss: 0.5089\n",
      "Epoch [123/1000], Loss: 0.5052\n",
      "Epoch [124/1000], Loss: 0.5072\n",
      "Epoch [125/1000], Loss: 0.5085\n",
      "Epoch [126/1000], Loss: 0.5097\n",
      "Epoch [127/1000], Loss: 0.5080\n",
      "Epoch [128/1000], Loss: 0.5089\n",
      "Epoch [129/1000], Loss: 0.5072\n",
      "Epoch [130/1000], Loss: 0.5109\n",
      "Epoch [131/1000], Loss: 0.5068\n",
      "Epoch [132/1000], Loss: 0.5085\n",
      "Epoch [133/1000], Loss: 0.5072\n",
      "Epoch [134/1000], Loss: 0.5080\n",
      "Epoch [135/1000], Loss: 0.5068\n",
      "Epoch [136/1000], Loss: 0.5101\n",
      "Epoch [137/1000], Loss: 0.5093\n",
      "Epoch [138/1000], Loss: 0.5080\n",
      "Epoch [139/1000], Loss: 0.5080\n",
      "Epoch [140/1000], Loss: 0.5105\n",
      "Epoch [141/1000], Loss: 0.5080\n",
      "Epoch [142/1000], Loss: 0.5068\n",
      "Epoch [143/1000], Loss: 0.5085\n",
      "Epoch [144/1000], Loss: 0.5056\n",
      "Epoch [145/1000], Loss: 0.5085\n",
      "Epoch [146/1000], Loss: 0.5085\n",
      "Epoch [147/1000], Loss: 0.5068\n",
      "Epoch [148/1000], Loss: 0.5105\n",
      "Epoch [149/1000], Loss: 0.5060\n",
      "Epoch [150/1000], Loss: 0.5080\n",
      "Epoch [151/1000], Loss: 0.5089\n",
      "Epoch [152/1000], Loss: 0.5076\n",
      "Epoch [153/1000], Loss: 0.5068\n",
      "Epoch [154/1000], Loss: 0.5064\n",
      "Epoch [155/1000], Loss: 0.5076\n",
      "Epoch [156/1000], Loss: 0.5113\n",
      "Epoch [157/1000], Loss: 0.5072\n",
      "Epoch [158/1000], Loss: 0.5072\n",
      "Epoch [159/1000], Loss: 0.5072\n",
      "Epoch [160/1000], Loss: 0.5072\n",
      "Epoch [161/1000], Loss: 0.5085\n",
      "Epoch [162/1000], Loss: 0.5093\n",
      "Epoch [163/1000], Loss: 0.5089\n",
      "Epoch [164/1000], Loss: 0.5089\n",
      "Epoch [165/1000], Loss: 0.5080\n",
      "Epoch [166/1000], Loss: 0.5093\n",
      "Epoch [167/1000], Loss: 0.5085\n",
      "Epoch [168/1000], Loss: 0.5089\n",
      "Epoch [169/1000], Loss: 0.5097\n",
      "Epoch [170/1000], Loss: 0.5076\n",
      "Epoch [171/1000], Loss: 0.5076\n",
      "Epoch [172/1000], Loss: 0.5080\n",
      "Epoch [173/1000], Loss: 0.5080\n",
      "Epoch [174/1000], Loss: 0.5101\n",
      "Epoch [175/1000], Loss: 0.5072\n",
      "Epoch [176/1000], Loss: 0.5072\n",
      "Epoch [177/1000], Loss: 0.5060\n",
      "Epoch [178/1000], Loss: 0.5105\n",
      "Epoch [179/1000], Loss: 0.5060\n",
      "Epoch [180/1000], Loss: 0.5080\n",
      "Epoch [181/1000], Loss: 0.5097\n",
      "Epoch [182/1000], Loss: 0.5048\n",
      "Epoch [183/1000], Loss: 0.5076\n",
      "Epoch [184/1000], Loss: 0.5072\n",
      "Epoch [185/1000], Loss: 0.5072\n",
      "Epoch [186/1000], Loss: 0.5089\n",
      "Epoch [187/1000], Loss: 0.5080\n",
      "Epoch [188/1000], Loss: 0.5097\n",
      "Epoch [189/1000], Loss: 0.5093\n",
      "Epoch [190/1000], Loss: 0.5101\n",
      "Epoch [191/1000], Loss: 0.5076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [192/1000], Loss: 0.5064\n",
      "Epoch [193/1000], Loss: 0.5072\n",
      "Epoch [194/1000], Loss: 0.5093\n",
      "Epoch [195/1000], Loss: 0.5060\n",
      "Epoch [196/1000], Loss: 0.5080\n",
      "Epoch [197/1000], Loss: 0.5080\n",
      "Epoch [198/1000], Loss: 0.5080\n",
      "Epoch [199/1000], Loss: 0.5085\n",
      "Epoch [200/1000], Loss: 0.5085\n",
      "Epoch [201/1000], Loss: 0.5064\n",
      "Epoch [202/1000], Loss: 0.5052\n",
      "Epoch [203/1000], Loss: 0.5048\n",
      "Epoch [204/1000], Loss: 0.5089\n",
      "Epoch [205/1000], Loss: 0.5072\n",
      "Epoch [206/1000], Loss: 0.5089\n",
      "Epoch [207/1000], Loss: 0.5064\n",
      "Epoch [208/1000], Loss: 0.5085\n",
      "Epoch [209/1000], Loss: 0.5093\n",
      "Epoch [210/1000], Loss: 0.5097\n",
      "Epoch [211/1000], Loss: 0.5072\n",
      "Epoch [212/1000], Loss: 0.5105\n",
      "Epoch [213/1000], Loss: 0.5080\n",
      "Epoch [214/1000], Loss: 0.5044\n",
      "Epoch [215/1000], Loss: 0.5085\n",
      "Epoch [216/1000], Loss: 0.5080\n",
      "Epoch [217/1000], Loss: 0.5097\n",
      "Epoch [218/1000], Loss: 0.5089\n",
      "Epoch [219/1000], Loss: 0.5093\n",
      "Epoch [220/1000], Loss: 0.5089\n",
      "Epoch [221/1000], Loss: 0.5072\n",
      "Epoch [222/1000], Loss: 0.5076\n",
      "Epoch [223/1000], Loss: 0.5101\n",
      "Epoch [224/1000], Loss: 0.5097\n",
      "Epoch [225/1000], Loss: 0.5109\n",
      "Epoch [226/1000], Loss: 0.5089\n",
      "Epoch [227/1000], Loss: 0.5085\n",
      "Epoch [228/1000], Loss: 0.5064\n",
      "Epoch [229/1000], Loss: 0.5089\n",
      "Epoch [230/1000], Loss: 0.5089\n",
      "Epoch [231/1000], Loss: 0.5076\n",
      "Epoch [232/1000], Loss: 0.5072\n",
      "Epoch [233/1000], Loss: 0.5080\n",
      "Epoch [234/1000], Loss: 0.5076\n",
      "Epoch [235/1000], Loss: 0.5093\n",
      "Epoch [236/1000], Loss: 0.5072\n",
      "Epoch [237/1000], Loss: 0.5064\n",
      "Epoch [238/1000], Loss: 0.5089\n",
      "Epoch [239/1000], Loss: 0.5072\n",
      "Epoch [240/1000], Loss: 0.5093\n",
      "Epoch [241/1000], Loss: 0.5097\n",
      "Epoch [242/1000], Loss: 0.5072\n",
      "Epoch [243/1000], Loss: 0.5080\n",
      "Epoch [244/1000], Loss: 0.5085\n",
      "Epoch [245/1000], Loss: 0.5052\n",
      "Epoch [246/1000], Loss: 0.5072\n",
      "Epoch [247/1000], Loss: 0.5093\n",
      "Epoch [248/1000], Loss: 0.5085\n",
      "Epoch [249/1000], Loss: 0.5097\n",
      "Epoch [250/1000], Loss: 0.5072\n",
      "Epoch [251/1000], Loss: 0.5076\n",
      "Epoch [252/1000], Loss: 0.5072\n",
      "Epoch [253/1000], Loss: 0.5076\n",
      "Epoch [254/1000], Loss: 0.5068\n",
      "Epoch [255/1000], Loss: 0.5064\n",
      "Epoch [256/1000], Loss: 0.5085\n",
      "Epoch [257/1000], Loss: 0.5093\n",
      "Epoch [258/1000], Loss: 0.5076\n",
      "Epoch [259/1000], Loss: 0.5089\n",
      "Epoch [260/1000], Loss: 0.5056\n",
      "Epoch [261/1000], Loss: 0.5072\n",
      "Epoch [262/1000], Loss: 0.5064\n",
      "Epoch [263/1000], Loss: 0.5093\n",
      "Epoch [264/1000], Loss: 0.5085\n",
      "Epoch [265/1000], Loss: 0.5072\n",
      "Epoch [266/1000], Loss: 0.5080\n",
      "Epoch [267/1000], Loss: 0.5085\n",
      "Epoch [268/1000], Loss: 0.5080\n",
      "Epoch [269/1000], Loss: 0.5076\n",
      "Epoch [270/1000], Loss: 0.5080\n",
      "Epoch [271/1000], Loss: 0.5101\n",
      "Epoch [272/1000], Loss: 0.5056\n",
      "Epoch [273/1000], Loss: 0.5097\n",
      "Epoch [274/1000], Loss: 0.5072\n",
      "Epoch [275/1000], Loss: 0.5072\n",
      "Epoch [276/1000], Loss: 0.5093\n",
      "Epoch [277/1000], Loss: 0.5085\n",
      "Epoch [278/1000], Loss: 0.5089\n",
      "Epoch [279/1000], Loss: 0.5052\n",
      "Epoch [280/1000], Loss: 0.5089\n",
      "Epoch [281/1000], Loss: 0.5089\n",
      "Epoch [282/1000], Loss: 0.5085\n",
      "Epoch [283/1000], Loss: 0.5093\n",
      "Epoch [284/1000], Loss: 0.5085\n",
      "Epoch [285/1000], Loss: 0.5060\n",
      "Epoch [286/1000], Loss: 0.5056\n",
      "Epoch [287/1000], Loss: 0.5072\n",
      "Epoch [288/1000], Loss: 0.5089\n",
      "Epoch [289/1000], Loss: 0.5080\n",
      "Epoch [290/1000], Loss: 0.5072\n",
      "Epoch [291/1000], Loss: 0.5093\n",
      "Epoch [292/1000], Loss: 0.5068\n",
      "Epoch [293/1000], Loss: 0.5085\n",
      "Epoch [294/1000], Loss: 0.5085\n",
      "Epoch [295/1000], Loss: 0.5076\n",
      "Epoch [296/1000], Loss: 0.5080\n",
      "Epoch [297/1000], Loss: 0.5105\n",
      "Epoch [298/1000], Loss: 0.5085\n",
      "Epoch [299/1000], Loss: 0.5085\n",
      "Epoch [300/1000], Loss: 0.5105\n",
      "Epoch [301/1000], Loss: 0.5089\n",
      "Epoch [302/1000], Loss: 0.5080\n",
      "Epoch [303/1000], Loss: 0.5080\n",
      "Epoch [304/1000], Loss: 0.5097\n",
      "Epoch [305/1000], Loss: 0.5105\n",
      "Epoch [306/1000], Loss: 0.5076\n",
      "Epoch [307/1000], Loss: 0.5072\n",
      "Epoch [308/1000], Loss: 0.5080\n",
      "Epoch [309/1000], Loss: 0.5072\n",
      "Epoch [310/1000], Loss: 0.5101\n",
      "Epoch [311/1000], Loss: 0.5080\n",
      "Epoch [312/1000], Loss: 0.5076\n",
      "Epoch [313/1000], Loss: 0.5113\n",
      "Epoch [314/1000], Loss: 0.5048\n",
      "Epoch [315/1000], Loss: 0.5085\n",
      "Epoch [316/1000], Loss: 0.5093\n",
      "Epoch [317/1000], Loss: 0.5085\n",
      "Epoch [318/1000], Loss: 0.5080\n",
      "Epoch [319/1000], Loss: 0.5080\n",
      "Epoch [320/1000], Loss: 0.5072\n",
      "Epoch [321/1000], Loss: 0.5089\n",
      "Epoch [322/1000], Loss: 0.5080\n",
      "Epoch [323/1000], Loss: 0.5085\n",
      "Epoch [324/1000], Loss: 0.5076\n",
      "Epoch [325/1000], Loss: 0.5048\n",
      "Epoch [326/1000], Loss: 0.5064\n",
      "Epoch [327/1000], Loss: 0.5093\n",
      "Epoch [328/1000], Loss: 0.5080\n",
      "Epoch [329/1000], Loss: 0.5089\n",
      "Epoch [330/1000], Loss: 0.5076\n",
      "Epoch [331/1000], Loss: 0.5085\n",
      "Epoch [332/1000], Loss: 0.5089\n",
      "Epoch [333/1000], Loss: 0.5080\n",
      "Epoch [334/1000], Loss: 0.5068\n",
      "Epoch [335/1000], Loss: 0.5093\n",
      "Epoch [336/1000], Loss: 0.5093\n",
      "Epoch [337/1000], Loss: 0.5064\n",
      "Epoch [338/1000], Loss: 0.5076\n",
      "Epoch [339/1000], Loss: 0.5064\n",
      "Epoch [340/1000], Loss: 0.5097\n",
      "Epoch [341/1000], Loss: 0.5072\n",
      "Epoch [342/1000], Loss: 0.5097\n",
      "Epoch [343/1000], Loss: 0.5060\n",
      "Epoch [344/1000], Loss: 0.5080\n",
      "Epoch [345/1000], Loss: 0.5093\n",
      "Epoch [346/1000], Loss: 0.5085\n",
      "Epoch [347/1000], Loss: 0.5093\n",
      "Epoch [348/1000], Loss: 0.5072\n",
      "Epoch [349/1000], Loss: 0.5076\n",
      "Epoch [350/1000], Loss: 0.5085\n",
      "Epoch [351/1000], Loss: 0.5080\n",
      "Epoch [352/1000], Loss: 0.5085\n",
      "Epoch [353/1000], Loss: 0.5093\n",
      "Epoch [354/1000], Loss: 0.5068\n",
      "Epoch [355/1000], Loss: 0.5101\n",
      "Epoch [356/1000], Loss: 0.5080\n",
      "Epoch [357/1000], Loss: 0.5076\n",
      "Epoch [358/1000], Loss: 0.5080\n",
      "Epoch [359/1000], Loss: 0.5076\n",
      "Epoch [360/1000], Loss: 0.5093\n",
      "Epoch [361/1000], Loss: 0.5060\n",
      "Epoch [362/1000], Loss: 0.5085\n",
      "Epoch [363/1000], Loss: 0.5060\n",
      "Epoch [364/1000], Loss: 0.5089\n",
      "Epoch [365/1000], Loss: 0.5060\n",
      "Epoch [366/1000], Loss: 0.5080\n",
      "Epoch [367/1000], Loss: 0.5064\n",
      "Epoch [368/1000], Loss: 0.5080\n",
      "Epoch [369/1000], Loss: 0.5072\n",
      "Epoch [370/1000], Loss: 0.5080\n",
      "Epoch [371/1000], Loss: 0.5076\n",
      "Epoch [372/1000], Loss: 0.5076\n",
      "Epoch [373/1000], Loss: 0.5085\n",
      "Epoch [374/1000], Loss: 0.5076\n",
      "Epoch [375/1000], Loss: 0.5085\n",
      "Epoch [376/1000], Loss: 0.5072\n",
      "Epoch [377/1000], Loss: 0.5080\n",
      "Epoch [378/1000], Loss: 0.5085\n",
      "Epoch [379/1000], Loss: 0.5064\n",
      "Epoch [380/1000], Loss: 0.5056\n",
      "Epoch [381/1000], Loss: 0.5076\n",
      "Epoch [382/1000], Loss: 0.5089\n",
      "Epoch [383/1000], Loss: 0.5097\n",
      "Epoch [384/1000], Loss: 0.5089\n",
      "Epoch [385/1000], Loss: 0.5085\n",
      "Epoch [386/1000], Loss: 0.5080\n",
      "Epoch [387/1000], Loss: 0.5076\n",
      "Epoch [388/1000], Loss: 0.5097\n",
      "Epoch [389/1000], Loss: 0.5068\n",
      "Epoch [390/1000], Loss: 0.5089\n",
      "Epoch [391/1000], Loss: 0.5080\n",
      "Epoch [392/1000], Loss: 0.5089\n",
      "Epoch [393/1000], Loss: 0.5072\n",
      "Epoch [394/1000], Loss: 0.5109\n",
      "Epoch [395/1000], Loss: 0.5085\n",
      "Epoch [396/1000], Loss: 0.5080\n",
      "Epoch [397/1000], Loss: 0.5076\n",
      "Epoch [398/1000], Loss: 0.5089\n",
      "Epoch [399/1000], Loss: 0.5068\n",
      "Epoch [400/1000], Loss: 0.5072\n",
      "Epoch [401/1000], Loss: 0.5072\n",
      "Epoch [402/1000], Loss: 0.5080\n",
      "Epoch [403/1000], Loss: 0.5068\n",
      "Epoch [404/1000], Loss: 0.5080\n",
      "Epoch [405/1000], Loss: 0.5089\n",
      "Epoch [406/1000], Loss: 0.5097\n",
      "Epoch [407/1000], Loss: 0.5089\n",
      "Epoch [408/1000], Loss: 0.5089\n",
      "Epoch [409/1000], Loss: 0.5044\n",
      "Epoch [410/1000], Loss: 0.5080\n",
      "Epoch [411/1000], Loss: 0.5085\n",
      "Epoch [412/1000], Loss: 0.5076\n",
      "Epoch [413/1000], Loss: 0.5060\n",
      "Epoch [414/1000], Loss: 0.5060\n",
      "Epoch [415/1000], Loss: 0.5068\n",
      "Epoch [416/1000], Loss: 0.5080\n",
      "Epoch [417/1000], Loss: 0.5076\n",
      "Epoch [418/1000], Loss: 0.5093\n",
      "Epoch [419/1000], Loss: 0.5097\n",
      "Epoch [420/1000], Loss: 0.5076\n",
      "Epoch [421/1000], Loss: 0.5068\n",
      "Epoch [422/1000], Loss: 0.5076\n",
      "Epoch [423/1000], Loss: 0.5064\n",
      "Epoch [424/1000], Loss: 0.5085\n",
      "Epoch [425/1000], Loss: 0.5097\n",
      "Epoch [426/1000], Loss: 0.5089\n",
      "Epoch [427/1000], Loss: 0.5076\n",
      "Epoch [428/1000], Loss: 0.5068\n",
      "Epoch [429/1000], Loss: 0.5121\n",
      "Epoch [430/1000], Loss: 0.5089\n",
      "Epoch [431/1000], Loss: 0.5064\n",
      "Epoch [432/1000], Loss: 0.5076\n",
      "Epoch [433/1000], Loss: 0.5105\n",
      "Epoch [434/1000], Loss: 0.5085\n",
      "Epoch [435/1000], Loss: 0.5089\n",
      "Epoch [436/1000], Loss: 0.5076\n",
      "Epoch [437/1000], Loss: 0.5076\n",
      "Epoch [438/1000], Loss: 0.5105\n",
      "Epoch [439/1000], Loss: 0.5068\n",
      "Epoch [440/1000], Loss: 0.5101\n",
      "Epoch [441/1000], Loss: 0.5080\n",
      "Epoch [442/1000], Loss: 0.5064\n",
      "Epoch [443/1000], Loss: 0.5080\n",
      "Epoch [444/1000], Loss: 0.5076\n",
      "Epoch [445/1000], Loss: 0.5060\n",
      "Epoch [446/1000], Loss: 0.5089\n",
      "Epoch [447/1000], Loss: 0.5085\n",
      "Epoch [448/1000], Loss: 0.5076\n",
      "Epoch [449/1000], Loss: 0.5060\n",
      "Epoch [450/1000], Loss: 0.5101\n",
      "Epoch [451/1000], Loss: 0.5085\n",
      "Epoch [452/1000], Loss: 0.5080\n",
      "Epoch [453/1000], Loss: 0.5093\n",
      "Epoch [454/1000], Loss: 0.5085\n",
      "Epoch [455/1000], Loss: 0.5072\n",
      "Epoch [456/1000], Loss: 0.5093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [457/1000], Loss: 0.5072\n",
      "Epoch [458/1000], Loss: 0.5085\n",
      "Epoch [459/1000], Loss: 0.5089\n",
      "Epoch [460/1000], Loss: 0.5085\n",
      "Epoch [461/1000], Loss: 0.5093\n",
      "Epoch [462/1000], Loss: 0.5093\n",
      "Epoch [463/1000], Loss: 0.5068\n",
      "Epoch [464/1000], Loss: 0.5093\n",
      "Epoch [465/1000], Loss: 0.5080\n",
      "Epoch [466/1000], Loss: 0.5080\n",
      "Epoch [467/1000], Loss: 0.5080\n",
      "Epoch [468/1000], Loss: 0.5093\n",
      "Epoch [469/1000], Loss: 0.5097\n",
      "Epoch [470/1000], Loss: 0.5085\n",
      "Epoch [471/1000], Loss: 0.5101\n",
      "Epoch [472/1000], Loss: 0.5085\n",
      "Epoch [473/1000], Loss: 0.5076\n",
      "Epoch [474/1000], Loss: 0.5072\n",
      "Epoch [475/1000], Loss: 0.5072\n",
      "Epoch [476/1000], Loss: 0.5076\n",
      "Epoch [477/1000], Loss: 0.5056\n",
      "Epoch [478/1000], Loss: 0.5076\n",
      "Epoch [479/1000], Loss: 0.5089\n",
      "Epoch [480/1000], Loss: 0.5089\n",
      "Epoch [481/1000], Loss: 0.5089\n",
      "Epoch [482/1000], Loss: 0.5068\n",
      "Epoch [483/1000], Loss: 0.5089\n",
      "Epoch [484/1000], Loss: 0.5093\n",
      "Epoch [485/1000], Loss: 0.5097\n",
      "Epoch [486/1000], Loss: 0.5101\n",
      "Epoch [487/1000], Loss: 0.5068\n",
      "Epoch [488/1000], Loss: 0.5085\n",
      "Epoch [489/1000], Loss: 0.5085\n",
      "Epoch [490/1000], Loss: 0.5101\n",
      "Epoch [491/1000], Loss: 0.5093\n",
      "Epoch [492/1000], Loss: 0.5072\n",
      "Epoch [493/1000], Loss: 0.5080\n",
      "Epoch [494/1000], Loss: 0.5076\n",
      "Epoch [495/1000], Loss: 0.5093\n",
      "Epoch [496/1000], Loss: 0.5076\n",
      "Epoch [497/1000], Loss: 0.5089\n",
      "Epoch [498/1000], Loss: 0.5080\n",
      "Epoch [499/1000], Loss: 0.5076\n",
      "Epoch [500/1000], Loss: 0.5076\n",
      "Epoch [501/1000], Loss: 0.5076\n",
      "Epoch [502/1000], Loss: 0.5089\n",
      "Epoch [503/1000], Loss: 0.5093\n",
      "Epoch [504/1000], Loss: 0.5101\n",
      "Epoch [505/1000], Loss: 0.5072\n",
      "Epoch [506/1000], Loss: 0.5064\n",
      "Epoch [507/1000], Loss: 0.5109\n",
      "Epoch [508/1000], Loss: 0.5080\n",
      "Epoch [509/1000], Loss: 0.5072\n",
      "Epoch [510/1000], Loss: 0.5089\n",
      "Epoch [511/1000], Loss: 0.5064\n",
      "Epoch [512/1000], Loss: 0.5072\n",
      "Epoch [513/1000], Loss: 0.5080\n",
      "Epoch [514/1000], Loss: 0.5101\n",
      "Epoch [515/1000], Loss: 0.5093\n",
      "Epoch [516/1000], Loss: 0.5089\n",
      "Epoch [517/1000], Loss: 0.5093\n",
      "Epoch [518/1000], Loss: 0.5080\n",
      "Epoch [519/1000], Loss: 0.5085\n",
      "Epoch [520/1000], Loss: 0.5080\n",
      "Epoch [521/1000], Loss: 0.5085\n",
      "Epoch [522/1000], Loss: 0.5080\n",
      "Epoch [523/1000], Loss: 0.5097\n",
      "Epoch [524/1000], Loss: 0.5076\n",
      "Epoch [525/1000], Loss: 0.5085\n",
      "Epoch [526/1000], Loss: 0.5093\n",
      "Epoch [527/1000], Loss: 0.5080\n",
      "Epoch [528/1000], Loss: 0.5089\n",
      "Epoch [529/1000], Loss: 0.5068\n",
      "Epoch [530/1000], Loss: 0.5060\n",
      "Epoch [531/1000], Loss: 0.5089\n",
      "Epoch [532/1000], Loss: 0.5080\n",
      "Epoch [533/1000], Loss: 0.5076\n",
      "Epoch [534/1000], Loss: 0.5076\n",
      "Epoch [535/1000], Loss: 0.5068\n",
      "Epoch [536/1000], Loss: 0.5076\n",
      "Epoch [537/1000], Loss: 0.5089\n",
      "Epoch [538/1000], Loss: 0.5089\n",
      "Epoch [539/1000], Loss: 0.5080\n",
      "Epoch [540/1000], Loss: 0.5085\n",
      "Epoch [541/1000], Loss: 0.5068\n",
      "Epoch [542/1000], Loss: 0.5080\n",
      "Epoch [543/1000], Loss: 0.5105\n",
      "Epoch [544/1000], Loss: 0.5089\n",
      "Epoch [545/1000], Loss: 0.5072\n",
      "Epoch [546/1000], Loss: 0.5064\n",
      "Epoch [547/1000], Loss: 0.5076\n",
      "Epoch [548/1000], Loss: 0.5080\n",
      "Epoch [549/1000], Loss: 0.5076\n",
      "Epoch [550/1000], Loss: 0.5076\n",
      "Epoch [551/1000], Loss: 0.5068\n",
      "Epoch [552/1000], Loss: 0.5076\n",
      "Epoch [553/1000], Loss: 0.5076\n",
      "Epoch [554/1000], Loss: 0.5097\n",
      "Epoch [555/1000], Loss: 0.5072\n",
      "Epoch [556/1000], Loss: 0.5076\n",
      "Epoch [557/1000], Loss: 0.5080\n",
      "Epoch [558/1000], Loss: 0.5080\n",
      "Epoch [559/1000], Loss: 0.5072\n",
      "Epoch [560/1000], Loss: 0.5076\n",
      "Epoch [561/1000], Loss: 0.5097\n",
      "Epoch [562/1000], Loss: 0.5109\n",
      "Epoch [563/1000], Loss: 0.5097\n",
      "Epoch [564/1000], Loss: 0.5085\n",
      "Epoch [565/1000], Loss: 0.5080\n",
      "Epoch [566/1000], Loss: 0.5076\n",
      "Epoch [567/1000], Loss: 0.5085\n",
      "Epoch [568/1000], Loss: 0.5080\n",
      "Epoch [569/1000], Loss: 0.5085\n",
      "Epoch [570/1000], Loss: 0.5089\n",
      "Epoch [571/1000], Loss: 0.5076\n",
      "Epoch [572/1000], Loss: 0.5093\n",
      "Epoch [573/1000], Loss: 0.5093\n",
      "Epoch [574/1000], Loss: 0.5080\n",
      "Epoch [575/1000], Loss: 0.5068\n",
      "Epoch [576/1000], Loss: 0.5080\n",
      "Epoch [577/1000], Loss: 0.5101\n",
      "Epoch [578/1000], Loss: 0.5080\n",
      "Epoch [579/1000], Loss: 0.5089\n",
      "Epoch [580/1000], Loss: 0.5068\n",
      "Epoch [581/1000], Loss: 0.5072\n",
      "Epoch [582/1000], Loss: 0.5060\n",
      "Epoch [583/1000], Loss: 0.5097\n",
      "Epoch [584/1000], Loss: 0.5105\n",
      "Epoch [585/1000], Loss: 0.5056\n",
      "Epoch [586/1000], Loss: 0.5101\n",
      "Epoch [587/1000], Loss: 0.5089\n",
      "Epoch [588/1000], Loss: 0.5089\n",
      "Epoch [589/1000], Loss: 0.5080\n",
      "Epoch [590/1000], Loss: 0.5072\n",
      "Epoch [591/1000], Loss: 0.5085\n",
      "Epoch [592/1000], Loss: 0.5076\n",
      "Epoch [593/1000], Loss: 0.5080\n",
      "Epoch [594/1000], Loss: 0.5064\n",
      "Epoch [595/1000], Loss: 0.5080\n",
      "Epoch [596/1000], Loss: 0.5105\n",
      "Epoch [597/1000], Loss: 0.5064\n",
      "Epoch [598/1000], Loss: 0.5089\n",
      "Epoch [599/1000], Loss: 0.5072\n",
      "Epoch [600/1000], Loss: 0.5085\n",
      "Epoch [601/1000], Loss: 0.5089\n",
      "Epoch [602/1000], Loss: 0.5109\n",
      "Epoch [603/1000], Loss: 0.5076\n",
      "Epoch [604/1000], Loss: 0.5056\n",
      "Epoch [605/1000], Loss: 0.5056\n",
      "Epoch [606/1000], Loss: 0.5085\n",
      "Epoch [607/1000], Loss: 0.5072\n",
      "Epoch [608/1000], Loss: 0.5085\n",
      "Epoch [609/1000], Loss: 0.5068\n",
      "Epoch [610/1000], Loss: 0.5093\n",
      "Epoch [611/1000], Loss: 0.5064\n",
      "Epoch [612/1000], Loss: 0.5097\n",
      "Epoch [613/1000], Loss: 0.5097\n",
      "Epoch [614/1000], Loss: 0.5085\n",
      "Epoch [615/1000], Loss: 0.5060\n",
      "Epoch [616/1000], Loss: 0.5072\n",
      "Epoch [617/1000], Loss: 0.5072\n",
      "Epoch [618/1000], Loss: 0.5064\n",
      "Epoch [619/1000], Loss: 0.5080\n",
      "Epoch [620/1000], Loss: 0.5064\n",
      "Epoch [621/1000], Loss: 0.5060\n",
      "Epoch [622/1000], Loss: 0.5076\n",
      "Epoch [623/1000], Loss: 0.5105\n",
      "Epoch [624/1000], Loss: 0.5072\n",
      "Epoch [625/1000], Loss: 0.5109\n",
      "Epoch [626/1000], Loss: 0.5064\n",
      "Epoch [627/1000], Loss: 0.5085\n",
      "Epoch [628/1000], Loss: 0.5060\n",
      "Epoch [629/1000], Loss: 0.5080\n",
      "Epoch [630/1000], Loss: 0.5101\n",
      "Epoch [631/1000], Loss: 0.5056\n",
      "Epoch [632/1000], Loss: 0.5085\n",
      "Epoch [633/1000], Loss: 0.5076\n",
      "Epoch [634/1000], Loss: 0.5080\n",
      "Epoch [635/1000], Loss: 0.5097\n",
      "Epoch [636/1000], Loss: 0.5089\n",
      "Epoch [637/1000], Loss: 0.5072\n",
      "Epoch [638/1000], Loss: 0.5072\n",
      "Epoch [639/1000], Loss: 0.5093\n",
      "Epoch [640/1000], Loss: 0.5117\n",
      "Epoch [641/1000], Loss: 0.5085\n",
      "Epoch [642/1000], Loss: 0.5064\n",
      "Epoch [643/1000], Loss: 0.5089\n",
      "Epoch [644/1000], Loss: 0.5064\n",
      "Epoch [645/1000], Loss: 0.5085\n",
      "Epoch [646/1000], Loss: 0.5072\n",
      "Epoch [647/1000], Loss: 0.5076\n",
      "Epoch [648/1000], Loss: 0.5072\n",
      "Epoch [649/1000], Loss: 0.5093\n",
      "Epoch [650/1000], Loss: 0.5113\n",
      "Epoch [651/1000], Loss: 0.5072\n",
      "Epoch [652/1000], Loss: 0.5072\n",
      "Epoch [653/1000], Loss: 0.5068\n",
      "Epoch [654/1000], Loss: 0.5072\n",
      "Epoch [655/1000], Loss: 0.5093\n",
      "Epoch [656/1000], Loss: 0.5080\n",
      "Epoch [657/1000], Loss: 0.5064\n",
      "Epoch [658/1000], Loss: 0.5076\n",
      "Epoch [659/1000], Loss: 0.5080\n",
      "Epoch [660/1000], Loss: 0.5093\n",
      "Epoch [661/1000], Loss: 0.5076\n",
      "Epoch [662/1000], Loss: 0.5080\n",
      "Epoch [663/1000], Loss: 0.5097\n",
      "Epoch [664/1000], Loss: 0.5089\n",
      "Epoch [665/1000], Loss: 0.5068\n",
      "Epoch [666/1000], Loss: 0.5064\n",
      "Epoch [667/1000], Loss: 0.5052\n",
      "Epoch [668/1000], Loss: 0.5085\n",
      "Epoch [669/1000], Loss: 0.5048\n",
      "Epoch [670/1000], Loss: 0.5064\n",
      "Epoch [671/1000], Loss: 0.5085\n",
      "Epoch [672/1000], Loss: 0.5089\n",
      "Epoch [673/1000], Loss: 0.5072\n",
      "Epoch [674/1000], Loss: 0.5093\n",
      "Epoch [675/1000], Loss: 0.5072\n",
      "Epoch [676/1000], Loss: 0.5101\n",
      "Epoch [677/1000], Loss: 0.5076\n",
      "Epoch [678/1000], Loss: 0.5097\n",
      "Epoch [679/1000], Loss: 0.5093\n",
      "Epoch [680/1000], Loss: 0.5109\n",
      "Epoch [681/1000], Loss: 0.5080\n",
      "Epoch [682/1000], Loss: 0.5097\n",
      "Epoch [683/1000], Loss: 0.5093\n",
      "Epoch [684/1000], Loss: 0.5113\n",
      "Epoch [685/1000], Loss: 0.5056\n",
      "Epoch [686/1000], Loss: 0.5076\n",
      "Epoch [687/1000], Loss: 0.5101\n",
      "Epoch [688/1000], Loss: 0.5101\n",
      "Epoch [689/1000], Loss: 0.5085\n",
      "Epoch [690/1000], Loss: 0.5089\n",
      "Epoch [691/1000], Loss: 0.5076\n",
      "Epoch [692/1000], Loss: 0.5080\n",
      "Epoch [693/1000], Loss: 0.5064\n",
      "Epoch [694/1000], Loss: 0.5064\n",
      "Epoch [695/1000], Loss: 0.5093\n",
      "Epoch [696/1000], Loss: 0.5068\n",
      "Epoch [697/1000], Loss: 0.5080\n",
      "Epoch [698/1000], Loss: 0.5076\n",
      "Epoch [699/1000], Loss: 0.5097\n",
      "Epoch [700/1000], Loss: 0.5105\n",
      "Epoch [701/1000], Loss: 0.5076\n",
      "Epoch [702/1000], Loss: 0.5072\n",
      "Epoch [703/1000], Loss: 0.5056\n",
      "Epoch [704/1000], Loss: 0.5089\n",
      "Epoch [705/1000], Loss: 0.5105\n",
      "Epoch [706/1000], Loss: 0.5093\n",
      "Epoch [707/1000], Loss: 0.5089\n",
      "Epoch [708/1000], Loss: 0.5076\n",
      "Epoch [709/1000], Loss: 0.5085\n",
      "Epoch [710/1000], Loss: 0.5060\n",
      "Epoch [711/1000], Loss: 0.5072\n",
      "Epoch [712/1000], Loss: 0.5097\n",
      "Epoch [713/1000], Loss: 0.5093\n",
      "Epoch [714/1000], Loss: 0.5068\n",
      "Epoch [715/1000], Loss: 0.5101\n",
      "Epoch [716/1000], Loss: 0.5117\n",
      "Epoch [717/1000], Loss: 0.5076\n",
      "Epoch [718/1000], Loss: 0.5089\n",
      "Epoch [719/1000], Loss: 0.5076\n",
      "Epoch [720/1000], Loss: 0.5080\n",
      "Epoch [721/1000], Loss: 0.5080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [722/1000], Loss: 0.5076\n",
      "Epoch [723/1000], Loss: 0.5072\n",
      "Epoch [724/1000], Loss: 0.5076\n",
      "Epoch [725/1000], Loss: 0.5097\n",
      "Epoch [726/1000], Loss: 0.5101\n",
      "Epoch [727/1000], Loss: 0.5105\n",
      "Epoch [728/1000], Loss: 0.5076\n",
      "Epoch [729/1000], Loss: 0.5085\n",
      "Epoch [730/1000], Loss: 0.5076\n",
      "Epoch [731/1000], Loss: 0.5080\n",
      "Epoch [732/1000], Loss: 0.5085\n",
      "Epoch [733/1000], Loss: 0.5080\n",
      "Epoch [734/1000], Loss: 0.5080\n",
      "Epoch [735/1000], Loss: 0.5089\n",
      "Epoch [736/1000], Loss: 0.5101\n",
      "Epoch [737/1000], Loss: 0.5093\n",
      "Epoch [738/1000], Loss: 0.5085\n",
      "Epoch [739/1000], Loss: 0.5109\n",
      "Epoch [740/1000], Loss: 0.5085\n",
      "Epoch [741/1000], Loss: 0.5097\n",
      "Epoch [742/1000], Loss: 0.5093\n",
      "Epoch [743/1000], Loss: 0.5072\n",
      "Epoch [744/1000], Loss: 0.5080\n",
      "Epoch [745/1000], Loss: 0.5076\n",
      "Epoch [746/1000], Loss: 0.5076\n",
      "Epoch [747/1000], Loss: 0.5097\n",
      "Epoch [748/1000], Loss: 0.5080\n",
      "Epoch [749/1000], Loss: 0.5076\n",
      "Epoch [750/1000], Loss: 0.5072\n",
      "Epoch [751/1000], Loss: 0.5093\n",
      "Epoch [752/1000], Loss: 0.5068\n",
      "Epoch [753/1000], Loss: 0.5097\n",
      "Epoch [754/1000], Loss: 0.5085\n",
      "Epoch [755/1000], Loss: 0.5072\n",
      "Epoch [756/1000], Loss: 0.5097\n",
      "Epoch [757/1000], Loss: 0.5068\n",
      "Epoch [758/1000], Loss: 0.5089\n",
      "Epoch [759/1000], Loss: 0.5080\n",
      "Epoch [760/1000], Loss: 0.5089\n",
      "Epoch [761/1000], Loss: 0.5072\n",
      "Epoch [762/1000], Loss: 0.5060\n",
      "Epoch [763/1000], Loss: 0.5080\n",
      "Epoch [764/1000], Loss: 0.5097\n",
      "Epoch [765/1000], Loss: 0.5085\n",
      "Epoch [766/1000], Loss: 0.5089\n",
      "Epoch [767/1000], Loss: 0.5076\n",
      "Epoch [768/1000], Loss: 0.5068\n",
      "Epoch [769/1000], Loss: 0.5080\n",
      "Epoch [770/1000], Loss: 0.5080\n",
      "Epoch [771/1000], Loss: 0.5060\n",
      "Epoch [772/1000], Loss: 0.5089\n",
      "Epoch [773/1000], Loss: 0.5060\n",
      "Epoch [774/1000], Loss: 0.5105\n",
      "Epoch [775/1000], Loss: 0.5097\n",
      "Epoch [776/1000], Loss: 0.5076\n",
      "Epoch [777/1000], Loss: 0.5085\n",
      "Epoch [778/1000], Loss: 0.5076\n",
      "Epoch [779/1000], Loss: 0.5105\n",
      "Epoch [780/1000], Loss: 0.5068\n",
      "Epoch [781/1000], Loss: 0.5064\n",
      "Epoch [782/1000], Loss: 0.5109\n",
      "Epoch [783/1000], Loss: 0.5089\n",
      "Epoch [784/1000], Loss: 0.5072\n",
      "Epoch [785/1000], Loss: 0.5080\n",
      "Epoch [786/1000], Loss: 0.5052\n",
      "Epoch [787/1000], Loss: 0.5097\n",
      "Epoch [788/1000], Loss: 0.5089\n",
      "Epoch [789/1000], Loss: 0.5072\n",
      "Epoch [790/1000], Loss: 0.5089\n",
      "Epoch [791/1000], Loss: 0.5089\n",
      "Epoch [792/1000], Loss: 0.5085\n",
      "Epoch [793/1000], Loss: 0.5105\n",
      "Epoch [794/1000], Loss: 0.5076\n",
      "Epoch [795/1000], Loss: 0.5072\n",
      "Epoch [796/1000], Loss: 0.5089\n",
      "Epoch [797/1000], Loss: 0.5093\n",
      "Epoch [798/1000], Loss: 0.5076\n",
      "Epoch [799/1000], Loss: 0.5076\n",
      "Epoch [800/1000], Loss: 0.5064\n",
      "Epoch [801/1000], Loss: 0.5064\n",
      "Epoch [802/1000], Loss: 0.5089\n",
      "Epoch [803/1000], Loss: 0.5080\n",
      "Epoch [804/1000], Loss: 0.5093\n",
      "Epoch [805/1000], Loss: 0.5097\n",
      "Epoch [806/1000], Loss: 0.5117\n",
      "Epoch [807/1000], Loss: 0.5089\n",
      "Epoch [808/1000], Loss: 0.5072\n",
      "Epoch [809/1000], Loss: 0.5080\n",
      "Epoch [810/1000], Loss: 0.5072\n",
      "Epoch [811/1000], Loss: 0.5101\n",
      "Epoch [812/1000], Loss: 0.5080\n",
      "Epoch [813/1000], Loss: 0.5064\n",
      "Epoch [814/1000], Loss: 0.5068\n",
      "Epoch [815/1000], Loss: 0.5105\n",
      "Epoch [816/1000], Loss: 0.5080\n",
      "Epoch [817/1000], Loss: 0.5105\n",
      "Epoch [818/1000], Loss: 0.5093\n",
      "Epoch [819/1000], Loss: 0.5080\n",
      "Epoch [820/1000], Loss: 0.5080\n",
      "Epoch [821/1000], Loss: 0.5089\n",
      "Epoch [822/1000], Loss: 0.5089\n",
      "Epoch [823/1000], Loss: 0.5085\n",
      "Epoch [824/1000], Loss: 0.5093\n",
      "Epoch [825/1000], Loss: 0.5105\n",
      "Epoch [826/1000], Loss: 0.5101\n",
      "Epoch [827/1000], Loss: 0.5085\n",
      "Epoch [828/1000], Loss: 0.5076\n",
      "Epoch [829/1000], Loss: 0.5085\n",
      "Epoch [830/1000], Loss: 0.5085\n",
      "Epoch [831/1000], Loss: 0.5085\n",
      "Epoch [832/1000], Loss: 0.5076\n",
      "Epoch [833/1000], Loss: 0.5064\n",
      "Epoch [834/1000], Loss: 0.5060\n",
      "Epoch [835/1000], Loss: 0.5068\n",
      "Epoch [836/1000], Loss: 0.5089\n",
      "Epoch [837/1000], Loss: 0.5072\n",
      "Epoch [838/1000], Loss: 0.5064\n",
      "Epoch [839/1000], Loss: 0.5105\n",
      "Epoch [840/1000], Loss: 0.5085\n",
      "Epoch [841/1000], Loss: 0.5105\n",
      "Epoch [842/1000], Loss: 0.5113\n",
      "Epoch [843/1000], Loss: 0.5056\n",
      "Epoch [844/1000], Loss: 0.5076\n",
      "Epoch [845/1000], Loss: 0.5080\n",
      "Epoch [846/1000], Loss: 0.5076\n",
      "Epoch [847/1000], Loss: 0.5093\n",
      "Epoch [848/1000], Loss: 0.5080\n",
      "Epoch [849/1000], Loss: 0.5085\n",
      "Epoch [850/1000], Loss: 0.5089\n",
      "Epoch [851/1000], Loss: 0.5101\n",
      "Epoch [852/1000], Loss: 0.5068\n",
      "Epoch [853/1000], Loss: 0.5093\n",
      "Epoch [854/1000], Loss: 0.5072\n",
      "Epoch [855/1000], Loss: 0.5080\n",
      "Epoch [856/1000], Loss: 0.5076\n",
      "Epoch [857/1000], Loss: 0.5068\n",
      "Epoch [858/1000], Loss: 0.5085\n",
      "Epoch [859/1000], Loss: 0.5072\n",
      "Epoch [860/1000], Loss: 0.5064\n",
      "Epoch [861/1000], Loss: 0.5076\n",
      "Epoch [862/1000], Loss: 0.5080\n",
      "Epoch [863/1000], Loss: 0.5080\n",
      "Epoch [864/1000], Loss: 0.5085\n",
      "Epoch [865/1000], Loss: 0.5060\n",
      "Epoch [866/1000], Loss: 0.5089\n",
      "Epoch [867/1000], Loss: 0.5089\n",
      "Epoch [868/1000], Loss: 0.5080\n",
      "Epoch [869/1000], Loss: 0.5072\n",
      "Epoch [870/1000], Loss: 0.5072\n",
      "Epoch [871/1000], Loss: 0.5105\n",
      "Epoch [872/1000], Loss: 0.5068\n",
      "Epoch [873/1000], Loss: 0.5113\n",
      "Epoch [874/1000], Loss: 0.5109\n",
      "Epoch [875/1000], Loss: 0.5076\n",
      "Epoch [876/1000], Loss: 0.5105\n",
      "Epoch [877/1000], Loss: 0.5052\n",
      "Epoch [878/1000], Loss: 0.5080\n",
      "Epoch [879/1000], Loss: 0.5101\n",
      "Epoch [880/1000], Loss: 0.5105\n",
      "Epoch [881/1000], Loss: 0.5109\n",
      "Epoch [882/1000], Loss: 0.5072\n",
      "Epoch [883/1000], Loss: 0.5072\n",
      "Epoch [884/1000], Loss: 0.5080\n",
      "Epoch [885/1000], Loss: 0.5109\n",
      "Epoch [886/1000], Loss: 0.5076\n",
      "Epoch [887/1000], Loss: 0.5089\n",
      "Epoch [888/1000], Loss: 0.5097\n",
      "Epoch [889/1000], Loss: 0.5101\n",
      "Epoch [890/1000], Loss: 0.5064\n",
      "Epoch [891/1000], Loss: 0.5097\n",
      "Epoch [892/1000], Loss: 0.5093\n",
      "Epoch [893/1000], Loss: 0.5064\n",
      "Epoch [894/1000], Loss: 0.5072\n",
      "Epoch [895/1000], Loss: 0.5093\n",
      "Epoch [896/1000], Loss: 0.5093\n",
      "Epoch [897/1000], Loss: 0.5093\n",
      "Epoch [898/1000], Loss: 0.5072\n",
      "Epoch [899/1000], Loss: 0.5080\n",
      "Epoch [900/1000], Loss: 0.5068\n",
      "Epoch [901/1000], Loss: 0.5060\n",
      "Epoch [902/1000], Loss: 0.5105\n",
      "Epoch [903/1000], Loss: 0.5080\n",
      "Epoch [904/1000], Loss: 0.5089\n",
      "Epoch [905/1000], Loss: 0.5072\n",
      "Epoch [906/1000], Loss: 0.5089\n",
      "Epoch [907/1000], Loss: 0.5093\n",
      "Epoch [908/1000], Loss: 0.5076\n",
      "Epoch [909/1000], Loss: 0.5093\n",
      "Epoch [910/1000], Loss: 0.5076\n",
      "Epoch [911/1000], Loss: 0.5093\n",
      "Epoch [912/1000], Loss: 0.5089\n",
      "Epoch [913/1000], Loss: 0.5097\n",
      "Epoch [914/1000], Loss: 0.5085\n",
      "Epoch [915/1000], Loss: 0.5089\n",
      "Epoch [916/1000], Loss: 0.5080\n",
      "Epoch [917/1000], Loss: 0.5064\n",
      "Epoch [918/1000], Loss: 0.5093\n",
      "Epoch [919/1000], Loss: 0.5097\n",
      "Epoch [920/1000], Loss: 0.5068\n",
      "Epoch [921/1000], Loss: 0.5101\n",
      "Epoch [922/1000], Loss: 0.5080\n",
      "Epoch [923/1000], Loss: 0.5089\n",
      "Epoch [924/1000], Loss: 0.5068\n",
      "Epoch [925/1000], Loss: 0.5093\n",
      "Epoch [926/1000], Loss: 0.5076\n",
      "Epoch [927/1000], Loss: 0.5085\n",
      "Epoch [928/1000], Loss: 0.5080\n",
      "Epoch [929/1000], Loss: 0.5089\n",
      "Epoch [930/1000], Loss: 0.5089\n",
      "Epoch [931/1000], Loss: 0.5097\n",
      "Epoch [932/1000], Loss: 0.5093\n",
      "Epoch [933/1000], Loss: 0.5072\n",
      "Epoch [934/1000], Loss: 0.5080\n",
      "Epoch [935/1000], Loss: 0.5068\n",
      "Epoch [936/1000], Loss: 0.5093\n",
      "Epoch [937/1000], Loss: 0.5085\n",
      "Epoch [938/1000], Loss: 0.5072\n",
      "Epoch [939/1000], Loss: 0.5093\n",
      "Epoch [940/1000], Loss: 0.5060\n",
      "Epoch [941/1000], Loss: 0.5097\n",
      "Epoch [942/1000], Loss: 0.5076\n",
      "Epoch [943/1000], Loss: 0.5093\n",
      "Epoch [944/1000], Loss: 0.5085\n",
      "Epoch [945/1000], Loss: 0.5089\n",
      "Epoch [946/1000], Loss: 0.5080\n",
      "Epoch [947/1000], Loss: 0.5068\n",
      "Epoch [948/1000], Loss: 0.5093\n",
      "Epoch [949/1000], Loss: 0.5068\n",
      "Epoch [950/1000], Loss: 0.5101\n",
      "Epoch [951/1000], Loss: 0.5097\n",
      "Epoch [952/1000], Loss: 0.5080\n",
      "Epoch [953/1000], Loss: 0.5085\n",
      "Epoch [954/1000], Loss: 0.5109\n",
      "Epoch [955/1000], Loss: 0.5105\n",
      "Epoch [956/1000], Loss: 0.5089\n",
      "Epoch [957/1000], Loss: 0.5064\n",
      "Epoch [958/1000], Loss: 0.5068\n",
      "Epoch [959/1000], Loss: 0.5068\n",
      "Epoch [960/1000], Loss: 0.5101\n",
      "Epoch [961/1000], Loss: 0.5109\n",
      "Epoch [962/1000], Loss: 0.5044\n",
      "Epoch [963/1000], Loss: 0.5072\n",
      "Epoch [964/1000], Loss: 0.5085\n",
      "Epoch [965/1000], Loss: 0.5085\n",
      "Epoch [966/1000], Loss: 0.5076\n",
      "Epoch [967/1000], Loss: 0.5072\n",
      "Epoch [968/1000], Loss: 0.5085\n",
      "Epoch [969/1000], Loss: 0.5060\n",
      "Epoch [970/1000], Loss: 0.5072\n",
      "Epoch [971/1000], Loss: 0.5093\n",
      "Epoch [972/1000], Loss: 0.5080\n",
      "Epoch [973/1000], Loss: 0.5089\n",
      "Epoch [974/1000], Loss: 0.5076\n",
      "Epoch [975/1000], Loss: 0.5064\n",
      "Epoch [976/1000], Loss: 0.5072\n",
      "Epoch [977/1000], Loss: 0.5060\n",
      "Epoch [978/1000], Loss: 0.5076\n",
      "Epoch [979/1000], Loss: 0.5093\n",
      "Epoch [980/1000], Loss: 0.5101\n",
      "Epoch [981/1000], Loss: 0.5093\n",
      "Epoch [982/1000], Loss: 0.5076\n",
      "Epoch [983/1000], Loss: 0.5089\n",
      "Epoch [984/1000], Loss: 0.5076\n",
      "Epoch [985/1000], Loss: 0.5097\n",
      "Epoch [986/1000], Loss: 0.5072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [987/1000], Loss: 0.5076\n",
      "Epoch [988/1000], Loss: 0.5068\n",
      "Epoch [989/1000], Loss: 0.5093\n",
      "Epoch [990/1000], Loss: 0.5097\n",
      "Epoch [991/1000], Loss: 0.5101\n",
      "Epoch [992/1000], Loss: 0.5080\n",
      "Epoch [993/1000], Loss: 0.5076\n",
      "Epoch [994/1000], Loss: 0.5093\n",
      "Epoch [995/1000], Loss: 0.5064\n",
      "Epoch [996/1000], Loss: 0.5089\n",
      "Epoch [997/1000], Loss: 0.5093\n",
      "Epoch [998/1000], Loss: 0.5101\n",
      "Epoch [999/1000], Loss: 0.5068\n",
      "Epoch [1000/1000], Loss: 0.5085\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 107, lr :10.0, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2656\n",
      "Epoch [2/1000], Loss: 0.2543\n",
      "Epoch [3/1000], Loss: 0.2531\n",
      "Epoch [4/1000], Loss: 0.2468\n",
      "Epoch [5/1000], Loss: 0.2475\n",
      "Epoch [6/1000], Loss: 0.2431\n",
      "Epoch [7/1000], Loss: 0.2235\n",
      "Epoch [8/1000], Loss: 0.2268\n",
      "Epoch [9/1000], Loss: 0.2234\n",
      "Epoch [10/1000], Loss: 0.2209\n",
      "Epoch [11/1000], Loss: 0.2238\n",
      "Epoch [12/1000], Loss: 0.2278\n",
      "Epoch [13/1000], Loss: 0.2171\n",
      "Epoch [14/1000], Loss: 0.2218\n",
      "Epoch [15/1000], Loss: 0.2313\n",
      "Epoch [16/1000], Loss: 0.2238\n",
      "Epoch [17/1000], Loss: 0.2491\n",
      "Epoch [18/1000], Loss: 0.2458\n",
      "Epoch [19/1000], Loss: 0.2356\n",
      "Epoch [20/1000], Loss: 0.2228\n",
      "Epoch [21/1000], Loss: 0.2186\n",
      "Epoch [22/1000], Loss: 0.2170\n",
      "Epoch [23/1000], Loss: 0.2184\n",
      "Epoch [24/1000], Loss: 0.2145\n",
      "Epoch [25/1000], Loss: 0.2215\n",
      "Epoch [26/1000], Loss: 0.2204\n",
      "Epoch [27/1000], Loss: 0.2170\n",
      "Epoch [28/1000], Loss: 0.2117\n",
      "Epoch [29/1000], Loss: 0.2149\n",
      "Epoch [30/1000], Loss: 0.2134\n",
      "Epoch [31/1000], Loss: 0.2123\n",
      "Epoch [32/1000], Loss: 0.2270\n",
      "Epoch [33/1000], Loss: 0.2476\n",
      "Epoch [34/1000], Loss: 0.2452\n",
      "Epoch [35/1000], Loss: 0.2443\n",
      "Epoch [36/1000], Loss: 0.2194\n",
      "Epoch [37/1000], Loss: 0.2082\n",
      "Epoch [38/1000], Loss: 0.2080\n",
      "Epoch [39/1000], Loss: 0.2202\n",
      "Epoch [40/1000], Loss: 0.2145\n",
      "Epoch [41/1000], Loss: 0.2158\n",
      "Epoch [42/1000], Loss: 0.2105\n",
      "Epoch [43/1000], Loss: 0.2115\n",
      "Epoch [44/1000], Loss: 0.2132\n",
      "Epoch [45/1000], Loss: 0.2119\n",
      "Epoch [46/1000], Loss: 0.2104\n",
      "Epoch [47/1000], Loss: 0.2131\n",
      "Epoch [48/1000], Loss: 0.2049\n",
      "Epoch [49/1000], Loss: 0.2136\n",
      "Epoch [50/1000], Loss: 0.2084\n",
      "Epoch [51/1000], Loss: 0.2110\n",
      "Epoch [52/1000], Loss: 0.2091\n",
      "Epoch [53/1000], Loss: 0.2137\n",
      "Epoch [54/1000], Loss: 0.2030\n",
      "Epoch [55/1000], Loss: 0.2059\n",
      "Epoch [56/1000], Loss: 0.2066\n",
      "Epoch [57/1000], Loss: 0.2056\n",
      "Epoch [58/1000], Loss: 0.2219\n",
      "Epoch [59/1000], Loss: 0.2094\n",
      "Epoch [60/1000], Loss: 0.2145\n",
      "Epoch [61/1000], Loss: 0.2085\n",
      "Epoch [62/1000], Loss: 0.2167\n",
      "Epoch [63/1000], Loss: 0.2114\n",
      "Epoch [64/1000], Loss: 0.2114\n",
      "Epoch [65/1000], Loss: 0.2127\n",
      "Epoch [66/1000], Loss: 0.2135\n",
      "Epoch [67/1000], Loss: 0.2123\n",
      "Epoch [68/1000], Loss: 0.2057\n",
      "Epoch [69/1000], Loss: 0.2048\n",
      "Epoch [70/1000], Loss: 0.2095\n",
      "Epoch [71/1000], Loss: 0.2096\n",
      "Epoch [72/1000], Loss: 0.2094\n",
      "Epoch [73/1000], Loss: 0.2092\n",
      "Epoch [74/1000], Loss: 0.2012\n",
      "Epoch [75/1000], Loss: 0.2016\n",
      "Epoch [76/1000], Loss: 0.2025\n",
      "Epoch [77/1000], Loss: 0.1994\n",
      "Epoch [78/1000], Loss: 0.2023\n",
      "Epoch [79/1000], Loss: 0.1962\n",
      "Epoch [80/1000], Loss: 0.2179\n",
      "Epoch [81/1000], Loss: 0.2351\n",
      "Epoch [82/1000], Loss: 0.2282\n",
      "Epoch [83/1000], Loss: 0.2132\n",
      "Epoch [84/1000], Loss: 0.2064\n",
      "Epoch [85/1000], Loss: 0.1985\n",
      "Epoch [86/1000], Loss: 0.1972\n",
      "Epoch [87/1000], Loss: 0.2033\n",
      "Epoch [88/1000], Loss: 0.2381\n",
      "Epoch [89/1000], Loss: 0.2196\n",
      "Epoch [90/1000], Loss: 0.1929\n",
      "Epoch [91/1000], Loss: 0.1863\n",
      "Epoch [92/1000], Loss: 0.1779\n",
      "Epoch [93/1000], Loss: 0.2147\n",
      "Epoch [94/1000], Loss: 0.2168\n",
      "Epoch [95/1000], Loss: 0.2171\n",
      "Epoch [96/1000], Loss: 0.2308\n",
      "Epoch [97/1000], Loss: 0.2565\n",
      "Epoch [98/1000], Loss: 0.2453\n",
      "Epoch [99/1000], Loss: 0.2437\n",
      "Epoch [100/1000], Loss: 0.2386\n",
      "Epoch [101/1000], Loss: 0.2566\n",
      "Epoch [102/1000], Loss: 0.2569\n",
      "Epoch [103/1000], Loss: 0.2586\n",
      "Epoch [104/1000], Loss: 0.2571\n",
      "Epoch [105/1000], Loss: 0.2570\n",
      "Epoch [106/1000], Loss: 0.2590\n",
      "Epoch [107/1000], Loss: 0.2574\n",
      "Epoch [108/1000], Loss: 0.2573\n",
      "Epoch [109/1000], Loss: 0.2613\n",
      "Epoch [110/1000], Loss: 0.2596\n",
      "Epoch [111/1000], Loss: 0.2604\n",
      "Epoch [112/1000], Loss: 0.2556\n",
      "Epoch [113/1000], Loss: 0.2571\n",
      "Epoch [114/1000], Loss: 0.2598\n",
      "Epoch [115/1000], Loss: 0.2565\n",
      "Epoch [116/1000], Loss: 0.2632\n",
      "Epoch [117/1000], Loss: 0.2577\n",
      "Epoch [118/1000], Loss: 0.2570\n",
      "Epoch [119/1000], Loss: 0.2573\n",
      "Epoch [120/1000], Loss: 0.2586\n",
      "Epoch [121/1000], Loss: 0.2596\n",
      "Epoch [122/1000], Loss: 0.2572\n",
      "Epoch [123/1000], Loss: 0.2587\n",
      "Epoch [124/1000], Loss: 0.2603\n",
      "Epoch [125/1000], Loss: 0.2588\n",
      "Epoch [126/1000], Loss: 0.2580\n",
      "Epoch [127/1000], Loss: 0.2572\n",
      "Epoch [128/1000], Loss: 0.2575\n",
      "Epoch [129/1000], Loss: 0.2571\n",
      "Epoch [130/1000], Loss: 0.2592\n",
      "Epoch [131/1000], Loss: 0.2575\n",
      "Epoch [132/1000], Loss: 0.2571\n",
      "Epoch [133/1000], Loss: 0.2577\n",
      "Epoch [134/1000], Loss: 0.2585\n",
      "Epoch [135/1000], Loss: 0.2606\n",
      "Epoch [136/1000], Loss: 0.2593\n",
      "Epoch [137/1000], Loss: 0.2597\n",
      "Epoch [138/1000], Loss: 0.2571\n",
      "Epoch [139/1000], Loss: 0.2571\n",
      "Epoch [140/1000], Loss: 0.2594\n",
      "Epoch [141/1000], Loss: 0.2590\n",
      "Epoch [142/1000], Loss: 0.2587\n",
      "Epoch [143/1000], Loss: 0.2585\n",
      "Epoch [144/1000], Loss: 0.2583\n",
      "Epoch [145/1000], Loss: 0.2592\n",
      "Epoch [146/1000], Loss: 0.2607\n",
      "Epoch [147/1000], Loss: 0.2588\n",
      "Epoch [148/1000], Loss: 0.2586\n",
      "Epoch [149/1000], Loss: 0.2563\n",
      "Epoch [150/1000], Loss: 0.2557\n",
      "Epoch [151/1000], Loss: 0.2565\n",
      "Epoch [152/1000], Loss: 0.2585\n",
      "Epoch [153/1000], Loss: 0.2573\n",
      "Epoch [154/1000], Loss: 0.2574\n",
      "Epoch [155/1000], Loss: 0.2569\n",
      "Epoch [156/1000], Loss: 0.2586\n",
      "Epoch [157/1000], Loss: 0.2568\n",
      "Epoch [158/1000], Loss: 0.2568\n",
      "Epoch [159/1000], Loss: 0.2569\n",
      "Epoch [160/1000], Loss: 0.2567\n",
      "Epoch [161/1000], Loss: 0.2594\n",
      "Epoch [162/1000], Loss: 0.2563\n",
      "Epoch [163/1000], Loss: 0.2554\n",
      "Epoch [164/1000], Loss: 0.2581\n",
      "Epoch [165/1000], Loss: 0.2561\n",
      "Epoch [166/1000], Loss: 0.2563\n",
      "Epoch [167/1000], Loss: 0.2571\n",
      "Epoch [168/1000], Loss: 0.2600\n",
      "Epoch [169/1000], Loss: 0.2577\n",
      "Epoch [170/1000], Loss: 0.2563\n",
      "Epoch [171/1000], Loss: 0.2566\n",
      "Epoch [172/1000], Loss: 0.2566\n",
      "Epoch [173/1000], Loss: 0.2590\n",
      "Epoch [174/1000], Loss: 0.2586\n",
      "Epoch [175/1000], Loss: 0.2585\n",
      "Epoch [176/1000], Loss: 0.2573\n",
      "Epoch [177/1000], Loss: 0.2578\n",
      "Epoch [178/1000], Loss: 0.2572\n",
      "Epoch [179/1000], Loss: 0.2607\n",
      "Epoch [180/1000], Loss: 0.2584\n",
      "Epoch [181/1000], Loss: 0.2567\n",
      "Epoch [182/1000], Loss: 0.2558\n",
      "Epoch [183/1000], Loss: 0.2620\n",
      "Epoch [184/1000], Loss: 0.2579\n",
      "Epoch [185/1000], Loss: 0.2573\n",
      "Epoch [186/1000], Loss: 0.2609\n",
      "Epoch [187/1000], Loss: 0.2574\n",
      "Epoch [188/1000], Loss: 0.2563\n",
      "Epoch [189/1000], Loss: 0.2561\n",
      "Epoch [190/1000], Loss: 0.2594\n",
      "Epoch [191/1000], Loss: 0.2589\n",
      "Epoch [192/1000], Loss: 0.2583\n",
      "Epoch [193/1000], Loss: 0.2590\n",
      "Epoch [194/1000], Loss: 0.2565\n",
      "Epoch [195/1000], Loss: 0.2578\n",
      "Epoch [196/1000], Loss: 0.2585\n",
      "Epoch [197/1000], Loss: 0.2605\n",
      "Epoch [198/1000], Loss: 0.2567\n",
      "Epoch [199/1000], Loss: 0.2605\n",
      "Epoch [200/1000], Loss: 0.2590\n",
      "Epoch [201/1000], Loss: 0.2578\n",
      "Epoch [202/1000], Loss: 0.2564\n",
      "Epoch [203/1000], Loss: 0.2586\n",
      "Epoch [204/1000], Loss: 0.2589\n",
      "Epoch [205/1000], Loss: 0.2576\n",
      "Epoch [206/1000], Loss: 0.2574\n",
      "Epoch [207/1000], Loss: 0.2602\n",
      "Epoch [208/1000], Loss: 0.2565\n",
      "Epoch [209/1000], Loss: 0.2580\n",
      "Epoch [210/1000], Loss: 0.2555\n",
      "Epoch [211/1000], Loss: 0.2566\n",
      "Epoch [212/1000], Loss: 0.2571\n",
      "Epoch [213/1000], Loss: 0.2599\n",
      "Epoch [214/1000], Loss: 0.2590\n",
      "Epoch [215/1000], Loss: 0.2575\n",
      "Epoch [216/1000], Loss: 0.2572\n",
      "Epoch [217/1000], Loss: 0.2575\n",
      "Epoch [218/1000], Loss: 0.2581\n",
      "Epoch [219/1000], Loss: 0.2595\n",
      "Epoch [220/1000], Loss: 0.2580\n",
      "Epoch [221/1000], Loss: 0.2586\n",
      "Epoch [222/1000], Loss: 0.2555\n",
      "Epoch [223/1000], Loss: 0.2586\n",
      "Epoch [224/1000], Loss: 0.2597\n",
      "Epoch [225/1000], Loss: 0.2564\n",
      "Epoch [226/1000], Loss: 0.2592\n",
      "Epoch [227/1000], Loss: 0.2574\n",
      "Epoch [228/1000], Loss: 0.2599\n",
      "Epoch [229/1000], Loss: 0.2570\n",
      "Epoch [230/1000], Loss: 0.2563\n",
      "Epoch [231/1000], Loss: 0.2581\n",
      "Epoch [232/1000], Loss: 0.2590\n",
      "Epoch [233/1000], Loss: 0.2590\n",
      "Epoch [234/1000], Loss: 0.2585\n",
      "Epoch [235/1000], Loss: 0.2585\n",
      "Epoch [236/1000], Loss: 0.2593\n",
      "Epoch [237/1000], Loss: 0.2576\n",
      "Epoch [238/1000], Loss: 0.2580\n",
      "Epoch [239/1000], Loss: 0.2602\n",
      "Epoch [240/1000], Loss: 0.2604\n",
      "Epoch [241/1000], Loss: 0.2584\n",
      "Epoch [242/1000], Loss: 0.2614\n",
      "Epoch [243/1000], Loss: 0.2583\n",
      "Epoch [244/1000], Loss: 0.2563\n",
      "Epoch [245/1000], Loss: 0.2584\n",
      "Epoch [246/1000], Loss: 0.2581\n",
      "Epoch [247/1000], Loss: 0.2567\n",
      "Epoch [248/1000], Loss: 0.2594\n",
      "Epoch [249/1000], Loss: 0.2574\n",
      "Epoch [250/1000], Loss: 0.2596\n",
      "Epoch [251/1000], Loss: 0.2560\n",
      "Epoch [252/1000], Loss: 0.2583\n",
      "Epoch [253/1000], Loss: 0.2609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [254/1000], Loss: 0.2588\n",
      "Epoch [255/1000], Loss: 0.2606\n",
      "Epoch [256/1000], Loss: 0.2601\n",
      "Epoch [257/1000], Loss: 0.2576\n",
      "Epoch [258/1000], Loss: 0.2597\n",
      "Epoch [259/1000], Loss: 0.2590\n",
      "Epoch [260/1000], Loss: 0.2576\n",
      "Epoch [261/1000], Loss: 0.2583\n",
      "Epoch [262/1000], Loss: 0.2593\n",
      "Epoch [263/1000], Loss: 0.2568\n",
      "Epoch [264/1000], Loss: 0.2589\n",
      "Epoch [265/1000], Loss: 0.2583\n",
      "Epoch [266/1000], Loss: 0.2570\n",
      "Epoch [267/1000], Loss: 0.2581\n",
      "Epoch [268/1000], Loss: 0.2591\n",
      "Epoch [269/1000], Loss: 0.2567\n",
      "Epoch [270/1000], Loss: 0.2606\n",
      "Epoch [271/1000], Loss: 0.2592\n",
      "Epoch [272/1000], Loss: 0.2567\n",
      "Epoch [273/1000], Loss: 0.2578\n",
      "Epoch [274/1000], Loss: 0.2564\n",
      "Epoch [275/1000], Loss: 0.2593\n",
      "Epoch [276/1000], Loss: 0.2563\n",
      "Epoch [277/1000], Loss: 0.2576\n",
      "Epoch [278/1000], Loss: 0.2575\n",
      "Epoch [279/1000], Loss: 0.2624\n",
      "Epoch [280/1000], Loss: 0.2566\n",
      "Epoch [281/1000], Loss: 0.2579\n",
      "Epoch [282/1000], Loss: 0.2582\n",
      "Epoch [283/1000], Loss: 0.2561\n",
      "Epoch [284/1000], Loss: 0.2569\n",
      "Epoch [285/1000], Loss: 0.2582\n",
      "Epoch [286/1000], Loss: 0.2598\n",
      "Epoch [287/1000], Loss: 0.2609\n",
      "Epoch [288/1000], Loss: 0.2556\n",
      "Epoch [289/1000], Loss: 0.2588\n",
      "Epoch [290/1000], Loss: 0.2605\n",
      "Epoch [291/1000], Loss: 0.2556\n",
      "Epoch [292/1000], Loss: 0.2585\n",
      "Epoch [293/1000], Loss: 0.2599\n",
      "Epoch [294/1000], Loss: 0.2572\n",
      "Epoch [295/1000], Loss: 0.2563\n",
      "Epoch [296/1000], Loss: 0.2590\n",
      "Epoch [297/1000], Loss: 0.2590\n",
      "Epoch [298/1000], Loss: 0.2567\n",
      "Epoch [299/1000], Loss: 0.2597\n",
      "Epoch [300/1000], Loss: 0.2595\n",
      "Epoch [301/1000], Loss: 0.2579\n",
      "Epoch [302/1000], Loss: 0.2570\n",
      "Epoch [303/1000], Loss: 0.2572\n",
      "Epoch [304/1000], Loss: 0.2552\n",
      "Epoch [305/1000], Loss: 0.2582\n",
      "Epoch [306/1000], Loss: 0.2583\n",
      "Epoch [307/1000], Loss: 0.2562\n",
      "Epoch [308/1000], Loss: 0.2557\n",
      "Epoch [309/1000], Loss: 0.2580\n",
      "Epoch [310/1000], Loss: 0.2575\n",
      "Epoch [311/1000], Loss: 0.2597\n",
      "Epoch [312/1000], Loss: 0.2585\n",
      "Epoch [313/1000], Loss: 0.2571\n",
      "Epoch [314/1000], Loss: 0.2581\n",
      "Epoch [315/1000], Loss: 0.2572\n",
      "Epoch [316/1000], Loss: 0.2576\n",
      "Epoch [317/1000], Loss: 0.2591\n",
      "Epoch [318/1000], Loss: 0.2597\n",
      "Epoch [319/1000], Loss: 0.2573\n",
      "Epoch [320/1000], Loss: 0.2591\n",
      "Epoch [321/1000], Loss: 0.2595\n",
      "Epoch [322/1000], Loss: 0.2609\n",
      "Epoch [323/1000], Loss: 0.2605\n",
      "Epoch [324/1000], Loss: 0.2563\n",
      "Epoch [325/1000], Loss: 0.2580\n",
      "Epoch [326/1000], Loss: 0.2580\n",
      "Epoch [327/1000], Loss: 0.2586\n",
      "Epoch [328/1000], Loss: 0.2592\n",
      "Epoch [329/1000], Loss: 0.2600\n",
      "Epoch [330/1000], Loss: 0.2569\n",
      "Epoch [331/1000], Loss: 0.2566\n",
      "Epoch [332/1000], Loss: 0.2568\n",
      "Epoch [333/1000], Loss: 0.2572\n",
      "Epoch [334/1000], Loss: 0.2574\n",
      "Epoch [335/1000], Loss: 0.2577\n",
      "Epoch [336/1000], Loss: 0.2577\n",
      "Epoch [337/1000], Loss: 0.2577\n",
      "Epoch [338/1000], Loss: 0.2592\n",
      "Epoch [339/1000], Loss: 0.2569\n",
      "Epoch [340/1000], Loss: 0.2568\n",
      "Epoch [341/1000], Loss: 0.2585\n",
      "Epoch [342/1000], Loss: 0.2589\n",
      "Epoch [343/1000], Loss: 0.2574\n",
      "Epoch [344/1000], Loss: 0.2583\n",
      "Epoch [345/1000], Loss: 0.2577\n",
      "Epoch [346/1000], Loss: 0.2593\n",
      "Epoch [347/1000], Loss: 0.2592\n",
      "Epoch [348/1000], Loss: 0.2614\n",
      "Epoch [349/1000], Loss: 0.2545\n",
      "Epoch [350/1000], Loss: 0.2580\n",
      "Epoch [351/1000], Loss: 0.2574\n",
      "Epoch [352/1000], Loss: 0.2611\n",
      "Epoch [353/1000], Loss: 0.2598\n",
      "Epoch [354/1000], Loss: 0.2574\n",
      "Epoch [355/1000], Loss: 0.2585\n",
      "Epoch [356/1000], Loss: 0.2581\n",
      "Epoch [357/1000], Loss: 0.2583\n",
      "Epoch [358/1000], Loss: 0.2602\n",
      "Epoch [359/1000], Loss: 0.2610\n",
      "Epoch [360/1000], Loss: 0.2586\n",
      "Epoch [361/1000], Loss: 0.2587\n",
      "Epoch [362/1000], Loss: 0.2574\n",
      "Epoch [363/1000], Loss: 0.2575\n",
      "Epoch [364/1000], Loss: 0.2568\n",
      "Epoch [365/1000], Loss: 0.2628\n",
      "Epoch [366/1000], Loss: 0.2577\n",
      "Epoch [367/1000], Loss: 0.2571\n",
      "Epoch [368/1000], Loss: 0.2613\n",
      "Epoch [369/1000], Loss: 0.2566\n",
      "Epoch [370/1000], Loss: 0.2571\n",
      "Epoch [371/1000], Loss: 0.2558\n",
      "Epoch [372/1000], Loss: 0.2572\n",
      "Epoch [373/1000], Loss: 0.2574\n",
      "Epoch [374/1000], Loss: 0.2556\n",
      "Epoch [375/1000], Loss: 0.2566\n",
      "Epoch [376/1000], Loss: 0.2552\n",
      "Epoch [377/1000], Loss: 0.2591\n",
      "Epoch [378/1000], Loss: 0.2566\n",
      "Epoch [379/1000], Loss: 0.2580\n",
      "Epoch [380/1000], Loss: 0.2610\n",
      "Epoch [381/1000], Loss: 0.2577\n",
      "Epoch [382/1000], Loss: 0.2570\n",
      "Epoch [383/1000], Loss: 0.2567\n",
      "Epoch [384/1000], Loss: 0.2563\n",
      "Epoch [385/1000], Loss: 0.2588\n",
      "Epoch [386/1000], Loss: 0.2558\n",
      "Epoch [387/1000], Loss: 0.2604\n",
      "Epoch [388/1000], Loss: 0.2566\n",
      "Epoch [389/1000], Loss: 0.2573\n",
      "Epoch [390/1000], Loss: 0.2561\n",
      "Epoch [391/1000], Loss: 0.2559\n",
      "Epoch [392/1000], Loss: 0.2614\n",
      "Epoch [393/1000], Loss: 0.2581\n",
      "Epoch [394/1000], Loss: 0.2566\n",
      "Epoch [395/1000], Loss: 0.2599\n",
      "Epoch [396/1000], Loss: 0.2574\n",
      "Epoch [397/1000], Loss: 0.2637\n",
      "Epoch [398/1000], Loss: 0.2574\n",
      "Epoch [399/1000], Loss: 0.2575\n",
      "Epoch [400/1000], Loss: 0.2581\n",
      "Epoch [401/1000], Loss: 0.2573\n",
      "Epoch [402/1000], Loss: 0.2576\n",
      "Epoch [403/1000], Loss: 0.2580\n",
      "Epoch [404/1000], Loss: 0.2592\n",
      "Epoch [405/1000], Loss: 0.2587\n",
      "Epoch [406/1000], Loss: 0.2586\n",
      "Epoch [407/1000], Loss: 0.2576\n",
      "Epoch [408/1000], Loss: 0.2571\n",
      "Epoch [409/1000], Loss: 0.2567\n",
      "Epoch [410/1000], Loss: 0.2581\n",
      "Epoch [411/1000], Loss: 0.2607\n",
      "Epoch [412/1000], Loss: 0.2567\n",
      "Epoch [413/1000], Loss: 0.2583\n",
      "Epoch [414/1000], Loss: 0.2580\n",
      "Epoch [415/1000], Loss: 0.2563\n",
      "Epoch [416/1000], Loss: 0.2557\n",
      "Epoch [417/1000], Loss: 0.2594\n",
      "Epoch [418/1000], Loss: 0.2581\n",
      "Epoch [419/1000], Loss: 0.2565\n",
      "Epoch [420/1000], Loss: 0.2572\n",
      "Epoch [421/1000], Loss: 0.2569\n",
      "Epoch [422/1000], Loss: 0.2573\n",
      "Epoch [423/1000], Loss: 0.2589\n",
      "Epoch [424/1000], Loss: 0.2582\n",
      "Epoch [425/1000], Loss: 0.2589\n",
      "Epoch [426/1000], Loss: 0.2581\n",
      "Epoch [427/1000], Loss: 0.2570\n",
      "Epoch [428/1000], Loss: 0.2577\n",
      "Epoch [429/1000], Loss: 0.2589\n",
      "Epoch [430/1000], Loss: 0.2582\n",
      "Epoch [431/1000], Loss: 0.2575\n",
      "Epoch [432/1000], Loss: 0.2581\n",
      "Epoch [433/1000], Loss: 0.2603\n",
      "Epoch [434/1000], Loss: 0.2604\n",
      "Epoch [435/1000], Loss: 0.2564\n",
      "Epoch [436/1000], Loss: 0.2557\n",
      "Epoch [437/1000], Loss: 0.2575\n",
      "Epoch [438/1000], Loss: 0.2572\n",
      "Epoch [439/1000], Loss: 0.2577\n",
      "Epoch [440/1000], Loss: 0.2564\n",
      "Epoch [441/1000], Loss: 0.2562\n",
      "Epoch [442/1000], Loss: 0.2563\n",
      "Epoch [443/1000], Loss: 0.2586\n",
      "Epoch [444/1000], Loss: 0.2571\n",
      "Epoch [445/1000], Loss: 0.2582\n",
      "Epoch [446/1000], Loss: 0.2570\n",
      "Epoch [447/1000], Loss: 0.2578\n",
      "Epoch [448/1000], Loss: 0.2596\n",
      "Epoch [449/1000], Loss: 0.2592\n",
      "Epoch [450/1000], Loss: 0.2594\n",
      "Epoch [451/1000], Loss: 0.2575\n",
      "Epoch [452/1000], Loss: 0.2564\n",
      "Epoch [453/1000], Loss: 0.2568\n",
      "Epoch [454/1000], Loss: 0.2584\n",
      "Epoch [455/1000], Loss: 0.2587\n",
      "Epoch [456/1000], Loss: 0.2560\n",
      "Epoch [457/1000], Loss: 0.2549\n",
      "Epoch [458/1000], Loss: 0.2567\n",
      "Epoch [459/1000], Loss: 0.2565\n",
      "Epoch [460/1000], Loss: 0.2574\n",
      "Epoch [461/1000], Loss: 0.2578\n",
      "Epoch [462/1000], Loss: 0.2581\n",
      "Epoch [463/1000], Loss: 0.2578\n",
      "Epoch [464/1000], Loss: 0.2580\n",
      "Epoch [465/1000], Loss: 0.2573\n",
      "Epoch [466/1000], Loss: 0.2565\n",
      "Epoch [467/1000], Loss: 0.2569\n",
      "Epoch [468/1000], Loss: 0.2606\n",
      "Epoch [469/1000], Loss: 0.2623\n",
      "Epoch [470/1000], Loss: 0.2575\n",
      "Epoch [471/1000], Loss: 0.2579\n",
      "Epoch [472/1000], Loss: 0.2575\n",
      "Epoch [473/1000], Loss: 0.2581\n",
      "Epoch [474/1000], Loss: 0.2576\n",
      "Epoch [475/1000], Loss: 0.2603\n",
      "Epoch [476/1000], Loss: 0.2567\n",
      "Epoch [477/1000], Loss: 0.2598\n",
      "Epoch [478/1000], Loss: 0.2593\n",
      "Epoch [479/1000], Loss: 0.2634\n",
      "Epoch [480/1000], Loss: 0.2566\n",
      "Epoch [481/1000], Loss: 0.2583\n",
      "Epoch [482/1000], Loss: 0.2570\n",
      "Epoch [483/1000], Loss: 0.2592\n",
      "Epoch [484/1000], Loss: 0.2601\n",
      "Epoch [485/1000], Loss: 0.2561\n",
      "Epoch [486/1000], Loss: 0.2596\n",
      "Epoch [487/1000], Loss: 0.2567\n",
      "Epoch [488/1000], Loss: 0.2630\n",
      "Epoch [489/1000], Loss: 0.2573\n",
      "Epoch [490/1000], Loss: 0.2589\n",
      "Epoch [491/1000], Loss: 0.2578\n",
      "Epoch [492/1000], Loss: 0.2585\n",
      "Epoch [493/1000], Loss: 0.2603\n",
      "Epoch [494/1000], Loss: 0.2582\n",
      "Epoch [495/1000], Loss: 0.2562\n",
      "Epoch [496/1000], Loss: 0.2573\n",
      "Epoch [497/1000], Loss: 0.2589\n",
      "Epoch [498/1000], Loss: 0.2564\n",
      "Epoch [499/1000], Loss: 0.2591\n",
      "Epoch [500/1000], Loss: 0.2584\n",
      "Epoch [501/1000], Loss: 0.2559\n",
      "Epoch [502/1000], Loss: 0.2589\n",
      "Epoch [503/1000], Loss: 0.2572\n",
      "Epoch [504/1000], Loss: 0.2597\n",
      "Epoch [505/1000], Loss: 0.2566\n",
      "Epoch [506/1000], Loss: 0.2570\n",
      "Epoch [507/1000], Loss: 0.2593\n",
      "Epoch [508/1000], Loss: 0.2616\n",
      "Epoch [509/1000], Loss: 0.2607\n",
      "Epoch [510/1000], Loss: 0.2573\n",
      "Epoch [511/1000], Loss: 0.2608\n",
      "Epoch [512/1000], Loss: 0.2584\n",
      "Epoch [513/1000], Loss: 0.2558\n",
      "Epoch [514/1000], Loss: 0.2557\n",
      "Epoch [515/1000], Loss: 0.2561\n",
      "Epoch [516/1000], Loss: 0.2585\n",
      "Epoch [517/1000], Loss: 0.2599\n",
      "Epoch [518/1000], Loss: 0.2587\n",
      "Epoch [519/1000], Loss: 0.2586\n",
      "Epoch [520/1000], Loss: 0.2592\n",
      "Epoch [521/1000], Loss: 0.2580\n",
      "Epoch [522/1000], Loss: 0.2570\n",
      "Epoch [523/1000], Loss: 0.2553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [524/1000], Loss: 0.2571\n",
      "Epoch [525/1000], Loss: 0.2565\n",
      "Epoch [526/1000], Loss: 0.2598\n",
      "Epoch [527/1000], Loss: 0.2596\n",
      "Epoch [528/1000], Loss: 0.2604\n",
      "Epoch [529/1000], Loss: 0.2561\n",
      "Epoch [530/1000], Loss: 0.2564\n",
      "Epoch [531/1000], Loss: 0.2566\n",
      "Epoch [532/1000], Loss: 0.2574\n",
      "Epoch [533/1000], Loss: 0.2580\n",
      "Epoch [534/1000], Loss: 0.2598\n",
      "Epoch [535/1000], Loss: 0.2560\n",
      "Epoch [536/1000], Loss: 0.2585\n",
      "Epoch [537/1000], Loss: 0.2588\n",
      "Epoch [538/1000], Loss: 0.2579\n",
      "Epoch [539/1000], Loss: 0.2567\n",
      "Epoch [540/1000], Loss: 0.2587\n",
      "Epoch [541/1000], Loss: 0.2607\n",
      "Epoch [542/1000], Loss: 0.2584\n",
      "Epoch [543/1000], Loss: 0.2578\n",
      "Epoch [544/1000], Loss: 0.2597\n",
      "Epoch [545/1000], Loss: 0.2592\n",
      "Epoch [546/1000], Loss: 0.2589\n",
      "Epoch [547/1000], Loss: 0.2609\n",
      "Epoch [548/1000], Loss: 0.2561\n",
      "Epoch [549/1000], Loss: 0.2592\n",
      "Epoch [550/1000], Loss: 0.2575\n",
      "Epoch [551/1000], Loss: 0.2610\n",
      "Epoch [552/1000], Loss: 0.2584\n",
      "Epoch [553/1000], Loss: 0.2574\n",
      "Epoch [554/1000], Loss: 0.2591\n",
      "Epoch [555/1000], Loss: 0.2582\n",
      "Epoch [556/1000], Loss: 0.2588\n",
      "Epoch [557/1000], Loss: 0.2555\n",
      "Epoch [558/1000], Loss: 0.2562\n",
      "Epoch [559/1000], Loss: 0.2570\n",
      "Epoch [560/1000], Loss: 0.2583\n",
      "Epoch [561/1000], Loss: 0.2581\n",
      "Epoch [562/1000], Loss: 0.2564\n",
      "Epoch [563/1000], Loss: 0.2564\n",
      "Epoch [564/1000], Loss: 0.2589\n",
      "Epoch [565/1000], Loss: 0.2566\n",
      "Epoch [566/1000], Loss: 0.2559\n",
      "Epoch [567/1000], Loss: 0.2584\n",
      "Epoch [568/1000], Loss: 0.2588\n",
      "Epoch [569/1000], Loss: 0.2601\n",
      "Epoch [570/1000], Loss: 0.2569\n",
      "Epoch [571/1000], Loss: 0.2575\n",
      "Epoch [572/1000], Loss: 0.2588\n",
      "Epoch [573/1000], Loss: 0.2570\n",
      "Epoch [574/1000], Loss: 0.2555\n",
      "Epoch [575/1000], Loss: 0.2570\n",
      "Epoch [576/1000], Loss: 0.2580\n",
      "Epoch [577/1000], Loss: 0.2559\n",
      "Epoch [578/1000], Loss: 0.2566\n",
      "Epoch [579/1000], Loss: 0.2612\n",
      "Epoch [580/1000], Loss: 0.2568\n",
      "Epoch [581/1000], Loss: 0.2569\n",
      "Epoch [582/1000], Loss: 0.2600\n",
      "Epoch [583/1000], Loss: 0.2558\n",
      "Epoch [584/1000], Loss: 0.2576\n",
      "Epoch [585/1000], Loss: 0.2560\n",
      "Epoch [586/1000], Loss: 0.2575\n",
      "Epoch [587/1000], Loss: 0.2564\n",
      "Epoch [588/1000], Loss: 0.2605\n",
      "Epoch [589/1000], Loss: 0.2611\n",
      "Epoch [590/1000], Loss: 0.2573\n",
      "Epoch [591/1000], Loss: 0.2585\n",
      "Epoch [592/1000], Loss: 0.2571\n",
      "Epoch [593/1000], Loss: 0.2563\n",
      "Epoch [594/1000], Loss: 0.2572\n",
      "Epoch [595/1000], Loss: 0.2607\n",
      "Epoch [596/1000], Loss: 0.2585\n",
      "Epoch [597/1000], Loss: 0.2586\n",
      "Epoch [598/1000], Loss: 0.2562\n",
      "Epoch [599/1000], Loss: 0.2575\n",
      "Epoch [600/1000], Loss: 0.2561\n",
      "Epoch [601/1000], Loss: 0.2578\n",
      "Epoch [602/1000], Loss: 0.2559\n",
      "Epoch [603/1000], Loss: 0.2562\n",
      "Epoch [604/1000], Loss: 0.2581\n",
      "Epoch [605/1000], Loss: 0.2559\n",
      "Epoch [606/1000], Loss: 0.2566\n",
      "Epoch [607/1000], Loss: 0.2588\n",
      "Epoch [608/1000], Loss: 0.2582\n",
      "Epoch [609/1000], Loss: 0.2620\n",
      "Epoch [610/1000], Loss: 0.2581\n",
      "Epoch [611/1000], Loss: 0.2568\n",
      "Epoch [612/1000], Loss: 0.2582\n",
      "Epoch [613/1000], Loss: 0.2565\n",
      "Epoch [614/1000], Loss: 0.2578\n",
      "Epoch [615/1000], Loss: 0.2584\n",
      "Epoch [616/1000], Loss: 0.2597\n",
      "Epoch [617/1000], Loss: 0.2575\n",
      "Epoch [618/1000], Loss: 0.2583\n",
      "Epoch [619/1000], Loss: 0.2565\n",
      "Epoch [620/1000], Loss: 0.2560\n",
      "Epoch [621/1000], Loss: 0.2583\n",
      "Epoch [622/1000], Loss: 0.2581\n",
      "Epoch [623/1000], Loss: 0.2572\n",
      "Epoch [624/1000], Loss: 0.2565\n",
      "Epoch [625/1000], Loss: 0.2565\n",
      "Epoch [626/1000], Loss: 0.2581\n",
      "Epoch [627/1000], Loss: 0.2580\n",
      "Epoch [628/1000], Loss: 0.2605\n",
      "Epoch [629/1000], Loss: 0.2596\n",
      "Epoch [630/1000], Loss: 0.2566\n",
      "Epoch [631/1000], Loss: 0.2581\n",
      "Epoch [632/1000], Loss: 0.2576\n",
      "Epoch [633/1000], Loss: 0.2583\n",
      "Epoch [634/1000], Loss: 0.2565\n",
      "Epoch [635/1000], Loss: 0.2595\n",
      "Epoch [636/1000], Loss: 0.2559\n",
      "Epoch [637/1000], Loss: 0.2562\n",
      "Epoch [638/1000], Loss: 0.2571\n",
      "Epoch [639/1000], Loss: 0.2597\n",
      "Epoch [640/1000], Loss: 0.2576\n",
      "Epoch [641/1000], Loss: 0.2608\n",
      "Epoch [642/1000], Loss: 0.2581\n",
      "Epoch [643/1000], Loss: 0.2590\n",
      "Epoch [644/1000], Loss: 0.2558\n",
      "Epoch [645/1000], Loss: 0.2560\n",
      "Epoch [646/1000], Loss: 0.2597\n",
      "Epoch [647/1000], Loss: 0.2576\n",
      "Epoch [648/1000], Loss: 0.2570\n",
      "Epoch [649/1000], Loss: 0.2578\n",
      "Epoch [650/1000], Loss: 0.2584\n",
      "Epoch [651/1000], Loss: 0.2617\n",
      "Epoch [652/1000], Loss: 0.2582\n",
      "Epoch [653/1000], Loss: 0.2592\n",
      "Epoch [654/1000], Loss: 0.2580\n",
      "Epoch [655/1000], Loss: 0.2576\n",
      "Epoch [656/1000], Loss: 0.2583\n",
      "Epoch [657/1000], Loss: 0.2552\n",
      "Epoch [658/1000], Loss: 0.2590\n",
      "Epoch [659/1000], Loss: 0.2576\n",
      "Epoch [660/1000], Loss: 0.2580\n",
      "Epoch [661/1000], Loss: 0.2577\n",
      "Epoch [662/1000], Loss: 0.2576\n",
      "Epoch [663/1000], Loss: 0.2575\n",
      "Epoch [664/1000], Loss: 0.2596\n",
      "Epoch [665/1000], Loss: 0.2584\n",
      "Epoch [666/1000], Loss: 0.2576\n",
      "Epoch [667/1000], Loss: 0.2569\n",
      "Epoch [668/1000], Loss: 0.2566\n",
      "Epoch [669/1000], Loss: 0.2590\n",
      "Epoch [670/1000], Loss: 0.2588\n",
      "Epoch [671/1000], Loss: 0.2553\n",
      "Epoch [672/1000], Loss: 0.2598\n",
      "Epoch [673/1000], Loss: 0.2561\n",
      "Epoch [674/1000], Loss: 0.2589\n",
      "Epoch [675/1000], Loss: 0.2582\n",
      "Epoch [676/1000], Loss: 0.2584\n",
      "Epoch [677/1000], Loss: 0.2597\n",
      "Epoch [678/1000], Loss: 0.2579\n",
      "Epoch [679/1000], Loss: 0.2582\n",
      "Epoch [680/1000], Loss: 0.2575\n",
      "Epoch [681/1000], Loss: 0.2574\n",
      "Epoch [682/1000], Loss: 0.2584\n",
      "Epoch [683/1000], Loss: 0.2567\n",
      "Epoch [684/1000], Loss: 0.2557\n",
      "Epoch [685/1000], Loss: 0.2569\n",
      "Epoch [686/1000], Loss: 0.2588\n",
      "Epoch [687/1000], Loss: 0.2566\n",
      "Epoch [688/1000], Loss: 0.2563\n",
      "Epoch [689/1000], Loss: 0.2561\n",
      "Epoch [690/1000], Loss: 0.2583\n",
      "Epoch [691/1000], Loss: 0.2587\n",
      "Epoch [692/1000], Loss: 0.2608\n",
      "Epoch [693/1000], Loss: 0.2554\n",
      "Epoch [694/1000], Loss: 0.2591\n",
      "Epoch [695/1000], Loss: 0.2574\n",
      "Epoch [696/1000], Loss: 0.2587\n",
      "Epoch [697/1000], Loss: 0.2585\n",
      "Epoch [698/1000], Loss: 0.2583\n",
      "Epoch [699/1000], Loss: 0.2575\n",
      "Epoch [700/1000], Loss: 0.2559\n",
      "Epoch [701/1000], Loss: 0.2569\n",
      "Epoch [702/1000], Loss: 0.2578\n",
      "Epoch [703/1000], Loss: 0.2579\n",
      "Epoch [704/1000], Loss: 0.2587\n",
      "Epoch [705/1000], Loss: 0.2591\n",
      "Epoch [706/1000], Loss: 0.2559\n",
      "Epoch [707/1000], Loss: 0.2576\n",
      "Epoch [708/1000], Loss: 0.2572\n",
      "Epoch [709/1000], Loss: 0.2572\n",
      "Epoch [710/1000], Loss: 0.2571\n",
      "Epoch [711/1000], Loss: 0.2606\n",
      "Epoch [712/1000], Loss: 0.2561\n",
      "Epoch [713/1000], Loss: 0.2580\n",
      "Epoch [714/1000], Loss: 0.2559\n",
      "Epoch [715/1000], Loss: 0.2575\n",
      "Epoch [716/1000], Loss: 0.2586\n",
      "Epoch [717/1000], Loss: 0.2577\n",
      "Epoch [718/1000], Loss: 0.2570\n",
      "Epoch [719/1000], Loss: 0.2570\n",
      "Epoch [720/1000], Loss: 0.2573\n",
      "Epoch [721/1000], Loss: 0.2583\n",
      "Epoch [722/1000], Loss: 0.2570\n",
      "Epoch [723/1000], Loss: 0.2575\n",
      "Epoch [724/1000], Loss: 0.2591\n",
      "Epoch [725/1000], Loss: 0.2568\n",
      "Epoch [726/1000], Loss: 0.2570\n",
      "Epoch [727/1000], Loss: 0.2582\n",
      "Epoch [728/1000], Loss: 0.2595\n",
      "Epoch [729/1000], Loss: 0.2576\n",
      "Epoch [730/1000], Loss: 0.2592\n",
      "Epoch [731/1000], Loss: 0.2555\n",
      "Epoch [732/1000], Loss: 0.2575\n",
      "Epoch [733/1000], Loss: 0.2557\n",
      "Epoch [734/1000], Loss: 0.2564\n",
      "Epoch [735/1000], Loss: 0.2584\n",
      "Epoch [736/1000], Loss: 0.2578\n",
      "Epoch [737/1000], Loss: 0.2576\n",
      "Epoch [738/1000], Loss: 0.2573\n",
      "Epoch [739/1000], Loss: 0.2611\n",
      "Epoch [740/1000], Loss: 0.2556\n",
      "Epoch [741/1000], Loss: 0.2586\n",
      "Epoch [742/1000], Loss: 0.2591\n",
      "Epoch [743/1000], Loss: 0.2595\n",
      "Epoch [744/1000], Loss: 0.2565\n",
      "Epoch [745/1000], Loss: 0.2570\n",
      "Epoch [746/1000], Loss: 0.2595\n",
      "Epoch [747/1000], Loss: 0.2572\n",
      "Epoch [748/1000], Loss: 0.2570\n",
      "Epoch [749/1000], Loss: 0.2585\n",
      "Epoch [750/1000], Loss: 0.2621\n",
      "Epoch [751/1000], Loss: 0.2594\n",
      "Epoch [752/1000], Loss: 0.2598\n",
      "Epoch [753/1000], Loss: 0.2595\n",
      "Epoch [754/1000], Loss: 0.2571\n",
      "Epoch [755/1000], Loss: 0.2588\n",
      "Epoch [756/1000], Loss: 0.2607\n",
      "Epoch [757/1000], Loss: 0.2591\n",
      "Epoch [758/1000], Loss: 0.2562\n",
      "Epoch [759/1000], Loss: 0.2584\n",
      "Epoch [760/1000], Loss: 0.2569\n",
      "Epoch [761/1000], Loss: 0.2573\n",
      "Epoch [762/1000], Loss: 0.2567\n",
      "Epoch [763/1000], Loss: 0.2581\n",
      "Epoch [764/1000], Loss: 0.2580\n",
      "Epoch [765/1000], Loss: 0.2587\n",
      "Epoch [766/1000], Loss: 0.2598\n",
      "Epoch [767/1000], Loss: 0.2590\n",
      "Epoch [768/1000], Loss: 0.2596\n",
      "Epoch [769/1000], Loss: 0.2580\n",
      "Epoch [770/1000], Loss: 0.2568\n",
      "Epoch [771/1000], Loss: 0.2585\n",
      "Epoch [772/1000], Loss: 0.2584\n",
      "Epoch [773/1000], Loss: 0.2581\n",
      "Epoch [774/1000], Loss: 0.2588\n",
      "Epoch [775/1000], Loss: 0.2560\n",
      "Epoch [776/1000], Loss: 0.2588\n",
      "Epoch [777/1000], Loss: 0.2592\n",
      "Epoch [778/1000], Loss: 0.2575\n",
      "Epoch [779/1000], Loss: 0.2579\n",
      "Epoch [780/1000], Loss: 0.2569\n",
      "Epoch [781/1000], Loss: 0.2556\n",
      "Epoch [782/1000], Loss: 0.2607\n",
      "Epoch [783/1000], Loss: 0.2588\n",
      "Epoch [784/1000], Loss: 0.2554\n",
      "Epoch [785/1000], Loss: 0.2580\n",
      "Epoch [786/1000], Loss: 0.2598\n",
      "Epoch [787/1000], Loss: 0.2569\n",
      "Epoch [788/1000], Loss: 0.2566\n",
      "Epoch [789/1000], Loss: 0.2574\n",
      "Epoch [790/1000], Loss: 0.2580\n",
      "Epoch [791/1000], Loss: 0.2560\n",
      "Epoch [792/1000], Loss: 0.2581\n",
      "Epoch [793/1000], Loss: 0.2616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [794/1000], Loss: 0.2570\n",
      "Epoch [795/1000], Loss: 0.2581\n",
      "Epoch [796/1000], Loss: 0.2594\n",
      "Epoch [797/1000], Loss: 0.2579\n",
      "Epoch [798/1000], Loss: 0.2564\n",
      "Epoch [799/1000], Loss: 0.2560\n",
      "Epoch [800/1000], Loss: 0.2589\n",
      "Epoch [801/1000], Loss: 0.2581\n",
      "Epoch [802/1000], Loss: 0.2584\n",
      "Epoch [803/1000], Loss: 0.2595\n",
      "Epoch [804/1000], Loss: 0.2566\n",
      "Epoch [805/1000], Loss: 0.2577\n",
      "Epoch [806/1000], Loss: 0.2575\n",
      "Epoch [807/1000], Loss: 0.2575\n",
      "Epoch [808/1000], Loss: 0.2564\n",
      "Epoch [809/1000], Loss: 0.2572\n",
      "Epoch [810/1000], Loss: 0.2567\n",
      "Epoch [811/1000], Loss: 0.2579\n",
      "Epoch [812/1000], Loss: 0.2581\n",
      "Epoch [813/1000], Loss: 0.2579\n",
      "Epoch [814/1000], Loss: 0.2595\n",
      "Epoch [815/1000], Loss: 0.2582\n",
      "Epoch [816/1000], Loss: 0.2587\n",
      "Epoch [817/1000], Loss: 0.2563\n",
      "Epoch [818/1000], Loss: 0.2579\n",
      "Epoch [819/1000], Loss: 0.2568\n",
      "Epoch [820/1000], Loss: 0.2593\n",
      "Epoch [821/1000], Loss: 0.2600\n",
      "Epoch [822/1000], Loss: 0.2570\n",
      "Epoch [823/1000], Loss: 0.2596\n",
      "Epoch [824/1000], Loss: 0.2564\n",
      "Epoch [825/1000], Loss: 0.2595\n",
      "Epoch [826/1000], Loss: 0.2570\n",
      "Epoch [827/1000], Loss: 0.2594\n",
      "Epoch [828/1000], Loss: 0.2572\n",
      "Epoch [829/1000], Loss: 0.2567\n",
      "Epoch [830/1000], Loss: 0.2579\n",
      "Epoch [831/1000], Loss: 0.2594\n",
      "Epoch [832/1000], Loss: 0.2577\n",
      "Epoch [833/1000], Loss: 0.2596\n",
      "Epoch [834/1000], Loss: 0.2572\n",
      "Epoch [835/1000], Loss: 0.2569\n",
      "Epoch [836/1000], Loss: 0.2568\n",
      "Epoch [837/1000], Loss: 0.2583\n",
      "Epoch [838/1000], Loss: 0.2564\n",
      "Epoch [839/1000], Loss: 0.2589\n",
      "Epoch [840/1000], Loss: 0.2558\n",
      "Epoch [841/1000], Loss: 0.2569\n",
      "Epoch [842/1000], Loss: 0.2586\n",
      "Epoch [843/1000], Loss: 0.2576\n",
      "Epoch [844/1000], Loss: 0.2556\n",
      "Epoch [845/1000], Loss: 0.2589\n",
      "Epoch [846/1000], Loss: 0.2579\n",
      "Epoch [847/1000], Loss: 0.2575\n",
      "Epoch [848/1000], Loss: 0.2580\n",
      "Epoch [849/1000], Loss: 0.2561\n",
      "Epoch [850/1000], Loss: 0.2570\n",
      "Epoch [851/1000], Loss: 0.2587\n",
      "Epoch [852/1000], Loss: 0.2583\n",
      "Epoch [853/1000], Loss: 0.2555\n",
      "Epoch [854/1000], Loss: 0.2574\n",
      "Epoch [855/1000], Loss: 0.2571\n",
      "Epoch [856/1000], Loss: 0.2610\n",
      "Epoch [857/1000], Loss: 0.2555\n",
      "Epoch [858/1000], Loss: 0.2614\n",
      "Epoch [859/1000], Loss: 0.2577\n",
      "Epoch [860/1000], Loss: 0.2581\n",
      "Epoch [861/1000], Loss: 0.2580\n",
      "Epoch [862/1000], Loss: 0.2564\n",
      "Epoch [863/1000], Loss: 0.2574\n",
      "Epoch [864/1000], Loss: 0.2572\n",
      "Epoch [865/1000], Loss: 0.2622\n",
      "Epoch [866/1000], Loss: 0.2599\n",
      "Epoch [867/1000], Loss: 0.2572\n",
      "Epoch [868/1000], Loss: 0.2590\n",
      "Epoch [869/1000], Loss: 0.2553\n",
      "Epoch [870/1000], Loss: 0.2604\n",
      "Epoch [871/1000], Loss: 0.2594\n",
      "Epoch [872/1000], Loss: 0.2574\n",
      "Epoch [873/1000], Loss: 0.2576\n",
      "Epoch [874/1000], Loss: 0.2563\n",
      "Epoch [875/1000], Loss: 0.2564\n",
      "Epoch [876/1000], Loss: 0.2561\n",
      "Epoch [877/1000], Loss: 0.2584\n",
      "Epoch [878/1000], Loss: 0.2598\n",
      "Epoch [879/1000], Loss: 0.2565\n",
      "Epoch [880/1000], Loss: 0.2582\n",
      "Epoch [881/1000], Loss: 0.2579\n",
      "Epoch [882/1000], Loss: 0.2572\n",
      "Epoch [883/1000], Loss: 0.2572\n",
      "Epoch [884/1000], Loss: 0.2578\n",
      "Epoch [885/1000], Loss: 0.2607\n",
      "Epoch [886/1000], Loss: 0.2607\n",
      "Epoch [887/1000], Loss: 0.2594\n",
      "Epoch [888/1000], Loss: 0.2564\n",
      "Epoch [889/1000], Loss: 0.2565\n",
      "Epoch [890/1000], Loss: 0.2585\n",
      "Epoch [891/1000], Loss: 0.2602\n",
      "Epoch [892/1000], Loss: 0.2600\n",
      "Epoch [893/1000], Loss: 0.2575\n",
      "Epoch [894/1000], Loss: 0.2604\n",
      "Epoch [895/1000], Loss: 0.2597\n",
      "Epoch [896/1000], Loss: 0.2574\n",
      "Epoch [897/1000], Loss: 0.2598\n",
      "Epoch [898/1000], Loss: 0.2576\n",
      "Epoch [899/1000], Loss: 0.2612\n",
      "Epoch [900/1000], Loss: 0.2570\n",
      "Epoch [901/1000], Loss: 0.2560\n",
      "Epoch [902/1000], Loss: 0.2558\n",
      "Epoch [903/1000], Loss: 0.2561\n",
      "Epoch [904/1000], Loss: 0.2599\n",
      "Epoch [905/1000], Loss: 0.2593\n",
      "Epoch [906/1000], Loss: 0.2560\n",
      "Epoch [907/1000], Loss: 0.2604\n",
      "Epoch [908/1000], Loss: 0.2561\n",
      "Epoch [909/1000], Loss: 0.2578\n",
      "Epoch [910/1000], Loss: 0.2565\n",
      "Epoch [911/1000], Loss: 0.2601\n",
      "Epoch [912/1000], Loss: 0.2572\n",
      "Epoch [913/1000], Loss: 0.2585\n",
      "Epoch [914/1000], Loss: 0.2617\n",
      "Epoch [915/1000], Loss: 0.2555\n",
      "Epoch [916/1000], Loss: 0.2561\n",
      "Epoch [917/1000], Loss: 0.2574\n",
      "Epoch [918/1000], Loss: 0.2605\n",
      "Epoch [919/1000], Loss: 0.2577\n",
      "Epoch [920/1000], Loss: 0.2576\n",
      "Epoch [921/1000], Loss: 0.2575\n",
      "Epoch [922/1000], Loss: 0.2602\n",
      "Epoch [923/1000], Loss: 0.2586\n",
      "Epoch [924/1000], Loss: 0.2598\n",
      "Epoch [925/1000], Loss: 0.2566\n",
      "Epoch [926/1000], Loss: 0.2582\n",
      "Epoch [927/1000], Loss: 0.2585\n",
      "Epoch [928/1000], Loss: 0.2576\n",
      "Epoch [929/1000], Loss: 0.2611\n",
      "Epoch [930/1000], Loss: 0.2590\n",
      "Epoch [931/1000], Loss: 0.2587\n",
      "Epoch [932/1000], Loss: 0.2550\n",
      "Epoch [933/1000], Loss: 0.2570\n",
      "Epoch [934/1000], Loss: 0.2562\n",
      "Epoch [935/1000], Loss: 0.2607\n",
      "Epoch [936/1000], Loss: 0.2555\n",
      "Epoch [937/1000], Loss: 0.2579\n",
      "Epoch [938/1000], Loss: 0.2576\n",
      "Epoch [939/1000], Loss: 0.2550\n",
      "Epoch [940/1000], Loss: 0.2584\n",
      "Epoch [941/1000], Loss: 0.2574\n",
      "Epoch [942/1000], Loss: 0.2572\n",
      "Epoch [943/1000], Loss: 0.2580\n",
      "Epoch [944/1000], Loss: 0.2576\n",
      "Epoch [945/1000], Loss: 0.2613\n",
      "Epoch [946/1000], Loss: 0.2625\n",
      "Epoch [947/1000], Loss: 0.2562\n",
      "Epoch [948/1000], Loss: 0.2576\n",
      "Epoch [949/1000], Loss: 0.2574\n",
      "Epoch [950/1000], Loss: 0.2586\n",
      "Epoch [951/1000], Loss: 0.2570\n",
      "Epoch [952/1000], Loss: 0.2567\n",
      "Epoch [953/1000], Loss: 0.2573\n",
      "Epoch [954/1000], Loss: 0.2557\n",
      "Epoch [955/1000], Loss: 0.2586\n",
      "Epoch [956/1000], Loss: 0.2589\n",
      "Epoch [957/1000], Loss: 0.2598\n",
      "Epoch [958/1000], Loss: 0.2585\n",
      "Epoch [959/1000], Loss: 0.2579\n",
      "Epoch [960/1000], Loss: 0.2588\n",
      "Epoch [961/1000], Loss: 0.2575\n",
      "Epoch [962/1000], Loss: 0.2570\n",
      "Epoch [963/1000], Loss: 0.2580\n",
      "Epoch [964/1000], Loss: 0.2601\n",
      "Epoch [965/1000], Loss: 0.2561\n",
      "Epoch [966/1000], Loss: 0.2557\n",
      "Epoch [967/1000], Loss: 0.2569\n",
      "Epoch [968/1000], Loss: 0.2565\n",
      "Epoch [969/1000], Loss: 0.2596\n",
      "Epoch [970/1000], Loss: 0.2567\n",
      "Epoch [971/1000], Loss: 0.2563\n",
      "Epoch [972/1000], Loss: 0.2584\n",
      "Epoch [973/1000], Loss: 0.2569\n",
      "Epoch [974/1000], Loss: 0.2572\n",
      "Epoch [975/1000], Loss: 0.2562\n",
      "Epoch [976/1000], Loss: 0.2585\n",
      "Epoch [977/1000], Loss: 0.2557\n",
      "Epoch [978/1000], Loss: 0.2581\n",
      "Epoch [979/1000], Loss: 0.2581\n",
      "Epoch [980/1000], Loss: 0.2598\n",
      "Epoch [981/1000], Loss: 0.2597\n",
      "Epoch [982/1000], Loss: 0.2605\n",
      "Epoch [983/1000], Loss: 0.2604\n",
      "Epoch [984/1000], Loss: 0.2573\n",
      "Epoch [985/1000], Loss: 0.2579\n",
      "Epoch [986/1000], Loss: 0.2625\n",
      "Epoch [987/1000], Loss: 0.2570\n",
      "Epoch [988/1000], Loss: 0.2560\n",
      "Epoch [989/1000], Loss: 0.2587\n",
      "Epoch [990/1000], Loss: 0.2571\n",
      "Epoch [991/1000], Loss: 0.2589\n",
      "Epoch [992/1000], Loss: 0.2564\n",
      "Epoch [993/1000], Loss: 0.2585\n",
      "Epoch [994/1000], Loss: 0.2589\n",
      "Epoch [995/1000], Loss: 0.2574\n",
      "Epoch [996/1000], Loss: 0.2574\n",
      "Epoch [997/1000], Loss: 0.2613\n",
      "Epoch [998/1000], Loss: 0.2575\n",
      "Epoch [999/1000], Loss: 0.2560\n",
      "Epoch [1000/1000], Loss: 0.2576\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 205, lr :0.001, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.2695\n",
      "Epoch [2/1000], Loss: 0.2608\n",
      "Epoch [3/1000], Loss: 0.2572\n",
      "Epoch [4/1000], Loss: 0.2544\n",
      "Epoch [5/1000], Loss: 0.2523\n",
      "Epoch [6/1000], Loss: 0.2510\n",
      "Epoch [7/1000], Loss: 0.2497\n",
      "Epoch [8/1000], Loss: 0.2492\n",
      "Epoch [9/1000], Loss: 0.2483\n",
      "Epoch [10/1000], Loss: 0.2476\n",
      "Epoch [11/1000], Loss: 0.2472\n",
      "Epoch [12/1000], Loss: 0.2466\n",
      "Epoch [13/1000], Loss: 0.2464\n",
      "Epoch [14/1000], Loss: 0.2460\n",
      "Epoch [15/1000], Loss: 0.2455\n",
      "Epoch [16/1000], Loss: 0.2456\n",
      "Epoch [17/1000], Loss: 0.2450\n",
      "Epoch [18/1000], Loss: 0.2451\n",
      "Epoch [19/1000], Loss: 0.2447\n",
      "Epoch [20/1000], Loss: 0.2447\n",
      "Epoch [21/1000], Loss: 0.2445\n",
      "Epoch [22/1000], Loss: 0.2444\n",
      "Epoch [23/1000], Loss: 0.2444\n",
      "Epoch [24/1000], Loss: 0.2444\n",
      "Epoch [25/1000], Loss: 0.2441\n",
      "Epoch [26/1000], Loss: 0.2438\n",
      "Epoch [27/1000], Loss: 0.2440\n",
      "Epoch [28/1000], Loss: 0.2440\n",
      "Epoch [29/1000], Loss: 0.2433\n",
      "Epoch [30/1000], Loss: 0.2437\n",
      "Epoch [31/1000], Loss: 0.2435\n",
      "Epoch [32/1000], Loss: 0.2432\n",
      "Epoch [33/1000], Loss: 0.2433\n",
      "Epoch [34/1000], Loss: 0.2430\n",
      "Epoch [35/1000], Loss: 0.2432\n",
      "Epoch [36/1000], Loss: 0.2431\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 62.10 %\n",
      "Training model with batch_size: 205, lr :0.001, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.2537\n",
      "Epoch [2/1000], Loss: 0.2450\n",
      "Epoch [3/1000], Loss: 0.2431\n",
      "Epoch [4/1000], Loss: 0.2421\n",
      "Epoch [5/1000], Loss: 0.2417\n",
      "Epoch [6/1000], Loss: 0.2412\n",
      "Epoch [7/1000], Loss: 0.2394\n",
      "Epoch [8/1000], Loss: 0.2394\n",
      "Epoch [9/1000], Loss: 0.2386\n",
      "Epoch [10/1000], Loss: 0.2382\n",
      "Epoch [11/1000], Loss: 0.2368\n",
      "Epoch [12/1000], Loss: 0.2357\n",
      "Epoch [13/1000], Loss: 0.2351\n",
      "Epoch [14/1000], Loss: 0.2341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/1000], Loss: 0.2332\n",
      "Epoch [16/1000], Loss: 0.2319\n",
      "Epoch [17/1000], Loss: 0.2309\n",
      "Epoch [18/1000], Loss: 0.2294\n",
      "Epoch [19/1000], Loss: 0.2280\n",
      "Epoch [20/1000], Loss: 0.2257\n",
      "Epoch [21/1000], Loss: 0.2237\n",
      "Epoch [22/1000], Loss: 0.2221\n",
      "Epoch [23/1000], Loss: 0.2195\n",
      "Epoch [24/1000], Loss: 0.2169\n",
      "Epoch [25/1000], Loss: 0.2146\n",
      "Epoch [26/1000], Loss: 0.2105\n",
      "Epoch [27/1000], Loss: 0.2065\n",
      "Epoch [28/1000], Loss: 0.2031\n",
      "Epoch [29/1000], Loss: 0.1994\n",
      "Epoch [30/1000], Loss: 0.1945\n",
      "Epoch [31/1000], Loss: 0.1907\n",
      "Epoch [32/1000], Loss: 0.1852\n",
      "Epoch [33/1000], Loss: 0.1812\n",
      "Epoch [34/1000], Loss: 0.1750\n",
      "Epoch [35/1000], Loss: 0.1698\n",
      "Epoch [36/1000], Loss: 0.1643\n",
      "Epoch [37/1000], Loss: 0.1598\n",
      "Epoch [38/1000], Loss: 0.1538\n",
      "Epoch [39/1000], Loss: 0.1491\n",
      "Epoch [40/1000], Loss: 0.1437\n",
      "Epoch [41/1000], Loss: 0.1393\n",
      "Epoch [42/1000], Loss: 0.1361\n",
      "Epoch [43/1000], Loss: 0.1312\n",
      "Epoch [44/1000], Loss: 0.1264\n",
      "Epoch [45/1000], Loss: 0.1226\n",
      "Epoch [46/1000], Loss: 0.1197\n",
      "Epoch [47/1000], Loss: 0.1160\n",
      "Epoch [48/1000], Loss: 0.1132\n",
      "Epoch [49/1000], Loss: 0.1097\n",
      "Epoch [50/1000], Loss: 0.1063\n",
      "Epoch [51/1000], Loss: 0.1037\n",
      "Epoch [52/1000], Loss: 0.1012\n",
      "Epoch [53/1000], Loss: 0.0988\n",
      "Epoch [54/1000], Loss: 0.0959\n",
      "Epoch [55/1000], Loss: 0.0940\n",
      "Epoch [56/1000], Loss: 0.0914\n",
      "Epoch [57/1000], Loss: 0.0899\n",
      "Epoch [58/1000], Loss: 0.0877\n",
      "Epoch [59/1000], Loss: 0.0854\n",
      "Epoch [60/1000], Loss: 0.0832\n",
      "Epoch [61/1000], Loss: 0.0816\n",
      "Epoch [62/1000], Loss: 0.0796\n",
      "Epoch [63/1000], Loss: 0.0780\n",
      "Epoch [64/1000], Loss: 0.0773\n",
      "Epoch [65/1000], Loss: 0.0755\n",
      "Epoch [66/1000], Loss: 0.0736\n",
      "Epoch [67/1000], Loss: 0.0728\n",
      "Epoch [68/1000], Loss: 0.0710\n",
      "Epoch [69/1000], Loss: 0.0691\n",
      "Epoch [70/1000], Loss: 0.0684\n",
      "Epoch [71/1000], Loss: 0.0676\n",
      "Epoch [72/1000], Loss: 0.0645\n",
      "Epoch [73/1000], Loss: 0.0619\n",
      "Epoch [74/1000], Loss: 0.0589\n",
      "Epoch [75/1000], Loss: 0.0561\n",
      "Epoch [76/1000], Loss: 0.0539\n",
      "Epoch [77/1000], Loss: 0.0516\n",
      "Epoch [78/1000], Loss: 0.0490\n",
      "Epoch [79/1000], Loss: 0.0472\n",
      "Epoch [80/1000], Loss: 0.0450\n",
      "Epoch [81/1000], Loss: 0.0438\n",
      "Epoch [82/1000], Loss: 0.0420\n",
      "Epoch [83/1000], Loss: 0.0409\n",
      "Epoch [84/1000], Loss: 0.0389\n",
      "Epoch [85/1000], Loss: 0.0376\n",
      "Epoch [86/1000], Loss: 0.0359\n",
      "Epoch [87/1000], Loss: 0.0346\n",
      "Epoch [88/1000], Loss: 0.0336\n",
      "Epoch [89/1000], Loss: 0.0322\n",
      "Epoch [90/1000], Loss: 0.0312\n",
      "Epoch [91/1000], Loss: 0.0299\n",
      "Epoch [92/1000], Loss: 0.0290\n",
      "Epoch [93/1000], Loss: 0.0284\n",
      "Epoch [94/1000], Loss: 0.0269\n",
      "Epoch [95/1000], Loss: 0.0258\n",
      "Epoch [96/1000], Loss: 0.0251\n",
      "Epoch [97/1000], Loss: 0.0240\n",
      "Epoch [98/1000], Loss: 0.0231\n",
      "Epoch [99/1000], Loss: 0.0227\n",
      "Epoch [100/1000], Loss: 0.0221\n",
      "Epoch [101/1000], Loss: 0.0208\n",
      "Epoch [102/1000], Loss: 0.0200\n",
      "Epoch [103/1000], Loss: 0.0199\n",
      "Epoch [104/1000], Loss: 0.0191\n",
      "Epoch [105/1000], Loss: 0.0182\n",
      "Epoch [106/1000], Loss: 0.0177\n",
      "Epoch [107/1000], Loss: 0.0173\n",
      "Epoch [108/1000], Loss: 0.0164\n",
      "Epoch [109/1000], Loss: 0.0158\n",
      "Epoch [110/1000], Loss: 0.0154\n",
      "Epoch [111/1000], Loss: 0.0147\n",
      "Epoch [112/1000], Loss: 0.0142\n",
      "Epoch [113/1000], Loss: 0.0138\n",
      "Epoch [114/1000], Loss: 0.0134\n",
      "Epoch [115/1000], Loss: 0.0130\n",
      "Epoch [116/1000], Loss: 0.0127\n",
      "Epoch [117/1000], Loss: 0.0123\n",
      "Epoch [118/1000], Loss: 0.0119\n",
      "Epoch [119/1000], Loss: 0.0115\n",
      "Epoch [120/1000], Loss: 0.0111\n",
      "Epoch [121/1000], Loss: 0.0107\n",
      "Epoch [122/1000], Loss: 0.0106\n",
      "Epoch [123/1000], Loss: 0.0101\n",
      "Epoch [124/1000], Loss: 0.0098\n",
      "Epoch [125/1000], Loss: 0.0096\n",
      "Epoch [126/1000], Loss: 0.0092\n",
      "Epoch [127/1000], Loss: 0.0089\n",
      "Epoch [128/1000], Loss: 0.0087\n",
      "Epoch [129/1000], Loss: 0.0085\n",
      "Epoch [130/1000], Loss: 0.0082\n",
      "Epoch [131/1000], Loss: 0.0080\n",
      "Epoch [132/1000], Loss: 0.0077\n",
      "Epoch [133/1000], Loss: 0.0075\n",
      "Epoch [134/1000], Loss: 0.0073\n",
      "Epoch [135/1000], Loss: 0.0071\n",
      "Epoch [136/1000], Loss: 0.0070\n",
      "Epoch [137/1000], Loss: 0.0067\n",
      "Epoch [138/1000], Loss: 0.0066\n",
      "Epoch [139/1000], Loss: 0.0063\n",
      "Epoch [140/1000], Loss: 0.0062\n",
      "Epoch [141/1000], Loss: 0.0060\n",
      "Epoch [142/1000], Loss: 0.0059\n",
      "Epoch [143/1000], Loss: 0.0057\n",
      "Epoch [144/1000], Loss: 0.0055\n",
      "Epoch [145/1000], Loss: 0.0054\n",
      "Epoch [146/1000], Loss: 0.0053\n",
      "Epoch [147/1000], Loss: 0.0052\n",
      "Epoch [148/1000], Loss: 0.0050\n",
      "Epoch [149/1000], Loss: 0.0050\n",
      "Epoch [150/1000], Loss: 0.0048\n",
      "Epoch [151/1000], Loss: 0.0047\n",
      "Epoch [152/1000], Loss: 0.0045\n",
      "Epoch [153/1000], Loss: 0.0044\n",
      "Epoch [154/1000], Loss: 0.0044\n",
      "Epoch [155/1000], Loss: 0.0042\n",
      "Epoch [156/1000], Loss: 0.0042\n",
      "Epoch [157/1000], Loss: 0.0040\n",
      "Epoch [158/1000], Loss: 0.0040\n",
      "Epoch [159/1000], Loss: 0.0039\n",
      "Epoch [160/1000], Loss: 0.0038\n",
      "Epoch [161/1000], Loss: 0.0037\n",
      "Epoch [162/1000], Loss: 0.0036\n",
      "Epoch [163/1000], Loss: 0.0035\n",
      "Epoch [164/1000], Loss: 0.0035\n",
      "Epoch [165/1000], Loss: 0.0033\n",
      "Epoch [166/1000], Loss: 0.0033\n",
      "Epoch [167/1000], Loss: 0.0032\n",
      "Epoch [168/1000], Loss: 0.0031\n",
      "Epoch [169/1000], Loss: 0.0031\n",
      "Epoch [170/1000], Loss: 0.0030\n",
      "Epoch [171/1000], Loss: 0.0029\n",
      "Epoch [172/1000], Loss: 0.0029\n",
      "Epoch [173/1000], Loss: 0.0028\n",
      "Epoch [174/1000], Loss: 0.0028\n",
      "Epoch [175/1000], Loss: 0.0027\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 205, lr :0.001, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.2521\n",
      "Epoch [2/1000], Loss: 0.2402\n",
      "Epoch [3/1000], Loss: 0.2379\n",
      "Epoch [4/1000], Loss: 0.2365\n",
      "Epoch [5/1000], Loss: 0.2342\n",
      "Epoch [6/1000], Loss: 0.2333\n",
      "Epoch [7/1000], Loss: 0.2311\n",
      "Epoch [8/1000], Loss: 0.2299\n",
      "Epoch [9/1000], Loss: 0.2286\n",
      "Epoch [10/1000], Loss: 0.2264\n",
      "Epoch [11/1000], Loss: 0.2241\n",
      "Epoch [12/1000], Loss: 0.2234\n",
      "Epoch [13/1000], Loss: 0.2214\n",
      "Epoch [14/1000], Loss: 0.2188\n",
      "Epoch [15/1000], Loss: 0.2168\n",
      "Epoch [16/1000], Loss: 0.2142\n",
      "Epoch [17/1000], Loss: 0.2121\n",
      "Epoch [18/1000], Loss: 0.2100\n",
      "Epoch [19/1000], Loss: 0.2078\n",
      "Epoch [20/1000], Loss: 0.2040\n",
      "Epoch [21/1000], Loss: 0.2012\n",
      "Epoch [22/1000], Loss: 0.1969\n",
      "Epoch [23/1000], Loss: 0.1938\n",
      "Epoch [24/1000], Loss: 0.1905\n",
      "Epoch [25/1000], Loss: 0.1872\n",
      "Epoch [26/1000], Loss: 0.1833\n",
      "Epoch [27/1000], Loss: 0.1796\n",
      "Epoch [28/1000], Loss: 0.1765\n",
      "Epoch [29/1000], Loss: 0.1726\n",
      "Epoch [30/1000], Loss: 0.1681\n",
      "Epoch [31/1000], Loss: 0.1634\n",
      "Epoch [32/1000], Loss: 0.1592\n",
      "Epoch [33/1000], Loss: 0.1545\n",
      "Epoch [34/1000], Loss: 0.1496\n",
      "Epoch [35/1000], Loss: 0.1455\n",
      "Epoch [36/1000], Loss: 0.1411\n",
      "Epoch [37/1000], Loss: 0.1360\n",
      "Epoch [38/1000], Loss: 0.1331\n",
      "Epoch [39/1000], Loss: 0.1286\n",
      "Epoch [40/1000], Loss: 0.1234\n",
      "Epoch [41/1000], Loss: 0.1197\n",
      "Epoch [42/1000], Loss: 0.1151\n",
      "Epoch [43/1000], Loss: 0.1110\n",
      "Epoch [44/1000], Loss: 0.1061\n",
      "Epoch [45/1000], Loss: 0.1020\n",
      "Epoch [46/1000], Loss: 0.0980\n",
      "Epoch [47/1000], Loss: 0.0938\n",
      "Epoch [48/1000], Loss: 0.0896\n",
      "Epoch [49/1000], Loss: 0.0862\n",
      "Epoch [50/1000], Loss: 0.0813\n",
      "Epoch [51/1000], Loss: 0.0782\n",
      "Epoch [52/1000], Loss: 0.0744\n",
      "Epoch [53/1000], Loss: 0.0711\n",
      "Epoch [54/1000], Loss: 0.0676\n",
      "Epoch [55/1000], Loss: 0.0631\n",
      "Epoch [56/1000], Loss: 0.0595\n",
      "Epoch [57/1000], Loss: 0.0559\n",
      "Epoch [58/1000], Loss: 0.0527\n",
      "Epoch [59/1000], Loss: 0.0496\n",
      "Epoch [60/1000], Loss: 0.0466\n",
      "Epoch [61/1000], Loss: 0.0440\n",
      "Epoch [62/1000], Loss: 0.0416\n",
      "Epoch [63/1000], Loss: 0.0394\n",
      "Epoch [64/1000], Loss: 0.0370\n",
      "Epoch [65/1000], Loss: 0.0345\n",
      "Epoch [66/1000], Loss: 0.0330\n",
      "Epoch [67/1000], Loss: 0.0308\n",
      "Epoch [68/1000], Loss: 0.0287\n",
      "Epoch [69/1000], Loss: 0.0272\n",
      "Epoch [70/1000], Loss: 0.0254\n",
      "Epoch [71/1000], Loss: 0.0236\n",
      "Epoch [72/1000], Loss: 0.0222\n",
      "Epoch [73/1000], Loss: 0.0207\n",
      "Epoch [74/1000], Loss: 0.0193\n",
      "Epoch [75/1000], Loss: 0.0181\n",
      "Epoch [76/1000], Loss: 0.0168\n",
      "Epoch [77/1000], Loss: 0.0157\n",
      "Epoch [78/1000], Loss: 0.0147\n",
      "Epoch [79/1000], Loss: 0.0136\n",
      "Epoch [80/1000], Loss: 0.0128\n",
      "Epoch [81/1000], Loss: 0.0121\n",
      "Epoch [82/1000], Loss: 0.0113\n",
      "Epoch [83/1000], Loss: 0.0105\n",
      "Epoch [84/1000], Loss: 0.0100\n",
      "Epoch [85/1000], Loss: 0.0094\n",
      "Epoch [86/1000], Loss: 0.0088\n",
      "Epoch [87/1000], Loss: 0.0082\n",
      "Epoch [88/1000], Loss: 0.0076\n",
      "Epoch [89/1000], Loss: 0.0072\n",
      "Epoch [90/1000], Loss: 0.0069\n",
      "Epoch [91/1000], Loss: 0.0065\n",
      "Epoch [92/1000], Loss: 0.0060\n",
      "Epoch [93/1000], Loss: 0.0058\n",
      "Epoch [94/1000], Loss: 0.0054\n",
      "Epoch [95/1000], Loss: 0.0052\n",
      "Epoch [96/1000], Loss: 0.0048\n",
      "Epoch [97/1000], Loss: 0.0045\n",
      "Epoch [98/1000], Loss: 0.0042\n",
      "Epoch [99/1000], Loss: 0.0040\n",
      "Epoch [100/1000], Loss: 0.0038\n",
      "Epoch [101/1000], Loss: 0.0036\n",
      "Epoch [102/1000], Loss: 0.0034\n",
      "Epoch [103/1000], Loss: 0.0031\n",
      "Epoch [104/1000], Loss: 0.0029\n",
      "Epoch [105/1000], Loss: 0.0028\n",
      "Epoch [106/1000], Loss: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/1000], Loss: 0.0026\n",
      "Epoch [108/1000], Loss: 0.0024\n",
      "Epoch [109/1000], Loss: 0.0022\n",
      "Epoch [110/1000], Loss: 0.0021\n",
      "Epoch [111/1000], Loss: 0.0021\n",
      "Epoch [112/1000], Loss: 0.0020\n",
      "Epoch [113/1000], Loss: 0.0019\n",
      "Epoch [114/1000], Loss: 0.0017\n",
      "Epoch [115/1000], Loss: 0.0017\n",
      "Epoch [116/1000], Loss: 0.0016\n",
      "Epoch [117/1000], Loss: 0.0016\n",
      "Epoch [118/1000], Loss: 0.0014\n",
      "Epoch [119/1000], Loss: 0.0014\n",
      "Epoch [120/1000], Loss: 0.0013\n",
      "Epoch [121/1000], Loss: 0.0012\n",
      "Epoch [122/1000], Loss: 0.0012\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 205, lr :0.001, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2636\n",
      "Epoch [2/1000], Loss: 0.2632\n",
      "Epoch [3/1000], Loss: 0.2628\n",
      "Epoch [4/1000], Loss: 0.2623\n",
      "Epoch [5/1000], Loss: 0.2625\n",
      "Epoch [6/1000], Loss: 0.2623\n",
      "Epoch [7/1000], Loss: 0.2618\n",
      "Epoch [8/1000], Loss: 0.2617\n",
      "Epoch [9/1000], Loss: 0.2611\n",
      "Epoch [10/1000], Loss: 0.2608\n",
      "Epoch [11/1000], Loss: 0.2606\n",
      "Epoch [12/1000], Loss: 0.2605\n",
      "Epoch [13/1000], Loss: 0.2600\n",
      "Epoch [14/1000], Loss: 0.2597\n",
      "Epoch [15/1000], Loss: 0.2596\n",
      "Epoch [16/1000], Loss: 0.2593\n",
      "Epoch [17/1000], Loss: 0.2593\n",
      "Epoch [18/1000], Loss: 0.2588\n",
      "Epoch [19/1000], Loss: 0.2587\n",
      "Epoch [20/1000], Loss: 0.2583\n",
      "Epoch [21/1000], Loss: 0.2582\n",
      "Epoch [22/1000], Loss: 0.2577\n",
      "Epoch [23/1000], Loss: 0.2576\n",
      "Epoch [24/1000], Loss: 0.2574\n",
      "Epoch [25/1000], Loss: 0.2575\n",
      "Epoch [26/1000], Loss: 0.2572\n",
      "Epoch [27/1000], Loss: 0.2571\n",
      "Epoch [28/1000], Loss: 0.2570\n",
      "Epoch [29/1000], Loss: 0.2568\n",
      "Epoch [30/1000], Loss: 0.2566\n",
      "Epoch [31/1000], Loss: 0.2561\n",
      "Epoch [32/1000], Loss: 0.2563\n",
      "Epoch [33/1000], Loss: 0.2556\n",
      "Epoch [34/1000], Loss: 0.2558\n",
      "Epoch [35/1000], Loss: 0.2556\n",
      "Epoch [36/1000], Loss: 0.2553\n",
      "Epoch [37/1000], Loss: 0.2551\n",
      "Epoch [38/1000], Loss: 0.2552\n",
      "Epoch [39/1000], Loss: 0.2550\n",
      "Epoch [40/1000], Loss: 0.2549\n",
      "Epoch [41/1000], Loss: 0.2546\n",
      "Epoch [42/1000], Loss: 0.2544\n",
      "Epoch [43/1000], Loss: 0.2544\n",
      "Epoch [44/1000], Loss: 0.2541\n",
      "Epoch [45/1000], Loss: 0.2539\n",
      "Epoch [46/1000], Loss: 0.2540\n",
      "Epoch [47/1000], Loss: 0.2538\n",
      "Epoch [48/1000], Loss: 0.2535\n",
      "Epoch [49/1000], Loss: 0.2536\n",
      "Epoch [50/1000], Loss: 0.2534\n",
      "Epoch [51/1000], Loss: 0.2534\n",
      "Epoch [52/1000], Loss: 0.2533\n",
      "Epoch [53/1000], Loss: 0.2529\n",
      "Epoch [54/1000], Loss: 0.2529\n",
      "Epoch [55/1000], Loss: 0.2526\n",
      "Epoch [56/1000], Loss: 0.2526\n",
      "Epoch [57/1000], Loss: 0.2526\n",
      "Epoch [58/1000], Loss: 0.2525\n",
      "Epoch [59/1000], Loss: 0.2522\n",
      "Epoch [60/1000], Loss: 0.2522\n",
      "Epoch [61/1000], Loss: 0.2519\n",
      "Epoch [62/1000], Loss: 0.2521\n",
      "Epoch [63/1000], Loss: 0.2519\n",
      "Epoch [64/1000], Loss: 0.2517\n",
      "Epoch [65/1000], Loss: 0.2516\n",
      "Epoch [66/1000], Loss: 0.2517\n",
      "Epoch [67/1000], Loss: 0.2516\n",
      "Epoch [68/1000], Loss: 0.2513\n",
      "Epoch [69/1000], Loss: 0.2511\n",
      "Epoch [70/1000], Loss: 0.2513\n",
      "Epoch [71/1000], Loss: 0.2509\n",
      "Epoch [72/1000], Loss: 0.2509\n",
      "Epoch [73/1000], Loss: 0.2508\n",
      "Epoch [74/1000], Loss: 0.2509\n",
      "Epoch [75/1000], Loss: 0.2507\n",
      "Epoch [76/1000], Loss: 0.2504\n",
      "Epoch [77/1000], Loss: 0.2505\n",
      "Epoch [78/1000], Loss: 0.2504\n",
      "Epoch [79/1000], Loss: 0.2503\n",
      "Epoch [80/1000], Loss: 0.2502\n",
      "Epoch [81/1000], Loss: 0.2500\n",
      "Epoch [82/1000], Loss: 0.2499\n",
      "Epoch [83/1000], Loss: 0.2497\n",
      "Epoch [84/1000], Loss: 0.2498\n",
      "Epoch [85/1000], Loss: 0.2497\n",
      "Epoch [86/1000], Loss: 0.2497\n",
      "Epoch [87/1000], Loss: 0.2493\n",
      "Epoch [88/1000], Loss: 0.2494\n",
      "Epoch [89/1000], Loss: 0.2494\n",
      "Epoch [90/1000], Loss: 0.2495\n",
      "Epoch [91/1000], Loss: 0.2491\n",
      "Epoch [92/1000], Loss: 0.2490\n",
      "Epoch [93/1000], Loss: 0.2490\n",
      "Epoch [94/1000], Loss: 0.2488\n",
      "Epoch [95/1000], Loss: 0.2489\n",
      "Epoch [96/1000], Loss: 0.2488\n",
      "Epoch [97/1000], Loss: 0.2487\n",
      "Epoch [98/1000], Loss: 0.2488\n",
      "Epoch [99/1000], Loss: 0.2486\n",
      "Epoch [100/1000], Loss: 0.2486\n",
      "Epoch [101/1000], Loss: 0.2485\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 59.00 %\n",
      "Training model with batch_size: 205, lr :0.01, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.2465\n",
      "Epoch [2/1000], Loss: 0.2400\n",
      "Epoch [3/1000], Loss: 0.2377\n",
      "Epoch [4/1000], Loss: 0.2354\n",
      "Epoch [5/1000], Loss: 0.2342\n",
      "Epoch [6/1000], Loss: 0.2327\n",
      "Epoch [7/1000], Loss: 0.2301\n",
      "Epoch [8/1000], Loss: 0.2281\n",
      "Epoch [9/1000], Loss: 0.2259\n",
      "Epoch [10/1000], Loss: 0.2239\n",
      "Epoch [11/1000], Loss: 0.2218\n",
      "Epoch [12/1000], Loss: 0.2202\n",
      "Epoch [13/1000], Loss: 0.2183\n",
      "Epoch [14/1000], Loss: 0.2163\n",
      "Epoch [15/1000], Loss: 0.2143\n",
      "Epoch [16/1000], Loss: 0.2128\n",
      "Epoch [17/1000], Loss: 0.2107\n",
      "Epoch [18/1000], Loss: 0.2086\n",
      "Epoch [19/1000], Loss: 0.2066\n",
      "Epoch [20/1000], Loss: 0.2050\n",
      "Epoch [21/1000], Loss: 0.2032\n",
      "Epoch [22/1000], Loss: 0.2007\n",
      "Epoch [23/1000], Loss: 0.1992\n",
      "Epoch [24/1000], Loss: 0.1977\n",
      "Epoch [25/1000], Loss: 0.1960\n",
      "Epoch [26/1000], Loss: 0.1942\n",
      "Epoch [27/1000], Loss: 0.1925\n",
      "Epoch [28/1000], Loss: 0.1918\n",
      "Epoch [29/1000], Loss: 0.1898\n",
      "Epoch [30/1000], Loss: 0.1885\n",
      "Epoch [31/1000], Loss: 0.1874\n",
      "Epoch [32/1000], Loss: 0.1852\n",
      "Epoch [33/1000], Loss: 0.1839\n",
      "Epoch [34/1000], Loss: 0.1830\n",
      "Epoch [35/1000], Loss: 0.1822\n",
      "Epoch [36/1000], Loss: 0.1804\n",
      "Epoch [37/1000], Loss: 0.1793\n",
      "Epoch [38/1000], Loss: 0.1774\n",
      "Epoch [39/1000], Loss: 0.1767\n",
      "Epoch [40/1000], Loss: 0.1751\n",
      "Epoch [41/1000], Loss: 0.1745\n",
      "Epoch [42/1000], Loss: 0.1729\n",
      "Epoch [43/1000], Loss: 0.1721\n",
      "Epoch [44/1000], Loss: 0.1708\n",
      "Epoch [45/1000], Loss: 0.1704\n",
      "Epoch [46/1000], Loss: 0.1696\n",
      "Epoch [47/1000], Loss: 0.1689\n",
      "Epoch [48/1000], Loss: 0.1673\n",
      "Epoch [49/1000], Loss: 0.1664\n",
      "Epoch [50/1000], Loss: 0.1652\n",
      "Epoch [51/1000], Loss: 0.1650\n",
      "Epoch [52/1000], Loss: 0.1642\n",
      "Epoch [53/1000], Loss: 0.1633\n",
      "Epoch [54/1000], Loss: 0.1624\n",
      "Epoch [55/1000], Loss: 0.1616\n",
      "Epoch [56/1000], Loss: 0.1612\n",
      "Epoch [57/1000], Loss: 0.1602\n",
      "Epoch [58/1000], Loss: 0.1593\n",
      "Epoch [59/1000], Loss: 0.1584\n",
      "Epoch [60/1000], Loss: 0.1575\n",
      "Epoch [61/1000], Loss: 0.1567\n",
      "Epoch [62/1000], Loss: 0.1563\n",
      "Epoch [63/1000], Loss: 0.1557\n",
      "Epoch [64/1000], Loss: 0.1548\n",
      "Epoch [65/1000], Loss: 0.1547\n",
      "Epoch [66/1000], Loss: 0.1534\n",
      "Epoch [67/1000], Loss: 0.1527\n",
      "Epoch [68/1000], Loss: 0.1515\n",
      "Epoch [69/1000], Loss: 0.1516\n",
      "Epoch [70/1000], Loss: 0.1512\n",
      "Epoch [71/1000], Loss: 0.1500\n",
      "Epoch [72/1000], Loss: 0.1493\n",
      "Epoch [73/1000], Loss: 0.1481\n",
      "Epoch [74/1000], Loss: 0.1481\n",
      "Epoch [75/1000], Loss: 0.1471\n",
      "Epoch [76/1000], Loss: 0.1458\n",
      "Epoch [77/1000], Loss: 0.1449\n",
      "Epoch [78/1000], Loss: 0.1443\n",
      "Epoch [79/1000], Loss: 0.1437\n",
      "Epoch [80/1000], Loss: 0.1424\n",
      "Epoch [81/1000], Loss: 0.1421\n",
      "Epoch [82/1000], Loss: 0.1417\n",
      "Epoch [83/1000], Loss: 0.1408\n",
      "Epoch [84/1000], Loss: 0.1402\n",
      "Epoch [85/1000], Loss: 0.1398\n",
      "Epoch [86/1000], Loss: 0.1391\n",
      "Epoch [87/1000], Loss: 0.1386\n",
      "Epoch [88/1000], Loss: 0.1386\n",
      "Epoch [89/1000], Loss: 0.1372\n",
      "Epoch [90/1000], Loss: 0.1365\n",
      "Epoch [91/1000], Loss: 0.1357\n",
      "Epoch [92/1000], Loss: 0.1356\n",
      "Epoch [93/1000], Loss: 0.1350\n",
      "Epoch [94/1000], Loss: 0.1345\n",
      "Epoch [95/1000], Loss: 0.1334\n",
      "Epoch [96/1000], Loss: 0.1325\n",
      "Epoch [97/1000], Loss: 0.1326\n",
      "Epoch [98/1000], Loss: 0.1320\n",
      "Epoch [99/1000], Loss: 0.1309\n",
      "Epoch [100/1000], Loss: 0.1305\n",
      "Epoch [101/1000], Loss: 0.1302\n",
      "Epoch [102/1000], Loss: 0.1296\n",
      "Epoch [103/1000], Loss: 0.1290\n",
      "Epoch [104/1000], Loss: 0.1284\n",
      "Epoch [105/1000], Loss: 0.1280\n",
      "Epoch [106/1000], Loss: 0.1272\n",
      "Epoch [107/1000], Loss: 0.1265\n",
      "Epoch [108/1000], Loss: 0.1257\n",
      "Epoch [109/1000], Loss: 0.1254\n",
      "Epoch [110/1000], Loss: 0.1250\n",
      "Epoch [111/1000], Loss: 0.1242\n",
      "Epoch [112/1000], Loss: 0.1236\n",
      "Epoch [113/1000], Loss: 0.1225\n",
      "Epoch [114/1000], Loss: 0.1220\n",
      "Epoch [115/1000], Loss: 0.1211\n",
      "Epoch [116/1000], Loss: 0.1204\n",
      "Epoch [117/1000], Loss: 0.1203\n",
      "Epoch [118/1000], Loss: 0.1189\n",
      "Epoch [119/1000], Loss: 0.1190\n",
      "Epoch [120/1000], Loss: 0.1182\n",
      "Epoch [121/1000], Loss: 0.1176\n",
      "Epoch [122/1000], Loss: 0.1167\n",
      "Epoch [123/1000], Loss: 0.1163\n",
      "Epoch [124/1000], Loss: 0.1160\n",
      "Epoch [125/1000], Loss: 0.1152\n",
      "Epoch [126/1000], Loss: 0.1144\n",
      "Epoch [127/1000], Loss: 0.1133\n",
      "Epoch [128/1000], Loss: 0.1125\n",
      "Epoch [129/1000], Loss: 0.1120\n",
      "Epoch [130/1000], Loss: 0.1111\n",
      "Epoch [131/1000], Loss: 0.1109\n",
      "Epoch [132/1000], Loss: 0.1100\n",
      "Epoch [133/1000], Loss: 0.1093\n",
      "Epoch [134/1000], Loss: 0.1085\n",
      "Epoch [135/1000], Loss: 0.1078\n",
      "Epoch [136/1000], Loss: 0.1074\n",
      "Epoch [137/1000], Loss: 0.1064\n",
      "Epoch [138/1000], Loss: 0.1061\n",
      "Epoch [139/1000], Loss: 0.1050\n",
      "Epoch [140/1000], Loss: 0.1045\n",
      "Epoch [141/1000], Loss: 0.1034\n",
      "Epoch [142/1000], Loss: 0.1028\n",
      "Epoch [143/1000], Loss: 0.1019\n",
      "Epoch [144/1000], Loss: 0.1013\n",
      "Epoch [145/1000], Loss: 0.1012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [146/1000], Loss: 0.0996\n",
      "Epoch [147/1000], Loss: 0.0988\n",
      "Epoch [148/1000], Loss: 0.0984\n",
      "Epoch [149/1000], Loss: 0.0973\n",
      "Epoch [150/1000], Loss: 0.0964\n",
      "Epoch [151/1000], Loss: 0.0959\n",
      "Epoch [152/1000], Loss: 0.0952\n",
      "Epoch [153/1000], Loss: 0.0946\n",
      "Epoch [154/1000], Loss: 0.0932\n",
      "Epoch [155/1000], Loss: 0.0930\n",
      "Epoch [156/1000], Loss: 0.0923\n",
      "Epoch [157/1000], Loss: 0.0916\n",
      "Epoch [158/1000], Loss: 0.0907\n",
      "Epoch [159/1000], Loss: 0.0895\n",
      "Epoch [160/1000], Loss: 0.0894\n",
      "Epoch [161/1000], Loss: 0.0880\n",
      "Epoch [162/1000], Loss: 0.0877\n",
      "Epoch [163/1000], Loss: 0.0872\n",
      "Epoch [164/1000], Loss: 0.0861\n",
      "Epoch [165/1000], Loss: 0.0850\n",
      "Epoch [166/1000], Loss: 0.0843\n",
      "Epoch [167/1000], Loss: 0.0841\n",
      "Epoch [168/1000], Loss: 0.0828\n",
      "Epoch [169/1000], Loss: 0.0823\n",
      "Epoch [170/1000], Loss: 0.0815\n",
      "Epoch [171/1000], Loss: 0.0806\n",
      "Epoch [172/1000], Loss: 0.0800\n",
      "Epoch [173/1000], Loss: 0.0794\n",
      "Epoch [174/1000], Loss: 0.0784\n",
      "Epoch [175/1000], Loss: 0.0779\n",
      "Epoch [176/1000], Loss: 0.0773\n",
      "Epoch [177/1000], Loss: 0.0770\n",
      "Epoch [178/1000], Loss: 0.0759\n",
      "Epoch [179/1000], Loss: 0.0752\n",
      "Epoch [180/1000], Loss: 0.0744\n",
      "Epoch [181/1000], Loss: 0.0739\n",
      "Epoch [182/1000], Loss: 0.0727\n",
      "Epoch [183/1000], Loss: 0.0725\n",
      "Epoch [184/1000], Loss: 0.0719\n",
      "Epoch [185/1000], Loss: 0.0714\n",
      "Epoch [186/1000], Loss: 0.0706\n",
      "Epoch [187/1000], Loss: 0.0697\n",
      "Epoch [188/1000], Loss: 0.0689\n",
      "Epoch [189/1000], Loss: 0.0681\n",
      "Epoch [190/1000], Loss: 0.0677\n",
      "Epoch [191/1000], Loss: 0.0669\n",
      "Epoch [192/1000], Loss: 0.0661\n",
      "Epoch [193/1000], Loss: 0.0658\n",
      "Epoch [194/1000], Loss: 0.0653\n",
      "Epoch [195/1000], Loss: 0.0645\n",
      "Epoch [196/1000], Loss: 0.0639\n",
      "Epoch [197/1000], Loss: 0.0632\n",
      "Epoch [198/1000], Loss: 0.0627\n",
      "Epoch [199/1000], Loss: 0.0620\n",
      "Epoch [200/1000], Loss: 0.0615\n",
      "Epoch [201/1000], Loss: 0.0611\n",
      "Epoch [202/1000], Loss: 0.0600\n",
      "Epoch [203/1000], Loss: 0.0593\n",
      "Epoch [204/1000], Loss: 0.0589\n",
      "Epoch [205/1000], Loss: 0.0585\n",
      "Epoch [206/1000], Loss: 0.0580\n",
      "Epoch [207/1000], Loss: 0.0572\n",
      "Epoch [208/1000], Loss: 0.0569\n",
      "Epoch [209/1000], Loss: 0.0564\n",
      "Epoch [210/1000], Loss: 0.0555\n",
      "Epoch [211/1000], Loss: 0.0549\n",
      "Epoch [212/1000], Loss: 0.0543\n",
      "Epoch [213/1000], Loss: 0.0539\n",
      "Epoch [214/1000], Loss: 0.0535\n",
      "Epoch [215/1000], Loss: 0.0531\n",
      "Epoch [216/1000], Loss: 0.0525\n",
      "Epoch [217/1000], Loss: 0.0522\n",
      "Epoch [218/1000], Loss: 0.0515\n",
      "Epoch [219/1000], Loss: 0.0508\n",
      "Epoch [220/1000], Loss: 0.0506\n",
      "Epoch [221/1000], Loss: 0.0501\n",
      "Epoch [222/1000], Loss: 0.0494\n",
      "Epoch [223/1000], Loss: 0.0490\n",
      "Epoch [224/1000], Loss: 0.0488\n",
      "Epoch [225/1000], Loss: 0.0479\n",
      "Epoch [226/1000], Loss: 0.0476\n",
      "Epoch [227/1000], Loss: 0.0470\n",
      "Epoch [228/1000], Loss: 0.0464\n",
      "Epoch [229/1000], Loss: 0.0461\n",
      "Epoch [230/1000], Loss: 0.0456\n",
      "Epoch [231/1000], Loss: 0.0452\n",
      "Epoch [232/1000], Loss: 0.0450\n",
      "Epoch [233/1000], Loss: 0.0444\n",
      "Epoch [234/1000], Loss: 0.0440\n",
      "Epoch [235/1000], Loss: 0.0434\n",
      "Epoch [236/1000], Loss: 0.0432\n",
      "Epoch [237/1000], Loss: 0.0427\n",
      "Epoch [238/1000], Loss: 0.0422\n",
      "Epoch [239/1000], Loss: 0.0417\n",
      "Epoch [240/1000], Loss: 0.0417\n",
      "Epoch [241/1000], Loss: 0.0411\n",
      "Epoch [242/1000], Loss: 0.0407\n",
      "Epoch [243/1000], Loss: 0.0403\n",
      "Epoch [244/1000], Loss: 0.0400\n",
      "Epoch [245/1000], Loss: 0.0396\n",
      "Epoch [246/1000], Loss: 0.0391\n",
      "Epoch [247/1000], Loss: 0.0388\n",
      "Epoch [248/1000], Loss: 0.0383\n",
      "Epoch [249/1000], Loss: 0.0382\n",
      "Epoch [250/1000], Loss: 0.0380\n",
      "Epoch [251/1000], Loss: 0.0374\n",
      "Epoch [252/1000], Loss: 0.0371\n",
      "Epoch [253/1000], Loss: 0.0367\n",
      "Epoch [254/1000], Loss: 0.0365\n",
      "Epoch [255/1000], Loss: 0.0361\n",
      "Epoch [256/1000], Loss: 0.0356\n",
      "Epoch [257/1000], Loss: 0.0355\n",
      "Epoch [258/1000], Loss: 0.0349\n",
      "Epoch [259/1000], Loss: 0.0347\n",
      "Epoch [260/1000], Loss: 0.0343\n",
      "Epoch [261/1000], Loss: 0.0341\n",
      "Epoch [262/1000], Loss: 0.0340\n",
      "Epoch [263/1000], Loss: 0.0336\n",
      "Epoch [264/1000], Loss: 0.0333\n",
      "Epoch [265/1000], Loss: 0.0329\n",
      "Epoch [266/1000], Loss: 0.0326\n",
      "Epoch [267/1000], Loss: 0.0323\n",
      "Epoch [268/1000], Loss: 0.0320\n",
      "Epoch [269/1000], Loss: 0.0319\n",
      "Epoch [270/1000], Loss: 0.0315\n",
      "Epoch [271/1000], Loss: 0.0312\n",
      "Epoch [272/1000], Loss: 0.0311\n",
      "Epoch [273/1000], Loss: 0.0308\n",
      "Epoch [274/1000], Loss: 0.0305\n",
      "Epoch [275/1000], Loss: 0.0302\n",
      "Epoch [276/1000], Loss: 0.0302\n",
      "Epoch [277/1000], Loss: 0.0298\n",
      "Epoch [278/1000], Loss: 0.0294\n",
      "Epoch [279/1000], Loss: 0.0292\n",
      "Epoch [280/1000], Loss: 0.0290\n",
      "Epoch [281/1000], Loss: 0.0288\n",
      "Epoch [282/1000], Loss: 0.0286\n",
      "Epoch [283/1000], Loss: 0.0283\n",
      "Epoch [284/1000], Loss: 0.0282\n",
      "Epoch [285/1000], Loss: 0.0279\n",
      "Epoch [286/1000], Loss: 0.0276\n",
      "Epoch [287/1000], Loss: 0.0275\n",
      "Epoch [288/1000], Loss: 0.0272\n",
      "Epoch [289/1000], Loss: 0.0270\n",
      "Epoch [290/1000], Loss: 0.0268\n",
      "Epoch [291/1000], Loss: 0.0265\n",
      "Epoch [292/1000], Loss: 0.0263\n",
      "Epoch [293/1000], Loss: 0.0261\n",
      "Epoch [294/1000], Loss: 0.0260\n",
      "Epoch [295/1000], Loss: 0.0258\n",
      "Epoch [296/1000], Loss: 0.0255\n",
      "Epoch [297/1000], Loss: 0.0254\n",
      "Epoch [298/1000], Loss: 0.0252\n",
      "Epoch [299/1000], Loss: 0.0250\n",
      "Epoch [300/1000], Loss: 0.0247\n",
      "Epoch [301/1000], Loss: 0.0244\n",
      "Epoch [302/1000], Loss: 0.0244\n",
      "Epoch [303/1000], Loss: 0.0242\n",
      "Epoch [304/1000], Loss: 0.0239\n",
      "Epoch [305/1000], Loss: 0.0238\n",
      "Epoch [306/1000], Loss: 0.0236\n",
      "Epoch [307/1000], Loss: 0.0234\n",
      "Epoch [308/1000], Loss: 0.0234\n",
      "Epoch [309/1000], Loss: 0.0233\n",
      "Epoch [310/1000], Loss: 0.0231\n",
      "Epoch [311/1000], Loss: 0.0229\n",
      "Epoch [312/1000], Loss: 0.0227\n",
      "Epoch [313/1000], Loss: 0.0224\n",
      "Epoch [314/1000], Loss: 0.0223\n",
      "Epoch [315/1000], Loss: 0.0221\n",
      "Epoch [316/1000], Loss: 0.0219\n",
      "Epoch [317/1000], Loss: 0.0219\n",
      "Epoch [318/1000], Loss: 0.0217\n",
      "Epoch [319/1000], Loss: 0.0215\n",
      "Epoch [320/1000], Loss: 0.0215\n",
      "Epoch [321/1000], Loss: 0.0211\n",
      "Epoch [322/1000], Loss: 0.0210\n",
      "Epoch [323/1000], Loss: 0.0209\n",
      "Epoch [324/1000], Loss: 0.0208\n",
      "Epoch [325/1000], Loss: 0.0207\n",
      "Epoch [326/1000], Loss: 0.0206\n",
      "Epoch [327/1000], Loss: 0.0203\n",
      "Epoch [328/1000], Loss: 0.0203\n",
      "Epoch [329/1000], Loss: 0.0201\n",
      "Epoch [330/1000], Loss: 0.0200\n",
      "Epoch [331/1000], Loss: 0.0198\n",
      "Epoch [332/1000], Loss: 0.0197\n",
      "Epoch [333/1000], Loss: 0.0196\n",
      "Epoch [334/1000], Loss: 0.0194\n",
      "Epoch [335/1000], Loss: 0.0194\n",
      "Epoch [336/1000], Loss: 0.0191\n",
      "Epoch [337/1000], Loss: 0.0191\n",
      "Epoch [338/1000], Loss: 0.0189\n",
      "Epoch [339/1000], Loss: 0.0189\n",
      "Epoch [340/1000], Loss: 0.0187\n",
      "Epoch [341/1000], Loss: 0.0185\n",
      "Epoch [342/1000], Loss: 0.0184\n",
      "Epoch [343/1000], Loss: 0.0184\n",
      "Epoch [344/1000], Loss: 0.0182\n",
      "Epoch [345/1000], Loss: 0.0180\n",
      "Epoch [346/1000], Loss: 0.0180\n",
      "Epoch [347/1000], Loss: 0.0178\n",
      "Epoch [348/1000], Loss: 0.0177\n",
      "Epoch [349/1000], Loss: 0.0176\n",
      "Epoch [350/1000], Loss: 0.0175\n",
      "Epoch [351/1000], Loss: 0.0174\n",
      "Epoch [352/1000], Loss: 0.0173\n",
      "Epoch [353/1000], Loss: 0.0173\n",
      "Epoch [354/1000], Loss: 0.0171\n",
      "Epoch [355/1000], Loss: 0.0170\n",
      "Epoch [356/1000], Loss: 0.0168\n",
      "Epoch [357/1000], Loss: 0.0167\n",
      "Epoch [358/1000], Loss: 0.0166\n",
      "Epoch [359/1000], Loss: 0.0165\n",
      "Epoch [360/1000], Loss: 0.0165\n",
      "Epoch [361/1000], Loss: 0.0163\n",
      "Epoch [362/1000], Loss: 0.0162\n",
      "Epoch [363/1000], Loss: 0.0161\n",
      "Epoch [364/1000], Loss: 0.0160\n",
      "Epoch [365/1000], Loss: 0.0159\n",
      "Epoch [366/1000], Loss: 0.0158\n",
      "Epoch [367/1000], Loss: 0.0158\n",
      "Epoch [368/1000], Loss: 0.0157\n",
      "Epoch [369/1000], Loss: 0.0157\n",
      "Epoch [370/1000], Loss: 0.0155\n",
      "Epoch [371/1000], Loss: 0.0154\n",
      "Epoch [372/1000], Loss: 0.0153\n",
      "Epoch [373/1000], Loss: 0.0153\n",
      "Epoch [374/1000], Loss: 0.0152\n",
      "Epoch [375/1000], Loss: 0.0150\n",
      "Epoch [376/1000], Loss: 0.0149\n",
      "Epoch [377/1000], Loss: 0.0149\n",
      "Epoch [378/1000], Loss: 0.0148\n",
      "Epoch [379/1000], Loss: 0.0146\n",
      "Epoch [380/1000], Loss: 0.0147\n",
      "Epoch [381/1000], Loss: 0.0145\n",
      "Epoch [382/1000], Loss: 0.0144\n",
      "Epoch [383/1000], Loss: 0.0144\n",
      "Epoch [384/1000], Loss: 0.0143\n",
      "Epoch [385/1000], Loss: 0.0142\n",
      "Epoch [386/1000], Loss: 0.0141\n",
      "Epoch [387/1000], Loss: 0.0141\n",
      "Epoch [388/1000], Loss: 0.0140\n",
      "Epoch [389/1000], Loss: 0.0139\n",
      "Epoch [390/1000], Loss: 0.0138\n",
      "Epoch [391/1000], Loss: 0.0138\n",
      "Epoch [392/1000], Loss: 0.0138\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 99.80 %\n",
      "Training model with batch_size: 205, lr :0.01, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.2466\n",
      "Epoch [2/1000], Loss: 0.2395\n",
      "Epoch [3/1000], Loss: 0.2336\n",
      "Epoch [4/1000], Loss: 0.2224\n",
      "Epoch [5/1000], Loss: 0.2000\n",
      "Epoch [6/1000], Loss: 0.1686\n",
      "Epoch [7/1000], Loss: 0.1366\n",
      "Epoch [8/1000], Loss: 0.1011\n",
      "Epoch [9/1000], Loss: 0.0767\n",
      "Epoch [10/1000], Loss: 0.0572\n",
      "Epoch [11/1000], Loss: 0.0403\n",
      "Epoch [12/1000], Loss: 0.0270\n",
      "Epoch [13/1000], Loss: 0.0181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/1000], Loss: 0.0128\n",
      "Epoch [15/1000], Loss: 0.0085\n",
      "Epoch [16/1000], Loss: 0.0060\n",
      "Epoch [17/1000], Loss: 0.0046\n",
      "Epoch [18/1000], Loss: 0.0041\n",
      "Epoch [19/1000], Loss: 0.0033\n",
      "Epoch [20/1000], Loss: 0.0025\n",
      "Epoch [21/1000], Loss: 0.0022\n",
      "Epoch [22/1000], Loss: 0.0020\n",
      "Epoch [23/1000], Loss: 0.0019\n",
      "Epoch [24/1000], Loss: 0.0017\n",
      "Epoch [25/1000], Loss: 0.0016\n",
      "Epoch [26/1000], Loss: 0.0013\n",
      "Epoch [27/1000], Loss: 0.0012\n",
      "Epoch [28/1000], Loss: 0.0012\n",
      "Epoch [29/1000], Loss: 0.0011\n",
      "Epoch [30/1000], Loss: 0.0011\n",
      "Epoch [31/1000], Loss: 0.0011\n",
      "Epoch [32/1000], Loss: 0.0009\n",
      "Epoch [33/1000], Loss: 0.0009\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 205, lr :0.01, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.2588\n",
      "Epoch [2/1000], Loss: 0.2412\n",
      "Epoch [3/1000], Loss: 0.2331\n",
      "Epoch [4/1000], Loss: 0.2072\n",
      "Epoch [5/1000], Loss: 0.1821\n",
      "Epoch [6/1000], Loss: 0.1509\n",
      "Epoch [7/1000], Loss: 0.1178\n",
      "Epoch [8/1000], Loss: 0.0797\n",
      "Epoch [9/1000], Loss: 0.0567\n",
      "Epoch [10/1000], Loss: 0.0414\n",
      "Epoch [11/1000], Loss: 0.0309\n",
      "Epoch [12/1000], Loss: 0.0259\n",
      "Epoch [13/1000], Loss: 0.0124\n",
      "Epoch [14/1000], Loss: 0.0095\n",
      "Epoch [15/1000], Loss: 0.0116\n",
      "Epoch [16/1000], Loss: 0.0052\n",
      "Epoch [17/1000], Loss: 0.0045\n",
      "Epoch [18/1000], Loss: 0.0039\n",
      "Epoch [19/1000], Loss: 0.0029\n",
      "Epoch [20/1000], Loss: 0.0028\n",
      "Epoch [21/1000], Loss: 0.0167\n",
      "Epoch [22/1000], Loss: 0.0019\n",
      "Epoch [23/1000], Loss: 0.0017\n",
      "Epoch [24/1000], Loss: 0.0017\n",
      "Epoch [25/1000], Loss: 0.0015\n",
      "Epoch [26/1000], Loss: 0.0013\n",
      "Epoch [27/1000], Loss: 0.0011\n",
      "Epoch [28/1000], Loss: 0.0010\n",
      "Epoch [29/1000], Loss: 0.0011\n",
      "Epoch [30/1000], Loss: 0.0010\n",
      "Epoch [31/1000], Loss: 0.0009\n",
      "Epoch [32/1000], Loss: 0.0007\n",
      "Epoch [33/1000], Loss: 0.0006\n",
      "Epoch [34/1000], Loss: 0.0007\n",
      "Epoch [35/1000], Loss: 0.0009\n",
      "Epoch [36/1000], Loss: 0.0657\n",
      "Epoch [37/1000], Loss: 0.0006\n",
      "Epoch [38/1000], Loss: 0.0005\n",
      "Epoch [39/1000], Loss: 0.0004\n",
      "Epoch [40/1000], Loss: 0.0004\n",
      "Epoch [41/1000], Loss: 0.0004\n",
      "Epoch [42/1000], Loss: 0.0003\n",
      "Epoch [43/1000], Loss: 0.0003\n",
      "Epoch [44/1000], Loss: 0.0003\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 205, lr :0.01, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2529\n",
      "Epoch [2/1000], Loss: 0.2511\n",
      "Epoch [3/1000], Loss: 0.2498\n",
      "Epoch [4/1000], Loss: 0.2487\n",
      "Epoch [5/1000], Loss: 0.2474\n",
      "Epoch [6/1000], Loss: 0.2468\n",
      "Epoch [7/1000], Loss: 0.2458\n",
      "Epoch [8/1000], Loss: 0.2453\n",
      "Epoch [9/1000], Loss: 0.2445\n",
      "Epoch [10/1000], Loss: 0.2441\n",
      "Epoch [11/1000], Loss: 0.2434\n",
      "Epoch [12/1000], Loss: 0.2432\n",
      "Epoch [13/1000], Loss: 0.2425\n",
      "Epoch [14/1000], Loss: 0.2426\n",
      "Epoch [15/1000], Loss: 0.2417\n",
      "Epoch [16/1000], Loss: 0.2419\n",
      "Epoch [17/1000], Loss: 0.2416\n",
      "Epoch [18/1000], Loss: 0.2416\n",
      "Epoch [19/1000], Loss: 0.2415\n",
      "Epoch [20/1000], Loss: 0.2415\n",
      "Epoch [21/1000], Loss: 0.2412\n",
      "Epoch [22/1000], Loss: 0.2410\n",
      "Epoch [23/1000], Loss: 0.2410\n",
      "Epoch [24/1000], Loss: 0.2409\n",
      "Epoch [25/1000], Loss: 0.2406\n",
      "Epoch [26/1000], Loss: 0.2409\n",
      "Epoch [27/1000], Loss: 0.2407\n",
      "Epoch [28/1000], Loss: 0.2404\n",
      "Epoch [29/1000], Loss: 0.2407\n",
      "Epoch [30/1000], Loss: 0.2406\n",
      "Epoch [31/1000], Loss: 0.2405\n",
      "Epoch [32/1000], Loss: 0.2405\n",
      "Epoch [33/1000], Loss: 0.2405\n",
      "Epoch [34/1000], Loss: 0.2401\n",
      "Epoch [35/1000], Loss: 0.2406\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 64.10 %\n",
      "Training model with batch_size: 205, lr :0.1, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.2487\n",
      "Epoch [2/1000], Loss: 0.2344\n",
      "Epoch [3/1000], Loss: 0.2202\n",
      "Epoch [4/1000], Loss: 0.1900\n",
      "Epoch [5/1000], Loss: 0.1504\n",
      "Epoch [6/1000], Loss: 0.1132\n",
      "Epoch [7/1000], Loss: 0.0794\n",
      "Epoch [8/1000], Loss: 0.0643\n",
      "Epoch [9/1000], Loss: 0.0490\n",
      "Epoch [10/1000], Loss: 0.0406\n",
      "Epoch [11/1000], Loss: 0.0297\n",
      "Epoch [12/1000], Loss: 0.0238\n",
      "Epoch [13/1000], Loss: 0.0191\n",
      "Epoch [14/1000], Loss: 0.0152\n",
      "Epoch [15/1000], Loss: 0.0126\n",
      "Epoch [16/1000], Loss: 0.0109\n",
      "Epoch [17/1000], Loss: 0.0093\n",
      "Epoch [18/1000], Loss: 0.0082\n",
      "Epoch [19/1000], Loss: 0.0072\n",
      "Epoch [20/1000], Loss: 0.0065\n",
      "Epoch [21/1000], Loss: 0.0059\n",
      "Epoch [22/1000], Loss: 0.0053\n",
      "Epoch [23/1000], Loss: 0.0048\n",
      "Epoch [24/1000], Loss: 0.0046\n",
      "Epoch [25/1000], Loss: 0.0041\n",
      "Epoch [26/1000], Loss: 0.0038\n",
      "Epoch [27/1000], Loss: 0.0036\n",
      "Epoch [28/1000], Loss: 0.0033\n",
      "Epoch [29/1000], Loss: 0.0032\n",
      "Epoch [30/1000], Loss: 0.0030\n",
      "Epoch [31/1000], Loss: 0.0028\n",
      "Epoch [32/1000], Loss: 0.0027\n",
      "Epoch [33/1000], Loss: 0.0025\n",
      "Epoch [34/1000], Loss: 0.0024\n",
      "Epoch [35/1000], Loss: 0.0023\n",
      "Epoch [36/1000], Loss: 0.0021\n",
      "Epoch [37/1000], Loss: 0.0021\n",
      "Epoch [38/1000], Loss: 0.0020\n",
      "Epoch [39/1000], Loss: 0.0019\n",
      "Epoch [40/1000], Loss: 0.0018\n",
      "Epoch [41/1000], Loss: 0.0017\n",
      "Epoch [42/1000], Loss: 0.0017\n",
      "Epoch [43/1000], Loss: 0.0016\n",
      "Epoch [44/1000], Loss: 0.0015\n",
      "Epoch [45/1000], Loss: 0.0015\n",
      "Epoch [46/1000], Loss: 0.0014\n",
      "Epoch [47/1000], Loss: 0.0014\n",
      "Epoch [48/1000], Loss: 0.0013\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 205, lr :0.1, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.2549\n",
      "Epoch [2/1000], Loss: 0.2123\n",
      "Epoch [3/1000], Loss: 0.1686\n",
      "Epoch [4/1000], Loss: 0.1309\n",
      "Epoch [5/1000], Loss: 0.1027\n",
      "Epoch [6/1000], Loss: 0.0740\n",
      "Epoch [7/1000], Loss: 0.0545\n",
      "Epoch [8/1000], Loss: 0.0261\n",
      "Epoch [9/1000], Loss: 0.0178\n",
      "Epoch [10/1000], Loss: 0.0337\n",
      "Epoch [11/1000], Loss: 0.0224\n",
      "Epoch [12/1000], Loss: 0.0078\n",
      "Epoch [13/1000], Loss: 0.0031\n",
      "Epoch [14/1000], Loss: 0.0104\n",
      "Epoch [15/1000], Loss: 0.0275\n",
      "Epoch [16/1000], Loss: 0.0203\n",
      "Epoch [17/1000], Loss: 0.0241\n",
      "Epoch [18/1000], Loss: 0.0161\n",
      "Epoch [19/1000], Loss: 0.0098\n",
      "Epoch [20/1000], Loss: 0.0059\n",
      "Epoch [21/1000], Loss: 0.0039\n",
      "Epoch [22/1000], Loss: 0.0020\n",
      "Epoch [23/1000], Loss: 0.0025\n",
      "Epoch [24/1000], Loss: 0.0050\n",
      "Epoch [25/1000], Loss: 0.0139\n",
      "Epoch [26/1000], Loss: 0.0068\n",
      "Epoch [27/1000], Loss: 0.0114\n",
      "Epoch [28/1000], Loss: 0.0156\n",
      "Epoch [29/1000], Loss: 0.0129\n",
      "Epoch [30/1000], Loss: 0.0041\n",
      "Epoch [31/1000], Loss: 0.0030\n",
      "Epoch [32/1000], Loss: 0.0018\n",
      "Epoch [33/1000], Loss: 0.0046\n",
      "Epoch [34/1000], Loss: 0.0024\n",
      "Epoch [35/1000], Loss: 0.0012\n",
      "Epoch [36/1000], Loss: 0.0040\n",
      "Epoch [37/1000], Loss: 0.0043\n",
      "Epoch [38/1000], Loss: 0.0043\n",
      "Epoch [39/1000], Loss: 0.0026\n",
      "Epoch [40/1000], Loss: 0.0029\n",
      "Epoch [41/1000], Loss: 0.0007\n",
      "Epoch [42/1000], Loss: 0.0001\n",
      "Epoch [43/1000], Loss: 0.0002\n",
      "Epoch [44/1000], Loss: 0.0018\n",
      "Epoch [45/1000], Loss: 0.0012\n",
      "Epoch [46/1000], Loss: 0.0003\n",
      "Epoch [47/1000], Loss: 0.0003\n",
      "Epoch [48/1000], Loss: 0.0006\n",
      "Epoch [49/1000], Loss: 0.0013\n",
      "Epoch [50/1000], Loss: 0.0001\n",
      "Epoch [51/1000], Loss: 0.0001\n",
      "Epoch [52/1000], Loss: 0.0000\n",
      "Epoch [53/1000], Loss: 0.0000\n",
      "Epoch [54/1000], Loss: 0.0000\n",
      "Epoch [55/1000], Loss: 0.0000\n",
      "Epoch [56/1000], Loss: 0.0000\n",
      "Epoch [57/1000], Loss: 0.0000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 205, lr :0.1, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.4942\n",
      "Epoch [2/1000], Loss: 0.5131\n",
      "Epoch [3/1000], Loss: 0.5124\n",
      "Epoch [4/1000], Loss: 0.5124\n",
      "Epoch [5/1000], Loss: 0.5129\n",
      "Epoch [6/1000], Loss: 0.5107\n",
      "Epoch [7/1000], Loss: 0.5107\n",
      "Epoch [8/1000], Loss: 0.5129\n",
      "Epoch [9/1000], Loss: 0.5124\n",
      "Epoch [10/1000], Loss: 0.5131\n",
      "Epoch [11/1000], Loss: 0.5117\n",
      "Epoch [12/1000], Loss: 0.5157\n",
      "Epoch [13/1000], Loss: 0.5119\n",
      "Epoch [14/1000], Loss: 0.5117\n",
      "Epoch [15/1000], Loss: 0.5126\n",
      "Epoch [16/1000], Loss: 0.5124\n",
      "Epoch [17/1000], Loss: 0.5133\n",
      "Epoch [18/1000], Loss: 0.5107\n",
      "Epoch [19/1000], Loss: 0.5114\n",
      "Epoch [20/1000], Loss: 0.5112\n",
      "Epoch [21/1000], Loss: 0.5117\n",
      "Epoch [22/1000], Loss: 0.5133\n",
      "Epoch [23/1000], Loss: 0.5114\n",
      "Epoch [24/1000], Loss: 0.5117\n",
      "Epoch [25/1000], Loss: 0.5138\n",
      "Epoch [26/1000], Loss: 0.5131\n",
      "Epoch [27/1000], Loss: 0.5131\n",
      "Epoch [28/1000], Loss: 0.5119\n",
      "Epoch [29/1000], Loss: 0.5131\n",
      "Epoch [30/1000], Loss: 0.5121\n",
      "Epoch [31/1000], Loss: 0.5121\n",
      "Epoch [32/1000], Loss: 0.5133\n",
      "Epoch [33/1000], Loss: 0.5112\n",
      "Epoch [34/1000], Loss: 0.5133\n",
      "Epoch [35/1000], Loss: 0.5143\n",
      "Epoch [36/1000], Loss: 0.5136\n",
      "Epoch [37/1000], Loss: 0.5119\n",
      "Epoch [38/1000], Loss: 0.5114\n",
      "Epoch [39/1000], Loss: 0.5121\n",
      "Epoch [40/1000], Loss: 0.5124\n",
      "Epoch [41/1000], Loss: 0.5117\n",
      "Epoch [42/1000], Loss: 0.5148\n",
      "Epoch [43/1000], Loss: 0.5136\n",
      "Epoch [44/1000], Loss: 0.5131\n",
      "Epoch [45/1000], Loss: 0.5129\n",
      "Epoch [46/1000], Loss: 0.5155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/1000], Loss: 0.5140\n",
      "Epoch [48/1000], Loss: 0.5107\n",
      "Epoch [49/1000], Loss: 0.5112\n",
      "Epoch [50/1000], Loss: 0.5114\n",
      "Epoch [51/1000], Loss: 0.5124\n",
      "Epoch [52/1000], Loss: 0.5133\n",
      "Epoch [53/1000], Loss: 0.5126\n",
      "Epoch [54/1000], Loss: 0.5138\n",
      "Epoch [55/1000], Loss: 0.5105\n",
      "Epoch [56/1000], Loss: 0.5126\n",
      "Epoch [57/1000], Loss: 0.5121\n",
      "Epoch [58/1000], Loss: 0.5119\n",
      "Epoch [59/1000], Loss: 0.5131\n",
      "Epoch [60/1000], Loss: 0.5129\n",
      "Epoch [61/1000], Loss: 0.5140\n",
      "Epoch [62/1000], Loss: 0.5121\n",
      "Epoch [63/1000], Loss: 0.5114\n",
      "Epoch [64/1000], Loss: 0.5133\n",
      "Epoch [65/1000], Loss: 0.5110\n",
      "Epoch [66/1000], Loss: 0.5129\n",
      "Epoch [67/1000], Loss: 0.5117\n",
      "Epoch [68/1000], Loss: 0.5114\n",
      "Epoch [69/1000], Loss: 0.5126\n",
      "Epoch [70/1000], Loss: 0.5129\n",
      "Epoch [71/1000], Loss: 0.5133\n",
      "Epoch [72/1000], Loss: 0.5136\n",
      "Epoch [73/1000], Loss: 0.5133\n",
      "Epoch [74/1000], Loss: 0.5133\n",
      "Epoch [75/1000], Loss: 0.5117\n",
      "Epoch [76/1000], Loss: 0.5124\n",
      "Epoch [77/1000], Loss: 0.5126\n",
      "Epoch [78/1000], Loss: 0.5145\n",
      "Epoch [79/1000], Loss: 0.5131\n",
      "Epoch [80/1000], Loss: 0.5129\n",
      "Epoch [81/1000], Loss: 0.5114\n",
      "Epoch [82/1000], Loss: 0.5136\n",
      "Epoch [83/1000], Loss: 0.5148\n",
      "Epoch [84/1000], Loss: 0.5121\n",
      "Epoch [85/1000], Loss: 0.5110\n",
      "Epoch [86/1000], Loss: 0.5121\n",
      "Epoch [87/1000], Loss: 0.5119\n",
      "Epoch [88/1000], Loss: 0.5129\n",
      "Epoch [89/1000], Loss: 0.5148\n",
      "Epoch [90/1000], Loss: 0.5112\n",
      "Epoch [91/1000], Loss: 0.5102\n",
      "Epoch [92/1000], Loss: 0.5150\n",
      "Epoch [93/1000], Loss: 0.5143\n",
      "Epoch [94/1000], Loss: 0.5110\n",
      "Epoch [95/1000], Loss: 0.5112\n",
      "Epoch [96/1000], Loss: 0.5117\n",
      "Epoch [97/1000], Loss: 0.5138\n",
      "Epoch [98/1000], Loss: 0.5121\n",
      "Epoch [99/1000], Loss: 0.5121\n",
      "Epoch [100/1000], Loss: 0.5117\n",
      "Epoch [101/1000], Loss: 0.5124\n",
      "Epoch [102/1000], Loss: 0.5112\n",
      "Epoch [103/1000], Loss: 0.5117\n",
      "Epoch [104/1000], Loss: 0.5148\n",
      "Epoch [105/1000], Loss: 0.5119\n",
      "Epoch [106/1000], Loss: 0.5110\n",
      "Epoch [107/1000], Loss: 0.5129\n",
      "Epoch [108/1000], Loss: 0.5119\n",
      "Epoch [109/1000], Loss: 0.5119\n",
      "Epoch [110/1000], Loss: 0.5102\n",
      "Epoch [111/1000], Loss: 0.5117\n",
      "Epoch [112/1000], Loss: 0.5148\n",
      "Epoch [113/1000], Loss: 0.5126\n",
      "Epoch [114/1000], Loss: 0.5098\n",
      "Epoch [115/1000], Loss: 0.5136\n",
      "Epoch [116/1000], Loss: 0.5110\n",
      "Epoch [117/1000], Loss: 0.5148\n",
      "Epoch [118/1000], Loss: 0.5112\n",
      "Epoch [119/1000], Loss: 0.5114\n",
      "Epoch [120/1000], Loss: 0.5114\n",
      "Epoch [121/1000], Loss: 0.5131\n",
      "Epoch [122/1000], Loss: 0.5124\n",
      "Epoch [123/1000], Loss: 0.5136\n",
      "Epoch [124/1000], Loss: 0.5138\n",
      "Epoch [125/1000], Loss: 0.5117\n",
      "Epoch [126/1000], Loss: 0.5133\n",
      "Epoch [127/1000], Loss: 0.5129\n",
      "Epoch [128/1000], Loss: 0.5114\n",
      "Epoch [129/1000], Loss: 0.5121\n",
      "Epoch [130/1000], Loss: 0.5124\n",
      "Epoch [131/1000], Loss: 0.5124\n",
      "Epoch [132/1000], Loss: 0.5121\n",
      "Epoch [133/1000], Loss: 0.5117\n",
      "Epoch [134/1000], Loss: 0.5114\n",
      "Epoch [135/1000], Loss: 0.5121\n",
      "Epoch [136/1000], Loss: 0.5121\n",
      "Epoch [137/1000], Loss: 0.5131\n",
      "Epoch [138/1000], Loss: 0.5143\n",
      "Epoch [139/1000], Loss: 0.5133\n",
      "Epoch [140/1000], Loss: 0.5117\n",
      "Epoch [141/1000], Loss: 0.5117\n",
      "Epoch [142/1000], Loss: 0.5124\n",
      "Epoch [143/1000], Loss: 0.5129\n",
      "Epoch [144/1000], Loss: 0.5119\n",
      "Epoch [145/1000], Loss: 0.5112\n",
      "Epoch [146/1000], Loss: 0.5112\n",
      "Epoch [147/1000], Loss: 0.5129\n",
      "Epoch [148/1000], Loss: 0.5119\n",
      "Epoch [149/1000], Loss: 0.5169\n",
      "Epoch [150/1000], Loss: 0.5126\n",
      "Epoch [151/1000], Loss: 0.5138\n",
      "Epoch [152/1000], Loss: 0.5126\n",
      "Epoch [153/1000], Loss: 0.5110\n",
      "Epoch [154/1000], Loss: 0.5150\n",
      "Epoch [155/1000], Loss: 0.5102\n",
      "Epoch [156/1000], Loss: 0.5131\n",
      "Epoch [157/1000], Loss: 0.5131\n",
      "Epoch [158/1000], Loss: 0.5131\n",
      "Epoch [159/1000], Loss: 0.5119\n",
      "Epoch [160/1000], Loss: 0.5126\n",
      "Epoch [161/1000], Loss: 0.5114\n",
      "Epoch [162/1000], Loss: 0.5117\n",
      "Epoch [163/1000], Loss: 0.5157\n",
      "Epoch [164/1000], Loss: 0.5140\n",
      "Epoch [165/1000], Loss: 0.5126\n",
      "Epoch [166/1000], Loss: 0.5138\n",
      "Epoch [167/1000], Loss: 0.5124\n",
      "Epoch [168/1000], Loss: 0.5133\n",
      "Epoch [169/1000], Loss: 0.5138\n",
      "Epoch [170/1000], Loss: 0.5124\n",
      "Epoch [171/1000], Loss: 0.5131\n",
      "Epoch [172/1000], Loss: 0.5121\n",
      "Epoch [173/1000], Loss: 0.5121\n",
      "Epoch [174/1000], Loss: 0.5114\n",
      "Epoch [175/1000], Loss: 0.5126\n",
      "Epoch [176/1000], Loss: 0.5117\n",
      "Epoch [177/1000], Loss: 0.5131\n",
      "Epoch [178/1000], Loss: 0.5136\n",
      "Epoch [179/1000], Loss: 0.5119\n",
      "Epoch [180/1000], Loss: 0.5105\n",
      "Epoch [181/1000], Loss: 0.5112\n",
      "Epoch [182/1000], Loss: 0.5126\n",
      "Epoch [183/1000], Loss: 0.5112\n",
      "Epoch [184/1000], Loss: 0.5150\n",
      "Epoch [185/1000], Loss: 0.5136\n",
      "Epoch [186/1000], Loss: 0.5112\n",
      "Epoch [187/1000], Loss: 0.5150\n",
      "Epoch [188/1000], Loss: 0.5110\n",
      "Epoch [189/1000], Loss: 0.5107\n",
      "Epoch [190/1000], Loss: 0.5119\n",
      "Epoch [191/1000], Loss: 0.5129\n",
      "Epoch [192/1000], Loss: 0.5131\n",
      "Epoch [193/1000], Loss: 0.5114\n",
      "Epoch [194/1000], Loss: 0.5110\n",
      "Epoch [195/1000], Loss: 0.5119\n",
      "Epoch [196/1000], Loss: 0.5140\n",
      "Epoch [197/1000], Loss: 0.5121\n",
      "Epoch [198/1000], Loss: 0.5124\n",
      "Epoch [199/1000], Loss: 0.5121\n",
      "Epoch [200/1000], Loss: 0.5138\n",
      "Epoch [201/1000], Loss: 0.5121\n",
      "Epoch [202/1000], Loss: 0.5143\n",
      "Epoch [203/1000], Loss: 0.5112\n",
      "Epoch [204/1000], Loss: 0.5119\n",
      "Epoch [205/1000], Loss: 0.5129\n",
      "Epoch [206/1000], Loss: 0.5136\n",
      "Epoch [207/1000], Loss: 0.5119\n",
      "Epoch [208/1000], Loss: 0.5124\n",
      "Epoch [209/1000], Loss: 0.5112\n",
      "Epoch [210/1000], Loss: 0.5129\n",
      "Epoch [211/1000], Loss: 0.5105\n",
      "Epoch [212/1000], Loss: 0.5145\n",
      "Epoch [213/1000], Loss: 0.5140\n",
      "Epoch [214/1000], Loss: 0.5119\n",
      "Epoch [215/1000], Loss: 0.5129\n",
      "Epoch [216/1000], Loss: 0.5124\n",
      "Epoch [217/1000], Loss: 0.5129\n",
      "Epoch [218/1000], Loss: 0.5136\n",
      "Epoch [219/1000], Loss: 0.5110\n",
      "Epoch [220/1000], Loss: 0.5114\n",
      "Epoch [221/1000], Loss: 0.5124\n",
      "Epoch [222/1000], Loss: 0.5114\n",
      "Epoch [223/1000], Loss: 0.5121\n",
      "Epoch [224/1000], Loss: 0.5114\n",
      "Epoch [225/1000], Loss: 0.5140\n",
      "Epoch [226/1000], Loss: 0.5140\n",
      "Epoch [227/1000], Loss: 0.5129\n",
      "Epoch [228/1000], Loss: 0.5119\n",
      "Epoch [229/1000], Loss: 0.5102\n",
      "Epoch [230/1000], Loss: 0.5126\n",
      "Epoch [231/1000], Loss: 0.5102\n",
      "Epoch [232/1000], Loss: 0.5114\n",
      "Epoch [233/1000], Loss: 0.5136\n",
      "Epoch [234/1000], Loss: 0.5114\n",
      "Epoch [235/1000], Loss: 0.5119\n",
      "Epoch [236/1000], Loss: 0.5124\n",
      "Epoch [237/1000], Loss: 0.5119\n",
      "Epoch [238/1000], Loss: 0.5124\n",
      "Epoch [239/1000], Loss: 0.5133\n",
      "Epoch [240/1000], Loss: 0.5126\n",
      "Epoch [241/1000], Loss: 0.5124\n",
      "Epoch [242/1000], Loss: 0.5105\n",
      "Epoch [243/1000], Loss: 0.5124\n",
      "Epoch [244/1000], Loss: 0.5136\n",
      "Epoch [245/1000], Loss: 0.5121\n",
      "Epoch [246/1000], Loss: 0.5129\n",
      "Epoch [247/1000], Loss: 0.5140\n",
      "Epoch [248/1000], Loss: 0.5131\n",
      "Epoch [249/1000], Loss: 0.5095\n",
      "Epoch [250/1000], Loss: 0.5152\n",
      "Epoch [251/1000], Loss: 0.5129\n",
      "Epoch [252/1000], Loss: 0.5110\n",
      "Epoch [253/1000], Loss: 0.5121\n",
      "Epoch [254/1000], Loss: 0.5119\n",
      "Epoch [255/1000], Loss: 0.5133\n",
      "Epoch [256/1000], Loss: 0.5150\n",
      "Epoch [257/1000], Loss: 0.5119\n",
      "Epoch [258/1000], Loss: 0.5114\n",
      "Epoch [259/1000], Loss: 0.5114\n",
      "Epoch [260/1000], Loss: 0.5126\n",
      "Epoch [261/1000], Loss: 0.5110\n",
      "Epoch [262/1000], Loss: 0.5129\n",
      "Epoch [263/1000], Loss: 0.5126\n",
      "Epoch [264/1000], Loss: 0.5126\n",
      "Epoch [265/1000], Loss: 0.5126\n",
      "Epoch [266/1000], Loss: 0.5119\n",
      "Epoch [267/1000], Loss: 0.5124\n",
      "Epoch [268/1000], Loss: 0.5138\n",
      "Epoch [269/1000], Loss: 0.5098\n",
      "Epoch [270/1000], Loss: 0.5171\n",
      "Epoch [271/1000], Loss: 0.5126\n",
      "Epoch [272/1000], Loss: 0.5119\n",
      "Epoch [273/1000], Loss: 0.5114\n",
      "Epoch [274/1000], Loss: 0.5119\n",
      "Epoch [275/1000], Loss: 0.5112\n",
      "Epoch [276/1000], Loss: 0.5119\n",
      "Epoch [277/1000], Loss: 0.5140\n",
      "Epoch [278/1000], Loss: 0.5131\n",
      "Epoch [279/1000], Loss: 0.5098\n",
      "Epoch [280/1000], Loss: 0.5131\n",
      "Epoch [281/1000], Loss: 0.5121\n",
      "Epoch [282/1000], Loss: 0.5114\n",
      "Epoch [283/1000], Loss: 0.5112\n",
      "Epoch [284/1000], Loss: 0.5121\n",
      "Epoch [285/1000], Loss: 0.5121\n",
      "Epoch [286/1000], Loss: 0.5133\n",
      "Epoch [287/1000], Loss: 0.5110\n",
      "Epoch [288/1000], Loss: 0.5133\n",
      "Epoch [289/1000], Loss: 0.5114\n",
      "Epoch [290/1000], Loss: 0.5152\n",
      "Epoch [291/1000], Loss: 0.5129\n",
      "Epoch [292/1000], Loss: 0.5150\n",
      "Epoch [293/1000], Loss: 0.5138\n",
      "Epoch [294/1000], Loss: 0.5119\n",
      "Epoch [295/1000], Loss: 0.5136\n",
      "Epoch [296/1000], Loss: 0.5119\n",
      "Epoch [297/1000], Loss: 0.5140\n",
      "Epoch [298/1000], Loss: 0.5129\n",
      "Epoch [299/1000], Loss: 0.5121\n",
      "Epoch [300/1000], Loss: 0.5119\n",
      "Epoch [301/1000], Loss: 0.5119\n",
      "Epoch [302/1000], Loss: 0.5133\n",
      "Epoch [303/1000], Loss: 0.5143\n",
      "Epoch [304/1000], Loss: 0.5140\n",
      "Epoch [305/1000], Loss: 0.5121\n",
      "Epoch [306/1000], Loss: 0.5107\n",
      "Epoch [307/1000], Loss: 0.5126\n",
      "Epoch [308/1000], Loss: 0.5143\n",
      "Epoch [309/1000], Loss: 0.5126\n",
      "Epoch [310/1000], Loss: 0.5114\n",
      "Epoch [311/1000], Loss: 0.5112\n",
      "Epoch [312/1000], Loss: 0.5138\n",
      "Epoch [313/1000], Loss: 0.5143\n",
      "Epoch [314/1000], Loss: 0.5138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [315/1000], Loss: 0.5124\n",
      "Epoch [316/1000], Loss: 0.5129\n",
      "Epoch [317/1000], Loss: 0.5136\n",
      "Epoch [318/1000], Loss: 0.5136\n",
      "Epoch [319/1000], Loss: 0.5129\n",
      "Epoch [320/1000], Loss: 0.5150\n",
      "Epoch [321/1000], Loss: 0.5126\n",
      "Epoch [322/1000], Loss: 0.5112\n",
      "Epoch [323/1000], Loss: 0.5117\n",
      "Epoch [324/1000], Loss: 0.5124\n",
      "Epoch [325/1000], Loss: 0.5126\n",
      "Epoch [326/1000], Loss: 0.5121\n",
      "Epoch [327/1000], Loss: 0.5112\n",
      "Epoch [328/1000], Loss: 0.5138\n",
      "Epoch [329/1000], Loss: 0.5131\n",
      "Epoch [330/1000], Loss: 0.5129\n",
      "Epoch [331/1000], Loss: 0.5124\n",
      "Epoch [332/1000], Loss: 0.5148\n",
      "Epoch [333/1000], Loss: 0.5136\n",
      "Epoch [334/1000], Loss: 0.5126\n",
      "Epoch [335/1000], Loss: 0.5119\n",
      "Epoch [336/1000], Loss: 0.5117\n",
      "Epoch [337/1000], Loss: 0.5119\n",
      "Epoch [338/1000], Loss: 0.5102\n",
      "Epoch [339/1000], Loss: 0.5107\n",
      "Epoch [340/1000], Loss: 0.5121\n",
      "Epoch [341/1000], Loss: 0.5112\n",
      "Epoch [342/1000], Loss: 0.5136\n",
      "Epoch [343/1000], Loss: 0.5133\n",
      "Epoch [344/1000], Loss: 0.5136\n",
      "Epoch [345/1000], Loss: 0.5110\n",
      "Epoch [346/1000], Loss: 0.5140\n",
      "Epoch [347/1000], Loss: 0.5143\n",
      "Epoch [348/1000], Loss: 0.5136\n",
      "Epoch [349/1000], Loss: 0.5131\n",
      "Epoch [350/1000], Loss: 0.5138\n",
      "Epoch [351/1000], Loss: 0.5112\n",
      "Epoch [352/1000], Loss: 0.5105\n",
      "Epoch [353/1000], Loss: 0.5143\n",
      "Epoch [354/1000], Loss: 0.5131\n",
      "Epoch [355/1000], Loss: 0.5138\n",
      "Epoch [356/1000], Loss: 0.5114\n",
      "Epoch [357/1000], Loss: 0.5112\n",
      "Epoch [358/1000], Loss: 0.5117\n",
      "Epoch [359/1000], Loss: 0.5112\n",
      "Epoch [360/1000], Loss: 0.5124\n",
      "Epoch [361/1000], Loss: 0.5138\n",
      "Epoch [362/1000], Loss: 0.5121\n",
      "Epoch [363/1000], Loss: 0.5098\n",
      "Epoch [364/1000], Loss: 0.5119\n",
      "Epoch [365/1000], Loss: 0.5114\n",
      "Epoch [366/1000], Loss: 0.5119\n",
      "Epoch [367/1000], Loss: 0.5107\n",
      "Epoch [368/1000], Loss: 0.5105\n",
      "Epoch [369/1000], Loss: 0.5124\n",
      "Epoch [370/1000], Loss: 0.5117\n",
      "Epoch [371/1000], Loss: 0.5155\n",
      "Epoch [372/1000], Loss: 0.5110\n",
      "Epoch [373/1000], Loss: 0.5121\n",
      "Epoch [374/1000], Loss: 0.5140\n",
      "Epoch [375/1000], Loss: 0.5129\n",
      "Epoch [376/1000], Loss: 0.5126\n",
      "Epoch [377/1000], Loss: 0.5114\n",
      "Epoch [378/1000], Loss: 0.5126\n",
      "Epoch [379/1000], Loss: 0.5133\n",
      "Epoch [380/1000], Loss: 0.5138\n",
      "Epoch [381/1000], Loss: 0.5138\n",
      "Epoch [382/1000], Loss: 0.5131\n",
      "Epoch [383/1000], Loss: 0.5117\n",
      "Epoch [384/1000], Loss: 0.5119\n",
      "Epoch [385/1000], Loss: 0.5114\n",
      "Epoch [386/1000], Loss: 0.5140\n",
      "Epoch [387/1000], Loss: 0.5121\n",
      "Epoch [388/1000], Loss: 0.5124\n",
      "Epoch [389/1000], Loss: 0.5129\n",
      "Epoch [390/1000], Loss: 0.5119\n",
      "Epoch [391/1000], Loss: 0.5129\n",
      "Epoch [392/1000], Loss: 0.5131\n",
      "Epoch [393/1000], Loss: 0.5124\n",
      "Epoch [394/1000], Loss: 0.5114\n",
      "Epoch [395/1000], Loss: 0.5119\n",
      "Epoch [396/1000], Loss: 0.5112\n",
      "Epoch [397/1000], Loss: 0.5131\n",
      "Epoch [398/1000], Loss: 0.5145\n",
      "Epoch [399/1000], Loss: 0.5119\n",
      "Epoch [400/1000], Loss: 0.5131\n",
      "Epoch [401/1000], Loss: 0.5124\n",
      "Epoch [402/1000], Loss: 0.5140\n",
      "Epoch [403/1000], Loss: 0.5119\n",
      "Epoch [404/1000], Loss: 0.5148\n",
      "Epoch [405/1000], Loss: 0.5121\n",
      "Epoch [406/1000], Loss: 0.5140\n",
      "Epoch [407/1000], Loss: 0.5138\n",
      "Epoch [408/1000], Loss: 0.5126\n",
      "Epoch [409/1000], Loss: 0.5114\n",
      "Epoch [410/1000], Loss: 0.5107\n",
      "Epoch [411/1000], Loss: 0.5124\n",
      "Epoch [412/1000], Loss: 0.5138\n",
      "Epoch [413/1000], Loss: 0.5133\n",
      "Epoch [414/1000], Loss: 0.5100\n",
      "Epoch [415/1000], Loss: 0.5126\n",
      "Epoch [416/1000], Loss: 0.5138\n",
      "Epoch [417/1000], Loss: 0.5098\n",
      "Epoch [418/1000], Loss: 0.5124\n",
      "Epoch [419/1000], Loss: 0.5110\n",
      "Epoch [420/1000], Loss: 0.5140\n",
      "Epoch [421/1000], Loss: 0.5119\n",
      "Epoch [422/1000], Loss: 0.5112\n",
      "Epoch [423/1000], Loss: 0.5112\n",
      "Epoch [424/1000], Loss: 0.5121\n",
      "Epoch [425/1000], Loss: 0.5105\n",
      "Epoch [426/1000], Loss: 0.5143\n",
      "Epoch [427/1000], Loss: 0.5136\n",
      "Epoch [428/1000], Loss: 0.5143\n",
      "Epoch [429/1000], Loss: 0.5121\n",
      "Epoch [430/1000], Loss: 0.5107\n",
      "Epoch [431/1000], Loss: 0.5114\n",
      "Epoch [432/1000], Loss: 0.5129\n",
      "Epoch [433/1000], Loss: 0.5143\n",
      "Epoch [434/1000], Loss: 0.5129\n",
      "Epoch [435/1000], Loss: 0.5121\n",
      "Epoch [436/1000], Loss: 0.5126\n",
      "Epoch [437/1000], Loss: 0.5117\n",
      "Epoch [438/1000], Loss: 0.5136\n",
      "Epoch [439/1000], Loss: 0.5145\n",
      "Epoch [440/1000], Loss: 0.5126\n",
      "Epoch [441/1000], Loss: 0.5126\n",
      "Epoch [442/1000], Loss: 0.5121\n",
      "Epoch [443/1000], Loss: 0.5131\n",
      "Epoch [444/1000], Loss: 0.5136\n",
      "Epoch [445/1000], Loss: 0.5140\n",
      "Epoch [446/1000], Loss: 0.5124\n",
      "Epoch [447/1000], Loss: 0.5124\n",
      "Epoch [448/1000], Loss: 0.5126\n",
      "Epoch [449/1000], Loss: 0.5126\n",
      "Epoch [450/1000], Loss: 0.5105\n",
      "Epoch [451/1000], Loss: 0.5119\n",
      "Epoch [452/1000], Loss: 0.5126\n",
      "Epoch [453/1000], Loss: 0.5119\n",
      "Epoch [454/1000], Loss: 0.5114\n",
      "Epoch [455/1000], Loss: 0.5124\n",
      "Epoch [456/1000], Loss: 0.5105\n",
      "Epoch [457/1000], Loss: 0.5136\n",
      "Epoch [458/1000], Loss: 0.5112\n",
      "Epoch [459/1000], Loss: 0.5131\n",
      "Epoch [460/1000], Loss: 0.5114\n",
      "Epoch [461/1000], Loss: 0.5100\n",
      "Epoch [462/1000], Loss: 0.5129\n",
      "Epoch [463/1000], Loss: 0.5124\n",
      "Epoch [464/1000], Loss: 0.5117\n",
      "Epoch [465/1000], Loss: 0.5145\n",
      "Epoch [466/1000], Loss: 0.5143\n",
      "Epoch [467/1000], Loss: 0.5131\n",
      "Epoch [468/1000], Loss: 0.5131\n",
      "Epoch [469/1000], Loss: 0.5138\n",
      "Epoch [470/1000], Loss: 0.5129\n",
      "Epoch [471/1000], Loss: 0.5145\n",
      "Epoch [472/1000], Loss: 0.5126\n",
      "Epoch [473/1000], Loss: 0.5136\n",
      "Epoch [474/1000], Loss: 0.5121\n",
      "Epoch [475/1000], Loss: 0.5114\n",
      "Epoch [476/1000], Loss: 0.5124\n",
      "Epoch [477/1000], Loss: 0.5140\n",
      "Epoch [478/1000], Loss: 0.5131\n",
      "Epoch [479/1000], Loss: 0.5117\n",
      "Epoch [480/1000], Loss: 0.5131\n",
      "Epoch [481/1000], Loss: 0.5160\n",
      "Epoch [482/1000], Loss: 0.5129\n",
      "Epoch [483/1000], Loss: 0.5112\n",
      "Epoch [484/1000], Loss: 0.5119\n",
      "Epoch [485/1000], Loss: 0.5148\n",
      "Epoch [486/1000], Loss: 0.5124\n",
      "Epoch [487/1000], Loss: 0.5110\n",
      "Epoch [488/1000], Loss: 0.5126\n",
      "Epoch [489/1000], Loss: 0.5121\n",
      "Epoch [490/1000], Loss: 0.5152\n",
      "Epoch [491/1000], Loss: 0.5126\n",
      "Epoch [492/1000], Loss: 0.5126\n",
      "Epoch [493/1000], Loss: 0.5107\n",
      "Epoch [494/1000], Loss: 0.5119\n",
      "Epoch [495/1000], Loss: 0.5131\n",
      "Epoch [496/1000], Loss: 0.5138\n",
      "Epoch [497/1000], Loss: 0.5126\n",
      "Epoch [498/1000], Loss: 0.5107\n",
      "Epoch [499/1000], Loss: 0.5126\n",
      "Epoch [500/1000], Loss: 0.5143\n",
      "Epoch [501/1000], Loss: 0.5129\n",
      "Epoch [502/1000], Loss: 0.5152\n",
      "Epoch [503/1000], Loss: 0.5126\n",
      "Epoch [504/1000], Loss: 0.5129\n",
      "Epoch [505/1000], Loss: 0.5107\n",
      "Epoch [506/1000], Loss: 0.5126\n",
      "Epoch [507/1000], Loss: 0.5117\n",
      "Epoch [508/1000], Loss: 0.5136\n",
      "Epoch [509/1000], Loss: 0.5136\n",
      "Epoch [510/1000], Loss: 0.5131\n",
      "Epoch [511/1000], Loss: 0.5140\n",
      "Epoch [512/1000], Loss: 0.5117\n",
      "Epoch [513/1000], Loss: 0.5114\n",
      "Epoch [514/1000], Loss: 0.5145\n",
      "Epoch [515/1000], Loss: 0.5133\n",
      "Epoch [516/1000], Loss: 0.5136\n",
      "Epoch [517/1000], Loss: 0.5148\n",
      "Epoch [518/1000], Loss: 0.5124\n",
      "Epoch [519/1000], Loss: 0.5117\n",
      "Epoch [520/1000], Loss: 0.5145\n",
      "Epoch [521/1000], Loss: 0.5131\n",
      "Epoch [522/1000], Loss: 0.5126\n",
      "Epoch [523/1000], Loss: 0.5133\n",
      "Epoch [524/1000], Loss: 0.5107\n",
      "Epoch [525/1000], Loss: 0.5117\n",
      "Epoch [526/1000], Loss: 0.5143\n",
      "Epoch [527/1000], Loss: 0.5129\n",
      "Epoch [528/1000], Loss: 0.5143\n",
      "Epoch [529/1000], Loss: 0.5124\n",
      "Epoch [530/1000], Loss: 0.5131\n",
      "Epoch [531/1000], Loss: 0.5107\n",
      "Epoch [532/1000], Loss: 0.5136\n",
      "Epoch [533/1000], Loss: 0.5138\n",
      "Epoch [534/1000], Loss: 0.5114\n",
      "Epoch [535/1000], Loss: 0.5140\n",
      "Epoch [536/1000], Loss: 0.5124\n",
      "Epoch [537/1000], Loss: 0.5126\n",
      "Epoch [538/1000], Loss: 0.5119\n",
      "Epoch [539/1000], Loss: 0.5129\n",
      "Epoch [540/1000], Loss: 0.5110\n",
      "Epoch [541/1000], Loss: 0.5126\n",
      "Epoch [542/1000], Loss: 0.5133\n",
      "Epoch [543/1000], Loss: 0.5102\n",
      "Epoch [544/1000], Loss: 0.5133\n",
      "Epoch [545/1000], Loss: 0.5136\n",
      "Epoch [546/1000], Loss: 0.5136\n",
      "Epoch [547/1000], Loss: 0.5117\n",
      "Epoch [548/1000], Loss: 0.5119\n",
      "Epoch [549/1000], Loss: 0.5105\n",
      "Epoch [550/1000], Loss: 0.5110\n",
      "Epoch [551/1000], Loss: 0.5136\n",
      "Epoch [552/1000], Loss: 0.5131\n",
      "Epoch [553/1000], Loss: 0.5133\n",
      "Epoch [554/1000], Loss: 0.5121\n",
      "Epoch [555/1000], Loss: 0.5119\n",
      "Epoch [556/1000], Loss: 0.5114\n",
      "Epoch [557/1000], Loss: 0.5136\n",
      "Epoch [558/1000], Loss: 0.5119\n",
      "Epoch [559/1000], Loss: 0.5138\n",
      "Epoch [560/1000], Loss: 0.5119\n",
      "Epoch [561/1000], Loss: 0.5138\n",
      "Epoch [562/1000], Loss: 0.5119\n",
      "Epoch [563/1000], Loss: 0.5110\n",
      "Epoch [564/1000], Loss: 0.5138\n",
      "Epoch [565/1000], Loss: 0.5119\n",
      "Epoch [566/1000], Loss: 0.5119\n",
      "Epoch [567/1000], Loss: 0.5133\n",
      "Epoch [568/1000], Loss: 0.5117\n",
      "Epoch [569/1000], Loss: 0.5114\n",
      "Epoch [570/1000], Loss: 0.5124\n",
      "Epoch [571/1000], Loss: 0.5131\n",
      "Epoch [572/1000], Loss: 0.5136\n",
      "Epoch [573/1000], Loss: 0.5126\n",
      "Epoch [574/1000], Loss: 0.5124\n",
      "Epoch [575/1000], Loss: 0.5140\n",
      "Epoch [576/1000], Loss: 0.5157\n",
      "Epoch [577/1000], Loss: 0.5114\n",
      "Epoch [578/1000], Loss: 0.5143\n",
      "Epoch [579/1000], Loss: 0.5121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [580/1000], Loss: 0.5138\n",
      "Epoch [581/1000], Loss: 0.5121\n",
      "Epoch [582/1000], Loss: 0.5114\n",
      "Epoch [583/1000], Loss: 0.5112\n",
      "Epoch [584/1000], Loss: 0.5112\n",
      "Epoch [585/1000], Loss: 0.5148\n",
      "Epoch [586/1000], Loss: 0.5145\n",
      "Epoch [587/1000], Loss: 0.5143\n",
      "Epoch [588/1000], Loss: 0.5136\n",
      "Epoch [589/1000], Loss: 0.5100\n",
      "Epoch [590/1000], Loss: 0.5119\n",
      "Epoch [591/1000], Loss: 0.5129\n",
      "Epoch [592/1000], Loss: 0.5124\n",
      "Epoch [593/1000], Loss: 0.5126\n",
      "Epoch [594/1000], Loss: 0.5117\n",
      "Epoch [595/1000], Loss: 0.5129\n",
      "Epoch [596/1000], Loss: 0.5112\n",
      "Epoch [597/1000], Loss: 0.5121\n",
      "Epoch [598/1000], Loss: 0.5143\n",
      "Epoch [599/1000], Loss: 0.5133\n",
      "Epoch [600/1000], Loss: 0.5121\n",
      "Epoch [601/1000], Loss: 0.5121\n",
      "Epoch [602/1000], Loss: 0.5107\n",
      "Epoch [603/1000], Loss: 0.5133\n",
      "Epoch [604/1000], Loss: 0.5114\n",
      "Epoch [605/1000], Loss: 0.5126\n",
      "Epoch [606/1000], Loss: 0.5131\n",
      "Epoch [607/1000], Loss: 0.5140\n",
      "Epoch [608/1000], Loss: 0.5131\n",
      "Epoch [609/1000], Loss: 0.5136\n",
      "Epoch [610/1000], Loss: 0.5126\n",
      "Epoch [611/1000], Loss: 0.5133\n",
      "Epoch [612/1000], Loss: 0.5119\n",
      "Epoch [613/1000], Loss: 0.5117\n",
      "Epoch [614/1000], Loss: 0.5107\n",
      "Epoch [615/1000], Loss: 0.5124\n",
      "Epoch [616/1000], Loss: 0.5110\n",
      "Epoch [617/1000], Loss: 0.5155\n",
      "Epoch [618/1000], Loss: 0.5126\n",
      "Epoch [619/1000], Loss: 0.5102\n",
      "Epoch [620/1000], Loss: 0.5119\n",
      "Epoch [621/1000], Loss: 0.5126\n",
      "Epoch [622/1000], Loss: 0.5105\n",
      "Epoch [623/1000], Loss: 0.5121\n",
      "Epoch [624/1000], Loss: 0.5138\n",
      "Epoch [625/1000], Loss: 0.5114\n",
      "Epoch [626/1000], Loss: 0.5114\n",
      "Epoch [627/1000], Loss: 0.5133\n",
      "Epoch [628/1000], Loss: 0.5150\n",
      "Epoch [629/1000], Loss: 0.5119\n",
      "Epoch [630/1000], Loss: 0.5133\n",
      "Epoch [631/1000], Loss: 0.5133\n",
      "Epoch [632/1000], Loss: 0.5131\n",
      "Epoch [633/1000], Loss: 0.5126\n",
      "Epoch [634/1000], Loss: 0.5126\n",
      "Epoch [635/1000], Loss: 0.5124\n",
      "Epoch [636/1000], Loss: 0.5110\n",
      "Epoch [637/1000], Loss: 0.5129\n",
      "Epoch [638/1000], Loss: 0.5117\n",
      "Epoch [639/1000], Loss: 0.5136\n",
      "Epoch [640/1000], Loss: 0.5129\n",
      "Epoch [641/1000], Loss: 0.5129\n",
      "Epoch [642/1000], Loss: 0.5138\n",
      "Epoch [643/1000], Loss: 0.5126\n",
      "Epoch [644/1000], Loss: 0.5119\n",
      "Epoch [645/1000], Loss: 0.5121\n",
      "Epoch [646/1000], Loss: 0.5126\n",
      "Epoch [647/1000], Loss: 0.5114\n",
      "Epoch [648/1000], Loss: 0.5140\n",
      "Epoch [649/1000], Loss: 0.5124\n",
      "Epoch [650/1000], Loss: 0.5119\n",
      "Epoch [651/1000], Loss: 0.5121\n",
      "Epoch [652/1000], Loss: 0.5126\n",
      "Epoch [653/1000], Loss: 0.5121\n",
      "Epoch [654/1000], Loss: 0.5121\n",
      "Epoch [655/1000], Loss: 0.5143\n",
      "Epoch [656/1000], Loss: 0.5129\n",
      "Epoch [657/1000], Loss: 0.5110\n",
      "Epoch [658/1000], Loss: 0.5112\n",
      "Epoch [659/1000], Loss: 0.5133\n",
      "Epoch [660/1000], Loss: 0.5148\n",
      "Epoch [661/1000], Loss: 0.5131\n",
      "Epoch [662/1000], Loss: 0.5110\n",
      "Epoch [663/1000], Loss: 0.5140\n",
      "Epoch [664/1000], Loss: 0.5136\n",
      "Epoch [665/1000], Loss: 0.5148\n",
      "Epoch [666/1000], Loss: 0.5126\n",
      "Epoch [667/1000], Loss: 0.5119\n",
      "Epoch [668/1000], Loss: 0.5138\n",
      "Epoch [669/1000], Loss: 0.5110\n",
      "Epoch [670/1000], Loss: 0.5136\n",
      "Epoch [671/1000], Loss: 0.5117\n",
      "Epoch [672/1000], Loss: 0.5114\n",
      "Epoch [673/1000], Loss: 0.5105\n",
      "Epoch [674/1000], Loss: 0.5138\n",
      "Epoch [675/1000], Loss: 0.5140\n",
      "Epoch [676/1000], Loss: 0.5107\n",
      "Epoch [677/1000], Loss: 0.5126\n",
      "Epoch [678/1000], Loss: 0.5136\n",
      "Epoch [679/1000], Loss: 0.5136\n",
      "Epoch [680/1000], Loss: 0.5140\n",
      "Epoch [681/1000], Loss: 0.5129\n",
      "Epoch [682/1000], Loss: 0.5105\n",
      "Epoch [683/1000], Loss: 0.5121\n",
      "Epoch [684/1000], Loss: 0.5138\n",
      "Epoch [685/1000], Loss: 0.5129\n",
      "Epoch [686/1000], Loss: 0.5124\n",
      "Epoch [687/1000], Loss: 0.5155\n",
      "Epoch [688/1000], Loss: 0.5138\n",
      "Epoch [689/1000], Loss: 0.5133\n",
      "Epoch [690/1000], Loss: 0.5119\n",
      "Epoch [691/1000], Loss: 0.5124\n",
      "Epoch [692/1000], Loss: 0.5124\n",
      "Epoch [693/1000], Loss: 0.5119\n",
      "Epoch [694/1000], Loss: 0.5136\n",
      "Epoch [695/1000], Loss: 0.5124\n",
      "Epoch [696/1000], Loss: 0.5119\n",
      "Epoch [697/1000], Loss: 0.5136\n",
      "Epoch [698/1000], Loss: 0.5148\n",
      "Epoch [699/1000], Loss: 0.5140\n",
      "Epoch [700/1000], Loss: 0.5131\n",
      "Epoch [701/1000], Loss: 0.5150\n",
      "Epoch [702/1000], Loss: 0.5145\n",
      "Epoch [703/1000], Loss: 0.5119\n",
      "Epoch [704/1000], Loss: 0.5117\n",
      "Epoch [705/1000], Loss: 0.5136\n",
      "Epoch [706/1000], Loss: 0.5148\n",
      "Epoch [707/1000], Loss: 0.5129\n",
      "Epoch [708/1000], Loss: 0.5117\n",
      "Epoch [709/1000], Loss: 0.5100\n",
      "Epoch [710/1000], Loss: 0.5136\n",
      "Epoch [711/1000], Loss: 0.5124\n",
      "Epoch [712/1000], Loss: 0.5112\n",
      "Epoch [713/1000], Loss: 0.5102\n",
      "Epoch [714/1000], Loss: 0.5117\n",
      "Epoch [715/1000], Loss: 0.5117\n",
      "Epoch [716/1000], Loss: 0.5124\n",
      "Epoch [717/1000], Loss: 0.5145\n",
      "Epoch [718/1000], Loss: 0.5145\n",
      "Epoch [719/1000], Loss: 0.5114\n",
      "Epoch [720/1000], Loss: 0.5129\n",
      "Epoch [721/1000], Loss: 0.5124\n",
      "Epoch [722/1000], Loss: 0.5119\n",
      "Epoch [723/1000], Loss: 0.5126\n",
      "Epoch [724/1000], Loss: 0.5133\n",
      "Epoch [725/1000], Loss: 0.5121\n",
      "Epoch [726/1000], Loss: 0.5126\n",
      "Epoch [727/1000], Loss: 0.5095\n",
      "Epoch [728/1000], Loss: 0.5143\n",
      "Epoch [729/1000], Loss: 0.5119\n",
      "Epoch [730/1000], Loss: 0.5124\n",
      "Epoch [731/1000], Loss: 0.5117\n",
      "Epoch [732/1000], Loss: 0.5140\n",
      "Epoch [733/1000], Loss: 0.5131\n",
      "Epoch [734/1000], Loss: 0.5129\n",
      "Epoch [735/1000], Loss: 0.5107\n",
      "Epoch [736/1000], Loss: 0.5112\n",
      "Epoch [737/1000], Loss: 0.5126\n",
      "Epoch [738/1000], Loss: 0.5117\n",
      "Epoch [739/1000], Loss: 0.5119\n",
      "Epoch [740/1000], Loss: 0.5110\n",
      "Epoch [741/1000], Loss: 0.5110\n",
      "Epoch [742/1000], Loss: 0.5133\n",
      "Epoch [743/1000], Loss: 0.5150\n",
      "Epoch [744/1000], Loss: 0.5136\n",
      "Epoch [745/1000], Loss: 0.5110\n",
      "Epoch [746/1000], Loss: 0.5138\n",
      "Epoch [747/1000], Loss: 0.5124\n",
      "Epoch [748/1000], Loss: 0.5136\n",
      "Epoch [749/1000], Loss: 0.5138\n",
      "Epoch [750/1000], Loss: 0.5133\n",
      "Epoch [751/1000], Loss: 0.5131\n",
      "Epoch [752/1000], Loss: 0.5148\n",
      "Epoch [753/1000], Loss: 0.5107\n",
      "Epoch [754/1000], Loss: 0.5133\n",
      "Epoch [755/1000], Loss: 0.5126\n",
      "Epoch [756/1000], Loss: 0.5110\n",
      "Epoch [757/1000], Loss: 0.5138\n",
      "Epoch [758/1000], Loss: 0.5119\n",
      "Epoch [759/1000], Loss: 0.5117\n",
      "Epoch [760/1000], Loss: 0.5129\n",
      "Epoch [761/1000], Loss: 0.5126\n",
      "Epoch [762/1000], Loss: 0.5107\n",
      "Epoch [763/1000], Loss: 0.5114\n",
      "Epoch [764/1000], Loss: 0.5133\n",
      "Epoch [765/1000], Loss: 0.5119\n",
      "Epoch [766/1000], Loss: 0.5121\n",
      "Epoch [767/1000], Loss: 0.5157\n",
      "Epoch [768/1000], Loss: 0.5119\n",
      "Epoch [769/1000], Loss: 0.5107\n",
      "Epoch [770/1000], Loss: 0.5131\n",
      "Epoch [771/1000], Loss: 0.5129\n",
      "Epoch [772/1000], Loss: 0.5114\n",
      "Epoch [773/1000], Loss: 0.5121\n",
      "Epoch [774/1000], Loss: 0.5124\n",
      "Epoch [775/1000], Loss: 0.5124\n",
      "Epoch [776/1000], Loss: 0.5121\n",
      "Epoch [777/1000], Loss: 0.5121\n",
      "Epoch [778/1000], Loss: 0.5098\n",
      "Epoch [779/1000], Loss: 0.5140\n",
      "Epoch [780/1000], Loss: 0.5138\n",
      "Epoch [781/1000], Loss: 0.5138\n",
      "Epoch [782/1000], Loss: 0.5140\n",
      "Epoch [783/1000], Loss: 0.5133\n",
      "Epoch [784/1000], Loss: 0.5140\n",
      "Epoch [785/1000], Loss: 0.5107\n",
      "Epoch [786/1000], Loss: 0.5119\n",
      "Epoch [787/1000], Loss: 0.5126\n",
      "Epoch [788/1000], Loss: 0.5131\n",
      "Epoch [789/1000], Loss: 0.5117\n",
      "Epoch [790/1000], Loss: 0.5138\n",
      "Epoch [791/1000], Loss: 0.5114\n",
      "Epoch [792/1000], Loss: 0.5114\n",
      "Epoch [793/1000], Loss: 0.5136\n",
      "Epoch [794/1000], Loss: 0.5150\n",
      "Epoch [795/1000], Loss: 0.5119\n",
      "Epoch [796/1000], Loss: 0.5129\n",
      "Epoch [797/1000], Loss: 0.5121\n",
      "Epoch [798/1000], Loss: 0.5112\n",
      "Epoch [799/1000], Loss: 0.5152\n",
      "Epoch [800/1000], Loss: 0.5133\n",
      "Epoch [801/1000], Loss: 0.5124\n",
      "Epoch [802/1000], Loss: 0.5145\n",
      "Epoch [803/1000], Loss: 0.5119\n",
      "Epoch [804/1000], Loss: 0.5131\n",
      "Epoch [805/1000], Loss: 0.5140\n",
      "Epoch [806/1000], Loss: 0.5117\n",
      "Epoch [807/1000], Loss: 0.5129\n",
      "Epoch [808/1000], Loss: 0.5143\n",
      "Epoch [809/1000], Loss: 0.5143\n",
      "Epoch [810/1000], Loss: 0.5138\n",
      "Epoch [811/1000], Loss: 0.5107\n",
      "Epoch [812/1000], Loss: 0.5126\n",
      "Epoch [813/1000], Loss: 0.5121\n",
      "Epoch [814/1000], Loss: 0.5143\n",
      "Epoch [815/1000], Loss: 0.5100\n",
      "Epoch [816/1000], Loss: 0.5119\n",
      "Epoch [817/1000], Loss: 0.5124\n",
      "Epoch [818/1000], Loss: 0.5133\n",
      "Epoch [819/1000], Loss: 0.5117\n",
      "Epoch [820/1000], Loss: 0.5126\n",
      "Epoch [821/1000], Loss: 0.5136\n",
      "Epoch [822/1000], Loss: 0.5117\n",
      "Epoch [823/1000], Loss: 0.5124\n",
      "Epoch [824/1000], Loss: 0.5145\n",
      "Epoch [825/1000], Loss: 0.5119\n",
      "Epoch [826/1000], Loss: 0.5119\n",
      "Epoch [827/1000], Loss: 0.5119\n",
      "Epoch [828/1000], Loss: 0.5117\n",
      "Epoch [829/1000], Loss: 0.5131\n",
      "Epoch [830/1000], Loss: 0.5145\n",
      "Epoch [831/1000], Loss: 0.5131\n",
      "Epoch [832/1000], Loss: 0.5102\n",
      "Epoch [833/1000], Loss: 0.5143\n",
      "Epoch [834/1000], Loss: 0.5110\n",
      "Epoch [835/1000], Loss: 0.5117\n",
      "Epoch [836/1000], Loss: 0.5136\n",
      "Epoch [837/1000], Loss: 0.5121\n",
      "Epoch [838/1000], Loss: 0.5107\n",
      "Epoch [839/1000], Loss: 0.5138\n",
      "Epoch [840/1000], Loss: 0.5133\n",
      "Epoch [841/1000], Loss: 0.5119\n",
      "Epoch [842/1000], Loss: 0.5107\n",
      "Epoch [843/1000], Loss: 0.5124\n",
      "Epoch [844/1000], Loss: 0.5129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [845/1000], Loss: 0.5148\n",
      "Epoch [846/1000], Loss: 0.5126\n",
      "Epoch [847/1000], Loss: 0.5148\n",
      "Epoch [848/1000], Loss: 0.5150\n",
      "Epoch [849/1000], Loss: 0.5129\n",
      "Epoch [850/1000], Loss: 0.5119\n",
      "Epoch [851/1000], Loss: 0.5124\n",
      "Epoch [852/1000], Loss: 0.5102\n",
      "Epoch [853/1000], Loss: 0.5136\n",
      "Epoch [854/1000], Loss: 0.5112\n",
      "Epoch [855/1000], Loss: 0.5129\n",
      "Epoch [856/1000], Loss: 0.5110\n",
      "Epoch [857/1000], Loss: 0.5102\n",
      "Epoch [858/1000], Loss: 0.5102\n",
      "Epoch [859/1000], Loss: 0.5131\n",
      "Epoch [860/1000], Loss: 0.5117\n",
      "Epoch [861/1000], Loss: 0.5129\n",
      "Epoch [862/1000], Loss: 0.5126\n",
      "Epoch [863/1000], Loss: 0.5114\n",
      "Epoch [864/1000], Loss: 0.5121\n",
      "Epoch [865/1000], Loss: 0.5140\n",
      "Epoch [866/1000], Loss: 0.5110\n",
      "Epoch [867/1000], Loss: 0.5138\n",
      "Epoch [868/1000], Loss: 0.5152\n",
      "Epoch [869/1000], Loss: 0.5148\n",
      "Epoch [870/1000], Loss: 0.5129\n",
      "Epoch [871/1000], Loss: 0.5138\n",
      "Epoch [872/1000], Loss: 0.5138\n",
      "Epoch [873/1000], Loss: 0.5117\n",
      "Epoch [874/1000], Loss: 0.5124\n",
      "Epoch [875/1000], Loss: 0.5119\n",
      "Epoch [876/1000], Loss: 0.5114\n",
      "Epoch [877/1000], Loss: 0.5133\n",
      "Epoch [878/1000], Loss: 0.5133\n",
      "Epoch [879/1000], Loss: 0.5098\n",
      "Epoch [880/1000], Loss: 0.5114\n",
      "Epoch [881/1000], Loss: 0.5129\n",
      "Epoch [882/1000], Loss: 0.5100\n",
      "Epoch [883/1000], Loss: 0.5129\n",
      "Epoch [884/1000], Loss: 0.5110\n",
      "Epoch [885/1000], Loss: 0.5112\n",
      "Epoch [886/1000], Loss: 0.5119\n",
      "Epoch [887/1000], Loss: 0.5105\n",
      "Epoch [888/1000], Loss: 0.5136\n",
      "Epoch [889/1000], Loss: 0.5143\n",
      "Epoch [890/1000], Loss: 0.5131\n",
      "Epoch [891/1000], Loss: 0.5100\n",
      "Epoch [892/1000], Loss: 0.5121\n",
      "Epoch [893/1000], Loss: 0.5126\n",
      "Epoch [894/1000], Loss: 0.5117\n",
      "Epoch [895/1000], Loss: 0.5112\n",
      "Epoch [896/1000], Loss: 0.5112\n",
      "Epoch [897/1000], Loss: 0.5129\n",
      "Epoch [898/1000], Loss: 0.5090\n",
      "Epoch [899/1000], Loss: 0.5121\n",
      "Epoch [900/1000], Loss: 0.5131\n",
      "Epoch [901/1000], Loss: 0.5119\n",
      "Epoch [902/1000], Loss: 0.5121\n",
      "Epoch [903/1000], Loss: 0.5129\n",
      "Epoch [904/1000], Loss: 0.5090\n",
      "Epoch [905/1000], Loss: 0.5117\n",
      "Epoch [906/1000], Loss: 0.5121\n",
      "Epoch [907/1000], Loss: 0.5117\n",
      "Epoch [908/1000], Loss: 0.5121\n",
      "Epoch [909/1000], Loss: 0.5119\n",
      "Epoch [910/1000], Loss: 0.5107\n",
      "Epoch [911/1000], Loss: 0.5117\n",
      "Epoch [912/1000], Loss: 0.5129\n",
      "Epoch [913/1000], Loss: 0.5133\n",
      "Epoch [914/1000], Loss: 0.5136\n",
      "Epoch [915/1000], Loss: 0.5133\n",
      "Epoch [916/1000], Loss: 0.5114\n",
      "Epoch [917/1000], Loss: 0.5114\n",
      "Epoch [918/1000], Loss: 0.5124\n",
      "Epoch [919/1000], Loss: 0.5112\n",
      "Epoch [920/1000], Loss: 0.5102\n",
      "Epoch [921/1000], Loss: 0.5119\n",
      "Epoch [922/1000], Loss: 0.5119\n",
      "Epoch [923/1000], Loss: 0.5133\n",
      "Epoch [924/1000], Loss: 0.5133\n",
      "Epoch [925/1000], Loss: 0.5110\n",
      "Epoch [926/1000], Loss: 0.5143\n",
      "Epoch [927/1000], Loss: 0.5119\n",
      "Epoch [928/1000], Loss: 0.5105\n",
      "Epoch [929/1000], Loss: 0.5136\n",
      "Epoch [930/1000], Loss: 0.5117\n",
      "Epoch [931/1000], Loss: 0.5124\n",
      "Epoch [932/1000], Loss: 0.5140\n",
      "Epoch [933/1000], Loss: 0.5124\n",
      "Epoch [934/1000], Loss: 0.5117\n",
      "Epoch [935/1000], Loss: 0.5133\n",
      "Epoch [936/1000], Loss: 0.5112\n",
      "Epoch [937/1000], Loss: 0.5119\n",
      "Epoch [938/1000], Loss: 0.5133\n",
      "Epoch [939/1000], Loss: 0.5143\n",
      "Epoch [940/1000], Loss: 0.5121\n",
      "Epoch [941/1000], Loss: 0.5124\n",
      "Epoch [942/1000], Loss: 0.5124\n",
      "Epoch [943/1000], Loss: 0.5124\n",
      "Epoch [944/1000], Loss: 0.5152\n",
      "Epoch [945/1000], Loss: 0.5105\n",
      "Epoch [946/1000], Loss: 0.5114\n",
      "Epoch [947/1000], Loss: 0.5124\n",
      "Epoch [948/1000], Loss: 0.5131\n",
      "Epoch [949/1000], Loss: 0.5138\n",
      "Epoch [950/1000], Loss: 0.5129\n",
      "Epoch [951/1000], Loss: 0.5107\n",
      "Epoch [952/1000], Loss: 0.5133\n",
      "Epoch [953/1000], Loss: 0.5126\n",
      "Epoch [954/1000], Loss: 0.5136\n",
      "Epoch [955/1000], Loss: 0.5112\n",
      "Epoch [956/1000], Loss: 0.5129\n",
      "Epoch [957/1000], Loss: 0.5114\n",
      "Epoch [958/1000], Loss: 0.5136\n",
      "Epoch [959/1000], Loss: 0.5136\n",
      "Epoch [960/1000], Loss: 0.5124\n",
      "Epoch [961/1000], Loss: 0.5160\n",
      "Epoch [962/1000], Loss: 0.5119\n",
      "Epoch [963/1000], Loss: 0.5129\n",
      "Epoch [964/1000], Loss: 0.5114\n",
      "Epoch [965/1000], Loss: 0.5138\n",
      "Epoch [966/1000], Loss: 0.5114\n",
      "Epoch [967/1000], Loss: 0.5105\n",
      "Epoch [968/1000], Loss: 0.5124\n",
      "Epoch [969/1000], Loss: 0.5110\n",
      "Epoch [970/1000], Loss: 0.5114\n",
      "Epoch [971/1000], Loss: 0.5126\n",
      "Epoch [972/1000], Loss: 0.5129\n",
      "Epoch [973/1000], Loss: 0.5114\n",
      "Epoch [974/1000], Loss: 0.5138\n",
      "Epoch [975/1000], Loss: 0.5129\n",
      "Epoch [976/1000], Loss: 0.5114\n",
      "Epoch [977/1000], Loss: 0.5129\n",
      "Epoch [978/1000], Loss: 0.5129\n",
      "Epoch [979/1000], Loss: 0.5133\n",
      "Epoch [980/1000], Loss: 0.5114\n",
      "Epoch [981/1000], Loss: 0.5124\n",
      "Epoch [982/1000], Loss: 0.5110\n",
      "Epoch [983/1000], Loss: 0.5148\n",
      "Epoch [984/1000], Loss: 0.5124\n",
      "Epoch [985/1000], Loss: 0.5121\n",
      "Epoch [986/1000], Loss: 0.5119\n",
      "Epoch [987/1000], Loss: 0.5131\n",
      "Epoch [988/1000], Loss: 0.5148\n",
      "Epoch [989/1000], Loss: 0.5131\n",
      "Epoch [990/1000], Loss: 0.5124\n",
      "Epoch [991/1000], Loss: 0.5129\n",
      "Epoch [992/1000], Loss: 0.5119\n",
      "Epoch [993/1000], Loss: 0.5126\n",
      "Epoch [994/1000], Loss: 0.5150\n",
      "Epoch [995/1000], Loss: 0.5102\n",
      "Epoch [996/1000], Loss: 0.5131\n",
      "Epoch [997/1000], Loss: 0.5129\n",
      "Epoch [998/1000], Loss: 0.5131\n",
      "Epoch [999/1000], Loss: 0.5131\n",
      "Epoch [1000/1000], Loss: 0.5136\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 205, lr :0.1, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2513\n",
      "Epoch [2/1000], Loss: 0.2446\n",
      "Epoch [3/1000], Loss: 0.2425\n",
      "Epoch [4/1000], Loss: 0.2412\n",
      "Epoch [5/1000], Loss: 0.2407\n",
      "Epoch [6/1000], Loss: 0.2410\n",
      "Epoch [7/1000], Loss: 0.2400\n",
      "Epoch [8/1000], Loss: 0.2397\n",
      "Epoch [9/1000], Loss: 0.2397\n",
      "Epoch [10/1000], Loss: 0.2391\n",
      "Epoch [11/1000], Loss: 0.2381\n",
      "Epoch [12/1000], Loss: 0.2380\n",
      "Epoch [13/1000], Loss: 0.2378\n",
      "Epoch [14/1000], Loss: 0.2378\n",
      "Epoch [15/1000], Loss: 0.2375\n",
      "Epoch [16/1000], Loss: 0.2373\n",
      "Epoch [17/1000], Loss: 0.2375\n",
      "Epoch [18/1000], Loss: 0.2366\n",
      "Epoch [19/1000], Loss: 0.2368\n",
      "Epoch [20/1000], Loss: 0.2358\n",
      "Epoch [21/1000], Loss: 0.2361\n",
      "Epoch [22/1000], Loss: 0.2361\n",
      "Epoch [23/1000], Loss: 0.2354\n",
      "Epoch [24/1000], Loss: 0.2358\n",
      "Epoch [25/1000], Loss: 0.2356\n",
      "Epoch [26/1000], Loss: 0.2352\n",
      "Epoch [27/1000], Loss: 0.2345\n",
      "Epoch [28/1000], Loss: 0.2349\n",
      "Epoch [29/1000], Loss: 0.2340\n",
      "Epoch [30/1000], Loss: 0.2338\n",
      "Epoch [31/1000], Loss: 0.2336\n",
      "Epoch [32/1000], Loss: 0.2330\n",
      "Epoch [33/1000], Loss: 0.2329\n",
      "Epoch [34/1000], Loss: 0.2327\n",
      "Epoch [35/1000], Loss: 0.2331\n",
      "Epoch [36/1000], Loss: 0.2322\n",
      "Epoch [37/1000], Loss: 0.2323\n",
      "Epoch [38/1000], Loss: 0.2316\n",
      "Epoch [39/1000], Loss: 0.2319\n",
      "Epoch [40/1000], Loss: 0.2309\n",
      "Epoch [41/1000], Loss: 0.2312\n",
      "Epoch [42/1000], Loss: 0.2309\n",
      "Epoch [43/1000], Loss: 0.2300\n",
      "Epoch [44/1000], Loss: 0.2300\n",
      "Epoch [45/1000], Loss: 0.2300\n",
      "Epoch [46/1000], Loss: 0.2292\n",
      "Epoch [47/1000], Loss: 0.2291\n",
      "Epoch [48/1000], Loss: 0.2291\n",
      "Epoch [49/1000], Loss: 0.2284\n",
      "Epoch [50/1000], Loss: 0.2283\n",
      "Epoch [51/1000], Loss: 0.2277\n",
      "Epoch [52/1000], Loss: 0.2267\n",
      "Epoch [53/1000], Loss: 0.2263\n",
      "Epoch [54/1000], Loss: 0.2258\n",
      "Epoch [55/1000], Loss: 0.2250\n",
      "Epoch [56/1000], Loss: 0.2250\n",
      "Epoch [57/1000], Loss: 0.2242\n",
      "Epoch [58/1000], Loss: 0.2236\n",
      "Epoch [59/1000], Loss: 0.2232\n",
      "Epoch [60/1000], Loss: 0.2222\n",
      "Epoch [61/1000], Loss: 0.2215\n",
      "Epoch [62/1000], Loss: 0.2218\n",
      "Epoch [63/1000], Loss: 0.2206\n",
      "Epoch [64/1000], Loss: 0.2195\n",
      "Epoch [65/1000], Loss: 0.2190\n",
      "Epoch [66/1000], Loss: 0.2187\n",
      "Epoch [67/1000], Loss: 0.2175\n",
      "Epoch [68/1000], Loss: 0.2167\n",
      "Epoch [69/1000], Loss: 0.2158\n",
      "Epoch [70/1000], Loss: 0.2150\n",
      "Epoch [71/1000], Loss: 0.2143\n",
      "Epoch [72/1000], Loss: 0.2134\n",
      "Epoch [73/1000], Loss: 0.2126\n",
      "Epoch [74/1000], Loss: 0.2118\n",
      "Epoch [75/1000], Loss: 0.2109\n",
      "Epoch [76/1000], Loss: 0.2105\n",
      "Epoch [77/1000], Loss: 0.2095\n",
      "Epoch [78/1000], Loss: 0.2089\n",
      "Epoch [79/1000], Loss: 0.2073\n",
      "Epoch [80/1000], Loss: 0.2069\n",
      "Epoch [81/1000], Loss: 0.2061\n",
      "Epoch [82/1000], Loss: 0.2054\n",
      "Epoch [83/1000], Loss: 0.2039\n",
      "Epoch [84/1000], Loss: 0.2034\n",
      "Epoch [85/1000], Loss: 0.2027\n",
      "Epoch [86/1000], Loss: 0.2018\n",
      "Epoch [87/1000], Loss: 0.2001\n",
      "Epoch [88/1000], Loss: 0.2002\n",
      "Epoch [89/1000], Loss: 0.1987\n",
      "Epoch [90/1000], Loss: 0.1971\n",
      "Epoch [91/1000], Loss: 0.1976\n",
      "Epoch [92/1000], Loss: 0.1952\n",
      "Epoch [93/1000], Loss: 0.1961\n",
      "Epoch [94/1000], Loss: 0.1929\n",
      "Epoch [95/1000], Loss: 0.1926\n",
      "Epoch [96/1000], Loss: 0.1910\n",
      "Epoch [97/1000], Loss: 0.1901\n",
      "Epoch [98/1000], Loss: 0.1896\n",
      "Epoch [99/1000], Loss: 0.1886\n",
      "Epoch [100/1000], Loss: 0.1877\n",
      "Epoch [101/1000], Loss: 0.1867\n",
      "Epoch [102/1000], Loss: 0.1850\n",
      "Epoch [103/1000], Loss: 0.1854\n",
      "Epoch [104/1000], Loss: 0.1823\n",
      "Epoch [105/1000], Loss: 0.1819\n",
      "Epoch [106/1000], Loss: 0.1814\n",
      "Epoch [107/1000], Loss: 0.1791\n",
      "Epoch [108/1000], Loss: 0.1789\n",
      "Epoch [109/1000], Loss: 0.1778\n",
      "Epoch [110/1000], Loss: 0.1783\n",
      "Epoch [111/1000], Loss: 0.1765\n",
      "Epoch [112/1000], Loss: 0.1746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [113/1000], Loss: 0.1767\n",
      "Epoch [114/1000], Loss: 0.1747\n",
      "Epoch [115/1000], Loss: 0.1731\n",
      "Epoch [116/1000], Loss: 0.1731\n",
      "Epoch [117/1000], Loss: 0.1706\n",
      "Epoch [118/1000], Loss: 0.1687\n",
      "Epoch [119/1000], Loss: 0.1684\n",
      "Epoch [120/1000], Loss: 0.1690\n",
      "Epoch [121/1000], Loss: 0.1703\n",
      "Epoch [122/1000], Loss: 0.1655\n",
      "Epoch [123/1000], Loss: 0.1662\n",
      "Epoch [124/1000], Loss: 0.1634\n",
      "Epoch [125/1000], Loss: 0.1630\n",
      "Epoch [126/1000], Loss: 0.1624\n",
      "Epoch [127/1000], Loss: 0.1618\n",
      "Epoch [128/1000], Loss: 0.1592\n",
      "Epoch [129/1000], Loss: 0.1613\n",
      "Epoch [130/1000], Loss: 0.1595\n",
      "Epoch [131/1000], Loss: 0.1553\n",
      "Epoch [132/1000], Loss: 0.1567\n",
      "Epoch [133/1000], Loss: 0.1554\n",
      "Epoch [134/1000], Loss: 0.1523\n",
      "Epoch [135/1000], Loss: 0.1512\n",
      "Epoch [136/1000], Loss: 0.1489\n",
      "Epoch [137/1000], Loss: 0.1505\n",
      "Epoch [138/1000], Loss: 0.1464\n",
      "Epoch [139/1000], Loss: 0.1497\n",
      "Epoch [140/1000], Loss: 0.1435\n",
      "Epoch [141/1000], Loss: 0.1419\n",
      "Epoch [142/1000], Loss: 0.1427\n",
      "Epoch [143/1000], Loss: 0.1452\n",
      "Epoch [144/1000], Loss: 0.1419\n",
      "Epoch [145/1000], Loss: 0.1358\n",
      "Epoch [146/1000], Loss: 0.1412\n",
      "Epoch [147/1000], Loss: 0.1335\n",
      "Epoch [148/1000], Loss: 0.1304\n",
      "Epoch [149/1000], Loss: 0.1295\n",
      "Epoch [150/1000], Loss: 0.1265\n",
      "Epoch [151/1000], Loss: 0.1274\n",
      "Epoch [152/1000], Loss: 0.1186\n",
      "Epoch [153/1000], Loss: 0.1157\n",
      "Epoch [154/1000], Loss: 0.1164\n",
      "Epoch [155/1000], Loss: 0.1124\n",
      "Epoch [156/1000], Loss: 0.1123\n",
      "Epoch [157/1000], Loss: 0.1047\n",
      "Epoch [158/1000], Loss: 0.1079\n",
      "Epoch [159/1000], Loss: 0.1065\n",
      "Epoch [160/1000], Loss: 0.1045\n",
      "Epoch [161/1000], Loss: 0.1037\n",
      "Epoch [162/1000], Loss: 0.1007\n",
      "Epoch [163/1000], Loss: 0.1021\n",
      "Epoch [164/1000], Loss: 0.0881\n",
      "Epoch [165/1000], Loss: 0.0951\n",
      "Epoch [166/1000], Loss: 0.0877\n",
      "Epoch [167/1000], Loss: 0.0879\n",
      "Epoch [168/1000], Loss: 0.0802\n",
      "Epoch [169/1000], Loss: 0.0891\n",
      "Epoch [170/1000], Loss: 0.0874\n",
      "Epoch [171/1000], Loss: 0.0792\n",
      "Epoch [172/1000], Loss: 0.0725\n",
      "Epoch [173/1000], Loss: 0.0642\n",
      "Epoch [174/1000], Loss: 0.0693\n",
      "Epoch [175/1000], Loss: 0.0753\n",
      "Epoch [176/1000], Loss: 0.0685\n",
      "Epoch [177/1000], Loss: 0.0619\n",
      "Epoch [178/1000], Loss: 0.0598\n",
      "Epoch [179/1000], Loss: 0.0488\n",
      "Epoch [180/1000], Loss: 0.0520\n",
      "Epoch [181/1000], Loss: 0.0533\n",
      "Epoch [182/1000], Loss: 0.0622\n",
      "Epoch [183/1000], Loss: 0.0482\n",
      "Epoch [184/1000], Loss: 0.0473\n",
      "Epoch [185/1000], Loss: 0.0547\n",
      "Epoch [186/1000], Loss: 0.0540\n",
      "Epoch [187/1000], Loss: 0.0357\n",
      "Epoch [188/1000], Loss: 0.0494\n",
      "Epoch [189/1000], Loss: 0.0369\n",
      "Epoch [190/1000], Loss: 0.0440\n",
      "Epoch [191/1000], Loss: 0.0439\n",
      "Epoch [192/1000], Loss: 0.0465\n",
      "Epoch [193/1000], Loss: 0.0371\n",
      "Epoch [194/1000], Loss: 0.0314\n",
      "Epoch [195/1000], Loss: 0.0317\n",
      "Epoch [196/1000], Loss: 0.0369\n",
      "Epoch [197/1000], Loss: 0.0505\n",
      "Epoch [198/1000], Loss: 0.0270\n",
      "Epoch [199/1000], Loss: 0.0314\n",
      "Epoch [200/1000], Loss: 0.0292\n",
      "Epoch [201/1000], Loss: 0.0325\n",
      "Epoch [202/1000], Loss: 0.0220\n",
      "Epoch [203/1000], Loss: 0.0172\n",
      "Epoch [204/1000], Loss: 0.0164\n",
      "Epoch [205/1000], Loss: 0.0432\n",
      "Epoch [206/1000], Loss: 0.0265\n",
      "Epoch [207/1000], Loss: 0.0254\n",
      "Epoch [208/1000], Loss: 0.0145\n",
      "Epoch [209/1000], Loss: 0.0331\n",
      "Epoch [210/1000], Loss: 0.0203\n",
      "Epoch [211/1000], Loss: 0.0212\n",
      "Epoch [212/1000], Loss: 0.0299\n",
      "Epoch [213/1000], Loss: 0.0155\n",
      "Epoch [214/1000], Loss: 0.0130\n",
      "Epoch [215/1000], Loss: 0.0166\n",
      "Epoch [216/1000], Loss: 0.0116\n",
      "Epoch [217/1000], Loss: 0.0121\n",
      "Epoch [218/1000], Loss: 0.0166\n",
      "Epoch [219/1000], Loss: 0.0119\n",
      "Epoch [220/1000], Loss: 0.0303\n",
      "Epoch [221/1000], Loss: 0.0103\n",
      "Epoch [222/1000], Loss: 0.0114\n",
      "Epoch [223/1000], Loss: 0.0097\n",
      "Epoch [224/1000], Loss: 0.0095\n",
      "Epoch [225/1000], Loss: 0.0095\n",
      "Epoch [226/1000], Loss: 0.0142\n",
      "Epoch [227/1000], Loss: 0.0198\n",
      "Epoch [228/1000], Loss: 0.0087\n",
      "Epoch [229/1000], Loss: 0.0086\n",
      "Epoch [230/1000], Loss: 0.0082\n",
      "Epoch [231/1000], Loss: 0.0083\n",
      "Epoch [232/1000], Loss: 0.0083\n",
      "Epoch [233/1000], Loss: 0.0082\n",
      "Epoch [234/1000], Loss: 0.0230\n",
      "Epoch [235/1000], Loss: 0.0177\n",
      "Epoch [236/1000], Loss: 0.0075\n",
      "Epoch [237/1000], Loss: 0.0072\n",
      "Epoch [238/1000], Loss: 0.0075\n",
      "Epoch [239/1000], Loss: 0.0069\n",
      "Epoch [240/1000], Loss: 0.0066\n",
      "Epoch [241/1000], Loss: 0.0067\n",
      "Epoch [242/1000], Loss: 0.0065\n",
      "Epoch [243/1000], Loss: 0.0063\n",
      "Epoch [244/1000], Loss: 0.0064\n",
      "Epoch [245/1000], Loss: 0.0062\n",
      "Epoch [246/1000], Loss: 0.0060\n",
      "Epoch [247/1000], Loss: 0.0061\n",
      "Epoch [248/1000], Loss: 0.0060\n",
      "Epoch [249/1000], Loss: 0.0059\n",
      "Epoch [250/1000], Loss: 0.0059\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 98.50 %\n",
      "Training model with batch_size: 205, lr :1.0, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.4968\n",
      "Epoch [2/1000], Loss: 0.5143\n",
      "Epoch [3/1000], Loss: 0.5145\n",
      "Epoch [4/1000], Loss: 0.5126\n",
      "Epoch [5/1000], Loss: 0.5131\n",
      "Epoch [6/1000], Loss: 0.5105\n",
      "Epoch [7/1000], Loss: 0.5140\n",
      "Epoch [8/1000], Loss: 0.5126\n",
      "Epoch [9/1000], Loss: 0.5131\n",
      "Epoch [10/1000], Loss: 0.5129\n",
      "Epoch [11/1000], Loss: 0.5119\n",
      "Epoch [12/1000], Loss: 0.5133\n",
      "Epoch [13/1000], Loss: 0.5114\n",
      "Epoch [14/1000], Loss: 0.5138\n",
      "Epoch [15/1000], Loss: 0.5105\n",
      "Epoch [16/1000], Loss: 0.5145\n",
      "Epoch [17/1000], Loss: 0.5114\n",
      "Epoch [18/1000], Loss: 0.5126\n",
      "Epoch [19/1000], Loss: 0.5157\n",
      "Epoch [20/1000], Loss: 0.5129\n",
      "Epoch [21/1000], Loss: 0.5121\n",
      "Epoch [22/1000], Loss: 0.5133\n",
      "Epoch [23/1000], Loss: 0.5136\n",
      "Epoch [24/1000], Loss: 0.5114\n",
      "Epoch [25/1000], Loss: 0.5117\n",
      "Epoch [26/1000], Loss: 0.5124\n",
      "Epoch [27/1000], Loss: 0.5121\n",
      "Epoch [28/1000], Loss: 0.5112\n",
      "Epoch [29/1000], Loss: 0.5124\n",
      "Epoch [30/1000], Loss: 0.5112\n",
      "Epoch [31/1000], Loss: 0.5148\n",
      "Epoch [32/1000], Loss: 0.5140\n",
      "Epoch [33/1000], Loss: 0.5121\n",
      "Epoch [34/1000], Loss: 0.5136\n",
      "Epoch [35/1000], Loss: 0.5117\n",
      "Epoch [36/1000], Loss: 0.5117\n",
      "Epoch [37/1000], Loss: 0.5117\n",
      "Epoch [38/1000], Loss: 0.5131\n",
      "Epoch [39/1000], Loss: 0.5112\n",
      "Epoch [40/1000], Loss: 0.5131\n",
      "Epoch [41/1000], Loss: 0.5112\n",
      "Epoch [42/1000], Loss: 0.5121\n",
      "Epoch [43/1000], Loss: 0.5107\n",
      "Epoch [44/1000], Loss: 0.5136\n",
      "Epoch [45/1000], Loss: 0.5129\n",
      "Epoch [46/1000], Loss: 0.5152\n",
      "Epoch [47/1000], Loss: 0.5124\n",
      "Epoch [48/1000], Loss: 0.5126\n",
      "Epoch [49/1000], Loss: 0.5133\n",
      "Epoch [50/1000], Loss: 0.5136\n",
      "Epoch [51/1000], Loss: 0.5121\n",
      "Epoch [52/1000], Loss: 0.5119\n",
      "Epoch [53/1000], Loss: 0.5138\n",
      "Epoch [54/1000], Loss: 0.5126\n",
      "Epoch [55/1000], Loss: 0.5148\n",
      "Epoch [56/1000], Loss: 0.5136\n",
      "Epoch [57/1000], Loss: 0.5117\n",
      "Epoch [58/1000], Loss: 0.5126\n",
      "Epoch [59/1000], Loss: 0.5102\n",
      "Epoch [60/1000], Loss: 0.5150\n",
      "Epoch [61/1000], Loss: 0.5121\n",
      "Epoch [62/1000], Loss: 0.5143\n",
      "Epoch [63/1000], Loss: 0.5102\n",
      "Epoch [64/1000], Loss: 0.5126\n",
      "Epoch [65/1000], Loss: 0.5136\n",
      "Epoch [66/1000], Loss: 0.5107\n",
      "Epoch [67/1000], Loss: 0.5136\n",
      "Epoch [68/1000], Loss: 0.5112\n",
      "Epoch [69/1000], Loss: 0.5136\n",
      "Epoch [70/1000], Loss: 0.5140\n",
      "Epoch [71/1000], Loss: 0.5124\n",
      "Epoch [72/1000], Loss: 0.5131\n",
      "Epoch [73/1000], Loss: 0.5121\n",
      "Epoch [74/1000], Loss: 0.5136\n",
      "Epoch [75/1000], Loss: 0.5110\n",
      "Epoch [76/1000], Loss: 0.5126\n",
      "Epoch [77/1000], Loss: 0.5121\n",
      "Epoch [78/1000], Loss: 0.5114\n",
      "Epoch [79/1000], Loss: 0.5114\n",
      "Epoch [80/1000], Loss: 0.5129\n",
      "Epoch [81/1000], Loss: 0.5117\n",
      "Epoch [82/1000], Loss: 0.5126\n",
      "Epoch [83/1000], Loss: 0.5126\n",
      "Epoch [84/1000], Loss: 0.5117\n",
      "Epoch [85/1000], Loss: 0.5150\n",
      "Epoch [86/1000], Loss: 0.5143\n",
      "Epoch [87/1000], Loss: 0.5121\n",
      "Epoch [88/1000], Loss: 0.5131\n",
      "Epoch [89/1000], Loss: 0.5129\n",
      "Epoch [90/1000], Loss: 0.5136\n",
      "Epoch [91/1000], Loss: 0.5121\n",
      "Epoch [92/1000], Loss: 0.5117\n",
      "Epoch [93/1000], Loss: 0.5138\n",
      "Epoch [94/1000], Loss: 0.5124\n",
      "Epoch [95/1000], Loss: 0.5152\n",
      "Epoch [96/1000], Loss: 0.5121\n",
      "Epoch [97/1000], Loss: 0.5121\n",
      "Epoch [98/1000], Loss: 0.5110\n",
      "Epoch [99/1000], Loss: 0.5140\n",
      "Epoch [100/1000], Loss: 0.5150\n",
      "Epoch [101/1000], Loss: 0.5136\n",
      "Epoch [102/1000], Loss: 0.5131\n",
      "Epoch [103/1000], Loss: 0.5121\n",
      "Epoch [104/1000], Loss: 0.5121\n",
      "Epoch [105/1000], Loss: 0.5126\n",
      "Epoch [106/1000], Loss: 0.5131\n",
      "Epoch [107/1000], Loss: 0.5117\n",
      "Epoch [108/1000], Loss: 0.5110\n",
      "Epoch [109/1000], Loss: 0.5148\n",
      "Epoch [110/1000], Loss: 0.5124\n",
      "Epoch [111/1000], Loss: 0.5112\n",
      "Epoch [112/1000], Loss: 0.5110\n",
      "Epoch [113/1000], Loss: 0.5124\n",
      "Epoch [114/1000], Loss: 0.5105\n",
      "Epoch [115/1000], Loss: 0.5117\n",
      "Epoch [116/1000], Loss: 0.5117\n",
      "Epoch [117/1000], Loss: 0.5110\n",
      "Epoch [118/1000], Loss: 0.5119\n",
      "Epoch [119/1000], Loss: 0.5121\n",
      "Epoch [120/1000], Loss: 0.5124\n",
      "Epoch [121/1000], Loss: 0.5112\n",
      "Epoch [122/1000], Loss: 0.5114\n",
      "Epoch [123/1000], Loss: 0.5107\n",
      "Epoch [124/1000], Loss: 0.5140\n",
      "Epoch [125/1000], Loss: 0.5145\n",
      "Epoch [126/1000], Loss: 0.5126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [127/1000], Loss: 0.5143\n",
      "Epoch [128/1000], Loss: 0.5129\n",
      "Epoch [129/1000], Loss: 0.5119\n",
      "Epoch [130/1000], Loss: 0.5129\n",
      "Epoch [131/1000], Loss: 0.5107\n",
      "Epoch [132/1000], Loss: 0.5107\n",
      "Epoch [133/1000], Loss: 0.5136\n",
      "Epoch [134/1000], Loss: 0.5145\n",
      "Epoch [135/1000], Loss: 0.5131\n",
      "Epoch [136/1000], Loss: 0.5112\n",
      "Epoch [137/1000], Loss: 0.5105\n",
      "Epoch [138/1000], Loss: 0.5112\n",
      "Epoch [139/1000], Loss: 0.5124\n",
      "Epoch [140/1000], Loss: 0.5143\n",
      "Epoch [141/1000], Loss: 0.5114\n",
      "Epoch [142/1000], Loss: 0.5119\n",
      "Epoch [143/1000], Loss: 0.5129\n",
      "Epoch [144/1000], Loss: 0.5133\n",
      "Epoch [145/1000], Loss: 0.5133\n",
      "Epoch [146/1000], Loss: 0.5131\n",
      "Epoch [147/1000], Loss: 0.5112\n",
      "Epoch [148/1000], Loss: 0.5145\n",
      "Epoch [149/1000], Loss: 0.5102\n",
      "Epoch [150/1000], Loss: 0.5105\n",
      "Epoch [151/1000], Loss: 0.5129\n",
      "Epoch [152/1000], Loss: 0.5133\n",
      "Epoch [153/1000], Loss: 0.5129\n",
      "Epoch [154/1000], Loss: 0.5117\n",
      "Epoch [155/1000], Loss: 0.5129\n",
      "Epoch [156/1000], Loss: 0.5133\n",
      "Epoch [157/1000], Loss: 0.5114\n",
      "Epoch [158/1000], Loss: 0.5126\n",
      "Epoch [159/1000], Loss: 0.5105\n",
      "Epoch [160/1000], Loss: 0.5143\n",
      "Epoch [161/1000], Loss: 0.5124\n",
      "Epoch [162/1000], Loss: 0.5136\n",
      "Epoch [163/1000], Loss: 0.5155\n",
      "Epoch [164/1000], Loss: 0.5140\n",
      "Epoch [165/1000], Loss: 0.5131\n",
      "Epoch [166/1000], Loss: 0.5119\n",
      "Epoch [167/1000], Loss: 0.5129\n",
      "Epoch [168/1000], Loss: 0.5112\n",
      "Epoch [169/1000], Loss: 0.5140\n",
      "Epoch [170/1000], Loss: 0.5133\n",
      "Epoch [171/1000], Loss: 0.5136\n",
      "Epoch [172/1000], Loss: 0.5129\n",
      "Epoch [173/1000], Loss: 0.5110\n",
      "Epoch [174/1000], Loss: 0.5131\n",
      "Epoch [175/1000], Loss: 0.5124\n",
      "Epoch [176/1000], Loss: 0.5140\n",
      "Epoch [177/1000], Loss: 0.5143\n",
      "Epoch [178/1000], Loss: 0.5121\n",
      "Epoch [179/1000], Loss: 0.5150\n",
      "Epoch [180/1000], Loss: 0.5129\n",
      "Epoch [181/1000], Loss: 0.5119\n",
      "Epoch [182/1000], Loss: 0.5131\n",
      "Epoch [183/1000], Loss: 0.5136\n",
      "Epoch [184/1000], Loss: 0.5133\n",
      "Epoch [185/1000], Loss: 0.5119\n",
      "Epoch [186/1000], Loss: 0.5143\n",
      "Epoch [187/1000], Loss: 0.5133\n",
      "Epoch [188/1000], Loss: 0.5133\n",
      "Epoch [189/1000], Loss: 0.5119\n",
      "Epoch [190/1000], Loss: 0.5105\n",
      "Epoch [191/1000], Loss: 0.5119\n",
      "Epoch [192/1000], Loss: 0.5131\n",
      "Epoch [193/1000], Loss: 0.5119\n",
      "Epoch [194/1000], Loss: 0.5110\n",
      "Epoch [195/1000], Loss: 0.5107\n",
      "Epoch [196/1000], Loss: 0.5119\n",
      "Epoch [197/1000], Loss: 0.5117\n",
      "Epoch [198/1000], Loss: 0.5140\n",
      "Epoch [199/1000], Loss: 0.5121\n",
      "Epoch [200/1000], Loss: 0.5117\n",
      "Epoch [201/1000], Loss: 0.5136\n",
      "Epoch [202/1000], Loss: 0.5150\n",
      "Epoch [203/1000], Loss: 0.5129\n",
      "Epoch [204/1000], Loss: 0.5138\n",
      "Epoch [205/1000], Loss: 0.5112\n",
      "Epoch [206/1000], Loss: 0.5138\n",
      "Epoch [207/1000], Loss: 0.5112\n",
      "Epoch [208/1000], Loss: 0.5150\n",
      "Epoch [209/1000], Loss: 0.5107\n",
      "Epoch [210/1000], Loss: 0.5131\n",
      "Epoch [211/1000], Loss: 0.5124\n",
      "Epoch [212/1000], Loss: 0.5129\n",
      "Epoch [213/1000], Loss: 0.5148\n",
      "Epoch [214/1000], Loss: 0.5129\n",
      "Epoch [215/1000], Loss: 0.5117\n",
      "Epoch [216/1000], Loss: 0.5129\n",
      "Epoch [217/1000], Loss: 0.5129\n",
      "Epoch [218/1000], Loss: 0.5126\n",
      "Epoch [219/1000], Loss: 0.5143\n",
      "Epoch [220/1000], Loss: 0.5117\n",
      "Epoch [221/1000], Loss: 0.5140\n",
      "Epoch [222/1000], Loss: 0.5138\n",
      "Epoch [223/1000], Loss: 0.5117\n",
      "Epoch [224/1000], Loss: 0.5117\n",
      "Epoch [225/1000], Loss: 0.5160\n",
      "Epoch [226/1000], Loss: 0.5126\n",
      "Epoch [227/1000], Loss: 0.5131\n",
      "Epoch [228/1000], Loss: 0.5114\n",
      "Epoch [229/1000], Loss: 0.5143\n",
      "Epoch [230/1000], Loss: 0.5121\n",
      "Epoch [231/1000], Loss: 0.5124\n",
      "Epoch [232/1000], Loss: 0.5129\n",
      "Epoch [233/1000], Loss: 0.5129\n",
      "Epoch [234/1000], Loss: 0.5121\n",
      "Epoch [235/1000], Loss: 0.5102\n",
      "Epoch [236/1000], Loss: 0.5129\n",
      "Epoch [237/1000], Loss: 0.5126\n",
      "Epoch [238/1000], Loss: 0.5117\n",
      "Epoch [239/1000], Loss: 0.5131\n",
      "Epoch [240/1000], Loss: 0.5131\n",
      "Epoch [241/1000], Loss: 0.5126\n",
      "Epoch [242/1000], Loss: 0.5145\n",
      "Epoch [243/1000], Loss: 0.5112\n",
      "Epoch [244/1000], Loss: 0.5129\n",
      "Epoch [245/1000], Loss: 0.5119\n",
      "Epoch [246/1000], Loss: 0.5112\n",
      "Epoch [247/1000], Loss: 0.5136\n",
      "Epoch [248/1000], Loss: 0.5126\n",
      "Epoch [249/1000], Loss: 0.5129\n",
      "Epoch [250/1000], Loss: 0.5138\n",
      "Epoch [251/1000], Loss: 0.5110\n",
      "Epoch [252/1000], Loss: 0.5110\n",
      "Epoch [253/1000], Loss: 0.5138\n",
      "Epoch [254/1000], Loss: 0.5124\n",
      "Epoch [255/1000], Loss: 0.5131\n",
      "Epoch [256/1000], Loss: 0.5124\n",
      "Epoch [257/1000], Loss: 0.5095\n",
      "Epoch [258/1000], Loss: 0.5126\n",
      "Epoch [259/1000], Loss: 0.5119\n",
      "Epoch [260/1000], Loss: 0.5121\n",
      "Epoch [261/1000], Loss: 0.5124\n",
      "Epoch [262/1000], Loss: 0.5136\n",
      "Epoch [263/1000], Loss: 0.5129\n",
      "Epoch [264/1000], Loss: 0.5117\n",
      "Epoch [265/1000], Loss: 0.5121\n",
      "Epoch [266/1000], Loss: 0.5119\n",
      "Epoch [267/1000], Loss: 0.5133\n",
      "Epoch [268/1000], Loss: 0.5131\n",
      "Epoch [269/1000], Loss: 0.5121\n",
      "Epoch [270/1000], Loss: 0.5124\n",
      "Epoch [271/1000], Loss: 0.5112\n",
      "Epoch [272/1000], Loss: 0.5131\n",
      "Epoch [273/1000], Loss: 0.5112\n",
      "Epoch [274/1000], Loss: 0.5105\n",
      "Epoch [275/1000], Loss: 0.5119\n",
      "Epoch [276/1000], Loss: 0.5138\n",
      "Epoch [277/1000], Loss: 0.5105\n",
      "Epoch [278/1000], Loss: 0.5119\n",
      "Epoch [279/1000], Loss: 0.5131\n",
      "Epoch [280/1000], Loss: 0.5140\n",
      "Epoch [281/1000], Loss: 0.5095\n",
      "Epoch [282/1000], Loss: 0.5133\n",
      "Epoch [283/1000], Loss: 0.5126\n",
      "Epoch [284/1000], Loss: 0.5131\n",
      "Epoch [285/1000], Loss: 0.5138\n",
      "Epoch [286/1000], Loss: 0.5114\n",
      "Epoch [287/1000], Loss: 0.5138\n",
      "Epoch [288/1000], Loss: 0.5138\n",
      "Epoch [289/1000], Loss: 0.5131\n",
      "Epoch [290/1000], Loss: 0.5145\n",
      "Epoch [291/1000], Loss: 0.5121\n",
      "Epoch [292/1000], Loss: 0.5126\n",
      "Epoch [293/1000], Loss: 0.5129\n",
      "Epoch [294/1000], Loss: 0.5138\n",
      "Epoch [295/1000], Loss: 0.5112\n",
      "Epoch [296/1000], Loss: 0.5145\n",
      "Epoch [297/1000], Loss: 0.5117\n",
      "Epoch [298/1000], Loss: 0.5129\n",
      "Epoch [299/1000], Loss: 0.5119\n",
      "Epoch [300/1000], Loss: 0.5112\n",
      "Epoch [301/1000], Loss: 0.5131\n",
      "Epoch [302/1000], Loss: 0.5090\n",
      "Epoch [303/1000], Loss: 0.5136\n",
      "Epoch [304/1000], Loss: 0.5126\n",
      "Epoch [305/1000], Loss: 0.5129\n",
      "Epoch [306/1000], Loss: 0.5124\n",
      "Epoch [307/1000], Loss: 0.5143\n",
      "Epoch [308/1000], Loss: 0.5121\n",
      "Epoch [309/1000], Loss: 0.5124\n",
      "Epoch [310/1000], Loss: 0.5083\n",
      "Epoch [311/1000], Loss: 0.5114\n",
      "Epoch [312/1000], Loss: 0.5119\n",
      "Epoch [313/1000], Loss: 0.5129\n",
      "Epoch [314/1000], Loss: 0.5105\n",
      "Epoch [315/1000], Loss: 0.5119\n",
      "Epoch [316/1000], Loss: 0.5117\n",
      "Epoch [317/1000], Loss: 0.5145\n",
      "Epoch [318/1000], Loss: 0.5136\n",
      "Epoch [319/1000], Loss: 0.5124\n",
      "Epoch [320/1000], Loss: 0.5140\n",
      "Epoch [321/1000], Loss: 0.5112\n",
      "Epoch [322/1000], Loss: 0.5110\n",
      "Epoch [323/1000], Loss: 0.5131\n",
      "Epoch [324/1000], Loss: 0.5143\n",
      "Epoch [325/1000], Loss: 0.5119\n",
      "Epoch [326/1000], Loss: 0.5114\n",
      "Epoch [327/1000], Loss: 0.5129\n",
      "Epoch [328/1000], Loss: 0.5124\n",
      "Epoch [329/1000], Loss: 0.5133\n",
      "Epoch [330/1000], Loss: 0.5102\n",
      "Epoch [331/1000], Loss: 0.5131\n",
      "Epoch [332/1000], Loss: 0.5129\n",
      "Epoch [333/1000], Loss: 0.5155\n",
      "Epoch [334/1000], Loss: 0.5140\n",
      "Epoch [335/1000], Loss: 0.5126\n",
      "Epoch [336/1000], Loss: 0.5107\n",
      "Epoch [337/1000], Loss: 0.5138\n",
      "Epoch [338/1000], Loss: 0.5121\n",
      "Epoch [339/1000], Loss: 0.5100\n",
      "Epoch [340/1000], Loss: 0.5138\n",
      "Epoch [341/1000], Loss: 0.5143\n",
      "Epoch [342/1000], Loss: 0.5110\n",
      "Epoch [343/1000], Loss: 0.5140\n",
      "Epoch [344/1000], Loss: 0.5121\n",
      "Epoch [345/1000], Loss: 0.5131\n",
      "Epoch [346/1000], Loss: 0.5133\n",
      "Epoch [347/1000], Loss: 0.5133\n",
      "Epoch [348/1000], Loss: 0.5117\n",
      "Epoch [349/1000], Loss: 0.5119\n",
      "Epoch [350/1000], Loss: 0.5121\n",
      "Epoch [351/1000], Loss: 0.5114\n",
      "Epoch [352/1000], Loss: 0.5114\n",
      "Epoch [353/1000], Loss: 0.5121\n",
      "Epoch [354/1000], Loss: 0.5121\n",
      "Epoch [355/1000], Loss: 0.5119\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 205, lr :1.0, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.4751\n",
      "Epoch [2/1000], Loss: 0.4677\n",
      "Epoch [3/1000], Loss: 0.4449\n",
      "Epoch [4/1000], Loss: 0.4649\n",
      "Epoch [5/1000], Loss: 0.4552\n",
      "Epoch [6/1000], Loss: 0.4437\n",
      "Epoch [7/1000], Loss: 0.4835\n",
      "Epoch [8/1000], Loss: 0.4644\n",
      "Epoch [9/1000], Loss: 0.4611\n",
      "Epoch [10/1000], Loss: 0.4654\n",
      "Epoch [11/1000], Loss: 0.4647\n",
      "Epoch [12/1000], Loss: 0.4644\n",
      "Epoch [13/1000], Loss: 0.4649\n",
      "Epoch [14/1000], Loss: 0.4661\n",
      "Epoch [15/1000], Loss: 0.4656\n",
      "Epoch [16/1000], Loss: 0.4666\n",
      "Epoch [17/1000], Loss: 0.4623\n",
      "Epoch [18/1000], Loss: 0.4644\n",
      "Epoch [19/1000], Loss: 0.4625\n",
      "Epoch [20/1000], Loss: 0.4635\n",
      "Epoch [21/1000], Loss: 0.4640\n",
      "Epoch [22/1000], Loss: 0.4628\n",
      "Epoch [23/1000], Loss: 0.4635\n",
      "Epoch [24/1000], Loss: 0.4654\n",
      "Epoch [25/1000], Loss: 0.4649\n",
      "Epoch [26/1000], Loss: 0.4635\n",
      "Epoch [27/1000], Loss: 0.4640\n",
      "Epoch [28/1000], Loss: 0.4644\n",
      "Epoch [29/1000], Loss: 0.4623\n",
      "Epoch [30/1000], Loss: 0.4637\n",
      "Epoch [31/1000], Loss: 0.4632\n",
      "Epoch [32/1000], Loss: 0.4642\n",
      "Epoch [33/1000], Loss: 0.4642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/1000], Loss: 0.4644\n",
      "Epoch [35/1000], Loss: 0.4649\n",
      "Epoch [36/1000], Loss: 0.4644\n",
      "Epoch [37/1000], Loss: 0.4651\n",
      "Epoch [38/1000], Loss: 0.4644\n",
      "Epoch [39/1000], Loss: 0.4668\n",
      "Epoch [40/1000], Loss: 0.4663\n",
      "Epoch [41/1000], Loss: 0.4649\n",
      "Epoch [42/1000], Loss: 0.4644\n",
      "Epoch [43/1000], Loss: 0.4651\n",
      "Epoch [44/1000], Loss: 0.4623\n",
      "Epoch [45/1000], Loss: 0.4628\n",
      "Epoch [46/1000], Loss: 0.4635\n",
      "Epoch [47/1000], Loss: 0.4632\n",
      "Epoch [48/1000], Loss: 0.4654\n",
      "Epoch [49/1000], Loss: 0.4628\n",
      "Epoch [50/1000], Loss: 0.4640\n",
      "Epoch [51/1000], Loss: 0.4635\n",
      "Epoch [52/1000], Loss: 0.4644\n",
      "Epoch [53/1000], Loss: 0.4654\n",
      "Epoch [54/1000], Loss: 0.4642\n",
      "Epoch [55/1000], Loss: 0.4651\n",
      "Epoch [56/1000], Loss: 0.4637\n",
      "Epoch [57/1000], Loss: 0.4623\n",
      "Epoch [58/1000], Loss: 0.4637\n",
      "Epoch [59/1000], Loss: 0.4644\n",
      "Epoch [60/1000], Loss: 0.4637\n",
      "Epoch [61/1000], Loss: 0.4647\n",
      "Epoch [62/1000], Loss: 0.4649\n",
      "Epoch [63/1000], Loss: 0.4635\n",
      "Epoch [64/1000], Loss: 0.4640\n",
      "Epoch [65/1000], Loss: 0.4637\n",
      "Epoch [66/1000], Loss: 0.4635\n",
      "Epoch [67/1000], Loss: 0.4623\n",
      "Epoch [68/1000], Loss: 0.4632\n",
      "Epoch [69/1000], Loss: 0.4630\n",
      "Epoch [70/1000], Loss: 0.4632\n",
      "Epoch [71/1000], Loss: 0.4640\n",
      "Epoch [72/1000], Loss: 0.4651\n",
      "Epoch [73/1000], Loss: 0.4625\n",
      "Epoch [74/1000], Loss: 0.4644\n",
      "Epoch [75/1000], Loss: 0.4616\n",
      "Epoch [76/1000], Loss: 0.4635\n",
      "Epoch [77/1000], Loss: 0.4632\n",
      "Epoch [78/1000], Loss: 0.4647\n",
      "Epoch [79/1000], Loss: 0.4628\n",
      "Epoch [80/1000], Loss: 0.4632\n",
      "Epoch [81/1000], Loss: 0.4651\n",
      "Epoch [82/1000], Loss: 0.4647\n",
      "Epoch [83/1000], Loss: 0.4640\n",
      "Epoch [84/1000], Loss: 0.4625\n",
      "Epoch [85/1000], Loss: 0.4642\n",
      "Epoch [86/1000], Loss: 0.4647\n",
      "Epoch [87/1000], Loss: 0.4651\n",
      "Epoch [88/1000], Loss: 0.4632\n",
      "Epoch [89/1000], Loss: 0.4613\n",
      "Epoch [90/1000], Loss: 0.4630\n",
      "Epoch [91/1000], Loss: 0.4642\n",
      "Epoch [92/1000], Loss: 0.4659\n",
      "Epoch [93/1000], Loss: 0.4644\n",
      "Epoch [94/1000], Loss: 0.4656\n",
      "Epoch [95/1000], Loss: 0.4644\n",
      "Epoch [96/1000], Loss: 0.4637\n",
      "Epoch [97/1000], Loss: 0.4644\n",
      "Epoch [98/1000], Loss: 0.4642\n",
      "Epoch [99/1000], Loss: 0.4637\n",
      "Epoch [100/1000], Loss: 0.4663\n",
      "Epoch [101/1000], Loss: 0.4644\n",
      "Epoch [102/1000], Loss: 0.4647\n",
      "Epoch [103/1000], Loss: 0.4637\n",
      "Epoch [104/1000], Loss: 0.4649\n",
      "Epoch [105/1000], Loss: 0.4651\n",
      "Epoch [106/1000], Loss: 0.4651\n",
      "Epoch [107/1000], Loss: 0.4640\n",
      "Epoch [108/1000], Loss: 0.4651\n",
      "Epoch [109/1000], Loss: 0.4635\n",
      "Epoch [110/1000], Loss: 0.4654\n",
      "Epoch [111/1000], Loss: 0.4647\n",
      "Epoch [112/1000], Loss: 0.4618\n",
      "Epoch [113/1000], Loss: 0.4661\n",
      "Epoch [114/1000], Loss: 0.4640\n",
      "Epoch [115/1000], Loss: 0.4659\n",
      "Epoch [116/1000], Loss: 0.4670\n",
      "Epoch [117/1000], Loss: 0.4644\n",
      "Epoch [118/1000], Loss: 0.4654\n",
      "Epoch [119/1000], Loss: 0.4635\n",
      "Epoch [120/1000], Loss: 0.4630\n",
      "Epoch [121/1000], Loss: 0.4663\n",
      "Epoch [122/1000], Loss: 0.4647\n",
      "Epoch [123/1000], Loss: 0.4649\n",
      "Epoch [124/1000], Loss: 0.4635\n",
      "Epoch [125/1000], Loss: 0.4647\n",
      "Epoch [126/1000], Loss: 0.4647\n",
      "Epoch [127/1000], Loss: 0.4616\n",
      "Epoch [128/1000], Loss: 0.4663\n",
      "Epoch [129/1000], Loss: 0.4632\n",
      "Epoch [130/1000], Loss: 0.4651\n",
      "Epoch [131/1000], Loss: 0.4618\n",
      "Epoch [132/1000], Loss: 0.4625\n",
      "Epoch [133/1000], Loss: 0.4668\n",
      "Epoch [134/1000], Loss: 0.4640\n",
      "Epoch [135/1000], Loss: 0.4640\n",
      "Epoch [136/1000], Loss: 0.4644\n",
      "Epoch [137/1000], Loss: 0.4618\n",
      "Epoch [138/1000], Loss: 0.4642\n",
      "Epoch [139/1000], Loss: 0.4654\n",
      "Epoch [140/1000], Loss: 0.4651\n",
      "Epoch [141/1000], Loss: 0.4656\n",
      "Epoch [142/1000], Loss: 0.4623\n",
      "Epoch [143/1000], Loss: 0.4632\n",
      "Epoch [144/1000], Loss: 0.4640\n",
      "Epoch [145/1000], Loss: 0.4625\n",
      "Epoch [146/1000], Loss: 0.4640\n",
      "Epoch [147/1000], Loss: 0.4651\n",
      "Epoch [148/1000], Loss: 0.4644\n",
      "Epoch [149/1000], Loss: 0.4625\n",
      "Epoch [150/1000], Loss: 0.4654\n",
      "Epoch [151/1000], Loss: 0.4637\n",
      "Epoch [152/1000], Loss: 0.4649\n",
      "Epoch [153/1000], Loss: 0.4651\n",
      "Epoch [154/1000], Loss: 0.4628\n",
      "Epoch [155/1000], Loss: 0.4640\n",
      "Epoch [156/1000], Loss: 0.4642\n",
      "Epoch [157/1000], Loss: 0.4628\n",
      "Epoch [158/1000], Loss: 0.4637\n",
      "Epoch [159/1000], Loss: 0.4644\n",
      "Epoch [160/1000], Loss: 0.4649\n",
      "Epoch [161/1000], Loss: 0.4628\n",
      "Epoch [162/1000], Loss: 0.4656\n",
      "Epoch [163/1000], Loss: 0.4666\n",
      "Epoch [164/1000], Loss: 0.4635\n",
      "Epoch [165/1000], Loss: 0.4644\n",
      "Epoch [166/1000], Loss: 0.4654\n",
      "Epoch [167/1000], Loss: 0.4670\n",
      "Epoch [168/1000], Loss: 0.4647\n",
      "Epoch [169/1000], Loss: 0.4647\n",
      "Epoch [170/1000], Loss: 0.4661\n",
      "Epoch [171/1000], Loss: 0.4642\n",
      "Epoch [172/1000], Loss: 0.4644\n",
      "Epoch [173/1000], Loss: 0.4637\n",
      "Epoch [174/1000], Loss: 0.4632\n",
      "Epoch [175/1000], Loss: 0.4647\n",
      "Epoch [176/1000], Loss: 0.4628\n",
      "Epoch [177/1000], Loss: 0.4640\n",
      "Epoch [178/1000], Loss: 0.4635\n",
      "Epoch [179/1000], Loss: 0.4630\n",
      "Epoch [180/1000], Loss: 0.4647\n",
      "Epoch [181/1000], Loss: 0.4632\n",
      "Epoch [182/1000], Loss: 0.4640\n",
      "Epoch [183/1000], Loss: 0.4649\n",
      "Epoch [184/1000], Loss: 0.4666\n",
      "Epoch [185/1000], Loss: 0.4640\n",
      "Epoch [186/1000], Loss: 0.4649\n",
      "Epoch [187/1000], Loss: 0.4644\n",
      "Epoch [188/1000], Loss: 0.4647\n",
      "Epoch [189/1000], Loss: 0.4661\n",
      "Epoch [190/1000], Loss: 0.4628\n",
      "Epoch [191/1000], Loss: 0.4640\n",
      "Epoch [192/1000], Loss: 0.4642\n",
      "Epoch [193/1000], Loss: 0.4651\n",
      "Epoch [194/1000], Loss: 0.4654\n",
      "Epoch [195/1000], Loss: 0.4630\n",
      "Epoch [196/1000], Loss: 0.4654\n",
      "Epoch [197/1000], Loss: 0.4635\n",
      "Epoch [198/1000], Loss: 0.4651\n",
      "Epoch [199/1000], Loss: 0.4659\n",
      "Epoch [200/1000], Loss: 0.4656\n",
      "Epoch [201/1000], Loss: 0.4642\n",
      "Epoch [202/1000], Loss: 0.4623\n",
      "Epoch [203/1000], Loss: 0.4649\n",
      "Epoch [204/1000], Loss: 0.4649\n",
      "Epoch [205/1000], Loss: 0.4632\n",
      "Epoch [206/1000], Loss: 0.4661\n",
      "Epoch [207/1000], Loss: 0.4651\n",
      "Epoch [208/1000], Loss: 0.4659\n",
      "Epoch [209/1000], Loss: 0.4632\n",
      "Epoch [210/1000], Loss: 0.4651\n",
      "Epoch [211/1000], Loss: 0.4644\n",
      "Epoch [212/1000], Loss: 0.4649\n",
      "Epoch [213/1000], Loss: 0.4644\n",
      "Epoch [214/1000], Loss: 0.4649\n",
      "Epoch [215/1000], Loss: 0.4637\n",
      "Epoch [216/1000], Loss: 0.4654\n",
      "Epoch [217/1000], Loss: 0.4668\n",
      "Epoch [218/1000], Loss: 0.4635\n",
      "Epoch [219/1000], Loss: 0.4661\n",
      "Epoch [220/1000], Loss: 0.4644\n",
      "Epoch [221/1000], Loss: 0.4635\n",
      "Epoch [222/1000], Loss: 0.4644\n",
      "Epoch [223/1000], Loss: 0.4644\n",
      "Epoch [224/1000], Loss: 0.4656\n",
      "Epoch [225/1000], Loss: 0.4651\n",
      "Epoch [226/1000], Loss: 0.4630\n",
      "Epoch [227/1000], Loss: 0.4637\n",
      "Epoch [228/1000], Loss: 0.4656\n",
      "Epoch [229/1000], Loss: 0.4656\n",
      "Epoch [230/1000], Loss: 0.4625\n",
      "Epoch [231/1000], Loss: 0.4618\n",
      "Epoch [232/1000], Loss: 0.4647\n",
      "Epoch [233/1000], Loss: 0.4649\n",
      "Epoch [234/1000], Loss: 0.4651\n",
      "Epoch [235/1000], Loss: 0.4654\n",
      "Epoch [236/1000], Loss: 0.4663\n",
      "Epoch [237/1000], Loss: 0.4675\n",
      "Epoch [238/1000], Loss: 0.4642\n",
      "Epoch [239/1000], Loss: 0.4644\n",
      "Epoch [240/1000], Loss: 0.4635\n",
      "Epoch [241/1000], Loss: 0.4644\n",
      "Epoch [242/1000], Loss: 0.4647\n",
      "Epoch [243/1000], Loss: 0.4611\n",
      "Epoch [244/1000], Loss: 0.4642\n",
      "Epoch [245/1000], Loss: 0.4625\n",
      "Epoch [246/1000], Loss: 0.4640\n",
      "Epoch [247/1000], Loss: 0.4637\n",
      "Epoch [248/1000], Loss: 0.4647\n",
      "Epoch [249/1000], Loss: 0.4637\n",
      "Epoch [250/1000], Loss: 0.4649\n",
      "Epoch [251/1000], Loss: 0.4635\n",
      "Epoch [252/1000], Loss: 0.4668\n",
      "Epoch [253/1000], Loss: 0.4635\n",
      "Epoch [254/1000], Loss: 0.4644\n",
      "Epoch [255/1000], Loss: 0.4640\n",
      "Epoch [256/1000], Loss: 0.4632\n",
      "Epoch [257/1000], Loss: 0.4635\n",
      "Epoch [258/1000], Loss: 0.4651\n",
      "Epoch [259/1000], Loss: 0.4651\n",
      "Epoch [260/1000], Loss: 0.4647\n",
      "Epoch [261/1000], Loss: 0.4649\n",
      "Epoch [262/1000], Loss: 0.4642\n",
      "Epoch [263/1000], Loss: 0.4656\n",
      "Epoch [264/1000], Loss: 0.4618\n",
      "Epoch [265/1000], Loss: 0.4637\n",
      "Epoch [266/1000], Loss: 0.4620\n",
      "Epoch [267/1000], Loss: 0.4647\n",
      "Epoch [268/1000], Loss: 0.4632\n",
      "Epoch [269/1000], Loss: 0.4668\n",
      "Epoch [270/1000], Loss: 0.4644\n",
      "Epoch [271/1000], Loss: 0.4632\n",
      "Epoch [272/1000], Loss: 0.4642\n",
      "Epoch [273/1000], Loss: 0.4666\n",
      "Epoch [274/1000], Loss: 0.4637\n",
      "Epoch [275/1000], Loss: 0.4642\n",
      "Epoch [276/1000], Loss: 0.4644\n",
      "Epoch [277/1000], Loss: 0.4647\n",
      "Epoch [278/1000], Loss: 0.4647\n",
      "Epoch [279/1000], Loss: 0.4663\n",
      "Epoch [280/1000], Loss: 0.4642\n",
      "Epoch [281/1000], Loss: 0.4644\n",
      "Epoch [282/1000], Loss: 0.4642\n",
      "Epoch [283/1000], Loss: 0.4647\n",
      "Epoch [284/1000], Loss: 0.4663\n",
      "Epoch [285/1000], Loss: 0.4668\n",
      "Epoch [286/1000], Loss: 0.4640\n",
      "Epoch [287/1000], Loss: 0.4644\n",
      "Epoch [288/1000], Loss: 0.4661\n",
      "Epoch [289/1000], Loss: 0.4642\n",
      "Epoch [290/1000], Loss: 0.4642\n",
      "Epoch [291/1000], Loss: 0.4651\n",
      "Epoch [292/1000], Loss: 0.4651\n",
      "Epoch [293/1000], Loss: 0.4644\n",
      "Epoch [294/1000], Loss: 0.4651\n",
      "Epoch [295/1000], Loss: 0.4649\n",
      "Epoch [296/1000], Loss: 0.4651\n",
      "Epoch [297/1000], Loss: 0.4630\n",
      "Epoch [298/1000], Loss: 0.4616\n",
      "Epoch [299/1000], Loss: 0.4618\n",
      "Epoch [300/1000], Loss: 0.4644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [301/1000], Loss: 0.4630\n",
      "Epoch [302/1000], Loss: 0.4642\n",
      "Epoch [303/1000], Loss: 0.4651\n",
      "Epoch [304/1000], Loss: 0.4623\n",
      "Epoch [305/1000], Loss: 0.4661\n",
      "Epoch [306/1000], Loss: 0.4647\n",
      "Epoch [307/1000], Loss: 0.4651\n",
      "Epoch [308/1000], Loss: 0.4632\n",
      "Epoch [309/1000], Loss: 0.4632\n",
      "Epoch [310/1000], Loss: 0.4630\n",
      "Epoch [311/1000], Loss: 0.4647\n",
      "Epoch [312/1000], Loss: 0.4642\n",
      "Epoch [313/1000], Loss: 0.4647\n",
      "Epoch [314/1000], Loss: 0.4642\n",
      "Epoch [315/1000], Loss: 0.4640\n",
      "Epoch [316/1000], Loss: 0.4635\n",
      "Epoch [317/1000], Loss: 0.4642\n",
      "Epoch [318/1000], Loss: 0.4656\n",
      "Epoch [319/1000], Loss: 0.4623\n",
      "Epoch [320/1000], Loss: 0.4637\n",
      "Epoch [321/1000], Loss: 0.4654\n",
      "Epoch [322/1000], Loss: 0.4668\n",
      "Epoch [323/1000], Loss: 0.4649\n",
      "Epoch [324/1000], Loss: 0.4647\n",
      "Epoch [325/1000], Loss: 0.4637\n",
      "Epoch [326/1000], Loss: 0.4663\n",
      "Epoch [327/1000], Loss: 0.4637\n",
      "Epoch [328/1000], Loss: 0.4640\n",
      "Epoch [329/1000], Loss: 0.4637\n",
      "Epoch [330/1000], Loss: 0.4642\n",
      "Epoch [331/1000], Loss: 0.4651\n",
      "Epoch [332/1000], Loss: 0.4644\n",
      "Epoch [333/1000], Loss: 0.4618\n",
      "Epoch [334/1000], Loss: 0.4649\n",
      "Epoch [335/1000], Loss: 0.4630\n",
      "Epoch [336/1000], Loss: 0.4618\n",
      "Epoch [337/1000], Loss: 0.4654\n",
      "Epoch [338/1000], Loss: 0.4613\n",
      "Epoch [339/1000], Loss: 0.4640\n",
      "Epoch [340/1000], Loss: 0.4637\n",
      "Epoch [341/1000], Loss: 0.4642\n",
      "Epoch [342/1000], Loss: 0.4640\n",
      "Epoch [343/1000], Loss: 0.4659\n",
      "Epoch [344/1000], Loss: 0.4637\n",
      "Epoch [345/1000], Loss: 0.4651\n",
      "Epoch [346/1000], Loss: 0.4661\n",
      "Epoch [347/1000], Loss: 0.4644\n",
      "Epoch [348/1000], Loss: 0.4656\n",
      "Epoch [349/1000], Loss: 0.4649\n",
      "Epoch [350/1000], Loss: 0.4632\n",
      "Epoch [351/1000], Loss: 0.4647\n",
      "Epoch [352/1000], Loss: 0.4659\n",
      "Epoch [353/1000], Loss: 0.4635\n",
      "Epoch [354/1000], Loss: 0.4642\n",
      "Epoch [355/1000], Loss: 0.4632\n",
      "Epoch [356/1000], Loss: 0.4640\n",
      "Epoch [357/1000], Loss: 0.4642\n",
      "Epoch [358/1000], Loss: 0.4640\n",
      "Epoch [359/1000], Loss: 0.4635\n",
      "Epoch [360/1000], Loss: 0.4656\n",
      "Epoch [361/1000], Loss: 0.4642\n",
      "Epoch [362/1000], Loss: 0.4647\n",
      "Epoch [363/1000], Loss: 0.4647\n",
      "Epoch [364/1000], Loss: 0.4637\n",
      "Epoch [365/1000], Loss: 0.4640\n",
      "Epoch [366/1000], Loss: 0.4635\n",
      "Epoch [367/1000], Loss: 0.4630\n",
      "Epoch [368/1000], Loss: 0.4618\n",
      "Epoch [369/1000], Loss: 0.4632\n",
      "Epoch [370/1000], Loss: 0.4659\n",
      "Epoch [371/1000], Loss: 0.4656\n",
      "Epoch [372/1000], Loss: 0.4625\n",
      "Epoch [373/1000], Loss: 0.4647\n",
      "Epoch [374/1000], Loss: 0.4647\n",
      "Epoch [375/1000], Loss: 0.4644\n",
      "Epoch [376/1000], Loss: 0.4637\n",
      "Epoch [377/1000], Loss: 0.4654\n",
      "Epoch [378/1000], Loss: 0.4654\n",
      "Epoch [379/1000], Loss: 0.4640\n",
      "Epoch [380/1000], Loss: 0.4647\n",
      "Epoch [381/1000], Loss: 0.4620\n",
      "Epoch [382/1000], Loss: 0.4625\n",
      "Epoch [383/1000], Loss: 0.4632\n",
      "Epoch [384/1000], Loss: 0.4644\n",
      "Epoch [385/1000], Loss: 0.4647\n",
      "Epoch [386/1000], Loss: 0.4637\n",
      "Epoch [387/1000], Loss: 0.4637\n",
      "Epoch [388/1000], Loss: 0.4640\n",
      "Epoch [389/1000], Loss: 0.4656\n",
      "Epoch [390/1000], Loss: 0.4635\n",
      "Epoch [391/1000], Loss: 0.4632\n",
      "Epoch [392/1000], Loss: 0.4647\n",
      "Epoch [393/1000], Loss: 0.4656\n",
      "Epoch [394/1000], Loss: 0.4673\n",
      "Epoch [395/1000], Loss: 0.4670\n",
      "Epoch [396/1000], Loss: 0.4668\n",
      "Epoch [397/1000], Loss: 0.4630\n",
      "Epoch [398/1000], Loss: 0.4656\n",
      "Epoch [399/1000], Loss: 0.4654\n",
      "Epoch [400/1000], Loss: 0.4647\n",
      "Epoch [401/1000], Loss: 0.4637\n",
      "Epoch [402/1000], Loss: 0.4654\n",
      "Epoch [403/1000], Loss: 0.4670\n",
      "Epoch [404/1000], Loss: 0.4635\n",
      "Epoch [405/1000], Loss: 0.4663\n",
      "Epoch [406/1000], Loss: 0.4640\n",
      "Epoch [407/1000], Loss: 0.4642\n",
      "Epoch [408/1000], Loss: 0.4651\n",
      "Epoch [409/1000], Loss: 0.4659\n",
      "Epoch [410/1000], Loss: 0.4637\n",
      "Epoch [411/1000], Loss: 0.4635\n",
      "Epoch [412/1000], Loss: 0.4640\n",
      "Epoch [413/1000], Loss: 0.4661\n",
      "Epoch [414/1000], Loss: 0.4663\n",
      "Epoch [415/1000], Loss: 0.4630\n",
      "Epoch [416/1000], Loss: 0.4635\n",
      "Epoch [417/1000], Loss: 0.4649\n",
      "Epoch [418/1000], Loss: 0.4647\n",
      "Epoch [419/1000], Loss: 0.4647\n",
      "Epoch [420/1000], Loss: 0.4628\n",
      "Epoch [421/1000], Loss: 0.4644\n",
      "Epoch [422/1000], Loss: 0.4649\n",
      "Epoch [423/1000], Loss: 0.4666\n",
      "Epoch [424/1000], Loss: 0.4642\n",
      "Epoch [425/1000], Loss: 0.4625\n",
      "Epoch [426/1000], Loss: 0.4666\n",
      "Epoch [427/1000], Loss: 0.4656\n",
      "Epoch [428/1000], Loss: 0.4659\n",
      "Epoch [429/1000], Loss: 0.4635\n",
      "Epoch [430/1000], Loss: 0.4651\n",
      "Epoch [431/1000], Loss: 0.4659\n",
      "Epoch [432/1000], Loss: 0.4668\n",
      "Epoch [433/1000], Loss: 0.4625\n",
      "Epoch [434/1000], Loss: 0.4647\n",
      "Epoch [435/1000], Loss: 0.4651\n",
      "Epoch [436/1000], Loss: 0.4661\n",
      "Epoch [437/1000], Loss: 0.4659\n",
      "Epoch [438/1000], Loss: 0.4670\n",
      "Epoch [439/1000], Loss: 0.4640\n",
      "Epoch [440/1000], Loss: 0.4651\n",
      "Epoch [441/1000], Loss: 0.4613\n",
      "Epoch [442/1000], Loss: 0.4625\n",
      "Epoch [443/1000], Loss: 0.4649\n",
      "Epoch [444/1000], Loss: 0.4635\n",
      "Epoch [445/1000], Loss: 0.4661\n",
      "Epoch [446/1000], Loss: 0.4656\n",
      "Epoch [447/1000], Loss: 0.4651\n",
      "Epoch [448/1000], Loss: 0.4654\n",
      "Epoch [449/1000], Loss: 0.4649\n",
      "Epoch [450/1000], Loss: 0.4642\n",
      "Epoch [451/1000], Loss: 0.4635\n",
      "Epoch [452/1000], Loss: 0.4630\n",
      "Epoch [453/1000], Loss: 0.4637\n",
      "Epoch [454/1000], Loss: 0.4649\n",
      "Epoch [455/1000], Loss: 0.4640\n",
      "Epoch [456/1000], Loss: 0.4654\n",
      "Epoch [457/1000], Loss: 0.4628\n",
      "Epoch [458/1000], Loss: 0.4640\n",
      "Epoch [459/1000], Loss: 0.4663\n",
      "Epoch [460/1000], Loss: 0.4649\n",
      "Epoch [461/1000], Loss: 0.4647\n",
      "Epoch [462/1000], Loss: 0.4656\n",
      "Epoch [463/1000], Loss: 0.4659\n",
      "Epoch [464/1000], Loss: 0.4649\n",
      "Epoch [465/1000], Loss: 0.4649\n",
      "Epoch [466/1000], Loss: 0.4661\n",
      "Epoch [467/1000], Loss: 0.4637\n",
      "Epoch [468/1000], Loss: 0.4656\n",
      "Epoch [469/1000], Loss: 0.4618\n",
      "Epoch [470/1000], Loss: 0.4630\n",
      "Epoch [471/1000], Loss: 0.4649\n",
      "Epoch [472/1000], Loss: 0.4668\n",
      "Epoch [473/1000], Loss: 0.4659\n",
      "Epoch [474/1000], Loss: 0.4647\n",
      "Epoch [475/1000], Loss: 0.4637\n",
      "Epoch [476/1000], Loss: 0.4620\n",
      "Epoch [477/1000], Loss: 0.4651\n",
      "Epoch [478/1000], Loss: 0.4661\n",
      "Epoch [479/1000], Loss: 0.4628\n",
      "Epoch [480/1000], Loss: 0.4651\n",
      "Epoch [481/1000], Loss: 0.4635\n",
      "Epoch [482/1000], Loss: 0.4635\n",
      "Epoch [483/1000], Loss: 0.4637\n",
      "Epoch [484/1000], Loss: 0.4640\n",
      "Epoch [485/1000], Loss: 0.4640\n",
      "Epoch [486/1000], Loss: 0.4647\n",
      "Epoch [487/1000], Loss: 0.4630\n",
      "Epoch [488/1000], Loss: 0.4637\n",
      "Epoch [489/1000], Loss: 0.4640\n",
      "Epoch [490/1000], Loss: 0.4659\n",
      "Epoch [491/1000], Loss: 0.4644\n",
      "Epoch [492/1000], Loss: 0.4644\n",
      "Epoch [493/1000], Loss: 0.4651\n",
      "Epoch [494/1000], Loss: 0.4649\n",
      "Epoch [495/1000], Loss: 0.4642\n",
      "Epoch [496/1000], Loss: 0.4640\n",
      "Epoch [497/1000], Loss: 0.4620\n",
      "Epoch [498/1000], Loss: 0.4675\n",
      "Epoch [499/1000], Loss: 0.4637\n",
      "Epoch [500/1000], Loss: 0.4644\n",
      "Epoch [501/1000], Loss: 0.4637\n",
      "Epoch [502/1000], Loss: 0.4649\n",
      "Epoch [503/1000], Loss: 0.4623\n",
      "Epoch [504/1000], Loss: 0.4632\n",
      "Epoch [505/1000], Loss: 0.4663\n",
      "Epoch [506/1000], Loss: 0.4654\n",
      "Epoch [507/1000], Loss: 0.4635\n",
      "Epoch [508/1000], Loss: 0.4673\n",
      "Epoch [509/1000], Loss: 0.4635\n",
      "Epoch [510/1000], Loss: 0.4635\n",
      "Epoch [511/1000], Loss: 0.4644\n",
      "Epoch [512/1000], Loss: 0.4635\n",
      "Epoch [513/1000], Loss: 0.4647\n",
      "Epoch [514/1000], Loss: 0.4637\n",
      "Epoch [515/1000], Loss: 0.4644\n",
      "Epoch [516/1000], Loss: 0.4644\n",
      "Epoch [517/1000], Loss: 0.4654\n",
      "Epoch [518/1000], Loss: 0.4630\n",
      "Epoch [519/1000], Loss: 0.4651\n",
      "Epoch [520/1000], Loss: 0.4651\n",
      "Epoch [521/1000], Loss: 0.4640\n",
      "Epoch [522/1000], Loss: 0.4630\n",
      "Epoch [523/1000], Loss: 0.4654\n",
      "Epoch [524/1000], Loss: 0.4654\n",
      "Epoch [525/1000], Loss: 0.4647\n",
      "Epoch [526/1000], Loss: 0.4625\n",
      "Epoch [527/1000], Loss: 0.4659\n",
      "Epoch [528/1000], Loss: 0.4644\n",
      "Epoch [529/1000], Loss: 0.4642\n",
      "Epoch [530/1000], Loss: 0.4630\n",
      "Epoch [531/1000], Loss: 0.4651\n",
      "Epoch [532/1000], Loss: 0.4640\n",
      "Epoch [533/1000], Loss: 0.4628\n",
      "Epoch [534/1000], Loss: 0.4613\n",
      "Epoch [535/1000], Loss: 0.4663\n",
      "Epoch [536/1000], Loss: 0.4635\n",
      "Epoch [537/1000], Loss: 0.4651\n",
      "Epoch [538/1000], Loss: 0.4640\n",
      "Epoch [539/1000], Loss: 0.4630\n",
      "Epoch [540/1000], Loss: 0.4637\n",
      "Epoch [541/1000], Loss: 0.4661\n",
      "Epoch [542/1000], Loss: 0.4628\n",
      "Epoch [543/1000], Loss: 0.4644\n",
      "Epoch [544/1000], Loss: 0.4632\n",
      "Epoch [545/1000], Loss: 0.4663\n",
      "Epoch [546/1000], Loss: 0.4647\n",
      "Epoch [547/1000], Loss: 0.4654\n",
      "Epoch [548/1000], Loss: 0.4630\n",
      "Epoch [549/1000], Loss: 0.4630\n",
      "Epoch [550/1000], Loss: 0.4630\n",
      "Epoch [551/1000], Loss: 0.4628\n",
      "Epoch [552/1000], Loss: 0.4635\n",
      "Epoch [553/1000], Loss: 0.4642\n",
      "Epoch [554/1000], Loss: 0.4630\n",
      "Epoch [555/1000], Loss: 0.4649\n",
      "Epoch [556/1000], Loss: 0.4649\n",
      "Epoch [557/1000], Loss: 0.4635\n",
      "Epoch [558/1000], Loss: 0.4637\n",
      "Epoch [559/1000], Loss: 0.4635\n",
      "Epoch [560/1000], Loss: 0.4647\n",
      "Epoch [561/1000], Loss: 0.4635\n",
      "Epoch [562/1000], Loss: 0.4659\n",
      "Epoch [563/1000], Loss: 0.4637\n",
      "Epoch [564/1000], Loss: 0.4644\n",
      "Epoch [565/1000], Loss: 0.4623\n",
      "Epoch [566/1000], Loss: 0.4642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [567/1000], Loss: 0.4644\n",
      "Epoch [568/1000], Loss: 0.4637\n",
      "Epoch [569/1000], Loss: 0.4628\n",
      "Epoch [570/1000], Loss: 0.4656\n",
      "Epoch [571/1000], Loss: 0.4647\n",
      "Epoch [572/1000], Loss: 0.4659\n",
      "Epoch [573/1000], Loss: 0.4623\n",
      "Epoch [574/1000], Loss: 0.4647\n",
      "Epoch [575/1000], Loss: 0.4651\n",
      "Epoch [576/1000], Loss: 0.4649\n",
      "Epoch [577/1000], Loss: 0.4642\n",
      "Epoch [578/1000], Loss: 0.4632\n",
      "Epoch [579/1000], Loss: 0.4661\n",
      "Epoch [580/1000], Loss: 0.4659\n",
      "Epoch [581/1000], Loss: 0.4666\n",
      "Epoch [582/1000], Loss: 0.4649\n",
      "Epoch [583/1000], Loss: 0.4651\n",
      "Epoch [584/1000], Loss: 0.4623\n",
      "Epoch [585/1000], Loss: 0.4628\n",
      "Epoch [586/1000], Loss: 0.4649\n",
      "Epoch [587/1000], Loss: 0.4635\n",
      "Epoch [588/1000], Loss: 0.4649\n",
      "Epoch [589/1000], Loss: 0.4651\n",
      "Epoch [590/1000], Loss: 0.4651\n",
      "Epoch [591/1000], Loss: 0.4635\n",
      "Epoch [592/1000], Loss: 0.4637\n",
      "Epoch [593/1000], Loss: 0.4642\n",
      "Epoch [594/1000], Loss: 0.4637\n",
      "Epoch [595/1000], Loss: 0.4644\n",
      "Epoch [596/1000], Loss: 0.4649\n",
      "Epoch [597/1000], Loss: 0.4644\n",
      "Epoch [598/1000], Loss: 0.4661\n",
      "Epoch [599/1000], Loss: 0.4654\n",
      "Epoch [600/1000], Loss: 0.4632\n",
      "Epoch [601/1000], Loss: 0.4644\n",
      "Epoch [602/1000], Loss: 0.4616\n",
      "Epoch [603/1000], Loss: 0.4623\n",
      "Epoch [604/1000], Loss: 0.4635\n",
      "Epoch [605/1000], Loss: 0.4642\n",
      "Epoch [606/1000], Loss: 0.4644\n",
      "Epoch [607/1000], Loss: 0.4640\n",
      "Epoch [608/1000], Loss: 0.4637\n",
      "Epoch [609/1000], Loss: 0.4635\n",
      "Epoch [610/1000], Loss: 0.4623\n",
      "Epoch [611/1000], Loss: 0.4659\n",
      "Epoch [612/1000], Loss: 0.4632\n",
      "Epoch [613/1000], Loss: 0.4644\n",
      "Epoch [614/1000], Loss: 0.4644\n",
      "Epoch [615/1000], Loss: 0.4628\n",
      "Epoch [616/1000], Loss: 0.4659\n",
      "Epoch [617/1000], Loss: 0.4623\n",
      "Epoch [618/1000], Loss: 0.4644\n",
      "Epoch [619/1000], Loss: 0.4663\n",
      "Epoch [620/1000], Loss: 0.4647\n",
      "Epoch [621/1000], Loss: 0.4640\n",
      "Epoch [622/1000], Loss: 0.4649\n",
      "Epoch [623/1000], Loss: 0.4659\n",
      "Epoch [624/1000], Loss: 0.4647\n",
      "Epoch [625/1000], Loss: 0.4656\n",
      "Epoch [626/1000], Loss: 0.4632\n",
      "Epoch [627/1000], Loss: 0.4640\n",
      "Epoch [628/1000], Loss: 0.4637\n",
      "Epoch [629/1000], Loss: 0.4637\n",
      "Epoch [630/1000], Loss: 0.4644\n",
      "Epoch [631/1000], Loss: 0.4630\n",
      "Epoch [632/1000], Loss: 0.4644\n",
      "Epoch [633/1000], Loss: 0.4651\n",
      "Epoch [634/1000], Loss: 0.4632\n",
      "Epoch [635/1000], Loss: 0.4637\n",
      "Epoch [636/1000], Loss: 0.4649\n",
      "Epoch [637/1000], Loss: 0.4654\n",
      "Epoch [638/1000], Loss: 0.4649\n",
      "Epoch [639/1000], Loss: 0.4644\n",
      "Epoch [640/1000], Loss: 0.4659\n",
      "Epoch [641/1000], Loss: 0.4637\n",
      "Epoch [642/1000], Loss: 0.4651\n",
      "Epoch [643/1000], Loss: 0.4651\n",
      "Epoch [644/1000], Loss: 0.4654\n",
      "Epoch [645/1000], Loss: 0.4647\n",
      "Epoch [646/1000], Loss: 0.4656\n",
      "Epoch [647/1000], Loss: 0.4637\n",
      "Epoch [648/1000], Loss: 0.4647\n",
      "Epoch [649/1000], Loss: 0.4623\n",
      "Epoch [650/1000], Loss: 0.4656\n",
      "Epoch [651/1000], Loss: 0.4651\n",
      "Epoch [652/1000], Loss: 0.4628\n",
      "Epoch [653/1000], Loss: 0.4649\n",
      "Epoch [654/1000], Loss: 0.4659\n",
      "Epoch [655/1000], Loss: 0.4637\n",
      "Epoch [656/1000], Loss: 0.4623\n",
      "Epoch [657/1000], Loss: 0.4630\n",
      "Epoch [658/1000], Loss: 0.4630\n",
      "Epoch [659/1000], Loss: 0.4632\n",
      "Epoch [660/1000], Loss: 0.4620\n",
      "Epoch [661/1000], Loss: 0.4625\n",
      "Epoch [662/1000], Loss: 0.4649\n",
      "Epoch [663/1000], Loss: 0.4637\n",
      "Epoch [664/1000], Loss: 0.4635\n",
      "Epoch [665/1000], Loss: 0.4654\n",
      "Epoch [666/1000], Loss: 0.4618\n",
      "Epoch [667/1000], Loss: 0.4640\n",
      "Epoch [668/1000], Loss: 0.4654\n",
      "Epoch [669/1000], Loss: 0.4651\n",
      "Epoch [670/1000], Loss: 0.4644\n",
      "Epoch [671/1000], Loss: 0.4630\n",
      "Epoch [672/1000], Loss: 0.4649\n",
      "Epoch [673/1000], Loss: 0.4644\n",
      "Epoch [674/1000], Loss: 0.4644\n",
      "Epoch [675/1000], Loss: 0.4635\n",
      "Epoch [676/1000], Loss: 0.4649\n",
      "Epoch [677/1000], Loss: 0.4661\n",
      "Epoch [678/1000], Loss: 0.4635\n",
      "Epoch [679/1000], Loss: 0.4628\n",
      "Epoch [680/1000], Loss: 0.4670\n",
      "Epoch [681/1000], Loss: 0.4620\n",
      "Epoch [682/1000], Loss: 0.4651\n",
      "Epoch [683/1000], Loss: 0.4656\n",
      "Epoch [684/1000], Loss: 0.4654\n",
      "Epoch [685/1000], Loss: 0.4640\n",
      "Epoch [686/1000], Loss: 0.4613\n",
      "Epoch [687/1000], Loss: 0.4649\n",
      "Epoch [688/1000], Loss: 0.4647\n",
      "Epoch [689/1000], Loss: 0.4654\n",
      "Epoch [690/1000], Loss: 0.4644\n",
      "Epoch [691/1000], Loss: 0.4623\n",
      "Epoch [692/1000], Loss: 0.4651\n",
      "Epoch [693/1000], Loss: 0.4642\n",
      "Epoch [694/1000], Loss: 0.4649\n",
      "Epoch [695/1000], Loss: 0.4651\n",
      "Epoch [696/1000], Loss: 0.4656\n",
      "Epoch [697/1000], Loss: 0.4630\n",
      "Epoch [698/1000], Loss: 0.4632\n",
      "Epoch [699/1000], Loss: 0.4654\n",
      "Epoch [700/1000], Loss: 0.4635\n",
      "Epoch [701/1000], Loss: 0.4654\n",
      "Epoch [702/1000], Loss: 0.4635\n",
      "Epoch [703/1000], Loss: 0.4642\n",
      "Epoch [704/1000], Loss: 0.4637\n",
      "Epoch [705/1000], Loss: 0.4637\n",
      "Epoch [706/1000], Loss: 0.4649\n",
      "Epoch [707/1000], Loss: 0.4620\n",
      "Epoch [708/1000], Loss: 0.4625\n",
      "Epoch [709/1000], Loss: 0.4637\n",
      "Epoch [710/1000], Loss: 0.4625\n",
      "Epoch [711/1000], Loss: 0.4640\n",
      "Epoch [712/1000], Loss: 0.4640\n",
      "Epoch [713/1000], Loss: 0.4635\n",
      "Epoch [714/1000], Loss: 0.4637\n",
      "Epoch [715/1000], Loss: 0.4649\n",
      "Epoch [716/1000], Loss: 0.4642\n",
      "Epoch [717/1000], Loss: 0.4623\n",
      "Epoch [718/1000], Loss: 0.4651\n",
      "Epoch [719/1000], Loss: 0.4642\n",
      "Epoch [720/1000], Loss: 0.4642\n",
      "Epoch [721/1000], Loss: 0.4637\n",
      "Epoch [722/1000], Loss: 0.4630\n",
      "Epoch [723/1000], Loss: 0.4630\n",
      "Epoch [724/1000], Loss: 0.4642\n",
      "Epoch [725/1000], Loss: 0.4644\n",
      "Epoch [726/1000], Loss: 0.4644\n",
      "Epoch [727/1000], Loss: 0.4654\n",
      "Epoch [728/1000], Loss: 0.4673\n",
      "Epoch [729/1000], Loss: 0.4635\n",
      "Epoch [730/1000], Loss: 0.4644\n",
      "Epoch [731/1000], Loss: 0.4647\n",
      "Epoch [732/1000], Loss: 0.4656\n",
      "Epoch [733/1000], Loss: 0.4630\n",
      "Epoch [734/1000], Loss: 0.4644\n",
      "Epoch [735/1000], Loss: 0.4625\n",
      "Epoch [736/1000], Loss: 0.4651\n",
      "Epoch [737/1000], Loss: 0.4651\n",
      "Epoch [738/1000], Loss: 0.4640\n",
      "Epoch [739/1000], Loss: 0.4628\n",
      "Epoch [740/1000], Loss: 0.4651\n",
      "Epoch [741/1000], Loss: 0.4642\n",
      "Epoch [742/1000], Loss: 0.4647\n",
      "Epoch [743/1000], Loss: 0.4642\n",
      "Epoch [744/1000], Loss: 0.4637\n",
      "Epoch [745/1000], Loss: 0.4647\n",
      "Epoch [746/1000], Loss: 0.4635\n",
      "Epoch [747/1000], Loss: 0.4656\n",
      "Epoch [748/1000], Loss: 0.4630\n",
      "Epoch [749/1000], Loss: 0.4651\n",
      "Epoch [750/1000], Loss: 0.4635\n",
      "Epoch [751/1000], Loss: 0.4625\n",
      "Epoch [752/1000], Loss: 0.4647\n",
      "Epoch [753/1000], Loss: 0.4630\n",
      "Epoch [754/1000], Loss: 0.4654\n",
      "Epoch [755/1000], Loss: 0.4642\n",
      "Epoch [756/1000], Loss: 0.4654\n",
      "Epoch [757/1000], Loss: 0.4642\n",
      "Epoch [758/1000], Loss: 0.4649\n",
      "Epoch [759/1000], Loss: 0.4670\n",
      "Epoch [760/1000], Loss: 0.4637\n",
      "Epoch [761/1000], Loss: 0.4659\n",
      "Epoch [762/1000], Loss: 0.4637\n",
      "Epoch [763/1000], Loss: 0.4637\n",
      "Epoch [764/1000], Loss: 0.4637\n",
      "Epoch [765/1000], Loss: 0.4642\n",
      "Epoch [766/1000], Loss: 0.4651\n",
      "Epoch [767/1000], Loss: 0.4630\n",
      "Epoch [768/1000], Loss: 0.4628\n",
      "Epoch [769/1000], Loss: 0.4649\n",
      "Epoch [770/1000], Loss: 0.4611\n",
      "Epoch [771/1000], Loss: 0.4642\n",
      "Epoch [772/1000], Loss: 0.4666\n",
      "Epoch [773/1000], Loss: 0.4620\n",
      "Epoch [774/1000], Loss: 0.4632\n",
      "Epoch [775/1000], Loss: 0.4642\n",
      "Epoch [776/1000], Loss: 0.4637\n",
      "Epoch [777/1000], Loss: 0.4632\n",
      "Epoch [778/1000], Loss: 0.4668\n",
      "Epoch [779/1000], Loss: 0.4632\n",
      "Epoch [780/1000], Loss: 0.4647\n",
      "Epoch [781/1000], Loss: 0.4644\n",
      "Epoch [782/1000], Loss: 0.4640\n",
      "Epoch [783/1000], Loss: 0.4651\n",
      "Epoch [784/1000], Loss: 0.4637\n",
      "Epoch [785/1000], Loss: 0.4649\n",
      "Epoch [786/1000], Loss: 0.4656\n",
      "Epoch [787/1000], Loss: 0.4637\n",
      "Epoch [788/1000], Loss: 0.4654\n",
      "Epoch [789/1000], Loss: 0.4623\n",
      "Epoch [790/1000], Loss: 0.4630\n",
      "Epoch [791/1000], Loss: 0.4640\n",
      "Epoch [792/1000], Loss: 0.4623\n",
      "Epoch [793/1000], Loss: 0.4647\n",
      "Epoch [794/1000], Loss: 0.4649\n",
      "Epoch [795/1000], Loss: 0.4654\n",
      "Epoch [796/1000], Loss: 0.4642\n",
      "Epoch [797/1000], Loss: 0.4618\n",
      "Epoch [798/1000], Loss: 0.4640\n",
      "Epoch [799/1000], Loss: 0.4642\n",
      "Epoch [800/1000], Loss: 0.4651\n",
      "Epoch [801/1000], Loss: 0.4644\n",
      "Epoch [802/1000], Loss: 0.4661\n",
      "Epoch [803/1000], Loss: 0.4661\n",
      "Epoch [804/1000], Loss: 0.4630\n",
      "Epoch [805/1000], Loss: 0.4632\n",
      "Epoch [806/1000], Loss: 0.4630\n",
      "Epoch [807/1000], Loss: 0.4647\n",
      "Epoch [808/1000], Loss: 0.4635\n",
      "Epoch [809/1000], Loss: 0.4640\n",
      "Epoch [810/1000], Loss: 0.4659\n",
      "Epoch [811/1000], Loss: 0.4649\n",
      "Epoch [812/1000], Loss: 0.4640\n",
      "Epoch [813/1000], Loss: 0.4666\n",
      "Epoch [814/1000], Loss: 0.4628\n",
      "Epoch [815/1000], Loss: 0.4647\n",
      "Epoch [816/1000], Loss: 0.4625\n",
      "Epoch [817/1000], Loss: 0.4644\n",
      "Epoch [818/1000], Loss: 0.4651\n",
      "Epoch [819/1000], Loss: 0.4651\n",
      "Epoch [820/1000], Loss: 0.4649\n",
      "Epoch [821/1000], Loss: 0.4635\n",
      "Epoch [822/1000], Loss: 0.4647\n",
      "Epoch [823/1000], Loss: 0.4661\n",
      "Epoch [824/1000], Loss: 0.4642\n",
      "Epoch [825/1000], Loss: 0.4642\n",
      "Epoch [826/1000], Loss: 0.4647\n",
      "Epoch [827/1000], Loss: 0.4656\n",
      "Epoch [828/1000], Loss: 0.4640\n",
      "Epoch [829/1000], Loss: 0.4651\n",
      "Epoch [830/1000], Loss: 0.4666\n",
      "Epoch [831/1000], Loss: 0.4663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [832/1000], Loss: 0.4623\n",
      "Epoch [833/1000], Loss: 0.4654\n",
      "Epoch [834/1000], Loss: 0.4647\n",
      "Epoch [835/1000], Loss: 0.4644\n",
      "Epoch [836/1000], Loss: 0.4642\n",
      "Epoch [837/1000], Loss: 0.4642\n",
      "Epoch [838/1000], Loss: 0.4642\n",
      "Epoch [839/1000], Loss: 0.4628\n",
      "Epoch [840/1000], Loss: 0.4656\n",
      "Epoch [841/1000], Loss: 0.4644\n",
      "Epoch [842/1000], Loss: 0.4640\n",
      "Epoch [843/1000], Loss: 0.4632\n",
      "Epoch [844/1000], Loss: 0.4647\n",
      "Epoch [845/1000], Loss: 0.4637\n",
      "Epoch [846/1000], Loss: 0.4644\n",
      "Epoch [847/1000], Loss: 0.4644\n",
      "Epoch [848/1000], Loss: 0.4630\n",
      "Epoch [849/1000], Loss: 0.4661\n",
      "Epoch [850/1000], Loss: 0.4640\n",
      "Epoch [851/1000], Loss: 0.4632\n",
      "Epoch [852/1000], Loss: 0.4635\n",
      "Epoch [853/1000], Loss: 0.4635\n",
      "Epoch [854/1000], Loss: 0.4642\n",
      "Epoch [855/1000], Loss: 0.4644\n",
      "Epoch [856/1000], Loss: 0.4635\n",
      "Epoch [857/1000], Loss: 0.4637\n",
      "Epoch [858/1000], Loss: 0.4640\n",
      "Epoch [859/1000], Loss: 0.4625\n",
      "Epoch [860/1000], Loss: 0.4644\n",
      "Epoch [861/1000], Loss: 0.4651\n",
      "Epoch [862/1000], Loss: 0.4637\n",
      "Epoch [863/1000], Loss: 0.4628\n",
      "Epoch [864/1000], Loss: 0.4647\n",
      "Epoch [865/1000], Loss: 0.4649\n",
      "Epoch [866/1000], Loss: 0.4632\n",
      "Epoch [867/1000], Loss: 0.4647\n",
      "Epoch [868/1000], Loss: 0.4654\n",
      "Epoch [869/1000], Loss: 0.4654\n",
      "Epoch [870/1000], Loss: 0.4620\n",
      "Epoch [871/1000], Loss: 0.4635\n",
      "Epoch [872/1000], Loss: 0.4649\n",
      "Epoch [873/1000], Loss: 0.4640\n",
      "Epoch [874/1000], Loss: 0.4661\n",
      "Epoch [875/1000], Loss: 0.4656\n",
      "Epoch [876/1000], Loss: 0.4640\n",
      "Epoch [877/1000], Loss: 0.4647\n",
      "Epoch [878/1000], Loss: 0.4649\n",
      "Epoch [879/1000], Loss: 0.4661\n",
      "Epoch [880/1000], Loss: 0.4628\n",
      "Epoch [881/1000], Loss: 0.4644\n",
      "Epoch [882/1000], Loss: 0.4663\n",
      "Epoch [883/1000], Loss: 0.4654\n",
      "Epoch [884/1000], Loss: 0.4651\n",
      "Epoch [885/1000], Loss: 0.4654\n",
      "Epoch [886/1000], Loss: 0.4649\n",
      "Epoch [887/1000], Loss: 0.4642\n",
      "Epoch [888/1000], Loss: 0.4654\n",
      "Epoch [889/1000], Loss: 0.4656\n",
      "Epoch [890/1000], Loss: 0.4647\n",
      "Epoch [891/1000], Loss: 0.4628\n",
      "Epoch [892/1000], Loss: 0.4651\n",
      "Epoch [893/1000], Loss: 0.4647\n",
      "Epoch [894/1000], Loss: 0.4642\n",
      "Epoch [895/1000], Loss: 0.4663\n",
      "Epoch [896/1000], Loss: 0.4632\n",
      "Epoch [897/1000], Loss: 0.4642\n",
      "Epoch [898/1000], Loss: 0.4630\n",
      "Epoch [899/1000], Loss: 0.4630\n",
      "Epoch [900/1000], Loss: 0.4642\n",
      "Epoch [901/1000], Loss: 0.4632\n",
      "Epoch [902/1000], Loss: 0.4654\n",
      "Epoch [903/1000], Loss: 0.4659\n",
      "Epoch [904/1000], Loss: 0.4640\n",
      "Epoch [905/1000], Loss: 0.4640\n",
      "Epoch [906/1000], Loss: 0.4635\n",
      "Epoch [907/1000], Loss: 0.4656\n",
      "Epoch [908/1000], Loss: 0.4654\n",
      "Epoch [909/1000], Loss: 0.4675\n",
      "Epoch [910/1000], Loss: 0.4654\n",
      "Epoch [911/1000], Loss: 0.4623\n",
      "Epoch [912/1000], Loss: 0.4616\n",
      "Epoch [913/1000], Loss: 0.4630\n",
      "Epoch [914/1000], Loss: 0.4651\n",
      "Epoch [915/1000], Loss: 0.4637\n",
      "Epoch [916/1000], Loss: 0.4625\n",
      "Epoch [917/1000], Loss: 0.4635\n",
      "Epoch [918/1000], Loss: 0.4654\n",
      "Epoch [919/1000], Loss: 0.4659\n",
      "Epoch [920/1000], Loss: 0.4661\n",
      "Epoch [921/1000], Loss: 0.4632\n",
      "Epoch [922/1000], Loss: 0.4642\n",
      "Epoch [923/1000], Loss: 0.4640\n",
      "Epoch [924/1000], Loss: 0.4661\n",
      "Epoch [925/1000], Loss: 0.4649\n",
      "Epoch [926/1000], Loss: 0.4623\n",
      "Epoch [927/1000], Loss: 0.4628\n",
      "Epoch [928/1000], Loss: 0.4635\n",
      "Epoch [929/1000], Loss: 0.4675\n",
      "Epoch [930/1000], Loss: 0.4659\n",
      "Epoch [931/1000], Loss: 0.4642\n",
      "Epoch [932/1000], Loss: 0.4647\n",
      "Epoch [933/1000], Loss: 0.4649\n",
      "Epoch [934/1000], Loss: 0.4654\n",
      "Epoch [935/1000], Loss: 0.4644\n",
      "Epoch [936/1000], Loss: 0.4663\n",
      "Epoch [937/1000], Loss: 0.4640\n",
      "Epoch [938/1000], Loss: 0.4656\n",
      "Epoch [939/1000], Loss: 0.4651\n",
      "Epoch [940/1000], Loss: 0.4647\n",
      "Epoch [941/1000], Loss: 0.4644\n",
      "Epoch [942/1000], Loss: 0.4659\n",
      "Epoch [943/1000], Loss: 0.4630\n",
      "Epoch [944/1000], Loss: 0.4651\n",
      "Epoch [945/1000], Loss: 0.4647\n",
      "Epoch [946/1000], Loss: 0.4640\n",
      "Epoch [947/1000], Loss: 0.4654\n",
      "Epoch [948/1000], Loss: 0.4644\n",
      "Epoch [949/1000], Loss: 0.4649\n",
      "Epoch [950/1000], Loss: 0.4635\n",
      "Epoch [951/1000], Loss: 0.4640\n",
      "Epoch [952/1000], Loss: 0.4632\n",
      "Epoch [953/1000], Loss: 0.4637\n",
      "Epoch [954/1000], Loss: 0.4656\n",
      "Epoch [955/1000], Loss: 0.4649\n",
      "Epoch [956/1000], Loss: 0.4635\n",
      "Epoch [957/1000], Loss: 0.4661\n",
      "Epoch [958/1000], Loss: 0.4654\n",
      "Epoch [959/1000], Loss: 0.4625\n",
      "Epoch [960/1000], Loss: 0.4649\n",
      "Epoch [961/1000], Loss: 0.4618\n",
      "Epoch [962/1000], Loss: 0.4644\n",
      "Epoch [963/1000], Loss: 0.4635\n",
      "Epoch [964/1000], Loss: 0.4623\n",
      "Epoch [965/1000], Loss: 0.4656\n",
      "Epoch [966/1000], Loss: 0.4640\n",
      "Epoch [967/1000], Loss: 0.4654\n",
      "Epoch [968/1000], Loss: 0.4654\n",
      "Epoch [969/1000], Loss: 0.4647\n",
      "Epoch [970/1000], Loss: 0.4628\n",
      "Epoch [971/1000], Loss: 0.4656\n",
      "Epoch [972/1000], Loss: 0.4654\n",
      "Epoch [973/1000], Loss: 0.4635\n",
      "Epoch [974/1000], Loss: 0.4661\n",
      "Epoch [975/1000], Loss: 0.4656\n",
      "Epoch [976/1000], Loss: 0.4635\n",
      "Epoch [977/1000], Loss: 0.4640\n",
      "Epoch [978/1000], Loss: 0.4637\n",
      "Epoch [979/1000], Loss: 0.4632\n",
      "Epoch [980/1000], Loss: 0.4649\n",
      "Epoch [981/1000], Loss: 0.4644\n",
      "Epoch [982/1000], Loss: 0.4640\n",
      "Epoch [983/1000], Loss: 0.4625\n",
      "Epoch [984/1000], Loss: 0.4620\n",
      "Epoch [985/1000], Loss: 0.4666\n",
      "Epoch [986/1000], Loss: 0.4637\n",
      "Epoch [987/1000], Loss: 0.4642\n",
      "Epoch [988/1000], Loss: 0.4618\n",
      "Epoch [989/1000], Loss: 0.4640\n",
      "Epoch [990/1000], Loss: 0.4649\n",
      "Epoch [991/1000], Loss: 0.4640\n",
      "Epoch [992/1000], Loss: 0.4647\n",
      "Epoch [993/1000], Loss: 0.4642\n",
      "Epoch [994/1000], Loss: 0.4640\n",
      "Epoch [995/1000], Loss: 0.4637\n",
      "Epoch [996/1000], Loss: 0.4642\n",
      "Epoch [997/1000], Loss: 0.4640\n",
      "Epoch [998/1000], Loss: 0.4651\n",
      "Epoch [999/1000], Loss: 0.4666\n",
      "Epoch [1000/1000], Loss: 0.4647\n",
      "Accuracy of the network on the 1000 validation data: 56.50 %\n",
      "Training model with batch_size: 205, lr :1.0, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.4725\n",
      "Epoch [2/1000], Loss: 0.4812\n",
      "Epoch [3/1000], Loss: 0.4821\n",
      "Epoch [4/1000], Loss: 0.4807\n",
      "Epoch [5/1000], Loss: 0.4814\n",
      "Epoch [6/1000], Loss: 0.4788\n",
      "Epoch [7/1000], Loss: 0.4819\n",
      "Epoch [8/1000], Loss: 0.4804\n",
      "Epoch [9/1000], Loss: 0.4804\n",
      "Epoch [10/1000], Loss: 0.4819\n",
      "Epoch [11/1000], Loss: 0.4814\n",
      "Epoch [12/1000], Loss: 0.4800\n",
      "Epoch [13/1000], Loss: 0.4785\n",
      "Epoch [14/1000], Loss: 0.4835\n",
      "Epoch [15/1000], Loss: 0.4807\n",
      "Epoch [16/1000], Loss: 0.4800\n",
      "Epoch [17/1000], Loss: 0.4812\n",
      "Epoch [18/1000], Loss: 0.4802\n",
      "Epoch [19/1000], Loss: 0.4804\n",
      "Epoch [20/1000], Loss: 0.4816\n",
      "Epoch [21/1000], Loss: 0.4814\n",
      "Epoch [22/1000], Loss: 0.4814\n",
      "Epoch [23/1000], Loss: 0.4797\n",
      "Epoch [24/1000], Loss: 0.4795\n",
      "Epoch [25/1000], Loss: 0.4809\n",
      "Epoch [26/1000], Loss: 0.4816\n",
      "Epoch [27/1000], Loss: 0.4826\n",
      "Epoch [28/1000], Loss: 0.4807\n",
      "Epoch [29/1000], Loss: 0.4809\n",
      "Epoch [30/1000], Loss: 0.4814\n",
      "Epoch [31/1000], Loss: 0.4819\n",
      "Epoch [32/1000], Loss: 0.4826\n",
      "Epoch [33/1000], Loss: 0.4816\n",
      "Epoch [34/1000], Loss: 0.4809\n",
      "Epoch [35/1000], Loss: 0.4814\n",
      "Epoch [36/1000], Loss: 0.4802\n",
      "Epoch [37/1000], Loss: 0.4823\n",
      "Epoch [38/1000], Loss: 0.4812\n",
      "Epoch [39/1000], Loss: 0.4804\n",
      "Epoch [40/1000], Loss: 0.4795\n",
      "Epoch [41/1000], Loss: 0.4812\n",
      "Epoch [42/1000], Loss: 0.4807\n",
      "Epoch [43/1000], Loss: 0.4826\n",
      "Epoch [44/1000], Loss: 0.4792\n",
      "Epoch [45/1000], Loss: 0.4821\n",
      "Epoch [46/1000], Loss: 0.4797\n",
      "Epoch [47/1000], Loss: 0.4819\n",
      "Epoch [48/1000], Loss: 0.4797\n",
      "Epoch [49/1000], Loss: 0.4819\n",
      "Epoch [50/1000], Loss: 0.4809\n",
      "Epoch [51/1000], Loss: 0.4804\n",
      "Epoch [52/1000], Loss: 0.4795\n",
      "Epoch [53/1000], Loss: 0.4812\n",
      "Epoch [54/1000], Loss: 0.4802\n",
      "Epoch [55/1000], Loss: 0.4812\n",
      "Epoch [56/1000], Loss: 0.4809\n",
      "Epoch [57/1000], Loss: 0.4797\n",
      "Epoch [58/1000], Loss: 0.4826\n",
      "Epoch [59/1000], Loss: 0.4792\n",
      "Epoch [60/1000], Loss: 0.4802\n",
      "Epoch [61/1000], Loss: 0.4812\n",
      "Epoch [62/1000], Loss: 0.4790\n",
      "Epoch [63/1000], Loss: 0.4795\n",
      "Epoch [64/1000], Loss: 0.4823\n",
      "Epoch [65/1000], Loss: 0.4816\n",
      "Epoch [66/1000], Loss: 0.4807\n",
      "Epoch [67/1000], Loss: 0.4807\n",
      "Epoch [68/1000], Loss: 0.4823\n",
      "Epoch [69/1000], Loss: 0.4821\n",
      "Epoch [70/1000], Loss: 0.4809\n",
      "Epoch [71/1000], Loss: 0.4826\n",
      "Epoch [72/1000], Loss: 0.4816\n",
      "Epoch [73/1000], Loss: 0.4807\n",
      "Epoch [74/1000], Loss: 0.4795\n",
      "Epoch [75/1000], Loss: 0.4812\n",
      "Epoch [76/1000], Loss: 0.4816\n",
      "Epoch [77/1000], Loss: 0.4819\n",
      "Epoch [78/1000], Loss: 0.4804\n",
      "Epoch [79/1000], Loss: 0.4807\n",
      "Epoch [80/1000], Loss: 0.4819\n",
      "Epoch [81/1000], Loss: 0.4800\n",
      "Epoch [82/1000], Loss: 0.4826\n",
      "Epoch [83/1000], Loss: 0.4809\n",
      "Epoch [84/1000], Loss: 0.4821\n",
      "Epoch [85/1000], Loss: 0.4804\n",
      "Epoch [86/1000], Loss: 0.4797\n",
      "Epoch [87/1000], Loss: 0.4800\n",
      "Epoch [88/1000], Loss: 0.4797\n",
      "Epoch [89/1000], Loss: 0.4776\n",
      "Epoch [90/1000], Loss: 0.4819\n",
      "Epoch [91/1000], Loss: 0.4814\n",
      "Epoch [92/1000], Loss: 0.4812\n",
      "Epoch [93/1000], Loss: 0.4790\n",
      "Epoch [94/1000], Loss: 0.4781\n",
      "Epoch [95/1000], Loss: 0.4809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/1000], Loss: 0.4816\n",
      "Epoch [97/1000], Loss: 0.4807\n",
      "Epoch [98/1000], Loss: 0.4828\n",
      "Epoch [99/1000], Loss: 0.4831\n",
      "Epoch [100/1000], Loss: 0.4823\n",
      "Epoch [101/1000], Loss: 0.4812\n",
      "Epoch [102/1000], Loss: 0.4802\n",
      "Epoch [103/1000], Loss: 0.4812\n",
      "Epoch [104/1000], Loss: 0.4797\n",
      "Epoch [105/1000], Loss: 0.4807\n",
      "Epoch [106/1000], Loss: 0.4809\n",
      "Epoch [107/1000], Loss: 0.4795\n",
      "Epoch [108/1000], Loss: 0.4812\n",
      "Epoch [109/1000], Loss: 0.4797\n",
      "Epoch [110/1000], Loss: 0.4807\n",
      "Epoch [111/1000], Loss: 0.4812\n",
      "Epoch [112/1000], Loss: 0.4807\n",
      "Epoch [113/1000], Loss: 0.4795\n",
      "Epoch [114/1000], Loss: 0.4797\n",
      "Epoch [115/1000], Loss: 0.4812\n",
      "Epoch [116/1000], Loss: 0.4785\n",
      "Epoch [117/1000], Loss: 0.4816\n",
      "Epoch [118/1000], Loss: 0.4802\n",
      "Epoch [119/1000], Loss: 0.4823\n",
      "Epoch [120/1000], Loss: 0.4809\n",
      "Epoch [121/1000], Loss: 0.4807\n",
      "Epoch [122/1000], Loss: 0.4816\n",
      "Epoch [123/1000], Loss: 0.4809\n",
      "Epoch [124/1000], Loss: 0.4814\n",
      "Epoch [125/1000], Loss: 0.4812\n",
      "Epoch [126/1000], Loss: 0.4814\n",
      "Epoch [127/1000], Loss: 0.4835\n",
      "Epoch [128/1000], Loss: 0.4807\n",
      "Epoch [129/1000], Loss: 0.4809\n",
      "Epoch [130/1000], Loss: 0.4814\n",
      "Epoch [131/1000], Loss: 0.4793\n",
      "Epoch [132/1000], Loss: 0.4800\n",
      "Epoch [133/1000], Loss: 0.4833\n",
      "Epoch [134/1000], Loss: 0.4790\n",
      "Epoch [135/1000], Loss: 0.4816\n",
      "Epoch [136/1000], Loss: 0.4833\n",
      "Epoch [137/1000], Loss: 0.4826\n",
      "Epoch [138/1000], Loss: 0.4804\n",
      "Epoch [139/1000], Loss: 0.4821\n",
      "Epoch [140/1000], Loss: 0.4800\n",
      "Epoch [141/1000], Loss: 0.4812\n",
      "Epoch [142/1000], Loss: 0.4816\n",
      "Epoch [143/1000], Loss: 0.4809\n",
      "Epoch [144/1000], Loss: 0.4812\n",
      "Epoch [145/1000], Loss: 0.4821\n",
      "Epoch [146/1000], Loss: 0.4788\n",
      "Epoch [147/1000], Loss: 0.4819\n",
      "Epoch [148/1000], Loss: 0.4788\n",
      "Epoch [149/1000], Loss: 0.4814\n",
      "Epoch [150/1000], Loss: 0.4802\n",
      "Epoch [151/1000], Loss: 0.4826\n",
      "Epoch [152/1000], Loss: 0.4802\n",
      "Epoch [153/1000], Loss: 0.4816\n",
      "Epoch [154/1000], Loss: 0.4795\n",
      "Epoch [155/1000], Loss: 0.4823\n",
      "Epoch [156/1000], Loss: 0.4807\n",
      "Epoch [157/1000], Loss: 0.4807\n",
      "Epoch [158/1000], Loss: 0.4788\n",
      "Epoch [159/1000], Loss: 0.4819\n",
      "Epoch [160/1000], Loss: 0.4804\n",
      "Epoch [161/1000], Loss: 0.4800\n",
      "Epoch [162/1000], Loss: 0.4800\n",
      "Epoch [163/1000], Loss: 0.4821\n",
      "Epoch [164/1000], Loss: 0.4804\n",
      "Epoch [165/1000], Loss: 0.4785\n",
      "Epoch [166/1000], Loss: 0.4797\n",
      "Epoch [167/1000], Loss: 0.4802\n",
      "Epoch [168/1000], Loss: 0.4807\n",
      "Epoch [169/1000], Loss: 0.4823\n",
      "Epoch [170/1000], Loss: 0.4819\n",
      "Epoch [171/1000], Loss: 0.4802\n",
      "Epoch [172/1000], Loss: 0.4812\n",
      "Epoch [173/1000], Loss: 0.4819\n",
      "Epoch [174/1000], Loss: 0.4835\n",
      "Epoch [175/1000], Loss: 0.4819\n",
      "Epoch [176/1000], Loss: 0.4819\n",
      "Epoch [177/1000], Loss: 0.4828\n",
      "Epoch [178/1000], Loss: 0.4819\n",
      "Epoch [179/1000], Loss: 0.4831\n",
      "Epoch [180/1000], Loss: 0.4802\n",
      "Epoch [181/1000], Loss: 0.4804\n",
      "Epoch [182/1000], Loss: 0.4802\n",
      "Epoch [183/1000], Loss: 0.4788\n",
      "Epoch [184/1000], Loss: 0.4826\n",
      "Epoch [185/1000], Loss: 0.4785\n",
      "Epoch [186/1000], Loss: 0.4793\n",
      "Epoch [187/1000], Loss: 0.4809\n",
      "Epoch [188/1000], Loss: 0.4804\n",
      "Epoch [189/1000], Loss: 0.4816\n",
      "Epoch [190/1000], Loss: 0.4792\n",
      "Epoch [191/1000], Loss: 0.4804\n",
      "Epoch [192/1000], Loss: 0.4802\n",
      "Epoch [193/1000], Loss: 0.4831\n",
      "Epoch [194/1000], Loss: 0.4792\n",
      "Epoch [195/1000], Loss: 0.4823\n",
      "Epoch [196/1000], Loss: 0.4802\n",
      "Epoch [197/1000], Loss: 0.4804\n",
      "Epoch [198/1000], Loss: 0.4814\n",
      "Epoch [199/1000], Loss: 0.4802\n",
      "Epoch [200/1000], Loss: 0.4785\n",
      "Epoch [201/1000], Loss: 0.4795\n",
      "Epoch [202/1000], Loss: 0.4814\n",
      "Epoch [203/1000], Loss: 0.4795\n",
      "Epoch [204/1000], Loss: 0.4814\n",
      "Epoch [205/1000], Loss: 0.4819\n",
      "Epoch [206/1000], Loss: 0.4802\n",
      "Epoch [207/1000], Loss: 0.4831\n",
      "Epoch [208/1000], Loss: 0.4812\n",
      "Epoch [209/1000], Loss: 0.4797\n",
      "Epoch [210/1000], Loss: 0.4809\n",
      "Epoch [211/1000], Loss: 0.4795\n",
      "Epoch [212/1000], Loss: 0.4795\n",
      "Epoch [213/1000], Loss: 0.4792\n",
      "Epoch [214/1000], Loss: 0.4807\n",
      "Epoch [215/1000], Loss: 0.4795\n",
      "Epoch [216/1000], Loss: 0.4807\n",
      "Epoch [217/1000], Loss: 0.4816\n",
      "Epoch [218/1000], Loss: 0.4812\n",
      "Epoch [219/1000], Loss: 0.4790\n",
      "Epoch [220/1000], Loss: 0.4812\n",
      "Epoch [221/1000], Loss: 0.4833\n",
      "Epoch [222/1000], Loss: 0.4790\n",
      "Epoch [223/1000], Loss: 0.4802\n",
      "Epoch [224/1000], Loss: 0.4814\n",
      "Epoch [225/1000], Loss: 0.4814\n",
      "Epoch [226/1000], Loss: 0.4802\n",
      "Epoch [227/1000], Loss: 0.4823\n",
      "Epoch [228/1000], Loss: 0.4819\n",
      "Epoch [229/1000], Loss: 0.4783\n",
      "Epoch [230/1000], Loss: 0.4821\n",
      "Epoch [231/1000], Loss: 0.4831\n",
      "Epoch [232/1000], Loss: 0.4812\n",
      "Epoch [233/1000], Loss: 0.4812\n",
      "Epoch [234/1000], Loss: 0.4804\n",
      "Epoch [235/1000], Loss: 0.4828\n",
      "Epoch [236/1000], Loss: 0.4821\n",
      "Epoch [237/1000], Loss: 0.4804\n",
      "Epoch [238/1000], Loss: 0.4800\n",
      "Epoch [239/1000], Loss: 0.4821\n",
      "Epoch [240/1000], Loss: 0.4821\n",
      "Epoch [241/1000], Loss: 0.4802\n",
      "Epoch [242/1000], Loss: 0.4812\n",
      "Epoch [243/1000], Loss: 0.4795\n",
      "Epoch [244/1000], Loss: 0.4812\n",
      "Epoch [245/1000], Loss: 0.4809\n",
      "Epoch [246/1000], Loss: 0.4804\n",
      "Epoch [247/1000], Loss: 0.4812\n",
      "Epoch [248/1000], Loss: 0.4819\n",
      "Epoch [249/1000], Loss: 0.4795\n",
      "Epoch [250/1000], Loss: 0.4819\n",
      "Epoch [251/1000], Loss: 0.4816\n",
      "Epoch [252/1000], Loss: 0.4802\n",
      "Epoch [253/1000], Loss: 0.4802\n",
      "Epoch [254/1000], Loss: 0.4807\n",
      "Epoch [255/1000], Loss: 0.4823\n",
      "Epoch [256/1000], Loss: 0.4804\n",
      "Epoch [257/1000], Loss: 0.4809\n",
      "Epoch [258/1000], Loss: 0.4819\n",
      "Epoch [259/1000], Loss: 0.4804\n",
      "Epoch [260/1000], Loss: 0.4783\n",
      "Epoch [261/1000], Loss: 0.4814\n",
      "Epoch [262/1000], Loss: 0.4797\n",
      "Epoch [263/1000], Loss: 0.4807\n",
      "Epoch [264/1000], Loss: 0.4795\n",
      "Epoch [265/1000], Loss: 0.4802\n",
      "Epoch [266/1000], Loss: 0.4826\n",
      "Epoch [267/1000], Loss: 0.4800\n",
      "Epoch [268/1000], Loss: 0.4797\n",
      "Epoch [269/1000], Loss: 0.4812\n",
      "Epoch [270/1000], Loss: 0.4816\n",
      "Epoch [271/1000], Loss: 0.4821\n",
      "Epoch [272/1000], Loss: 0.4812\n",
      "Epoch [273/1000], Loss: 0.4814\n",
      "Epoch [274/1000], Loss: 0.4823\n",
      "Epoch [275/1000], Loss: 0.4821\n",
      "Epoch [276/1000], Loss: 0.4828\n",
      "Epoch [277/1000], Loss: 0.4807\n",
      "Epoch [278/1000], Loss: 0.4833\n",
      "Epoch [279/1000], Loss: 0.4814\n",
      "Epoch [280/1000], Loss: 0.4812\n",
      "Epoch [281/1000], Loss: 0.4809\n",
      "Epoch [282/1000], Loss: 0.4788\n",
      "Epoch [283/1000], Loss: 0.4778\n",
      "Epoch [284/1000], Loss: 0.4812\n",
      "Epoch [285/1000], Loss: 0.4797\n",
      "Epoch [286/1000], Loss: 0.4819\n",
      "Epoch [287/1000], Loss: 0.4821\n",
      "Epoch [288/1000], Loss: 0.4826\n",
      "Epoch [289/1000], Loss: 0.4800\n",
      "Epoch [290/1000], Loss: 0.4814\n",
      "Epoch [291/1000], Loss: 0.4807\n",
      "Epoch [292/1000], Loss: 0.4800\n",
      "Epoch [293/1000], Loss: 0.4826\n",
      "Epoch [294/1000], Loss: 0.4788\n",
      "Epoch [295/1000], Loss: 0.4814\n",
      "Epoch [296/1000], Loss: 0.4823\n",
      "Epoch [297/1000], Loss: 0.4835\n",
      "Epoch [298/1000], Loss: 0.4807\n",
      "Epoch [299/1000], Loss: 0.4812\n",
      "Epoch [300/1000], Loss: 0.4809\n",
      "Epoch [301/1000], Loss: 0.4826\n",
      "Epoch [302/1000], Loss: 0.4804\n",
      "Epoch [303/1000], Loss: 0.4814\n",
      "Epoch [304/1000], Loss: 0.4816\n",
      "Epoch [305/1000], Loss: 0.4792\n",
      "Epoch [306/1000], Loss: 0.4807\n",
      "Epoch [307/1000], Loss: 0.4804\n",
      "Epoch [308/1000], Loss: 0.4816\n",
      "Epoch [309/1000], Loss: 0.4812\n",
      "Epoch [310/1000], Loss: 0.4788\n",
      "Epoch [311/1000], Loss: 0.4800\n",
      "Epoch [312/1000], Loss: 0.4802\n",
      "Epoch [313/1000], Loss: 0.4838\n",
      "Epoch [314/1000], Loss: 0.4809\n",
      "Epoch [315/1000], Loss: 0.4816\n",
      "Epoch [316/1000], Loss: 0.4809\n",
      "Epoch [317/1000], Loss: 0.4812\n",
      "Epoch [318/1000], Loss: 0.4814\n",
      "Epoch [319/1000], Loss: 0.4819\n",
      "Epoch [320/1000], Loss: 0.4809\n",
      "Epoch [321/1000], Loss: 0.4804\n",
      "Epoch [322/1000], Loss: 0.4809\n",
      "Epoch [323/1000], Loss: 0.4821\n",
      "Epoch [324/1000], Loss: 0.4812\n",
      "Epoch [325/1000], Loss: 0.4793\n",
      "Epoch [326/1000], Loss: 0.4821\n",
      "Epoch [327/1000], Loss: 0.4812\n",
      "Epoch [328/1000], Loss: 0.4828\n",
      "Epoch [329/1000], Loss: 0.4814\n",
      "Epoch [330/1000], Loss: 0.4793\n",
      "Epoch [331/1000], Loss: 0.4819\n",
      "Epoch [332/1000], Loss: 0.4809\n",
      "Epoch [333/1000], Loss: 0.4804\n",
      "Epoch [334/1000], Loss: 0.4826\n",
      "Epoch [335/1000], Loss: 0.4802\n",
      "Epoch [336/1000], Loss: 0.4807\n",
      "Epoch [337/1000], Loss: 0.4802\n",
      "Epoch [338/1000], Loss: 0.4804\n",
      "Epoch [339/1000], Loss: 0.4802\n",
      "Epoch [340/1000], Loss: 0.4814\n",
      "Epoch [341/1000], Loss: 0.4831\n",
      "Epoch [342/1000], Loss: 0.4795\n",
      "Epoch [343/1000], Loss: 0.4812\n",
      "Epoch [344/1000], Loss: 0.4800\n",
      "Epoch [345/1000], Loss: 0.4807\n",
      "Epoch [346/1000], Loss: 0.4802\n",
      "Epoch [347/1000], Loss: 0.4797\n",
      "Epoch [348/1000], Loss: 0.4828\n",
      "Epoch [349/1000], Loss: 0.4821\n",
      "Epoch [350/1000], Loss: 0.4783\n",
      "Epoch [351/1000], Loss: 0.4809\n",
      "Epoch [352/1000], Loss: 0.4802\n",
      "Epoch [353/1000], Loss: 0.4795\n",
      "Epoch [354/1000], Loss: 0.4807\n",
      "Epoch [355/1000], Loss: 0.4807\n",
      "Epoch [356/1000], Loss: 0.4785\n",
      "Epoch [357/1000], Loss: 0.4821\n",
      "Epoch [358/1000], Loss: 0.4785\n",
      "Epoch [359/1000], Loss: 0.4807\n",
      "Epoch [360/1000], Loss: 0.4783\n",
      "Epoch [361/1000], Loss: 0.4826\n",
      "Epoch [362/1000], Loss: 0.4788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [363/1000], Loss: 0.4797\n",
      "Epoch [364/1000], Loss: 0.4819\n",
      "Epoch [365/1000], Loss: 0.4790\n",
      "Epoch [366/1000], Loss: 0.4809\n",
      "Epoch [367/1000], Loss: 0.4804\n",
      "Epoch [368/1000], Loss: 0.4819\n",
      "Epoch [369/1000], Loss: 0.4797\n",
      "Epoch [370/1000], Loss: 0.4833\n",
      "Epoch [371/1000], Loss: 0.4816\n",
      "Epoch [372/1000], Loss: 0.4802\n",
      "Epoch [373/1000], Loss: 0.4816\n",
      "Epoch [374/1000], Loss: 0.4828\n",
      "Epoch [375/1000], Loss: 0.4814\n",
      "Epoch [376/1000], Loss: 0.4804\n",
      "Epoch [377/1000], Loss: 0.4816\n",
      "Epoch [378/1000], Loss: 0.4814\n",
      "Epoch [379/1000], Loss: 0.4812\n",
      "Epoch [380/1000], Loss: 0.4797\n",
      "Epoch [381/1000], Loss: 0.4804\n",
      "Epoch [382/1000], Loss: 0.4812\n",
      "Epoch [383/1000], Loss: 0.4804\n",
      "Epoch [384/1000], Loss: 0.4795\n",
      "Epoch [385/1000], Loss: 0.4802\n",
      "Epoch [386/1000], Loss: 0.4804\n",
      "Epoch [387/1000], Loss: 0.4821\n",
      "Epoch [388/1000], Loss: 0.4812\n",
      "Epoch [389/1000], Loss: 0.4783\n",
      "Epoch [390/1000], Loss: 0.4831\n",
      "Epoch [391/1000], Loss: 0.4797\n",
      "Epoch [392/1000], Loss: 0.4802\n",
      "Epoch [393/1000], Loss: 0.4785\n",
      "Epoch [394/1000], Loss: 0.4814\n",
      "Epoch [395/1000], Loss: 0.4814\n",
      "Epoch [396/1000], Loss: 0.4788\n",
      "Epoch [397/1000], Loss: 0.4802\n",
      "Epoch [398/1000], Loss: 0.4800\n",
      "Epoch [399/1000], Loss: 0.4807\n",
      "Epoch [400/1000], Loss: 0.4790\n",
      "Epoch [401/1000], Loss: 0.4821\n",
      "Epoch [402/1000], Loss: 0.4819\n",
      "Epoch [403/1000], Loss: 0.4804\n",
      "Epoch [404/1000], Loss: 0.4795\n",
      "Epoch [405/1000], Loss: 0.4812\n",
      "Epoch [406/1000], Loss: 0.4807\n",
      "Epoch [407/1000], Loss: 0.4795\n",
      "Epoch [408/1000], Loss: 0.4802\n",
      "Epoch [409/1000], Loss: 0.4800\n",
      "Epoch [410/1000], Loss: 0.4804\n",
      "Epoch [411/1000], Loss: 0.4812\n",
      "Epoch [412/1000], Loss: 0.4812\n",
      "Epoch [413/1000], Loss: 0.4790\n",
      "Epoch [414/1000], Loss: 0.4826\n",
      "Epoch [415/1000], Loss: 0.4800\n",
      "Epoch [416/1000], Loss: 0.4821\n",
      "Epoch [417/1000], Loss: 0.4797\n",
      "Epoch [418/1000], Loss: 0.4802\n",
      "Epoch [419/1000], Loss: 0.4809\n",
      "Epoch [420/1000], Loss: 0.4812\n",
      "Epoch [421/1000], Loss: 0.4819\n",
      "Epoch [422/1000], Loss: 0.4807\n",
      "Epoch [423/1000], Loss: 0.4831\n",
      "Epoch [424/1000], Loss: 0.4804\n",
      "Epoch [425/1000], Loss: 0.4812\n",
      "Epoch [426/1000], Loss: 0.4814\n",
      "Epoch [427/1000], Loss: 0.4826\n",
      "Epoch [428/1000], Loss: 0.4809\n",
      "Epoch [429/1000], Loss: 0.4823\n",
      "Epoch [430/1000], Loss: 0.4797\n",
      "Epoch [431/1000], Loss: 0.4804\n",
      "Epoch [432/1000], Loss: 0.4816\n",
      "Epoch [433/1000], Loss: 0.4819\n",
      "Epoch [434/1000], Loss: 0.4785\n",
      "Epoch [435/1000], Loss: 0.4814\n",
      "Epoch [436/1000], Loss: 0.4807\n",
      "Epoch [437/1000], Loss: 0.4828\n",
      "Epoch [438/1000], Loss: 0.4809\n",
      "Epoch [439/1000], Loss: 0.4819\n",
      "Epoch [440/1000], Loss: 0.4783\n",
      "Epoch [441/1000], Loss: 0.4819\n",
      "Epoch [442/1000], Loss: 0.4800\n",
      "Epoch [443/1000], Loss: 0.4819\n",
      "Epoch [444/1000], Loss: 0.4785\n",
      "Epoch [445/1000], Loss: 0.4807\n",
      "Epoch [446/1000], Loss: 0.4814\n",
      "Epoch [447/1000], Loss: 0.4812\n",
      "Epoch [448/1000], Loss: 0.4807\n",
      "Epoch [449/1000], Loss: 0.4809\n",
      "Epoch [450/1000], Loss: 0.4816\n",
      "Epoch [451/1000], Loss: 0.4804\n",
      "Epoch [452/1000], Loss: 0.4807\n",
      "Epoch [453/1000], Loss: 0.4804\n",
      "Epoch [454/1000], Loss: 0.4812\n",
      "Epoch [455/1000], Loss: 0.4802\n",
      "Epoch [456/1000], Loss: 0.4828\n",
      "Epoch [457/1000], Loss: 0.4821\n",
      "Epoch [458/1000], Loss: 0.4804\n",
      "Epoch [459/1000], Loss: 0.4802\n",
      "Epoch [460/1000], Loss: 0.4802\n",
      "Epoch [461/1000], Loss: 0.4821\n",
      "Epoch [462/1000], Loss: 0.4800\n",
      "Epoch [463/1000], Loss: 0.4807\n",
      "Epoch [464/1000], Loss: 0.4816\n",
      "Epoch [465/1000], Loss: 0.4807\n",
      "Epoch [466/1000], Loss: 0.4807\n",
      "Epoch [467/1000], Loss: 0.4816\n",
      "Epoch [468/1000], Loss: 0.4809\n",
      "Epoch [469/1000], Loss: 0.4807\n",
      "Epoch [470/1000], Loss: 0.4812\n",
      "Epoch [471/1000], Loss: 0.4809\n",
      "Epoch [472/1000], Loss: 0.4819\n",
      "Epoch [473/1000], Loss: 0.4816\n",
      "Epoch [474/1000], Loss: 0.4807\n",
      "Epoch [475/1000], Loss: 0.4812\n",
      "Epoch [476/1000], Loss: 0.4823\n",
      "Epoch [477/1000], Loss: 0.4812\n",
      "Epoch [478/1000], Loss: 0.4804\n",
      "Epoch [479/1000], Loss: 0.4823\n",
      "Epoch [480/1000], Loss: 0.4790\n",
      "Epoch [481/1000], Loss: 0.4788\n",
      "Epoch [482/1000], Loss: 0.4795\n",
      "Epoch [483/1000], Loss: 0.4816\n",
      "Epoch [484/1000], Loss: 0.4809\n",
      "Epoch [485/1000], Loss: 0.4812\n",
      "Epoch [486/1000], Loss: 0.4807\n",
      "Epoch [487/1000], Loss: 0.4807\n",
      "Epoch [488/1000], Loss: 0.4838\n",
      "Epoch [489/1000], Loss: 0.4831\n",
      "Epoch [490/1000], Loss: 0.4816\n",
      "Epoch [491/1000], Loss: 0.4821\n",
      "Epoch [492/1000], Loss: 0.4807\n",
      "Epoch [493/1000], Loss: 0.4804\n",
      "Epoch [494/1000], Loss: 0.4804\n",
      "Epoch [495/1000], Loss: 0.4802\n",
      "Epoch [496/1000], Loss: 0.4835\n",
      "Epoch [497/1000], Loss: 0.4809\n",
      "Epoch [498/1000], Loss: 0.4785\n",
      "Epoch [499/1000], Loss: 0.4807\n",
      "Epoch [500/1000], Loss: 0.4790\n",
      "Epoch [501/1000], Loss: 0.4795\n",
      "Epoch [502/1000], Loss: 0.4802\n",
      "Epoch [503/1000], Loss: 0.4816\n",
      "Epoch [504/1000], Loss: 0.4828\n",
      "Epoch [505/1000], Loss: 0.4802\n",
      "Epoch [506/1000], Loss: 0.4826\n",
      "Epoch [507/1000], Loss: 0.4790\n",
      "Epoch [508/1000], Loss: 0.4812\n",
      "Epoch [509/1000], Loss: 0.4804\n",
      "Epoch [510/1000], Loss: 0.4804\n",
      "Epoch [511/1000], Loss: 0.4804\n",
      "Epoch [512/1000], Loss: 0.4809\n",
      "Epoch [513/1000], Loss: 0.4814\n",
      "Epoch [514/1000], Loss: 0.4812\n",
      "Epoch [515/1000], Loss: 0.4804\n",
      "Epoch [516/1000], Loss: 0.4814\n",
      "Epoch [517/1000], Loss: 0.4812\n",
      "Epoch [518/1000], Loss: 0.4838\n",
      "Epoch [519/1000], Loss: 0.4797\n",
      "Epoch [520/1000], Loss: 0.4807\n",
      "Epoch [521/1000], Loss: 0.4819\n",
      "Epoch [522/1000], Loss: 0.4800\n",
      "Epoch [523/1000], Loss: 0.4807\n",
      "Epoch [524/1000], Loss: 0.4804\n",
      "Epoch [525/1000], Loss: 0.4802\n",
      "Epoch [526/1000], Loss: 0.4802\n",
      "Epoch [527/1000], Loss: 0.4814\n",
      "Epoch [528/1000], Loss: 0.4816\n",
      "Epoch [529/1000], Loss: 0.4773\n",
      "Epoch [530/1000], Loss: 0.4812\n",
      "Epoch [531/1000], Loss: 0.4826\n",
      "Epoch [532/1000], Loss: 0.4831\n",
      "Epoch [533/1000], Loss: 0.4797\n",
      "Epoch [534/1000], Loss: 0.4785\n",
      "Epoch [535/1000], Loss: 0.4807\n",
      "Epoch [536/1000], Loss: 0.4828\n",
      "Epoch [537/1000], Loss: 0.4828\n",
      "Epoch [538/1000], Loss: 0.4802\n",
      "Epoch [539/1000], Loss: 0.4809\n",
      "Epoch [540/1000], Loss: 0.4831\n",
      "Epoch [541/1000], Loss: 0.4809\n",
      "Epoch [542/1000], Loss: 0.4823\n",
      "Epoch [543/1000], Loss: 0.4802\n",
      "Epoch [544/1000], Loss: 0.4823\n",
      "Epoch [545/1000], Loss: 0.4795\n",
      "Epoch [546/1000], Loss: 0.4823\n",
      "Epoch [547/1000], Loss: 0.4812\n",
      "Epoch [548/1000], Loss: 0.4819\n",
      "Epoch [549/1000], Loss: 0.4795\n",
      "Epoch [550/1000], Loss: 0.4814\n",
      "Epoch [551/1000], Loss: 0.4812\n",
      "Epoch [552/1000], Loss: 0.4812\n",
      "Epoch [553/1000], Loss: 0.4816\n",
      "Epoch [554/1000], Loss: 0.4819\n",
      "Epoch [555/1000], Loss: 0.4792\n",
      "Epoch [556/1000], Loss: 0.4809\n",
      "Epoch [557/1000], Loss: 0.4828\n",
      "Epoch [558/1000], Loss: 0.4795\n",
      "Epoch [559/1000], Loss: 0.4788\n",
      "Epoch [560/1000], Loss: 0.4823\n",
      "Epoch [561/1000], Loss: 0.4802\n",
      "Epoch [562/1000], Loss: 0.4809\n",
      "Epoch [563/1000], Loss: 0.4816\n",
      "Epoch [564/1000], Loss: 0.4835\n",
      "Epoch [565/1000], Loss: 0.4819\n",
      "Epoch [566/1000], Loss: 0.4809\n",
      "Epoch [567/1000], Loss: 0.4804\n",
      "Epoch [568/1000], Loss: 0.4783\n",
      "Epoch [569/1000], Loss: 0.4802\n",
      "Epoch [570/1000], Loss: 0.4802\n",
      "Epoch [571/1000], Loss: 0.4819\n",
      "Epoch [572/1000], Loss: 0.4809\n",
      "Epoch [573/1000], Loss: 0.4814\n",
      "Epoch [574/1000], Loss: 0.4802\n",
      "Epoch [575/1000], Loss: 0.4819\n",
      "Epoch [576/1000], Loss: 0.4800\n",
      "Epoch [577/1000], Loss: 0.4807\n",
      "Epoch [578/1000], Loss: 0.4816\n",
      "Epoch [579/1000], Loss: 0.4804\n",
      "Epoch [580/1000], Loss: 0.4821\n",
      "Epoch [581/1000], Loss: 0.4814\n",
      "Epoch [582/1000], Loss: 0.4812\n",
      "Epoch [583/1000], Loss: 0.4828\n",
      "Epoch [584/1000], Loss: 0.4804\n",
      "Epoch [585/1000], Loss: 0.4828\n",
      "Epoch [586/1000], Loss: 0.4809\n",
      "Epoch [587/1000], Loss: 0.4826\n",
      "Epoch [588/1000], Loss: 0.4814\n",
      "Epoch [589/1000], Loss: 0.4793\n",
      "Epoch [590/1000], Loss: 0.4816\n",
      "Epoch [591/1000], Loss: 0.4821\n",
      "Epoch [592/1000], Loss: 0.4819\n",
      "Epoch [593/1000], Loss: 0.4814\n",
      "Epoch [594/1000], Loss: 0.4816\n",
      "Epoch [595/1000], Loss: 0.4821\n",
      "Epoch [596/1000], Loss: 0.4790\n",
      "Epoch [597/1000], Loss: 0.4814\n",
      "Epoch [598/1000], Loss: 0.4809\n",
      "Epoch [599/1000], Loss: 0.4812\n",
      "Epoch [600/1000], Loss: 0.4821\n",
      "Epoch [601/1000], Loss: 0.4814\n",
      "Epoch [602/1000], Loss: 0.4788\n",
      "Epoch [603/1000], Loss: 0.4804\n",
      "Epoch [604/1000], Loss: 0.4812\n",
      "Epoch [605/1000], Loss: 0.4800\n",
      "Epoch [606/1000], Loss: 0.4809\n",
      "Epoch [607/1000], Loss: 0.4812\n",
      "Epoch [608/1000], Loss: 0.4821\n",
      "Epoch [609/1000], Loss: 0.4828\n",
      "Epoch [610/1000], Loss: 0.4814\n",
      "Epoch [611/1000], Loss: 0.4814\n",
      "Epoch [612/1000], Loss: 0.4812\n",
      "Epoch [613/1000], Loss: 0.4823\n",
      "Epoch [614/1000], Loss: 0.4821\n",
      "Epoch [615/1000], Loss: 0.4800\n",
      "Epoch [616/1000], Loss: 0.4802\n",
      "Epoch [617/1000], Loss: 0.4812\n",
      "Epoch [618/1000], Loss: 0.4812\n",
      "Epoch [619/1000], Loss: 0.4812\n",
      "Epoch [620/1000], Loss: 0.4790\n",
      "Epoch [621/1000], Loss: 0.4795\n",
      "Epoch [622/1000], Loss: 0.4831\n",
      "Epoch [623/1000], Loss: 0.4781\n",
      "Epoch [624/1000], Loss: 0.4835\n",
      "Epoch [625/1000], Loss: 0.4804\n",
      "Epoch [626/1000], Loss: 0.4816\n",
      "Epoch [627/1000], Loss: 0.4804\n",
      "Epoch [628/1000], Loss: 0.4814\n",
      "Epoch [629/1000], Loss: 0.4823\n",
      "Epoch [630/1000], Loss: 0.4800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [631/1000], Loss: 0.4800\n",
      "Epoch [632/1000], Loss: 0.4814\n",
      "Epoch [633/1000], Loss: 0.4809\n",
      "Epoch [634/1000], Loss: 0.4797\n",
      "Epoch [635/1000], Loss: 0.4802\n",
      "Epoch [636/1000], Loss: 0.4833\n",
      "Epoch [637/1000], Loss: 0.4790\n",
      "Epoch [638/1000], Loss: 0.4823\n",
      "Epoch [639/1000], Loss: 0.4812\n",
      "Epoch [640/1000], Loss: 0.4802\n",
      "Epoch [641/1000], Loss: 0.4821\n",
      "Epoch [642/1000], Loss: 0.4809\n",
      "Epoch [643/1000], Loss: 0.4809\n",
      "Epoch [644/1000], Loss: 0.4819\n",
      "Epoch [645/1000], Loss: 0.4819\n",
      "Epoch [646/1000], Loss: 0.4797\n",
      "Epoch [647/1000], Loss: 0.4802\n",
      "Epoch [648/1000], Loss: 0.4809\n",
      "Epoch [649/1000], Loss: 0.4812\n",
      "Epoch [650/1000], Loss: 0.4788\n",
      "Epoch [651/1000], Loss: 0.4804\n",
      "Epoch [652/1000], Loss: 0.4804\n",
      "Epoch [653/1000], Loss: 0.4819\n",
      "Epoch [654/1000], Loss: 0.4790\n",
      "Epoch [655/1000], Loss: 0.4831\n",
      "Epoch [656/1000], Loss: 0.4814\n",
      "Epoch [657/1000], Loss: 0.4800\n",
      "Epoch [658/1000], Loss: 0.4792\n",
      "Epoch [659/1000], Loss: 0.4800\n",
      "Epoch [660/1000], Loss: 0.4788\n",
      "Epoch [661/1000], Loss: 0.4809\n",
      "Epoch [662/1000], Loss: 0.4802\n",
      "Epoch [663/1000], Loss: 0.4809\n",
      "Epoch [664/1000], Loss: 0.4804\n",
      "Epoch [665/1000], Loss: 0.4819\n",
      "Epoch [666/1000], Loss: 0.4814\n",
      "Epoch [667/1000], Loss: 0.4807\n",
      "Epoch [668/1000], Loss: 0.4826\n",
      "Epoch [669/1000], Loss: 0.4793\n",
      "Epoch [670/1000], Loss: 0.4816\n",
      "Epoch [671/1000], Loss: 0.4793\n",
      "Epoch [672/1000], Loss: 0.4797\n",
      "Epoch [673/1000], Loss: 0.4804\n",
      "Epoch [674/1000], Loss: 0.4802\n",
      "Epoch [675/1000], Loss: 0.4819\n",
      "Epoch [676/1000], Loss: 0.4804\n",
      "Epoch [677/1000], Loss: 0.4809\n",
      "Epoch [678/1000], Loss: 0.4797\n",
      "Epoch [679/1000], Loss: 0.4821\n",
      "Epoch [680/1000], Loss: 0.4821\n",
      "Epoch [681/1000], Loss: 0.4816\n",
      "Epoch [682/1000], Loss: 0.4814\n",
      "Epoch [683/1000], Loss: 0.4823\n",
      "Epoch [684/1000], Loss: 0.4800\n",
      "Epoch [685/1000], Loss: 0.4809\n",
      "Epoch [686/1000], Loss: 0.4819\n",
      "Epoch [687/1000], Loss: 0.4800\n",
      "Epoch [688/1000], Loss: 0.4814\n",
      "Epoch [689/1000], Loss: 0.4819\n",
      "Epoch [690/1000], Loss: 0.4814\n",
      "Epoch [691/1000], Loss: 0.4797\n",
      "Epoch [692/1000], Loss: 0.4816\n",
      "Epoch [693/1000], Loss: 0.4812\n",
      "Epoch [694/1000], Loss: 0.4816\n",
      "Epoch [695/1000], Loss: 0.4823\n",
      "Epoch [696/1000], Loss: 0.4814\n",
      "Epoch [697/1000], Loss: 0.4797\n",
      "Epoch [698/1000], Loss: 0.4809\n",
      "Epoch [699/1000], Loss: 0.4809\n",
      "Epoch [700/1000], Loss: 0.4783\n",
      "Epoch [701/1000], Loss: 0.4831\n",
      "Epoch [702/1000], Loss: 0.4812\n",
      "Epoch [703/1000], Loss: 0.4831\n",
      "Epoch [704/1000], Loss: 0.4826\n",
      "Epoch [705/1000], Loss: 0.4828\n",
      "Epoch [706/1000], Loss: 0.4826\n",
      "Epoch [707/1000], Loss: 0.4792\n",
      "Epoch [708/1000], Loss: 0.4788\n",
      "Epoch [709/1000], Loss: 0.4802\n",
      "Epoch [710/1000], Loss: 0.4804\n",
      "Epoch [711/1000], Loss: 0.4821\n",
      "Epoch [712/1000], Loss: 0.4797\n",
      "Epoch [713/1000], Loss: 0.4804\n",
      "Epoch [714/1000], Loss: 0.4781\n",
      "Epoch [715/1000], Loss: 0.4800\n",
      "Epoch [716/1000], Loss: 0.4828\n",
      "Epoch [717/1000], Loss: 0.4812\n",
      "Epoch [718/1000], Loss: 0.4812\n",
      "Epoch [719/1000], Loss: 0.4807\n",
      "Epoch [720/1000], Loss: 0.4812\n",
      "Epoch [721/1000], Loss: 0.4826\n",
      "Epoch [722/1000], Loss: 0.4788\n",
      "Epoch [723/1000], Loss: 0.4814\n",
      "Epoch [724/1000], Loss: 0.4802\n",
      "Epoch [725/1000], Loss: 0.4828\n",
      "Epoch [726/1000], Loss: 0.4802\n",
      "Epoch [727/1000], Loss: 0.4809\n",
      "Epoch [728/1000], Loss: 0.4807\n",
      "Epoch [729/1000], Loss: 0.4814\n",
      "Epoch [730/1000], Loss: 0.4821\n",
      "Epoch [731/1000], Loss: 0.4802\n",
      "Epoch [732/1000], Loss: 0.4802\n",
      "Epoch [733/1000], Loss: 0.4826\n",
      "Epoch [734/1000], Loss: 0.4831\n",
      "Epoch [735/1000], Loss: 0.4804\n",
      "Epoch [736/1000], Loss: 0.4823\n",
      "Epoch [737/1000], Loss: 0.4804\n",
      "Epoch [738/1000], Loss: 0.4814\n",
      "Epoch [739/1000], Loss: 0.4797\n",
      "Epoch [740/1000], Loss: 0.4807\n",
      "Epoch [741/1000], Loss: 0.4826\n",
      "Epoch [742/1000], Loss: 0.4802\n",
      "Epoch [743/1000], Loss: 0.4812\n",
      "Epoch [744/1000], Loss: 0.4807\n",
      "Epoch [745/1000], Loss: 0.4809\n",
      "Epoch [746/1000], Loss: 0.4823\n",
      "Epoch [747/1000], Loss: 0.4795\n",
      "Epoch [748/1000], Loss: 0.4802\n",
      "Epoch [749/1000], Loss: 0.4807\n",
      "Epoch [750/1000], Loss: 0.4833\n",
      "Epoch [751/1000], Loss: 0.4792\n",
      "Epoch [752/1000], Loss: 0.4804\n",
      "Epoch [753/1000], Loss: 0.4814\n",
      "Epoch [754/1000], Loss: 0.4788\n",
      "Epoch [755/1000], Loss: 0.4814\n",
      "Epoch [756/1000], Loss: 0.4795\n",
      "Epoch [757/1000], Loss: 0.4788\n",
      "Epoch [758/1000], Loss: 0.4807\n",
      "Epoch [759/1000], Loss: 0.4821\n",
      "Epoch [760/1000], Loss: 0.4812\n",
      "Epoch [761/1000], Loss: 0.4819\n",
      "Epoch [762/1000], Loss: 0.4843\n",
      "Epoch [763/1000], Loss: 0.4802\n",
      "Epoch [764/1000], Loss: 0.4828\n",
      "Epoch [765/1000], Loss: 0.4809\n",
      "Epoch [766/1000], Loss: 0.4797\n",
      "Epoch [767/1000], Loss: 0.4807\n",
      "Epoch [768/1000], Loss: 0.4816\n",
      "Epoch [769/1000], Loss: 0.4814\n",
      "Epoch [770/1000], Loss: 0.4828\n",
      "Epoch [771/1000], Loss: 0.4802\n",
      "Epoch [772/1000], Loss: 0.4809\n",
      "Epoch [773/1000], Loss: 0.4790\n",
      "Epoch [774/1000], Loss: 0.4807\n",
      "Epoch [775/1000], Loss: 0.4821\n",
      "Epoch [776/1000], Loss: 0.4814\n",
      "Epoch [777/1000], Loss: 0.4821\n",
      "Epoch [778/1000], Loss: 0.4795\n",
      "Epoch [779/1000], Loss: 0.4831\n",
      "Epoch [780/1000], Loss: 0.4826\n",
      "Epoch [781/1000], Loss: 0.4797\n",
      "Epoch [782/1000], Loss: 0.4819\n",
      "Epoch [783/1000], Loss: 0.4833\n",
      "Epoch [784/1000], Loss: 0.4831\n",
      "Epoch [785/1000], Loss: 0.4814\n",
      "Epoch [786/1000], Loss: 0.4792\n",
      "Epoch [787/1000], Loss: 0.4819\n",
      "Epoch [788/1000], Loss: 0.4826\n",
      "Epoch [789/1000], Loss: 0.4809\n",
      "Epoch [790/1000], Loss: 0.4788\n",
      "Epoch [791/1000], Loss: 0.4816\n",
      "Epoch [792/1000], Loss: 0.4797\n",
      "Epoch [793/1000], Loss: 0.4814\n",
      "Epoch [794/1000], Loss: 0.4804\n",
      "Epoch [795/1000], Loss: 0.4792\n",
      "Epoch [796/1000], Loss: 0.4816\n",
      "Epoch [797/1000], Loss: 0.4809\n",
      "Epoch [798/1000], Loss: 0.4800\n",
      "Epoch [799/1000], Loss: 0.4838\n",
      "Epoch [800/1000], Loss: 0.4812\n",
      "Epoch [801/1000], Loss: 0.4797\n",
      "Epoch [802/1000], Loss: 0.4828\n",
      "Epoch [803/1000], Loss: 0.4819\n",
      "Epoch [804/1000], Loss: 0.4812\n",
      "Epoch [805/1000], Loss: 0.4788\n",
      "Epoch [806/1000], Loss: 0.4809\n",
      "Epoch [807/1000], Loss: 0.4807\n",
      "Epoch [808/1000], Loss: 0.4792\n",
      "Epoch [809/1000], Loss: 0.4807\n",
      "Epoch [810/1000], Loss: 0.4809\n",
      "Epoch [811/1000], Loss: 0.4814\n",
      "Epoch [812/1000], Loss: 0.4800\n",
      "Epoch [813/1000], Loss: 0.4802\n",
      "Epoch [814/1000], Loss: 0.4804\n",
      "Epoch [815/1000], Loss: 0.4793\n",
      "Epoch [816/1000], Loss: 0.4809\n",
      "Epoch [817/1000], Loss: 0.4845\n",
      "Epoch [818/1000], Loss: 0.4812\n",
      "Epoch [819/1000], Loss: 0.4797\n",
      "Epoch [820/1000], Loss: 0.4819\n",
      "Epoch [821/1000], Loss: 0.4797\n",
      "Epoch [822/1000], Loss: 0.4823\n",
      "Epoch [823/1000], Loss: 0.4783\n",
      "Epoch [824/1000], Loss: 0.4831\n",
      "Epoch [825/1000], Loss: 0.4804\n",
      "Epoch [826/1000], Loss: 0.4793\n",
      "Epoch [827/1000], Loss: 0.4812\n",
      "Epoch [828/1000], Loss: 0.4826\n",
      "Epoch [829/1000], Loss: 0.4823\n",
      "Epoch [830/1000], Loss: 0.4807\n",
      "Epoch [831/1000], Loss: 0.4795\n",
      "Epoch [832/1000], Loss: 0.4804\n",
      "Epoch [833/1000], Loss: 0.4790\n",
      "Epoch [834/1000], Loss: 0.4828\n",
      "Epoch [835/1000], Loss: 0.4807\n",
      "Epoch [836/1000], Loss: 0.4807\n",
      "Epoch [837/1000], Loss: 0.4800\n",
      "Epoch [838/1000], Loss: 0.4795\n",
      "Epoch [839/1000], Loss: 0.4800\n",
      "Epoch [840/1000], Loss: 0.4833\n",
      "Epoch [841/1000], Loss: 0.4804\n",
      "Epoch [842/1000], Loss: 0.4812\n",
      "Epoch [843/1000], Loss: 0.4809\n",
      "Epoch [844/1000], Loss: 0.4804\n",
      "Epoch [845/1000], Loss: 0.4800\n",
      "Epoch [846/1000], Loss: 0.4831\n",
      "Epoch [847/1000], Loss: 0.4809\n",
      "Epoch [848/1000], Loss: 0.4807\n",
      "Epoch [849/1000], Loss: 0.4835\n",
      "Epoch [850/1000], Loss: 0.4812\n",
      "Epoch [851/1000], Loss: 0.4823\n",
      "Epoch [852/1000], Loss: 0.4800\n",
      "Epoch [853/1000], Loss: 0.4823\n",
      "Epoch [854/1000], Loss: 0.4804\n",
      "Epoch [855/1000], Loss: 0.4831\n",
      "Epoch [856/1000], Loss: 0.4807\n",
      "Epoch [857/1000], Loss: 0.4814\n",
      "Epoch [858/1000], Loss: 0.4807\n",
      "Epoch [859/1000], Loss: 0.4812\n",
      "Epoch [860/1000], Loss: 0.4812\n",
      "Epoch [861/1000], Loss: 0.4807\n",
      "Epoch [862/1000], Loss: 0.4807\n",
      "Epoch [863/1000], Loss: 0.4797\n",
      "Epoch [864/1000], Loss: 0.4821\n",
      "Epoch [865/1000], Loss: 0.4831\n",
      "Epoch [866/1000], Loss: 0.4831\n",
      "Epoch [867/1000], Loss: 0.4835\n",
      "Epoch [868/1000], Loss: 0.4795\n",
      "Epoch [869/1000], Loss: 0.4800\n",
      "Epoch [870/1000], Loss: 0.4816\n",
      "Epoch [871/1000], Loss: 0.4814\n",
      "Epoch [872/1000], Loss: 0.4807\n",
      "Epoch [873/1000], Loss: 0.4800\n",
      "Epoch [874/1000], Loss: 0.4812\n",
      "Epoch [875/1000], Loss: 0.4800\n",
      "Epoch [876/1000], Loss: 0.4807\n",
      "Epoch [877/1000], Loss: 0.4809\n",
      "Epoch [878/1000], Loss: 0.4823\n",
      "Epoch [879/1000], Loss: 0.4807\n",
      "Epoch [880/1000], Loss: 0.4809\n",
      "Epoch [881/1000], Loss: 0.4812\n",
      "Epoch [882/1000], Loss: 0.4816\n",
      "Epoch [883/1000], Loss: 0.4833\n",
      "Epoch [884/1000], Loss: 0.4804\n",
      "Epoch [885/1000], Loss: 0.4816\n",
      "Epoch [886/1000], Loss: 0.4797\n",
      "Epoch [887/1000], Loss: 0.4809\n",
      "Epoch [888/1000], Loss: 0.4793\n",
      "Epoch [889/1000], Loss: 0.4816\n",
      "Epoch [890/1000], Loss: 0.4793\n",
      "Epoch [891/1000], Loss: 0.4804\n",
      "Epoch [892/1000], Loss: 0.4809\n",
      "Epoch [893/1000], Loss: 0.4807\n",
      "Epoch [894/1000], Loss: 0.4781\n",
      "Epoch [895/1000], Loss: 0.4797\n",
      "Epoch [896/1000], Loss: 0.4790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [897/1000], Loss: 0.4814\n",
      "Epoch [898/1000], Loss: 0.4828\n",
      "Epoch [899/1000], Loss: 0.4781\n",
      "Epoch [900/1000], Loss: 0.4814\n",
      "Epoch [901/1000], Loss: 0.4819\n",
      "Epoch [902/1000], Loss: 0.4802\n",
      "Epoch [903/1000], Loss: 0.4833\n",
      "Epoch [904/1000], Loss: 0.4804\n",
      "Epoch [905/1000], Loss: 0.4831\n",
      "Epoch [906/1000], Loss: 0.4788\n",
      "Epoch [907/1000], Loss: 0.4812\n",
      "Epoch [908/1000], Loss: 0.4828\n",
      "Epoch [909/1000], Loss: 0.4835\n",
      "Epoch [910/1000], Loss: 0.4821\n",
      "Epoch [911/1000], Loss: 0.4807\n",
      "Epoch [912/1000], Loss: 0.4781\n",
      "Epoch [913/1000], Loss: 0.4800\n",
      "Epoch [914/1000], Loss: 0.4802\n",
      "Epoch [915/1000], Loss: 0.4800\n",
      "Epoch [916/1000], Loss: 0.4800\n",
      "Epoch [917/1000], Loss: 0.4804\n",
      "Epoch [918/1000], Loss: 0.4804\n",
      "Epoch [919/1000], Loss: 0.4797\n",
      "Epoch [920/1000], Loss: 0.4812\n",
      "Epoch [921/1000], Loss: 0.4826\n",
      "Epoch [922/1000], Loss: 0.4809\n",
      "Epoch [923/1000], Loss: 0.4802\n",
      "Epoch [924/1000], Loss: 0.4807\n",
      "Epoch [925/1000], Loss: 0.4828\n",
      "Epoch [926/1000], Loss: 0.4783\n",
      "Epoch [927/1000], Loss: 0.4800\n",
      "Epoch [928/1000], Loss: 0.4812\n",
      "Epoch [929/1000], Loss: 0.4802\n",
      "Epoch [930/1000], Loss: 0.4816\n",
      "Epoch [931/1000], Loss: 0.4790\n",
      "Epoch [932/1000], Loss: 0.4797\n",
      "Epoch [933/1000], Loss: 0.4807\n",
      "Epoch [934/1000], Loss: 0.4812\n",
      "Epoch [935/1000], Loss: 0.4812\n",
      "Epoch [936/1000], Loss: 0.4814\n",
      "Epoch [937/1000], Loss: 0.4812\n",
      "Epoch [938/1000], Loss: 0.4800\n",
      "Epoch [939/1000], Loss: 0.4831\n",
      "Epoch [940/1000], Loss: 0.4792\n",
      "Epoch [941/1000], Loss: 0.4802\n",
      "Epoch [942/1000], Loss: 0.4816\n",
      "Epoch [943/1000], Loss: 0.4807\n",
      "Epoch [944/1000], Loss: 0.4819\n",
      "Epoch [945/1000], Loss: 0.4797\n",
      "Epoch [946/1000], Loss: 0.4793\n",
      "Epoch [947/1000], Loss: 0.4809\n",
      "Epoch [948/1000], Loss: 0.4783\n",
      "Epoch [949/1000], Loss: 0.4807\n",
      "Epoch [950/1000], Loss: 0.4814\n",
      "Epoch [951/1000], Loss: 0.4792\n",
      "Epoch [952/1000], Loss: 0.4816\n",
      "Epoch [953/1000], Loss: 0.4788\n",
      "Epoch [954/1000], Loss: 0.4800\n",
      "Epoch [955/1000], Loss: 0.4807\n",
      "Epoch [956/1000], Loss: 0.4800\n",
      "Epoch [957/1000], Loss: 0.4807\n",
      "Epoch [958/1000], Loss: 0.4814\n",
      "Epoch [959/1000], Loss: 0.4826\n",
      "Epoch [960/1000], Loss: 0.4821\n",
      "Epoch [961/1000], Loss: 0.4816\n",
      "Epoch [962/1000], Loss: 0.4812\n",
      "Epoch [963/1000], Loss: 0.4812\n",
      "Epoch [964/1000], Loss: 0.4795\n",
      "Epoch [965/1000], Loss: 0.4809\n",
      "Epoch [966/1000], Loss: 0.4812\n",
      "Epoch [967/1000], Loss: 0.4826\n",
      "Epoch [968/1000], Loss: 0.4804\n",
      "Epoch [969/1000], Loss: 0.4802\n",
      "Epoch [970/1000], Loss: 0.4802\n",
      "Epoch [971/1000], Loss: 0.4809\n",
      "Epoch [972/1000], Loss: 0.4809\n",
      "Epoch [973/1000], Loss: 0.4792\n",
      "Epoch [974/1000], Loss: 0.4800\n",
      "Epoch [975/1000], Loss: 0.4812\n",
      "Epoch [976/1000], Loss: 0.4809\n",
      "Epoch [977/1000], Loss: 0.4807\n",
      "Epoch [978/1000], Loss: 0.4814\n",
      "Epoch [979/1000], Loss: 0.4831\n",
      "Epoch [980/1000], Loss: 0.4804\n",
      "Epoch [981/1000], Loss: 0.4826\n",
      "Epoch [982/1000], Loss: 0.4819\n",
      "Epoch [983/1000], Loss: 0.4788\n",
      "Epoch [984/1000], Loss: 0.4831\n",
      "Epoch [985/1000], Loss: 0.4807\n",
      "Epoch [986/1000], Loss: 0.4816\n",
      "Epoch [987/1000], Loss: 0.4804\n",
      "Epoch [988/1000], Loss: 0.4816\n",
      "Epoch [989/1000], Loss: 0.4823\n",
      "Epoch [990/1000], Loss: 0.4804\n",
      "Epoch [991/1000], Loss: 0.4816\n",
      "Epoch [992/1000], Loss: 0.4804\n",
      "Epoch [993/1000], Loss: 0.4797\n",
      "Epoch [994/1000], Loss: 0.4797\n",
      "Epoch [995/1000], Loss: 0.4823\n",
      "Epoch [996/1000], Loss: 0.4802\n",
      "Epoch [997/1000], Loss: 0.4809\n",
      "Epoch [998/1000], Loss: 0.4812\n",
      "Epoch [999/1000], Loss: 0.4823\n",
      "Epoch [1000/1000], Loss: 0.4807\n",
      "Accuracy of the network on the 1000 validation data: 53.00 %\n",
      "Training model with batch_size: 205, lr :1.0, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2481\n",
      "Epoch [2/1000], Loss: 0.2418\n",
      "Epoch [3/1000], Loss: 0.2413\n",
      "Epoch [4/1000], Loss: 0.2382\n",
      "Epoch [5/1000], Loss: 0.2374\n",
      "Epoch [6/1000], Loss: 0.2342\n",
      "Epoch [7/1000], Loss: 0.2287\n",
      "Epoch [8/1000], Loss: 0.2245\n",
      "Epoch [9/1000], Loss: 0.2184\n",
      "Epoch [10/1000], Loss: 0.2111\n",
      "Epoch [11/1000], Loss: 0.2068\n",
      "Epoch [12/1000], Loss: 0.2033\n",
      "Epoch [13/1000], Loss: 0.1990\n",
      "Epoch [14/1000], Loss: 0.1963\n",
      "Epoch [15/1000], Loss: 0.1910\n",
      "Epoch [16/1000], Loss: 0.1906\n",
      "Epoch [17/1000], Loss: 0.1897\n",
      "Epoch [18/1000], Loss: 0.1795\n",
      "Epoch [19/1000], Loss: 0.1790\n",
      "Epoch [20/1000], Loss: 0.1706\n",
      "Epoch [21/1000], Loss: 0.1550\n",
      "Epoch [22/1000], Loss: 0.1611\n",
      "Epoch [23/1000], Loss: 0.1398\n",
      "Epoch [24/1000], Loss: 0.1416\n",
      "Epoch [25/1000], Loss: 0.1395\n",
      "Epoch [26/1000], Loss: 0.1358\n",
      "Epoch [27/1000], Loss: 0.1213\n",
      "Epoch [28/1000], Loss: 0.1162\n",
      "Epoch [29/1000], Loss: 0.1234\n",
      "Epoch [30/1000], Loss: 0.0964\n",
      "Epoch [31/1000], Loss: 0.1165\n",
      "Epoch [32/1000], Loss: 0.0972\n",
      "Epoch [33/1000], Loss: 0.0796\n",
      "Epoch [34/1000], Loss: 0.1152\n",
      "Epoch [35/1000], Loss: 0.0725\n",
      "Epoch [36/1000], Loss: 0.1178\n",
      "Epoch [37/1000], Loss: 0.0597\n",
      "Epoch [38/1000], Loss: 0.0426\n",
      "Epoch [39/1000], Loss: 0.1222\n",
      "Epoch [40/1000], Loss: 0.0683\n",
      "Epoch [41/1000], Loss: 0.0540\n",
      "Epoch [42/1000], Loss: 0.0108\n",
      "Epoch [43/1000], Loss: 0.0071\n",
      "Epoch [44/1000], Loss: 0.1048\n",
      "Epoch [45/1000], Loss: 0.1291\n",
      "Epoch [46/1000], Loss: 0.0439\n",
      "Epoch [47/1000], Loss: 0.0590\n",
      "Epoch [48/1000], Loss: 0.0611\n",
      "Epoch [49/1000], Loss: 0.0396\n",
      "Epoch [50/1000], Loss: 0.0700\n",
      "Epoch [51/1000], Loss: 0.0532\n",
      "Epoch [52/1000], Loss: 0.0276\n",
      "Epoch [53/1000], Loss: 0.0722\n",
      "Epoch [54/1000], Loss: 0.0050\n",
      "Epoch [55/1000], Loss: 0.0034\n",
      "Epoch [56/1000], Loss: 0.0029\n",
      "Epoch [57/1000], Loss: 0.0024\n",
      "Epoch [58/1000], Loss: 0.0023\n",
      "Epoch [59/1000], Loss: 0.0021\n",
      "Epoch [60/1000], Loss: 0.0019\n",
      "Epoch [61/1000], Loss: 0.0016\n",
      "Epoch [62/1000], Loss: 0.0015\n",
      "Epoch [63/1000], Loss: 0.0014\n",
      "Epoch [64/1000], Loss: 0.0013\n",
      "Epoch [65/1000], Loss: 0.0012\n",
      "Epoch [66/1000], Loss: 0.0012\n",
      "Epoch [67/1000], Loss: 0.0011\n",
      "Epoch [68/1000], Loss: 0.0010\n",
      "Epoch [69/1000], Loss: 0.0011\n",
      "Epoch [70/1000], Loss: 0.0010\n",
      "Epoch [71/1000], Loss: 0.0009\n",
      "Epoch [72/1000], Loss: 0.0009\n",
      "Epoch [73/1000], Loss: 0.0008\n",
      "Epoch [74/1000], Loss: 0.0007\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 205, lr :10.0, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.5002\n",
      "Epoch [2/1000], Loss: 0.5119\n",
      "Epoch [3/1000], Loss: 0.5143\n",
      "Epoch [4/1000], Loss: 0.5124\n",
      "Epoch [5/1000], Loss: 0.5107\n",
      "Epoch [6/1000], Loss: 0.5121\n",
      "Epoch [7/1000], Loss: 0.5136\n",
      "Epoch [8/1000], Loss: 0.5138\n",
      "Epoch [9/1000], Loss: 0.5131\n",
      "Epoch [10/1000], Loss: 0.5129\n",
      "Epoch [11/1000], Loss: 0.5126\n",
      "Epoch [12/1000], Loss: 0.5119\n",
      "Epoch [13/1000], Loss: 0.5112\n",
      "Epoch [14/1000], Loss: 0.5152\n",
      "Epoch [15/1000], Loss: 0.5100\n",
      "Epoch [16/1000], Loss: 0.5129\n",
      "Epoch [17/1000], Loss: 0.5110\n",
      "Epoch [18/1000], Loss: 0.5129\n",
      "Epoch [19/1000], Loss: 0.5121\n",
      "Epoch [20/1000], Loss: 0.5121\n",
      "Epoch [21/1000], Loss: 0.5114\n",
      "Epoch [22/1000], Loss: 0.5129\n",
      "Epoch [23/1000], Loss: 0.5138\n",
      "Epoch [24/1000], Loss: 0.5126\n",
      "Epoch [25/1000], Loss: 0.5133\n",
      "Epoch [26/1000], Loss: 0.5136\n",
      "Epoch [27/1000], Loss: 0.5121\n",
      "Epoch [28/1000], Loss: 0.5140\n",
      "Epoch [29/1000], Loss: 0.5117\n",
      "Epoch [30/1000], Loss: 0.5140\n",
      "Epoch [31/1000], Loss: 0.5110\n",
      "Epoch [32/1000], Loss: 0.5121\n",
      "Epoch [33/1000], Loss: 0.5140\n",
      "Epoch [34/1000], Loss: 0.5119\n",
      "Epoch [35/1000], Loss: 0.5126\n",
      "Epoch [36/1000], Loss: 0.5136\n",
      "Epoch [37/1000], Loss: 0.5133\n",
      "Epoch [38/1000], Loss: 0.5126\n",
      "Epoch [39/1000], Loss: 0.5136\n",
      "Epoch [40/1000], Loss: 0.5121\n",
      "Epoch [41/1000], Loss: 0.5098\n",
      "Epoch [42/1000], Loss: 0.5117\n",
      "Epoch [43/1000], Loss: 0.5138\n",
      "Epoch [44/1000], Loss: 0.5110\n",
      "Epoch [45/1000], Loss: 0.5119\n",
      "Epoch [46/1000], Loss: 0.5131\n",
      "Epoch [47/1000], Loss: 0.5129\n",
      "Epoch [48/1000], Loss: 0.5124\n",
      "Epoch [49/1000], Loss: 0.5133\n",
      "Epoch [50/1000], Loss: 0.5131\n",
      "Epoch [51/1000], Loss: 0.5138\n",
      "Epoch [52/1000], Loss: 0.5112\n",
      "Epoch [53/1000], Loss: 0.5126\n",
      "Epoch [54/1000], Loss: 0.5107\n",
      "Epoch [55/1000], Loss: 0.5145\n",
      "Epoch [56/1000], Loss: 0.5124\n",
      "Epoch [57/1000], Loss: 0.5114\n",
      "Epoch [58/1000], Loss: 0.5107\n",
      "Epoch [59/1000], Loss: 0.5117\n",
      "Epoch [60/1000], Loss: 0.5136\n",
      "Epoch [61/1000], Loss: 0.5105\n",
      "Epoch [62/1000], Loss: 0.5114\n",
      "Epoch [63/1000], Loss: 0.5124\n",
      "Epoch [64/1000], Loss: 0.5110\n",
      "Epoch [65/1000], Loss: 0.5112\n",
      "Epoch [66/1000], Loss: 0.5143\n",
      "Epoch [67/1000], Loss: 0.5133\n",
      "Epoch [68/1000], Loss: 0.5107\n",
      "Epoch [69/1000], Loss: 0.5136\n",
      "Epoch [70/1000], Loss: 0.5143\n",
      "Epoch [71/1000], Loss: 0.5126\n",
      "Epoch [72/1000], Loss: 0.5126\n",
      "Epoch [73/1000], Loss: 0.5114\n",
      "Epoch [74/1000], Loss: 0.5119\n",
      "Epoch [75/1000], Loss: 0.5131\n",
      "Epoch [76/1000], Loss: 0.5114\n",
      "Epoch [77/1000], Loss: 0.5136\n",
      "Epoch [78/1000], Loss: 0.5131\n",
      "Epoch [79/1000], Loss: 0.5131\n",
      "Epoch [80/1000], Loss: 0.5117\n",
      "Epoch [81/1000], Loss: 0.5131\n",
      "Epoch [82/1000], Loss: 0.5112\n",
      "Epoch [83/1000], Loss: 0.5129\n",
      "Epoch [84/1000], Loss: 0.5117\n",
      "Epoch [85/1000], Loss: 0.5129\n",
      "Epoch [86/1000], Loss: 0.5102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/1000], Loss: 0.5136\n",
      "Epoch [88/1000], Loss: 0.5124\n",
      "Epoch [89/1000], Loss: 0.5131\n",
      "Epoch [90/1000], Loss: 0.5124\n",
      "Epoch [91/1000], Loss: 0.5131\n",
      "Epoch [92/1000], Loss: 0.5117\n",
      "Epoch [93/1000], Loss: 0.5107\n",
      "Epoch [94/1000], Loss: 0.5110\n",
      "Epoch [95/1000], Loss: 0.5129\n",
      "Epoch [96/1000], Loss: 0.5133\n",
      "Epoch [97/1000], Loss: 0.5107\n",
      "Epoch [98/1000], Loss: 0.5117\n",
      "Epoch [99/1000], Loss: 0.5117\n",
      "Epoch [100/1000], Loss: 0.5121\n",
      "Epoch [101/1000], Loss: 0.5138\n",
      "Epoch [102/1000], Loss: 0.5121\n",
      "Epoch [103/1000], Loss: 0.5112\n",
      "Epoch [104/1000], Loss: 0.5119\n",
      "Epoch [105/1000], Loss: 0.5148\n",
      "Epoch [106/1000], Loss: 0.5117\n",
      "Epoch [107/1000], Loss: 0.5121\n",
      "Epoch [108/1000], Loss: 0.5126\n",
      "Epoch [109/1000], Loss: 0.5143\n",
      "Epoch [110/1000], Loss: 0.5136\n",
      "Epoch [111/1000], Loss: 0.5138\n",
      "Epoch [112/1000], Loss: 0.5121\n",
      "Epoch [113/1000], Loss: 0.5126\n",
      "Epoch [114/1000], Loss: 0.5129\n",
      "Epoch [115/1000], Loss: 0.5110\n",
      "Epoch [116/1000], Loss: 0.5138\n",
      "Epoch [117/1000], Loss: 0.5133\n",
      "Epoch [118/1000], Loss: 0.5129\n",
      "Epoch [119/1000], Loss: 0.5126\n",
      "Epoch [120/1000], Loss: 0.5121\n",
      "Epoch [121/1000], Loss: 0.5131\n",
      "Epoch [122/1000], Loss: 0.5117\n",
      "Epoch [123/1000], Loss: 0.5119\n",
      "Epoch [124/1000], Loss: 0.5131\n",
      "Epoch [125/1000], Loss: 0.5131\n",
      "Epoch [126/1000], Loss: 0.5105\n",
      "Epoch [127/1000], Loss: 0.5126\n",
      "Epoch [128/1000], Loss: 0.5110\n",
      "Epoch [129/1000], Loss: 0.5124\n",
      "Epoch [130/1000], Loss: 0.5148\n",
      "Epoch [131/1000], Loss: 0.5148\n",
      "Epoch [132/1000], Loss: 0.5117\n",
      "Epoch [133/1000], Loss: 0.5124\n",
      "Epoch [134/1000], Loss: 0.5121\n",
      "Epoch [135/1000], Loss: 0.5121\n",
      "Epoch [136/1000], Loss: 0.5126\n",
      "Epoch [137/1000], Loss: 0.5117\n",
      "Epoch [138/1000], Loss: 0.5143\n",
      "Epoch [139/1000], Loss: 0.5148\n",
      "Epoch [140/1000], Loss: 0.5119\n",
      "Epoch [141/1000], Loss: 0.5112\n",
      "Epoch [142/1000], Loss: 0.5117\n",
      "Epoch [143/1000], Loss: 0.5117\n",
      "Epoch [144/1000], Loss: 0.5136\n",
      "Epoch [145/1000], Loss: 0.5114\n",
      "Epoch [146/1000], Loss: 0.5136\n",
      "Epoch [147/1000], Loss: 0.5095\n",
      "Epoch [148/1000], Loss: 0.5102\n",
      "Epoch [149/1000], Loss: 0.5105\n",
      "Epoch [150/1000], Loss: 0.5133\n",
      "Epoch [151/1000], Loss: 0.5124\n",
      "Epoch [152/1000], Loss: 0.5102\n",
      "Epoch [153/1000], Loss: 0.5114\n",
      "Epoch [154/1000], Loss: 0.5131\n",
      "Epoch [155/1000], Loss: 0.5119\n",
      "Epoch [156/1000], Loss: 0.5140\n",
      "Epoch [157/1000], Loss: 0.5121\n",
      "Epoch [158/1000], Loss: 0.5124\n",
      "Epoch [159/1000], Loss: 0.5140\n",
      "Epoch [160/1000], Loss: 0.5126\n",
      "Epoch [161/1000], Loss: 0.5110\n",
      "Epoch [162/1000], Loss: 0.5121\n",
      "Epoch [163/1000], Loss: 0.5140\n",
      "Epoch [164/1000], Loss: 0.5124\n",
      "Epoch [165/1000], Loss: 0.5119\n",
      "Epoch [166/1000], Loss: 0.5131\n",
      "Epoch [167/1000], Loss: 0.5124\n",
      "Epoch [168/1000], Loss: 0.5140\n",
      "Epoch [169/1000], Loss: 0.5107\n",
      "Epoch [170/1000], Loss: 0.5119\n",
      "Epoch [171/1000], Loss: 0.5126\n",
      "Epoch [172/1000], Loss: 0.5140\n",
      "Epoch [173/1000], Loss: 0.5131\n",
      "Epoch [174/1000], Loss: 0.5124\n",
      "Epoch [175/1000], Loss: 0.5100\n",
      "Epoch [176/1000], Loss: 0.5136\n",
      "Epoch [177/1000], Loss: 0.5136\n",
      "Epoch [178/1000], Loss: 0.5138\n",
      "Epoch [179/1000], Loss: 0.5119\n",
      "Epoch [180/1000], Loss: 0.5133\n",
      "Epoch [181/1000], Loss: 0.5107\n",
      "Epoch [182/1000], Loss: 0.5112\n",
      "Epoch [183/1000], Loss: 0.5117\n",
      "Epoch [184/1000], Loss: 0.5136\n",
      "Epoch [185/1000], Loss: 0.5136\n",
      "Epoch [186/1000], Loss: 0.5114\n",
      "Epoch [187/1000], Loss: 0.5114\n",
      "Epoch [188/1000], Loss: 0.5126\n",
      "Epoch [189/1000], Loss: 0.5119\n",
      "Epoch [190/1000], Loss: 0.5119\n",
      "Epoch [191/1000], Loss: 0.5126\n",
      "Epoch [192/1000], Loss: 0.5126\n",
      "Epoch [193/1000], Loss: 0.5119\n",
      "Epoch [194/1000], Loss: 0.5119\n",
      "Epoch [195/1000], Loss: 0.5119\n",
      "Epoch [196/1000], Loss: 0.5119\n",
      "Epoch [197/1000], Loss: 0.5124\n",
      "Epoch [198/1000], Loss: 0.5143\n",
      "Epoch [199/1000], Loss: 0.5133\n",
      "Epoch [200/1000], Loss: 0.5129\n",
      "Epoch [201/1000], Loss: 0.5114\n",
      "Epoch [202/1000], Loss: 0.5117\n",
      "Epoch [203/1000], Loss: 0.5105\n",
      "Epoch [204/1000], Loss: 0.5126\n",
      "Epoch [205/1000], Loss: 0.5114\n",
      "Epoch [206/1000], Loss: 0.5129\n",
      "Epoch [207/1000], Loss: 0.5148\n",
      "Epoch [208/1000], Loss: 0.5121\n",
      "Epoch [209/1000], Loss: 0.5145\n",
      "Epoch [210/1000], Loss: 0.5107\n",
      "Epoch [211/1000], Loss: 0.5126\n",
      "Epoch [212/1000], Loss: 0.5138\n",
      "Epoch [213/1000], Loss: 0.5124\n",
      "Epoch [214/1000], Loss: 0.5126\n",
      "Epoch [215/1000], Loss: 0.5119\n",
      "Epoch [216/1000], Loss: 0.5119\n",
      "Epoch [217/1000], Loss: 0.5126\n",
      "Epoch [218/1000], Loss: 0.5129\n",
      "Epoch [219/1000], Loss: 0.5126\n",
      "Epoch [220/1000], Loss: 0.5136\n",
      "Epoch [221/1000], Loss: 0.5129\n",
      "Epoch [222/1000], Loss: 0.5129\n",
      "Epoch [223/1000], Loss: 0.5124\n",
      "Epoch [224/1000], Loss: 0.5124\n",
      "Epoch [225/1000], Loss: 0.5126\n",
      "Epoch [226/1000], Loss: 0.5110\n",
      "Epoch [227/1000], Loss: 0.5133\n",
      "Epoch [228/1000], Loss: 0.5143\n",
      "Epoch [229/1000], Loss: 0.5129\n",
      "Epoch [230/1000], Loss: 0.5129\n",
      "Epoch [231/1000], Loss: 0.5133\n",
      "Epoch [232/1000], Loss: 0.5102\n",
      "Epoch [233/1000], Loss: 0.5117\n",
      "Epoch [234/1000], Loss: 0.5121\n",
      "Epoch [235/1000], Loss: 0.5145\n",
      "Epoch [236/1000], Loss: 0.5157\n",
      "Epoch [237/1000], Loss: 0.5136\n",
      "Epoch [238/1000], Loss: 0.5110\n",
      "Epoch [239/1000], Loss: 0.5119\n",
      "Epoch [240/1000], Loss: 0.5133\n",
      "Epoch [241/1000], Loss: 0.5117\n",
      "Epoch [242/1000], Loss: 0.5133\n",
      "Epoch [243/1000], Loss: 0.5112\n",
      "Epoch [244/1000], Loss: 0.5121\n",
      "Epoch [245/1000], Loss: 0.5105\n",
      "Epoch [246/1000], Loss: 0.5136\n",
      "Epoch [247/1000], Loss: 0.5119\n",
      "Epoch [248/1000], Loss: 0.5131\n",
      "Epoch [249/1000], Loss: 0.5124\n",
      "Epoch [250/1000], Loss: 0.5148\n",
      "Epoch [251/1000], Loss: 0.5129\n",
      "Epoch [252/1000], Loss: 0.5136\n",
      "Epoch [253/1000], Loss: 0.5121\n",
      "Epoch [254/1000], Loss: 0.5112\n",
      "Epoch [255/1000], Loss: 0.5126\n",
      "Epoch [256/1000], Loss: 0.5121\n",
      "Epoch [257/1000], Loss: 0.5143\n",
      "Epoch [258/1000], Loss: 0.5117\n",
      "Epoch [259/1000], Loss: 0.5133\n",
      "Epoch [260/1000], Loss: 0.5131\n",
      "Epoch [261/1000], Loss: 0.5133\n",
      "Epoch [262/1000], Loss: 0.5133\n",
      "Epoch [263/1000], Loss: 0.5126\n",
      "Epoch [264/1000], Loss: 0.5129\n",
      "Epoch [265/1000], Loss: 0.5152\n",
      "Epoch [266/1000], Loss: 0.5138\n",
      "Epoch [267/1000], Loss: 0.5160\n",
      "Epoch [268/1000], Loss: 0.5126\n",
      "Epoch [269/1000], Loss: 0.5131\n",
      "Epoch [270/1000], Loss: 0.5145\n",
      "Epoch [271/1000], Loss: 0.5129\n",
      "Epoch [272/1000], Loss: 0.5126\n",
      "Epoch [273/1000], Loss: 0.5102\n",
      "Epoch [274/1000], Loss: 0.5119\n",
      "Epoch [275/1000], Loss: 0.5119\n",
      "Epoch [276/1000], Loss: 0.5119\n",
      "Epoch [277/1000], Loss: 0.5114\n",
      "Epoch [278/1000], Loss: 0.5129\n",
      "Epoch [279/1000], Loss: 0.5105\n",
      "Epoch [280/1000], Loss: 0.5112\n",
      "Epoch [281/1000], Loss: 0.5112\n",
      "Epoch [282/1000], Loss: 0.5124\n",
      "Epoch [283/1000], Loss: 0.5124\n",
      "Epoch [284/1000], Loss: 0.5105\n",
      "Epoch [285/1000], Loss: 0.5136\n",
      "Epoch [286/1000], Loss: 0.5126\n",
      "Epoch [287/1000], Loss: 0.5131\n",
      "Epoch [288/1000], Loss: 0.5148\n",
      "Epoch [289/1000], Loss: 0.5131\n",
      "Epoch [290/1000], Loss: 0.5124\n",
      "Epoch [291/1000], Loss: 0.5102\n",
      "Epoch [292/1000], Loss: 0.5105\n",
      "Epoch [293/1000], Loss: 0.5126\n",
      "Epoch [294/1000], Loss: 0.5124\n",
      "Epoch [295/1000], Loss: 0.5131\n",
      "Epoch [296/1000], Loss: 0.5145\n",
      "Epoch [297/1000], Loss: 0.5119\n",
      "Epoch [298/1000], Loss: 0.5129\n",
      "Epoch [299/1000], Loss: 0.5133\n",
      "Epoch [300/1000], Loss: 0.5110\n",
      "Epoch [301/1000], Loss: 0.5124\n",
      "Epoch [302/1000], Loss: 0.5110\n",
      "Epoch [303/1000], Loss: 0.5145\n",
      "Epoch [304/1000], Loss: 0.5162\n",
      "Epoch [305/1000], Loss: 0.5131\n",
      "Epoch [306/1000], Loss: 0.5126\n",
      "Epoch [307/1000], Loss: 0.5133\n",
      "Epoch [308/1000], Loss: 0.5129\n",
      "Epoch [309/1000], Loss: 0.5126\n",
      "Epoch [310/1000], Loss: 0.5131\n",
      "Epoch [311/1000], Loss: 0.5133\n",
      "Epoch [312/1000], Loss: 0.5119\n",
      "Epoch [313/1000], Loss: 0.5112\n",
      "Epoch [314/1000], Loss: 0.5138\n",
      "Epoch [315/1000], Loss: 0.5117\n",
      "Epoch [316/1000], Loss: 0.5136\n",
      "Epoch [317/1000], Loss: 0.5136\n",
      "Epoch [318/1000], Loss: 0.5138\n",
      "Epoch [319/1000], Loss: 0.5138\n",
      "Epoch [320/1000], Loss: 0.5114\n",
      "Epoch [321/1000], Loss: 0.5129\n",
      "Epoch [322/1000], Loss: 0.5133\n",
      "Epoch [323/1000], Loss: 0.5136\n",
      "Epoch [324/1000], Loss: 0.5110\n",
      "Epoch [325/1000], Loss: 0.5131\n",
      "Epoch [326/1000], Loss: 0.5126\n",
      "Epoch [327/1000], Loss: 0.5145\n",
      "Epoch [328/1000], Loss: 0.5136\n",
      "Epoch [329/1000], Loss: 0.5155\n",
      "Epoch [330/1000], Loss: 0.5117\n",
      "Epoch [331/1000], Loss: 0.5112\n",
      "Epoch [332/1000], Loss: 0.5117\n",
      "Epoch [333/1000], Loss: 0.5129\n",
      "Epoch [334/1000], Loss: 0.5124\n",
      "Epoch [335/1000], Loss: 0.5107\n",
      "Epoch [336/1000], Loss: 0.5114\n",
      "Epoch [337/1000], Loss: 0.5114\n",
      "Epoch [338/1000], Loss: 0.5145\n",
      "Epoch [339/1000], Loss: 0.5117\n",
      "Epoch [340/1000], Loss: 0.5117\n",
      "Epoch [341/1000], Loss: 0.5133\n",
      "Epoch [342/1000], Loss: 0.5119\n",
      "Epoch [343/1000], Loss: 0.5105\n",
      "Epoch [344/1000], Loss: 0.5136\n",
      "Epoch [345/1000], Loss: 0.5126\n",
      "Epoch [346/1000], Loss: 0.5117\n",
      "Epoch [347/1000], Loss: 0.5110\n",
      "Epoch [348/1000], Loss: 0.5143\n",
      "Epoch [349/1000], Loss: 0.5124\n",
      "Epoch [350/1000], Loss: 0.5131\n",
      "Epoch [351/1000], Loss: 0.5138\n",
      "Epoch [352/1000], Loss: 0.5110\n",
      "Epoch [353/1000], Loss: 0.5143\n",
      "Epoch [354/1000], Loss: 0.5114\n",
      "Epoch [355/1000], Loss: 0.5131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [356/1000], Loss: 0.5126\n",
      "Epoch [357/1000], Loss: 0.5119\n",
      "Epoch [358/1000], Loss: 0.5112\n",
      "Epoch [359/1000], Loss: 0.5117\n",
      "Epoch [360/1000], Loss: 0.5126\n",
      "Epoch [361/1000], Loss: 0.5121\n",
      "Epoch [362/1000], Loss: 0.5131\n",
      "Epoch [363/1000], Loss: 0.5129\n",
      "Epoch [364/1000], Loss: 0.5117\n",
      "Epoch [365/1000], Loss: 0.5114\n",
      "Epoch [366/1000], Loss: 0.5102\n",
      "Epoch [367/1000], Loss: 0.5112\n",
      "Epoch [368/1000], Loss: 0.5114\n",
      "Epoch [369/1000], Loss: 0.5129\n",
      "Epoch [370/1000], Loss: 0.5102\n",
      "Epoch [371/1000], Loss: 0.5117\n",
      "Epoch [372/1000], Loss: 0.5124\n",
      "Epoch [373/1000], Loss: 0.5126\n",
      "Epoch [374/1000], Loss: 0.5136\n",
      "Epoch [375/1000], Loss: 0.5114\n",
      "Epoch [376/1000], Loss: 0.5107\n",
      "Epoch [377/1000], Loss: 0.5126\n",
      "Epoch [378/1000], Loss: 0.5126\n",
      "Epoch [379/1000], Loss: 0.5131\n",
      "Epoch [380/1000], Loss: 0.5129\n",
      "Epoch [381/1000], Loss: 0.5121\n",
      "Epoch [382/1000], Loss: 0.5117\n",
      "Epoch [383/1000], Loss: 0.5098\n",
      "Epoch [384/1000], Loss: 0.5140\n",
      "Epoch [385/1000], Loss: 0.5114\n",
      "Epoch [386/1000], Loss: 0.5117\n",
      "Epoch [387/1000], Loss: 0.5145\n",
      "Epoch [388/1000], Loss: 0.5133\n",
      "Epoch [389/1000], Loss: 0.5136\n",
      "Epoch [390/1000], Loss: 0.5126\n",
      "Epoch [391/1000], Loss: 0.5140\n",
      "Epoch [392/1000], Loss: 0.5119\n",
      "Epoch [393/1000], Loss: 0.5124\n",
      "Epoch [394/1000], Loss: 0.5124\n",
      "Epoch [395/1000], Loss: 0.5126\n",
      "Epoch [396/1000], Loss: 0.5117\n",
      "Epoch [397/1000], Loss: 0.5124\n",
      "Epoch [398/1000], Loss: 0.5121\n",
      "Epoch [399/1000], Loss: 0.5131\n",
      "Epoch [400/1000], Loss: 0.5124\n",
      "Epoch [401/1000], Loss: 0.5112\n",
      "Epoch [402/1000], Loss: 0.5129\n",
      "Epoch [403/1000], Loss: 0.5133\n",
      "Epoch [404/1000], Loss: 0.5129\n",
      "Epoch [405/1000], Loss: 0.5121\n",
      "Epoch [406/1000], Loss: 0.5133\n",
      "Epoch [407/1000], Loss: 0.5119\n",
      "Epoch [408/1000], Loss: 0.5112\n",
      "Epoch [409/1000], Loss: 0.5129\n",
      "Epoch [410/1000], Loss: 0.5107\n",
      "Epoch [411/1000], Loss: 0.5138\n",
      "Epoch [412/1000], Loss: 0.5136\n",
      "Epoch [413/1000], Loss: 0.5143\n",
      "Epoch [414/1000], Loss: 0.5121\n",
      "Epoch [415/1000], Loss: 0.5133\n",
      "Epoch [416/1000], Loss: 0.5138\n",
      "Epoch [417/1000], Loss: 0.5143\n",
      "Epoch [418/1000], Loss: 0.5133\n",
      "Epoch [419/1000], Loss: 0.5143\n",
      "Epoch [420/1000], Loss: 0.5126\n",
      "Epoch [421/1000], Loss: 0.5124\n",
      "Epoch [422/1000], Loss: 0.5117\n",
      "Epoch [423/1000], Loss: 0.5119\n",
      "Epoch [424/1000], Loss: 0.5112\n",
      "Epoch [425/1000], Loss: 0.5121\n",
      "Epoch [426/1000], Loss: 0.5138\n",
      "Epoch [427/1000], Loss: 0.5107\n",
      "Epoch [428/1000], Loss: 0.5150\n",
      "Epoch [429/1000], Loss: 0.5126\n",
      "Epoch [430/1000], Loss: 0.5133\n",
      "Epoch [431/1000], Loss: 0.5126\n",
      "Epoch [432/1000], Loss: 0.5117\n",
      "Epoch [433/1000], Loss: 0.5119\n",
      "Epoch [434/1000], Loss: 0.5129\n",
      "Epoch [435/1000], Loss: 0.5121\n",
      "Epoch [436/1000], Loss: 0.5117\n",
      "Epoch [437/1000], Loss: 0.5131\n",
      "Epoch [438/1000], Loss: 0.5133\n",
      "Epoch [439/1000], Loss: 0.5133\n",
      "Epoch [440/1000], Loss: 0.5136\n",
      "Epoch [441/1000], Loss: 0.5131\n",
      "Epoch [442/1000], Loss: 0.5145\n",
      "Epoch [443/1000], Loss: 0.5126\n",
      "Epoch [444/1000], Loss: 0.5138\n",
      "Epoch [445/1000], Loss: 0.5136\n",
      "Epoch [446/1000], Loss: 0.5112\n",
      "Epoch [447/1000], Loss: 0.5152\n",
      "Epoch [448/1000], Loss: 0.5117\n",
      "Epoch [449/1000], Loss: 0.5112\n",
      "Epoch [450/1000], Loss: 0.5126\n",
      "Epoch [451/1000], Loss: 0.5117\n",
      "Epoch [452/1000], Loss: 0.5124\n",
      "Epoch [453/1000], Loss: 0.5145\n",
      "Epoch [454/1000], Loss: 0.5121\n",
      "Epoch [455/1000], Loss: 0.5112\n",
      "Epoch [456/1000], Loss: 0.5133\n",
      "Epoch [457/1000], Loss: 0.5119\n",
      "Epoch [458/1000], Loss: 0.5124\n",
      "Epoch [459/1000], Loss: 0.5119\n",
      "Epoch [460/1000], Loss: 0.5124\n",
      "Epoch [461/1000], Loss: 0.5131\n",
      "Epoch [462/1000], Loss: 0.5124\n",
      "Epoch [463/1000], Loss: 0.5140\n",
      "Epoch [464/1000], Loss: 0.5126\n",
      "Epoch [465/1000], Loss: 0.5124\n",
      "Epoch [466/1000], Loss: 0.5124\n",
      "Epoch [467/1000], Loss: 0.5107\n",
      "Epoch [468/1000], Loss: 0.5143\n",
      "Epoch [469/1000], Loss: 0.5121\n",
      "Epoch [470/1000], Loss: 0.5133\n",
      "Epoch [471/1000], Loss: 0.5100\n",
      "Epoch [472/1000], Loss: 0.5095\n",
      "Epoch [473/1000], Loss: 0.5112\n",
      "Epoch [474/1000], Loss: 0.5124\n",
      "Epoch [475/1000], Loss: 0.5126\n",
      "Epoch [476/1000], Loss: 0.5117\n",
      "Epoch [477/1000], Loss: 0.5107\n",
      "Epoch [478/1000], Loss: 0.5143\n",
      "Epoch [479/1000], Loss: 0.5136\n",
      "Epoch [480/1000], Loss: 0.5121\n",
      "Epoch [481/1000], Loss: 0.5145\n",
      "Epoch [482/1000], Loss: 0.5107\n",
      "Epoch [483/1000], Loss: 0.5119\n",
      "Epoch [484/1000], Loss: 0.5100\n",
      "Epoch [485/1000], Loss: 0.5114\n",
      "Epoch [486/1000], Loss: 0.5131\n",
      "Epoch [487/1000], Loss: 0.5110\n",
      "Epoch [488/1000], Loss: 0.5140\n",
      "Epoch [489/1000], Loss: 0.5131\n",
      "Epoch [490/1000], Loss: 0.5112\n",
      "Epoch [491/1000], Loss: 0.5107\n",
      "Epoch [492/1000], Loss: 0.5119\n",
      "Epoch [493/1000], Loss: 0.5098\n",
      "Epoch [494/1000], Loss: 0.5131\n",
      "Epoch [495/1000], Loss: 0.5129\n",
      "Epoch [496/1000], Loss: 0.5121\n",
      "Epoch [497/1000], Loss: 0.5107\n",
      "Epoch [498/1000], Loss: 0.5107\n",
      "Epoch [499/1000], Loss: 0.5119\n",
      "Epoch [500/1000], Loss: 0.5102\n",
      "Epoch [501/1000], Loss: 0.5105\n",
      "Epoch [502/1000], Loss: 0.5102\n",
      "Epoch [503/1000], Loss: 0.5121\n",
      "Epoch [504/1000], Loss: 0.5121\n",
      "Epoch [505/1000], Loss: 0.5167\n",
      "Epoch [506/1000], Loss: 0.5131\n",
      "Epoch [507/1000], Loss: 0.5114\n",
      "Epoch [508/1000], Loss: 0.5121\n",
      "Epoch [509/1000], Loss: 0.5093\n",
      "Epoch [510/1000], Loss: 0.5145\n",
      "Epoch [511/1000], Loss: 0.5138\n",
      "Epoch [512/1000], Loss: 0.5124\n",
      "Epoch [513/1000], Loss: 0.5112\n",
      "Epoch [514/1000], Loss: 0.5112\n",
      "Epoch [515/1000], Loss: 0.5124\n",
      "Epoch [516/1000], Loss: 0.5112\n",
      "Epoch [517/1000], Loss: 0.5129\n",
      "Epoch [518/1000], Loss: 0.5143\n",
      "Epoch [519/1000], Loss: 0.5136\n",
      "Epoch [520/1000], Loss: 0.5110\n",
      "Epoch [521/1000], Loss: 0.5119\n",
      "Epoch [522/1000], Loss: 0.5129\n",
      "Epoch [523/1000], Loss: 0.5129\n",
      "Epoch [524/1000], Loss: 0.5117\n",
      "Epoch [525/1000], Loss: 0.5124\n",
      "Epoch [526/1000], Loss: 0.5124\n",
      "Epoch [527/1000], Loss: 0.5145\n",
      "Epoch [528/1000], Loss: 0.5126\n",
      "Epoch [529/1000], Loss: 0.5124\n",
      "Epoch [530/1000], Loss: 0.5124\n",
      "Epoch [531/1000], Loss: 0.5129\n",
      "Epoch [532/1000], Loss: 0.5140\n",
      "Epoch [533/1000], Loss: 0.5110\n",
      "Epoch [534/1000], Loss: 0.5121\n",
      "Epoch [535/1000], Loss: 0.5110\n",
      "Epoch [536/1000], Loss: 0.5129\n",
      "Epoch [537/1000], Loss: 0.5129\n",
      "Epoch [538/1000], Loss: 0.5131\n",
      "Epoch [539/1000], Loss: 0.5121\n",
      "Epoch [540/1000], Loss: 0.5126\n",
      "Epoch [541/1000], Loss: 0.5129\n",
      "Epoch [542/1000], Loss: 0.5143\n",
      "Epoch [543/1000], Loss: 0.5124\n",
      "Epoch [544/1000], Loss: 0.5124\n",
      "Epoch [545/1000], Loss: 0.5126\n",
      "Epoch [546/1000], Loss: 0.5114\n",
      "Epoch [547/1000], Loss: 0.5110\n",
      "Epoch [548/1000], Loss: 0.5138\n",
      "Epoch [549/1000], Loss: 0.5133\n",
      "Epoch [550/1000], Loss: 0.5098\n",
      "Epoch [551/1000], Loss: 0.5155\n",
      "Epoch [552/1000], Loss: 0.5112\n",
      "Epoch [553/1000], Loss: 0.5119\n",
      "Epoch [554/1000], Loss: 0.5126\n",
      "Epoch [555/1000], Loss: 0.5131\n",
      "Epoch [556/1000], Loss: 0.5136\n",
      "Epoch [557/1000], Loss: 0.5126\n",
      "Epoch [558/1000], Loss: 0.5131\n",
      "Epoch [559/1000], Loss: 0.5117\n",
      "Epoch [560/1000], Loss: 0.5126\n",
      "Epoch [561/1000], Loss: 0.5124\n",
      "Epoch [562/1000], Loss: 0.5121\n",
      "Epoch [563/1000], Loss: 0.5133\n",
      "Epoch [564/1000], Loss: 0.5124\n",
      "Epoch [565/1000], Loss: 0.5126\n",
      "Epoch [566/1000], Loss: 0.5119\n",
      "Epoch [567/1000], Loss: 0.5140\n",
      "Epoch [568/1000], Loss: 0.5131\n",
      "Epoch [569/1000], Loss: 0.5117\n",
      "Epoch [570/1000], Loss: 0.5121\n",
      "Epoch [571/1000], Loss: 0.5143\n",
      "Epoch [572/1000], Loss: 0.5105\n",
      "Epoch [573/1000], Loss: 0.5102\n",
      "Epoch [574/1000], Loss: 0.5119\n",
      "Epoch [575/1000], Loss: 0.5150\n",
      "Epoch [576/1000], Loss: 0.5148\n",
      "Epoch [577/1000], Loss: 0.5121\n",
      "Epoch [578/1000], Loss: 0.5124\n",
      "Epoch [579/1000], Loss: 0.5119\n",
      "Epoch [580/1000], Loss: 0.5124\n",
      "Epoch [581/1000], Loss: 0.5105\n",
      "Epoch [582/1000], Loss: 0.5124\n",
      "Epoch [583/1000], Loss: 0.5121\n",
      "Epoch [584/1000], Loss: 0.5138\n",
      "Epoch [585/1000], Loss: 0.5138\n",
      "Epoch [586/1000], Loss: 0.5119\n",
      "Epoch [587/1000], Loss: 0.5138\n",
      "Epoch [588/1000], Loss: 0.5121\n",
      "Epoch [589/1000], Loss: 0.5133\n",
      "Epoch [590/1000], Loss: 0.5131\n",
      "Epoch [591/1000], Loss: 0.5133\n",
      "Epoch [592/1000], Loss: 0.5143\n",
      "Epoch [593/1000], Loss: 0.5119\n",
      "Epoch [594/1000], Loss: 0.5131\n",
      "Epoch [595/1000], Loss: 0.5121\n",
      "Epoch [596/1000], Loss: 0.5124\n",
      "Epoch [597/1000], Loss: 0.5131\n",
      "Epoch [598/1000], Loss: 0.5140\n",
      "Epoch [599/1000], Loss: 0.5126\n",
      "Epoch [600/1000], Loss: 0.5117\n",
      "Epoch [601/1000], Loss: 0.5138\n",
      "Epoch [602/1000], Loss: 0.5119\n",
      "Epoch [603/1000], Loss: 0.5119\n",
      "Epoch [604/1000], Loss: 0.5138\n",
      "Epoch [605/1000], Loss: 0.5131\n",
      "Epoch [606/1000], Loss: 0.5126\n",
      "Epoch [607/1000], Loss: 0.5119\n",
      "Epoch [608/1000], Loss: 0.5117\n",
      "Epoch [609/1000], Loss: 0.5119\n",
      "Epoch [610/1000], Loss: 0.5117\n",
      "Epoch [611/1000], Loss: 0.5136\n",
      "Epoch [612/1000], Loss: 0.5138\n",
      "Epoch [613/1000], Loss: 0.5129\n",
      "Epoch [614/1000], Loss: 0.5126\n",
      "Epoch [615/1000], Loss: 0.5133\n",
      "Epoch [616/1000], Loss: 0.5145\n",
      "Epoch [617/1000], Loss: 0.5105\n",
      "Epoch [618/1000], Loss: 0.5133\n",
      "Epoch [619/1000], Loss: 0.5126\n",
      "Epoch [620/1000], Loss: 0.5124\n",
      "Epoch [621/1000], Loss: 0.5133\n",
      "Epoch [622/1000], Loss: 0.5126\n",
      "Epoch [623/1000], Loss: 0.5133\n",
      "Epoch [624/1000], Loss: 0.5129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [625/1000], Loss: 0.5112\n",
      "Epoch [626/1000], Loss: 0.5131\n",
      "Epoch [627/1000], Loss: 0.5131\n",
      "Epoch [628/1000], Loss: 0.5121\n",
      "Epoch [629/1000], Loss: 0.5119\n",
      "Epoch [630/1000], Loss: 0.5107\n",
      "Epoch [631/1000], Loss: 0.5121\n",
      "Epoch [632/1000], Loss: 0.5138\n",
      "Epoch [633/1000], Loss: 0.5126\n",
      "Epoch [634/1000], Loss: 0.5133\n",
      "Epoch [635/1000], Loss: 0.5114\n",
      "Epoch [636/1000], Loss: 0.5126\n",
      "Epoch [637/1000], Loss: 0.5110\n",
      "Epoch [638/1000], Loss: 0.5119\n",
      "Epoch [639/1000], Loss: 0.5112\n",
      "Epoch [640/1000], Loss: 0.5129\n",
      "Epoch [641/1000], Loss: 0.5131\n",
      "Epoch [642/1000], Loss: 0.5121\n",
      "Epoch [643/1000], Loss: 0.5131\n",
      "Epoch [644/1000], Loss: 0.5119\n",
      "Epoch [645/1000], Loss: 0.5129\n",
      "Epoch [646/1000], Loss: 0.5107\n",
      "Epoch [647/1000], Loss: 0.5114\n",
      "Epoch [648/1000], Loss: 0.5124\n",
      "Epoch [649/1000], Loss: 0.5124\n",
      "Epoch [650/1000], Loss: 0.5119\n",
      "Epoch [651/1000], Loss: 0.5133\n",
      "Epoch [652/1000], Loss: 0.5114\n",
      "Epoch [653/1000], Loss: 0.5133\n",
      "Epoch [654/1000], Loss: 0.5117\n",
      "Epoch [655/1000], Loss: 0.5136\n",
      "Epoch [656/1000], Loss: 0.5148\n",
      "Epoch [657/1000], Loss: 0.5126\n",
      "Epoch [658/1000], Loss: 0.5126\n",
      "Epoch [659/1000], Loss: 0.5143\n",
      "Epoch [660/1000], Loss: 0.5140\n",
      "Epoch [661/1000], Loss: 0.5145\n",
      "Epoch [662/1000], Loss: 0.5102\n",
      "Epoch [663/1000], Loss: 0.5117\n",
      "Epoch [664/1000], Loss: 0.5136\n",
      "Epoch [665/1000], Loss: 0.5119\n",
      "Epoch [666/1000], Loss: 0.5112\n",
      "Epoch [667/1000], Loss: 0.5107\n",
      "Epoch [668/1000], Loss: 0.5140\n",
      "Epoch [669/1000], Loss: 0.5126\n",
      "Epoch [670/1000], Loss: 0.5136\n",
      "Epoch [671/1000], Loss: 0.5133\n",
      "Epoch [672/1000], Loss: 0.5140\n",
      "Epoch [673/1000], Loss: 0.5121\n",
      "Epoch [674/1000], Loss: 0.5110\n",
      "Epoch [675/1000], Loss: 0.5126\n",
      "Epoch [676/1000], Loss: 0.5129\n",
      "Epoch [677/1000], Loss: 0.5136\n",
      "Epoch [678/1000], Loss: 0.5148\n",
      "Epoch [679/1000], Loss: 0.5148\n",
      "Epoch [680/1000], Loss: 0.5126\n",
      "Epoch [681/1000], Loss: 0.5112\n",
      "Epoch [682/1000], Loss: 0.5129\n",
      "Epoch [683/1000], Loss: 0.5129\n",
      "Epoch [684/1000], Loss: 0.5121\n",
      "Epoch [685/1000], Loss: 0.5126\n",
      "Epoch [686/1000], Loss: 0.5126\n",
      "Epoch [687/1000], Loss: 0.5131\n",
      "Epoch [688/1000], Loss: 0.5136\n",
      "Epoch [689/1000], Loss: 0.5110\n",
      "Epoch [690/1000], Loss: 0.5124\n",
      "Epoch [691/1000], Loss: 0.5121\n",
      "Epoch [692/1000], Loss: 0.5114\n",
      "Epoch [693/1000], Loss: 0.5152\n",
      "Epoch [694/1000], Loss: 0.5121\n",
      "Epoch [695/1000], Loss: 0.5114\n",
      "Epoch [696/1000], Loss: 0.5131\n",
      "Epoch [697/1000], Loss: 0.5126\n",
      "Epoch [698/1000], Loss: 0.5129\n",
      "Epoch [699/1000], Loss: 0.5136\n",
      "Epoch [700/1000], Loss: 0.5124\n",
      "Epoch [701/1000], Loss: 0.5121\n",
      "Epoch [702/1000], Loss: 0.5150\n",
      "Epoch [703/1000], Loss: 0.5114\n",
      "Epoch [704/1000], Loss: 0.5124\n",
      "Epoch [705/1000], Loss: 0.5110\n",
      "Epoch [706/1000], Loss: 0.5140\n",
      "Epoch [707/1000], Loss: 0.5110\n",
      "Epoch [708/1000], Loss: 0.5126\n",
      "Epoch [709/1000], Loss: 0.5131\n",
      "Epoch [710/1000], Loss: 0.5131\n",
      "Epoch [711/1000], Loss: 0.5102\n",
      "Epoch [712/1000], Loss: 0.5124\n",
      "Epoch [713/1000], Loss: 0.5136\n",
      "Epoch [714/1000], Loss: 0.5117\n",
      "Epoch [715/1000], Loss: 0.5126\n",
      "Epoch [716/1000], Loss: 0.5121\n",
      "Epoch [717/1000], Loss: 0.5112\n",
      "Epoch [718/1000], Loss: 0.5129\n",
      "Epoch [719/1000], Loss: 0.5126\n",
      "Epoch [720/1000], Loss: 0.5126\n",
      "Epoch [721/1000], Loss: 0.5131\n",
      "Epoch [722/1000], Loss: 0.5131\n",
      "Epoch [723/1000], Loss: 0.5140\n",
      "Epoch [724/1000], Loss: 0.5133\n",
      "Epoch [725/1000], Loss: 0.5129\n",
      "Epoch [726/1000], Loss: 0.5126\n",
      "Epoch [727/1000], Loss: 0.5117\n",
      "Epoch [728/1000], Loss: 0.5129\n",
      "Epoch [729/1000], Loss: 0.5129\n",
      "Epoch [730/1000], Loss: 0.5114\n",
      "Epoch [731/1000], Loss: 0.5126\n",
      "Epoch [732/1000], Loss: 0.5129\n",
      "Epoch [733/1000], Loss: 0.5121\n",
      "Epoch [734/1000], Loss: 0.5126\n",
      "Epoch [735/1000], Loss: 0.5110\n",
      "Epoch [736/1000], Loss: 0.5117\n",
      "Epoch [737/1000], Loss: 0.5140\n",
      "Epoch [738/1000], Loss: 0.5145\n",
      "Epoch [739/1000], Loss: 0.5126\n",
      "Epoch [740/1000], Loss: 0.5119\n",
      "Epoch [741/1000], Loss: 0.5136\n",
      "Epoch [742/1000], Loss: 0.5140\n",
      "Epoch [743/1000], Loss: 0.5133\n",
      "Epoch [744/1000], Loss: 0.5138\n",
      "Epoch [745/1000], Loss: 0.5148\n",
      "Epoch [746/1000], Loss: 0.5133\n",
      "Epoch [747/1000], Loss: 0.5129\n",
      "Epoch [748/1000], Loss: 0.5136\n",
      "Epoch [749/1000], Loss: 0.5129\n",
      "Epoch [750/1000], Loss: 0.5145\n",
      "Epoch [751/1000], Loss: 0.5129\n",
      "Epoch [752/1000], Loss: 0.5148\n",
      "Epoch [753/1000], Loss: 0.5117\n",
      "Epoch [754/1000], Loss: 0.5117\n",
      "Epoch [755/1000], Loss: 0.5121\n",
      "Epoch [756/1000], Loss: 0.5121\n",
      "Epoch [757/1000], Loss: 0.5131\n",
      "Epoch [758/1000], Loss: 0.5138\n",
      "Epoch [759/1000], Loss: 0.5136\n",
      "Epoch [760/1000], Loss: 0.5152\n",
      "Epoch [761/1000], Loss: 0.5114\n",
      "Epoch [762/1000], Loss: 0.5129\n",
      "Epoch [763/1000], Loss: 0.5121\n",
      "Epoch [764/1000], Loss: 0.5126\n",
      "Epoch [765/1000], Loss: 0.5107\n",
      "Epoch [766/1000], Loss: 0.5102\n",
      "Epoch [767/1000], Loss: 0.5126\n",
      "Epoch [768/1000], Loss: 0.5140\n",
      "Epoch [769/1000], Loss: 0.5121\n",
      "Epoch [770/1000], Loss: 0.5126\n",
      "Epoch [771/1000], Loss: 0.5110\n",
      "Epoch [772/1000], Loss: 0.5114\n",
      "Epoch [773/1000], Loss: 0.5133\n",
      "Epoch [774/1000], Loss: 0.5129\n",
      "Epoch [775/1000], Loss: 0.5119\n",
      "Epoch [776/1000], Loss: 0.5133\n",
      "Epoch [777/1000], Loss: 0.5124\n",
      "Epoch [778/1000], Loss: 0.5131\n",
      "Epoch [779/1000], Loss: 0.5136\n",
      "Epoch [780/1000], Loss: 0.5138\n",
      "Epoch [781/1000], Loss: 0.5126\n",
      "Epoch [782/1000], Loss: 0.5136\n",
      "Epoch [783/1000], Loss: 0.5119\n",
      "Epoch [784/1000], Loss: 0.5152\n",
      "Epoch [785/1000], Loss: 0.5129\n",
      "Epoch [786/1000], Loss: 0.5152\n",
      "Epoch [787/1000], Loss: 0.5102\n",
      "Epoch [788/1000], Loss: 0.5110\n",
      "Epoch [789/1000], Loss: 0.5121\n",
      "Epoch [790/1000], Loss: 0.5138\n",
      "Epoch [791/1000], Loss: 0.5138\n",
      "Epoch [792/1000], Loss: 0.5131\n",
      "Epoch [793/1000], Loss: 0.5136\n",
      "Epoch [794/1000], Loss: 0.5112\n",
      "Epoch [795/1000], Loss: 0.5121\n",
      "Epoch [796/1000], Loss: 0.5119\n",
      "Epoch [797/1000], Loss: 0.5131\n",
      "Epoch [798/1000], Loss: 0.5112\n",
      "Epoch [799/1000], Loss: 0.5124\n",
      "Epoch [800/1000], Loss: 0.5124\n",
      "Epoch [801/1000], Loss: 0.5107\n",
      "Epoch [802/1000], Loss: 0.5145\n",
      "Epoch [803/1000], Loss: 0.5117\n",
      "Epoch [804/1000], Loss: 0.5121\n",
      "Epoch [805/1000], Loss: 0.5136\n",
      "Epoch [806/1000], Loss: 0.5138\n",
      "Epoch [807/1000], Loss: 0.5117\n",
      "Epoch [808/1000], Loss: 0.5114\n",
      "Epoch [809/1000], Loss: 0.5133\n",
      "Epoch [810/1000], Loss: 0.5114\n",
      "Epoch [811/1000], Loss: 0.5121\n",
      "Epoch [812/1000], Loss: 0.5114\n",
      "Epoch [813/1000], Loss: 0.5117\n",
      "Epoch [814/1000], Loss: 0.5131\n",
      "Epoch [815/1000], Loss: 0.5114\n",
      "Epoch [816/1000], Loss: 0.5140\n",
      "Epoch [817/1000], Loss: 0.5155\n",
      "Epoch [818/1000], Loss: 0.5131\n",
      "Epoch [819/1000], Loss: 0.5124\n",
      "Epoch [820/1000], Loss: 0.5110\n",
      "Epoch [821/1000], Loss: 0.5143\n",
      "Epoch [822/1000], Loss: 0.5131\n",
      "Epoch [823/1000], Loss: 0.5133\n",
      "Epoch [824/1000], Loss: 0.5121\n",
      "Epoch [825/1000], Loss: 0.5110\n",
      "Epoch [826/1000], Loss: 0.5136\n",
      "Epoch [827/1000], Loss: 0.5117\n",
      "Epoch [828/1000], Loss: 0.5114\n",
      "Epoch [829/1000], Loss: 0.5114\n",
      "Epoch [830/1000], Loss: 0.5105\n",
      "Epoch [831/1000], Loss: 0.5126\n",
      "Epoch [832/1000], Loss: 0.5117\n",
      "Epoch [833/1000], Loss: 0.5119\n",
      "Epoch [834/1000], Loss: 0.5121\n",
      "Epoch [835/1000], Loss: 0.5124\n",
      "Epoch [836/1000], Loss: 0.5129\n",
      "Epoch [837/1000], Loss: 0.5090\n",
      "Epoch [838/1000], Loss: 0.5121\n",
      "Epoch [839/1000], Loss: 0.5131\n",
      "Epoch [840/1000], Loss: 0.5110\n",
      "Epoch [841/1000], Loss: 0.5119\n",
      "Epoch [842/1000], Loss: 0.5121\n",
      "Epoch [843/1000], Loss: 0.5114\n",
      "Epoch [844/1000], Loss: 0.5138\n",
      "Epoch [845/1000], Loss: 0.5117\n",
      "Epoch [846/1000], Loss: 0.5117\n",
      "Epoch [847/1000], Loss: 0.5140\n",
      "Epoch [848/1000], Loss: 0.5126\n",
      "Epoch [849/1000], Loss: 0.5145\n",
      "Epoch [850/1000], Loss: 0.5131\n",
      "Epoch [851/1000], Loss: 0.5129\n",
      "Epoch [852/1000], Loss: 0.5140\n",
      "Epoch [853/1000], Loss: 0.5138\n",
      "Epoch [854/1000], Loss: 0.5131\n",
      "Epoch [855/1000], Loss: 0.5143\n",
      "Epoch [856/1000], Loss: 0.5124\n",
      "Epoch [857/1000], Loss: 0.5119\n",
      "Epoch [858/1000], Loss: 0.5126\n",
      "Epoch [859/1000], Loss: 0.5119\n",
      "Epoch [860/1000], Loss: 0.5129\n",
      "Epoch [861/1000], Loss: 0.5121\n",
      "Epoch [862/1000], Loss: 0.5136\n",
      "Epoch [863/1000], Loss: 0.5126\n",
      "Epoch [864/1000], Loss: 0.5133\n",
      "Epoch [865/1000], Loss: 0.5133\n",
      "Epoch [866/1000], Loss: 0.5136\n",
      "Epoch [867/1000], Loss: 0.5126\n",
      "Epoch [868/1000], Loss: 0.5124\n",
      "Epoch [869/1000], Loss: 0.5102\n",
      "Epoch [870/1000], Loss: 0.5121\n",
      "Epoch [871/1000], Loss: 0.5136\n",
      "Epoch [872/1000], Loss: 0.5138\n",
      "Epoch [873/1000], Loss: 0.5131\n",
      "Epoch [874/1000], Loss: 0.5119\n",
      "Epoch [875/1000], Loss: 0.5143\n",
      "Epoch [876/1000], Loss: 0.5131\n",
      "Epoch [877/1000], Loss: 0.5110\n",
      "Epoch [878/1000], Loss: 0.5129\n",
      "Epoch [879/1000], Loss: 0.5131\n",
      "Epoch [880/1000], Loss: 0.5131\n",
      "Epoch [881/1000], Loss: 0.5117\n",
      "Epoch [882/1000], Loss: 0.5140\n",
      "Epoch [883/1000], Loss: 0.5110\n",
      "Epoch [884/1000], Loss: 0.5112\n",
      "Epoch [885/1000], Loss: 0.5124\n",
      "Epoch [886/1000], Loss: 0.5133\n",
      "Epoch [887/1000], Loss: 0.5129\n",
      "Epoch [888/1000], Loss: 0.5110\n",
      "Epoch [889/1000], Loss: 0.5124\n",
      "Epoch [890/1000], Loss: 0.5138\n",
      "Epoch [891/1000], Loss: 0.5131\n",
      "Epoch [892/1000], Loss: 0.5140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [893/1000], Loss: 0.5133\n",
      "Epoch [894/1000], Loss: 0.5112\n",
      "Epoch [895/1000], Loss: 0.5114\n",
      "Epoch [896/1000], Loss: 0.5124\n",
      "Epoch [897/1000], Loss: 0.5117\n",
      "Epoch [898/1000], Loss: 0.5117\n",
      "Epoch [899/1000], Loss: 0.5110\n",
      "Epoch [900/1000], Loss: 0.5119\n",
      "Epoch [901/1000], Loss: 0.5107\n",
      "Epoch [902/1000], Loss: 0.5131\n",
      "Epoch [903/1000], Loss: 0.5136\n",
      "Epoch [904/1000], Loss: 0.5133\n",
      "Epoch [905/1000], Loss: 0.5133\n",
      "Epoch [906/1000], Loss: 0.5143\n",
      "Epoch [907/1000], Loss: 0.5138\n",
      "Epoch [908/1000], Loss: 0.5119\n",
      "Epoch [909/1000], Loss: 0.5131\n",
      "Epoch [910/1000], Loss: 0.5138\n",
      "Epoch [911/1000], Loss: 0.5114\n",
      "Epoch [912/1000], Loss: 0.5126\n",
      "Epoch [913/1000], Loss: 0.5129\n",
      "Epoch [914/1000], Loss: 0.5131\n",
      "Epoch [915/1000], Loss: 0.5117\n",
      "Epoch [916/1000], Loss: 0.5140\n",
      "Epoch [917/1000], Loss: 0.5129\n",
      "Epoch [918/1000], Loss: 0.5126\n",
      "Epoch [919/1000], Loss: 0.5117\n",
      "Epoch [920/1000], Loss: 0.5138\n",
      "Epoch [921/1000], Loss: 0.5138\n",
      "Epoch [922/1000], Loss: 0.5124\n",
      "Epoch [923/1000], Loss: 0.5121\n",
      "Epoch [924/1000], Loss: 0.5121\n",
      "Epoch [925/1000], Loss: 0.5121\n",
      "Epoch [926/1000], Loss: 0.5138\n",
      "Epoch [927/1000], Loss: 0.5119\n",
      "Epoch [928/1000], Loss: 0.5124\n",
      "Epoch [929/1000], Loss: 0.5124\n",
      "Epoch [930/1000], Loss: 0.5114\n",
      "Epoch [931/1000], Loss: 0.5119\n",
      "Epoch [932/1000], Loss: 0.5145\n",
      "Epoch [933/1000], Loss: 0.5136\n",
      "Epoch [934/1000], Loss: 0.5110\n",
      "Epoch [935/1000], Loss: 0.5129\n",
      "Epoch [936/1000], Loss: 0.5138\n",
      "Epoch [937/1000], Loss: 0.5107\n",
      "Epoch [938/1000], Loss: 0.5119\n",
      "Epoch [939/1000], Loss: 0.5117\n",
      "Epoch [940/1000], Loss: 0.5124\n",
      "Epoch [941/1000], Loss: 0.5107\n",
      "Epoch [942/1000], Loss: 0.5157\n",
      "Epoch [943/1000], Loss: 0.5110\n",
      "Epoch [944/1000], Loss: 0.5131\n",
      "Epoch [945/1000], Loss: 0.5136\n",
      "Epoch [946/1000], Loss: 0.5129\n",
      "Epoch [947/1000], Loss: 0.5133\n",
      "Epoch [948/1000], Loss: 0.5138\n",
      "Epoch [949/1000], Loss: 0.5131\n",
      "Epoch [950/1000], Loss: 0.5126\n",
      "Epoch [951/1000], Loss: 0.5100\n",
      "Epoch [952/1000], Loss: 0.5119\n",
      "Epoch [953/1000], Loss: 0.5150\n",
      "Epoch [954/1000], Loss: 0.5119\n",
      "Epoch [955/1000], Loss: 0.5138\n",
      "Epoch [956/1000], Loss: 0.5112\n",
      "Epoch [957/1000], Loss: 0.5126\n",
      "Epoch [958/1000], Loss: 0.5140\n",
      "Epoch [959/1000], Loss: 0.5105\n",
      "Epoch [960/1000], Loss: 0.5143\n",
      "Epoch [961/1000], Loss: 0.5114\n",
      "Epoch [962/1000], Loss: 0.5129\n",
      "Epoch [963/1000], Loss: 0.5133\n",
      "Epoch [964/1000], Loss: 0.5126\n",
      "Epoch [965/1000], Loss: 0.5102\n",
      "Epoch [966/1000], Loss: 0.5119\n",
      "Epoch [967/1000], Loss: 0.5140\n",
      "Epoch [968/1000], Loss: 0.5131\n",
      "Epoch [969/1000], Loss: 0.5126\n",
      "Epoch [970/1000], Loss: 0.5117\n",
      "Epoch [971/1000], Loss: 0.5110\n",
      "Epoch [972/1000], Loss: 0.5114\n",
      "Epoch [973/1000], Loss: 0.5121\n",
      "Epoch [974/1000], Loss: 0.5124\n",
      "Epoch [975/1000], Loss: 0.5131\n",
      "Epoch [976/1000], Loss: 0.5136\n",
      "Epoch [977/1000], Loss: 0.5129\n",
      "Epoch [978/1000], Loss: 0.5117\n",
      "Epoch [979/1000], Loss: 0.5133\n",
      "Epoch [980/1000], Loss: 0.5138\n",
      "Epoch [981/1000], Loss: 0.5121\n",
      "Epoch [982/1000], Loss: 0.5124\n",
      "Epoch [983/1000], Loss: 0.5136\n",
      "Epoch [984/1000], Loss: 0.5133\n",
      "Epoch [985/1000], Loss: 0.5133\n",
      "Epoch [986/1000], Loss: 0.5124\n",
      "Epoch [987/1000], Loss: 0.5105\n",
      "Epoch [988/1000], Loss: 0.5126\n",
      "Epoch [989/1000], Loss: 0.5131\n",
      "Epoch [990/1000], Loss: 0.5110\n",
      "Epoch [991/1000], Loss: 0.5110\n",
      "Epoch [992/1000], Loss: 0.5126\n",
      "Epoch [993/1000], Loss: 0.5107\n",
      "Epoch [994/1000], Loss: 0.5126\n",
      "Epoch [995/1000], Loss: 0.5105\n",
      "Epoch [996/1000], Loss: 0.5117\n",
      "Epoch [997/1000], Loss: 0.5129\n",
      "Epoch [998/1000], Loss: 0.5105\n",
      "Epoch [999/1000], Loss: 0.5114\n",
      "Epoch [1000/1000], Loss: 0.5114\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 205, lr :10.0, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.5047\n",
      "Epoch [2/1000], Loss: 0.5189\n",
      "Epoch [3/1000], Loss: 0.5186\n",
      "Epoch [4/1000], Loss: 0.5179\n",
      "Epoch [5/1000], Loss: 0.5170\n",
      "Epoch [6/1000], Loss: 0.5174\n",
      "Epoch [7/1000], Loss: 0.5189\n",
      "Epoch [8/1000], Loss: 0.5196\n",
      "Epoch [9/1000], Loss: 0.5177\n",
      "Epoch [10/1000], Loss: 0.5181\n",
      "Epoch [11/1000], Loss: 0.5165\n",
      "Epoch [12/1000], Loss: 0.5174\n",
      "Epoch [13/1000], Loss: 0.5181\n",
      "Epoch [14/1000], Loss: 0.5177\n",
      "Epoch [15/1000], Loss: 0.5184\n",
      "Epoch [16/1000], Loss: 0.5170\n",
      "Epoch [17/1000], Loss: 0.5181\n",
      "Epoch [18/1000], Loss: 0.5179\n",
      "Epoch [19/1000], Loss: 0.5208\n",
      "Epoch [20/1000], Loss: 0.5174\n",
      "Epoch [21/1000], Loss: 0.5181\n",
      "Epoch [22/1000], Loss: 0.5179\n",
      "Epoch [23/1000], Loss: 0.5184\n",
      "Epoch [24/1000], Loss: 0.5191\n",
      "Epoch [25/1000], Loss: 0.5196\n",
      "Epoch [26/1000], Loss: 0.5193\n",
      "Epoch [27/1000], Loss: 0.5184\n",
      "Epoch [28/1000], Loss: 0.5189\n",
      "Epoch [29/1000], Loss: 0.5177\n",
      "Epoch [30/1000], Loss: 0.5196\n",
      "Epoch [31/1000], Loss: 0.5193\n",
      "Epoch [32/1000], Loss: 0.5208\n",
      "Epoch [33/1000], Loss: 0.5208\n",
      "Epoch [34/1000], Loss: 0.5189\n",
      "Epoch [35/1000], Loss: 0.5177\n",
      "Epoch [36/1000], Loss: 0.5191\n",
      "Epoch [37/1000], Loss: 0.5196\n",
      "Epoch [38/1000], Loss: 0.5170\n",
      "Epoch [39/1000], Loss: 0.5184\n",
      "Epoch [40/1000], Loss: 0.5191\n",
      "Epoch [41/1000], Loss: 0.5172\n",
      "Epoch [42/1000], Loss: 0.5160\n",
      "Epoch [43/1000], Loss: 0.5179\n",
      "Epoch [44/1000], Loss: 0.5191\n",
      "Epoch [45/1000], Loss: 0.5179\n",
      "Epoch [46/1000], Loss: 0.5196\n",
      "Epoch [47/1000], Loss: 0.5193\n",
      "Epoch [48/1000], Loss: 0.5193\n",
      "Epoch [49/1000], Loss: 0.5189\n",
      "Epoch [50/1000], Loss: 0.5162\n",
      "Epoch [51/1000], Loss: 0.5200\n",
      "Epoch [52/1000], Loss: 0.5189\n",
      "Epoch [53/1000], Loss: 0.5200\n",
      "Epoch [54/1000], Loss: 0.5217\n",
      "Epoch [55/1000], Loss: 0.5186\n",
      "Epoch [56/1000], Loss: 0.5189\n",
      "Epoch [57/1000], Loss: 0.5174\n",
      "Epoch [58/1000], Loss: 0.5208\n",
      "Epoch [59/1000], Loss: 0.5181\n",
      "Epoch [60/1000], Loss: 0.5186\n",
      "Epoch [61/1000], Loss: 0.5179\n",
      "Epoch [62/1000], Loss: 0.5165\n",
      "Epoch [63/1000], Loss: 0.5200\n",
      "Epoch [64/1000], Loss: 0.5162\n",
      "Epoch [65/1000], Loss: 0.5193\n",
      "Epoch [66/1000], Loss: 0.5205\n",
      "Epoch [67/1000], Loss: 0.5155\n",
      "Epoch [68/1000], Loss: 0.5186\n",
      "Epoch [69/1000], Loss: 0.5167\n",
      "Epoch [70/1000], Loss: 0.5208\n",
      "Epoch [71/1000], Loss: 0.5191\n",
      "Epoch [72/1000], Loss: 0.5177\n",
      "Epoch [73/1000], Loss: 0.5196\n",
      "Epoch [74/1000], Loss: 0.5179\n",
      "Epoch [75/1000], Loss: 0.5186\n",
      "Epoch [76/1000], Loss: 0.5200\n",
      "Epoch [77/1000], Loss: 0.5215\n",
      "Epoch [78/1000], Loss: 0.5189\n",
      "Epoch [79/1000], Loss: 0.5208\n",
      "Epoch [80/1000], Loss: 0.5186\n",
      "Epoch [81/1000], Loss: 0.5189\n",
      "Epoch [82/1000], Loss: 0.5186\n",
      "Epoch [83/1000], Loss: 0.5193\n",
      "Epoch [84/1000], Loss: 0.5172\n",
      "Epoch [85/1000], Loss: 0.5193\n",
      "Epoch [86/1000], Loss: 0.5186\n",
      "Epoch [87/1000], Loss: 0.5193\n",
      "Epoch [88/1000], Loss: 0.5193\n",
      "Epoch [89/1000], Loss: 0.5170\n",
      "Epoch [90/1000], Loss: 0.5191\n",
      "Epoch [91/1000], Loss: 0.5189\n",
      "Epoch [92/1000], Loss: 0.5186\n",
      "Epoch [93/1000], Loss: 0.5198\n",
      "Epoch [94/1000], Loss: 0.5162\n",
      "Epoch [95/1000], Loss: 0.5184\n",
      "Epoch [96/1000], Loss: 0.5184\n",
      "Epoch [97/1000], Loss: 0.5179\n",
      "Epoch [98/1000], Loss: 0.5191\n",
      "Epoch [99/1000], Loss: 0.5172\n",
      "Epoch [100/1000], Loss: 0.5186\n",
      "Epoch [101/1000], Loss: 0.5191\n",
      "Epoch [102/1000], Loss: 0.5196\n",
      "Epoch [103/1000], Loss: 0.5191\n",
      "Epoch [104/1000], Loss: 0.5191\n",
      "Epoch [105/1000], Loss: 0.5174\n",
      "Epoch [106/1000], Loss: 0.5172\n",
      "Epoch [107/1000], Loss: 0.5184\n",
      "Epoch [108/1000], Loss: 0.5191\n",
      "Epoch [109/1000], Loss: 0.5212\n",
      "Epoch [110/1000], Loss: 0.5184\n",
      "Epoch [111/1000], Loss: 0.5179\n",
      "Epoch [112/1000], Loss: 0.5205\n",
      "Epoch [113/1000], Loss: 0.5172\n",
      "Epoch [114/1000], Loss: 0.5189\n",
      "Epoch [115/1000], Loss: 0.5181\n",
      "Epoch [116/1000], Loss: 0.5177\n",
      "Epoch [117/1000], Loss: 0.5212\n",
      "Epoch [118/1000], Loss: 0.5198\n",
      "Epoch [119/1000], Loss: 0.5179\n",
      "Epoch [120/1000], Loss: 0.5181\n",
      "Epoch [121/1000], Loss: 0.5174\n",
      "Epoch [122/1000], Loss: 0.5205\n",
      "Epoch [123/1000], Loss: 0.5189\n",
      "Epoch [124/1000], Loss: 0.5193\n",
      "Epoch [125/1000], Loss: 0.5208\n",
      "Epoch [126/1000], Loss: 0.5186\n",
      "Epoch [127/1000], Loss: 0.5186\n",
      "Epoch [128/1000], Loss: 0.5179\n",
      "Epoch [129/1000], Loss: 0.5193\n",
      "Epoch [130/1000], Loss: 0.5217\n",
      "Epoch [131/1000], Loss: 0.5193\n",
      "Epoch [132/1000], Loss: 0.5179\n",
      "Epoch [133/1000], Loss: 0.5160\n",
      "Epoch [134/1000], Loss: 0.5189\n",
      "Epoch [135/1000], Loss: 0.5191\n",
      "Epoch [136/1000], Loss: 0.5191\n",
      "Epoch [137/1000], Loss: 0.5200\n",
      "Epoch [138/1000], Loss: 0.5181\n",
      "Epoch [139/1000], Loss: 0.5196\n",
      "Epoch [140/1000], Loss: 0.5177\n",
      "Epoch [141/1000], Loss: 0.5177\n",
      "Epoch [142/1000], Loss: 0.5174\n",
      "Epoch [143/1000], Loss: 0.5191\n",
      "Epoch [144/1000], Loss: 0.5186\n",
      "Epoch [145/1000], Loss: 0.5167\n",
      "Epoch [146/1000], Loss: 0.5191\n",
      "Epoch [147/1000], Loss: 0.5181\n",
      "Epoch [148/1000], Loss: 0.5196\n",
      "Epoch [149/1000], Loss: 0.5186\n",
      "Epoch [150/1000], Loss: 0.5193\n",
      "Epoch [151/1000], Loss: 0.5191\n",
      "Epoch [152/1000], Loss: 0.5193\n",
      "Epoch [153/1000], Loss: 0.5174\n",
      "Epoch [154/1000], Loss: 0.5177\n",
      "Epoch [155/1000], Loss: 0.5193\n",
      "Epoch [156/1000], Loss: 0.5186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [157/1000], Loss: 0.5193\n",
      "Epoch [158/1000], Loss: 0.5193\n",
      "Epoch [159/1000], Loss: 0.5181\n",
      "Epoch [160/1000], Loss: 0.5177\n",
      "Epoch [161/1000], Loss: 0.5177\n",
      "Epoch [162/1000], Loss: 0.5162\n",
      "Epoch [163/1000], Loss: 0.5186\n",
      "Epoch [164/1000], Loss: 0.5181\n",
      "Epoch [165/1000], Loss: 0.5170\n",
      "Epoch [166/1000], Loss: 0.5181\n",
      "Epoch [167/1000], Loss: 0.5184\n",
      "Epoch [168/1000], Loss: 0.5184\n",
      "Epoch [169/1000], Loss: 0.5181\n",
      "Epoch [170/1000], Loss: 0.5208\n",
      "Epoch [171/1000], Loss: 0.5200\n",
      "Epoch [172/1000], Loss: 0.5177\n",
      "Epoch [173/1000], Loss: 0.5193\n",
      "Epoch [174/1000], Loss: 0.5198\n",
      "Epoch [175/1000], Loss: 0.5172\n",
      "Epoch [176/1000], Loss: 0.5179\n",
      "Epoch [177/1000], Loss: 0.5200\n",
      "Epoch [178/1000], Loss: 0.5205\n",
      "Epoch [179/1000], Loss: 0.5222\n",
      "Epoch [180/1000], Loss: 0.5181\n",
      "Epoch [181/1000], Loss: 0.5184\n",
      "Epoch [182/1000], Loss: 0.5203\n",
      "Epoch [183/1000], Loss: 0.5215\n",
      "Epoch [184/1000], Loss: 0.5193\n",
      "Epoch [185/1000], Loss: 0.5193\n",
      "Epoch [186/1000], Loss: 0.5186\n",
      "Epoch [187/1000], Loss: 0.5177\n",
      "Epoch [188/1000], Loss: 0.5181\n",
      "Epoch [189/1000], Loss: 0.5191\n",
      "Epoch [190/1000], Loss: 0.5177\n",
      "Epoch [191/1000], Loss: 0.5184\n",
      "Epoch [192/1000], Loss: 0.5181\n",
      "Epoch [193/1000], Loss: 0.5184\n",
      "Epoch [194/1000], Loss: 0.5184\n",
      "Epoch [195/1000], Loss: 0.5186\n",
      "Epoch [196/1000], Loss: 0.5184\n",
      "Epoch [197/1000], Loss: 0.5172\n",
      "Epoch [198/1000], Loss: 0.5186\n",
      "Epoch [199/1000], Loss: 0.5162\n",
      "Epoch [200/1000], Loss: 0.5186\n",
      "Epoch [201/1000], Loss: 0.5200\n",
      "Epoch [202/1000], Loss: 0.5198\n",
      "Epoch [203/1000], Loss: 0.5186\n",
      "Epoch [204/1000], Loss: 0.5181\n",
      "Epoch [205/1000], Loss: 0.5200\n",
      "Epoch [206/1000], Loss: 0.5198\n",
      "Epoch [207/1000], Loss: 0.5181\n",
      "Epoch [208/1000], Loss: 0.5181\n",
      "Epoch [209/1000], Loss: 0.5186\n",
      "Epoch [210/1000], Loss: 0.5184\n",
      "Epoch [211/1000], Loss: 0.5186\n",
      "Epoch [212/1000], Loss: 0.5181\n",
      "Epoch [213/1000], Loss: 0.5196\n",
      "Epoch [214/1000], Loss: 0.5189\n",
      "Epoch [215/1000], Loss: 0.5205\n",
      "Epoch [216/1000], Loss: 0.5196\n",
      "Epoch [217/1000], Loss: 0.5189\n",
      "Epoch [218/1000], Loss: 0.5181\n",
      "Epoch [219/1000], Loss: 0.5160\n",
      "Epoch [220/1000], Loss: 0.5160\n",
      "Epoch [221/1000], Loss: 0.5179\n",
      "Epoch [222/1000], Loss: 0.5191\n",
      "Epoch [223/1000], Loss: 0.5186\n",
      "Epoch [224/1000], Loss: 0.5186\n",
      "Epoch [225/1000], Loss: 0.5167\n",
      "Epoch [226/1000], Loss: 0.5189\n",
      "Epoch [227/1000], Loss: 0.5184\n",
      "Epoch [228/1000], Loss: 0.5196\n",
      "Epoch [229/1000], Loss: 0.5191\n",
      "Epoch [230/1000], Loss: 0.5181\n",
      "Epoch [231/1000], Loss: 0.5181\n",
      "Epoch [232/1000], Loss: 0.5191\n",
      "Epoch [233/1000], Loss: 0.5193\n",
      "Epoch [234/1000], Loss: 0.5170\n",
      "Epoch [235/1000], Loss: 0.5181\n",
      "Epoch [236/1000], Loss: 0.5181\n",
      "Epoch [237/1000], Loss: 0.5189\n",
      "Epoch [238/1000], Loss: 0.5196\n",
      "Epoch [239/1000], Loss: 0.5179\n",
      "Epoch [240/1000], Loss: 0.5196\n",
      "Epoch [241/1000], Loss: 0.5193\n",
      "Epoch [242/1000], Loss: 0.5200\n",
      "Epoch [243/1000], Loss: 0.5198\n",
      "Epoch [244/1000], Loss: 0.5174\n",
      "Epoch [245/1000], Loss: 0.5191\n",
      "Epoch [246/1000], Loss: 0.5179\n",
      "Epoch [247/1000], Loss: 0.5179\n",
      "Epoch [248/1000], Loss: 0.5179\n",
      "Epoch [249/1000], Loss: 0.5184\n",
      "Epoch [250/1000], Loss: 0.5210\n",
      "Epoch [251/1000], Loss: 0.5174\n",
      "Epoch [252/1000], Loss: 0.5184\n",
      "Epoch [253/1000], Loss: 0.5193\n",
      "Epoch [254/1000], Loss: 0.5191\n",
      "Epoch [255/1000], Loss: 0.5181\n",
      "Epoch [256/1000], Loss: 0.5208\n",
      "Epoch [257/1000], Loss: 0.5179\n",
      "Epoch [258/1000], Loss: 0.5193\n",
      "Epoch [259/1000], Loss: 0.5186\n",
      "Epoch [260/1000], Loss: 0.5193\n",
      "Epoch [261/1000], Loss: 0.5186\n",
      "Epoch [262/1000], Loss: 0.5174\n",
      "Epoch [263/1000], Loss: 0.5184\n",
      "Epoch [264/1000], Loss: 0.5189\n",
      "Epoch [265/1000], Loss: 0.5198\n",
      "Epoch [266/1000], Loss: 0.5186\n",
      "Epoch [267/1000], Loss: 0.5205\n",
      "Epoch [268/1000], Loss: 0.5193\n",
      "Epoch [269/1000], Loss: 0.5179\n",
      "Epoch [270/1000], Loss: 0.5189\n",
      "Epoch [271/1000], Loss: 0.5186\n",
      "Epoch [272/1000], Loss: 0.5181\n",
      "Epoch [273/1000], Loss: 0.5179\n",
      "Epoch [274/1000], Loss: 0.5174\n",
      "Epoch [275/1000], Loss: 0.5170\n",
      "Epoch [276/1000], Loss: 0.5186\n",
      "Epoch [277/1000], Loss: 0.5186\n",
      "Epoch [278/1000], Loss: 0.5186\n",
      "Epoch [279/1000], Loss: 0.5193\n",
      "Epoch [280/1000], Loss: 0.5162\n",
      "Epoch [281/1000], Loss: 0.5170\n",
      "Epoch [282/1000], Loss: 0.5181\n",
      "Epoch [283/1000], Loss: 0.5174\n",
      "Epoch [284/1000], Loss: 0.5184\n",
      "Epoch [285/1000], Loss: 0.5184\n",
      "Epoch [286/1000], Loss: 0.5184\n",
      "Epoch [287/1000], Loss: 0.5210\n",
      "Epoch [288/1000], Loss: 0.5196\n",
      "Epoch [289/1000], Loss: 0.5186\n",
      "Epoch [290/1000], Loss: 0.5184\n",
      "Epoch [291/1000], Loss: 0.5196\n",
      "Epoch [292/1000], Loss: 0.5186\n",
      "Epoch [293/1000], Loss: 0.5172\n",
      "Epoch [294/1000], Loss: 0.5172\n",
      "Epoch [295/1000], Loss: 0.5179\n",
      "Epoch [296/1000], Loss: 0.5193\n",
      "Epoch [297/1000], Loss: 0.5184\n",
      "Epoch [298/1000], Loss: 0.5177\n",
      "Epoch [299/1000], Loss: 0.5179\n",
      "Epoch [300/1000], Loss: 0.5184\n",
      "Epoch [301/1000], Loss: 0.5198\n",
      "Epoch [302/1000], Loss: 0.5179\n",
      "Epoch [303/1000], Loss: 0.5184\n",
      "Epoch [304/1000], Loss: 0.5184\n",
      "Epoch [305/1000], Loss: 0.5191\n",
      "Epoch [306/1000], Loss: 0.5215\n",
      "Epoch [307/1000], Loss: 0.5200\n",
      "Epoch [308/1000], Loss: 0.5198\n",
      "Epoch [309/1000], Loss: 0.5179\n",
      "Epoch [310/1000], Loss: 0.5179\n",
      "Epoch [311/1000], Loss: 0.5193\n",
      "Epoch [312/1000], Loss: 0.5184\n",
      "Epoch [313/1000], Loss: 0.5172\n",
      "Epoch [314/1000], Loss: 0.5193\n",
      "Epoch [315/1000], Loss: 0.5191\n",
      "Epoch [316/1000], Loss: 0.5184\n",
      "Epoch [317/1000], Loss: 0.5200\n",
      "Epoch [318/1000], Loss: 0.5177\n",
      "Epoch [319/1000], Loss: 0.5181\n",
      "Epoch [320/1000], Loss: 0.5191\n",
      "Epoch [321/1000], Loss: 0.5196\n",
      "Epoch [322/1000], Loss: 0.5193\n",
      "Epoch [323/1000], Loss: 0.5172\n",
      "Epoch [324/1000], Loss: 0.5212\n",
      "Epoch [325/1000], Loss: 0.5189\n",
      "Epoch [326/1000], Loss: 0.5191\n",
      "Epoch [327/1000], Loss: 0.5208\n",
      "Epoch [328/1000], Loss: 0.5174\n",
      "Epoch [329/1000], Loss: 0.5196\n",
      "Epoch [330/1000], Loss: 0.5179\n",
      "Epoch [331/1000], Loss: 0.5189\n",
      "Epoch [332/1000], Loss: 0.5181\n",
      "Epoch [333/1000], Loss: 0.5186\n",
      "Epoch [334/1000], Loss: 0.5193\n",
      "Epoch [335/1000], Loss: 0.5212\n",
      "Epoch [336/1000], Loss: 0.5193\n",
      "Epoch [337/1000], Loss: 0.5191\n",
      "Epoch [338/1000], Loss: 0.5196\n",
      "Epoch [339/1000], Loss: 0.5186\n",
      "Epoch [340/1000], Loss: 0.5205\n",
      "Epoch [341/1000], Loss: 0.5184\n",
      "Epoch [342/1000], Loss: 0.5165\n",
      "Epoch [343/1000], Loss: 0.5179\n",
      "Epoch [344/1000], Loss: 0.5162\n",
      "Epoch [345/1000], Loss: 0.5189\n",
      "Epoch [346/1000], Loss: 0.5193\n",
      "Epoch [347/1000], Loss: 0.5189\n",
      "Epoch [348/1000], Loss: 0.5203\n",
      "Epoch [349/1000], Loss: 0.5189\n",
      "Epoch [350/1000], Loss: 0.5177\n",
      "Epoch [351/1000], Loss: 0.5174\n",
      "Epoch [352/1000], Loss: 0.5174\n",
      "Epoch [353/1000], Loss: 0.5196\n",
      "Epoch [354/1000], Loss: 0.5162\n",
      "Epoch [355/1000], Loss: 0.5189\n",
      "Epoch [356/1000], Loss: 0.5217\n",
      "Epoch [357/1000], Loss: 0.5203\n",
      "Epoch [358/1000], Loss: 0.5170\n",
      "Epoch [359/1000], Loss: 0.5184\n",
      "Epoch [360/1000], Loss: 0.5179\n",
      "Epoch [361/1000], Loss: 0.5191\n",
      "Epoch [362/1000], Loss: 0.5198\n",
      "Epoch [363/1000], Loss: 0.5196\n",
      "Epoch [364/1000], Loss: 0.5181\n",
      "Epoch [365/1000], Loss: 0.5189\n",
      "Epoch [366/1000], Loss: 0.5205\n",
      "Epoch [367/1000], Loss: 0.5189\n",
      "Epoch [368/1000], Loss: 0.5179\n",
      "Epoch [369/1000], Loss: 0.5200\n",
      "Epoch [370/1000], Loss: 0.5179\n",
      "Epoch [371/1000], Loss: 0.5189\n",
      "Epoch [372/1000], Loss: 0.5179\n",
      "Epoch [373/1000], Loss: 0.5181\n",
      "Epoch [374/1000], Loss: 0.5205\n",
      "Epoch [375/1000], Loss: 0.5184\n",
      "Epoch [376/1000], Loss: 0.5186\n",
      "Epoch [377/1000], Loss: 0.5191\n",
      "Epoch [378/1000], Loss: 0.5186\n",
      "Epoch [379/1000], Loss: 0.5189\n",
      "Epoch [380/1000], Loss: 0.5177\n",
      "Epoch [381/1000], Loss: 0.5174\n",
      "Epoch [382/1000], Loss: 0.5179\n",
      "Epoch [383/1000], Loss: 0.5184\n",
      "Epoch [384/1000], Loss: 0.5205\n",
      "Epoch [385/1000], Loss: 0.5177\n",
      "Epoch [386/1000], Loss: 0.5184\n",
      "Epoch [387/1000], Loss: 0.5174\n",
      "Epoch [388/1000], Loss: 0.5177\n",
      "Epoch [389/1000], Loss: 0.5186\n",
      "Epoch [390/1000], Loss: 0.5181\n",
      "Epoch [391/1000], Loss: 0.5210\n",
      "Epoch [392/1000], Loss: 0.5200\n",
      "Epoch [393/1000], Loss: 0.5186\n",
      "Epoch [394/1000], Loss: 0.5179\n",
      "Epoch [395/1000], Loss: 0.5186\n",
      "Epoch [396/1000], Loss: 0.5165\n",
      "Epoch [397/1000], Loss: 0.5179\n",
      "Epoch [398/1000], Loss: 0.5177\n",
      "Epoch [399/1000], Loss: 0.5160\n",
      "Epoch [400/1000], Loss: 0.5179\n",
      "Epoch [401/1000], Loss: 0.5184\n",
      "Epoch [402/1000], Loss: 0.5189\n",
      "Epoch [403/1000], Loss: 0.5177\n",
      "Epoch [404/1000], Loss: 0.5205\n",
      "Epoch [405/1000], Loss: 0.5179\n",
      "Epoch [406/1000], Loss: 0.5181\n",
      "Epoch [407/1000], Loss: 0.5203\n",
      "Epoch [408/1000], Loss: 0.5193\n",
      "Epoch [409/1000], Loss: 0.5179\n",
      "Epoch [410/1000], Loss: 0.5172\n",
      "Epoch [411/1000], Loss: 0.5193\n",
      "Epoch [412/1000], Loss: 0.5193\n",
      "Epoch [413/1000], Loss: 0.5198\n",
      "Epoch [414/1000], Loss: 0.5186\n",
      "Epoch [415/1000], Loss: 0.5200\n",
      "Epoch [416/1000], Loss: 0.5172\n",
      "Epoch [417/1000], Loss: 0.5189\n",
      "Epoch [418/1000], Loss: 0.5198\n",
      "Epoch [419/1000], Loss: 0.5203\n",
      "Epoch [420/1000], Loss: 0.5203\n",
      "Epoch [421/1000], Loss: 0.5177\n",
      "Epoch [422/1000], Loss: 0.5184\n",
      "Epoch [423/1000], Loss: 0.5189\n",
      "Epoch [424/1000], Loss: 0.5189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [425/1000], Loss: 0.5177\n",
      "Epoch [426/1000], Loss: 0.5191\n",
      "Epoch [427/1000], Loss: 0.5203\n",
      "Epoch [428/1000], Loss: 0.5205\n",
      "Epoch [429/1000], Loss: 0.5196\n",
      "Epoch [430/1000], Loss: 0.5193\n",
      "Epoch [431/1000], Loss: 0.5210\n",
      "Epoch [432/1000], Loss: 0.5196\n",
      "Epoch [433/1000], Loss: 0.5181\n",
      "Epoch [434/1000], Loss: 0.5177\n",
      "Epoch [435/1000], Loss: 0.5189\n",
      "Epoch [436/1000], Loss: 0.5186\n",
      "Epoch [437/1000], Loss: 0.5191\n",
      "Epoch [438/1000], Loss: 0.5186\n",
      "Epoch [439/1000], Loss: 0.5177\n",
      "Epoch [440/1000], Loss: 0.5184\n",
      "Epoch [441/1000], Loss: 0.5191\n",
      "Epoch [442/1000], Loss: 0.5172\n",
      "Epoch [443/1000], Loss: 0.5177\n",
      "Epoch [444/1000], Loss: 0.5172\n",
      "Epoch [445/1000], Loss: 0.5203\n",
      "Epoch [446/1000], Loss: 0.5162\n",
      "Epoch [447/1000], Loss: 0.5170\n",
      "Epoch [448/1000], Loss: 0.5172\n",
      "Epoch [449/1000], Loss: 0.5186\n",
      "Epoch [450/1000], Loss: 0.5193\n",
      "Epoch [451/1000], Loss: 0.5177\n",
      "Epoch [452/1000], Loss: 0.5162\n",
      "Epoch [453/1000], Loss: 0.5191\n",
      "Epoch [454/1000], Loss: 0.5189\n",
      "Epoch [455/1000], Loss: 0.5179\n",
      "Epoch [456/1000], Loss: 0.5205\n",
      "Epoch [457/1000], Loss: 0.5200\n",
      "Epoch [458/1000], Loss: 0.5203\n",
      "Epoch [459/1000], Loss: 0.5198\n",
      "Epoch [460/1000], Loss: 0.5196\n",
      "Epoch [461/1000], Loss: 0.5184\n",
      "Epoch [462/1000], Loss: 0.5177\n",
      "Epoch [463/1000], Loss: 0.5196\n",
      "Epoch [464/1000], Loss: 0.5172\n",
      "Epoch [465/1000], Loss: 0.5181\n",
      "Epoch [466/1000], Loss: 0.5196\n",
      "Epoch [467/1000], Loss: 0.5186\n",
      "Epoch [468/1000], Loss: 0.5191\n",
      "Epoch [469/1000], Loss: 0.5191\n",
      "Epoch [470/1000], Loss: 0.5181\n",
      "Epoch [471/1000], Loss: 0.5191\n",
      "Epoch [472/1000], Loss: 0.5181\n",
      "Epoch [473/1000], Loss: 0.5193\n",
      "Epoch [474/1000], Loss: 0.5193\n",
      "Epoch [475/1000], Loss: 0.5189\n",
      "Epoch [476/1000], Loss: 0.5181\n",
      "Epoch [477/1000], Loss: 0.5174\n",
      "Epoch [478/1000], Loss: 0.5189\n",
      "Epoch [479/1000], Loss: 0.5200\n",
      "Epoch [480/1000], Loss: 0.5186\n",
      "Epoch [481/1000], Loss: 0.5186\n",
      "Epoch [482/1000], Loss: 0.5179\n",
      "Epoch [483/1000], Loss: 0.5179\n",
      "Epoch [484/1000], Loss: 0.5210\n",
      "Epoch [485/1000], Loss: 0.5198\n",
      "Epoch [486/1000], Loss: 0.5170\n",
      "Epoch [487/1000], Loss: 0.5172\n",
      "Epoch [488/1000], Loss: 0.5177\n",
      "Epoch [489/1000], Loss: 0.5191\n",
      "Epoch [490/1000], Loss: 0.5186\n",
      "Epoch [491/1000], Loss: 0.5189\n",
      "Epoch [492/1000], Loss: 0.5179\n",
      "Epoch [493/1000], Loss: 0.5167\n",
      "Epoch [494/1000], Loss: 0.5184\n",
      "Epoch [495/1000], Loss: 0.5184\n",
      "Epoch [496/1000], Loss: 0.5172\n",
      "Epoch [497/1000], Loss: 0.5198\n",
      "Epoch [498/1000], Loss: 0.5184\n",
      "Epoch [499/1000], Loss: 0.5181\n",
      "Epoch [500/1000], Loss: 0.5181\n",
      "Epoch [501/1000], Loss: 0.5162\n",
      "Epoch [502/1000], Loss: 0.5170\n",
      "Epoch [503/1000], Loss: 0.5205\n",
      "Epoch [504/1000], Loss: 0.5227\n",
      "Epoch [505/1000], Loss: 0.5200\n",
      "Epoch [506/1000], Loss: 0.5170\n",
      "Epoch [507/1000], Loss: 0.5186\n",
      "Epoch [508/1000], Loss: 0.5205\n",
      "Epoch [509/1000], Loss: 0.5189\n",
      "Epoch [510/1000], Loss: 0.5193\n",
      "Epoch [511/1000], Loss: 0.5177\n",
      "Epoch [512/1000], Loss: 0.5165\n",
      "Epoch [513/1000], Loss: 0.5181\n",
      "Epoch [514/1000], Loss: 0.5184\n",
      "Epoch [515/1000], Loss: 0.5179\n",
      "Epoch [516/1000], Loss: 0.5184\n",
      "Epoch [517/1000], Loss: 0.5184\n",
      "Epoch [518/1000], Loss: 0.5177\n",
      "Epoch [519/1000], Loss: 0.5191\n",
      "Epoch [520/1000], Loss: 0.5186\n",
      "Epoch [521/1000], Loss: 0.5191\n",
      "Epoch [522/1000], Loss: 0.5212\n",
      "Epoch [523/1000], Loss: 0.5181\n",
      "Epoch [524/1000], Loss: 0.5186\n",
      "Epoch [525/1000], Loss: 0.5191\n",
      "Epoch [526/1000], Loss: 0.5203\n",
      "Epoch [527/1000], Loss: 0.5186\n",
      "Epoch [528/1000], Loss: 0.5200\n",
      "Epoch [529/1000], Loss: 0.5186\n",
      "Epoch [530/1000], Loss: 0.5177\n",
      "Epoch [531/1000], Loss: 0.5179\n",
      "Epoch [532/1000], Loss: 0.5208\n",
      "Epoch [533/1000], Loss: 0.5186\n",
      "Epoch [534/1000], Loss: 0.5198\n",
      "Epoch [535/1000], Loss: 0.5198\n",
      "Epoch [536/1000], Loss: 0.5208\n",
      "Epoch [537/1000], Loss: 0.5170\n",
      "Epoch [538/1000], Loss: 0.5172\n",
      "Epoch [539/1000], Loss: 0.5191\n",
      "Epoch [540/1000], Loss: 0.5186\n",
      "Epoch [541/1000], Loss: 0.5174\n",
      "Epoch [542/1000], Loss: 0.5184\n",
      "Epoch [543/1000], Loss: 0.5179\n",
      "Epoch [544/1000], Loss: 0.5193\n",
      "Epoch [545/1000], Loss: 0.5184\n",
      "Epoch [546/1000], Loss: 0.5191\n",
      "Epoch [547/1000], Loss: 0.5181\n",
      "Epoch [548/1000], Loss: 0.5165\n",
      "Epoch [549/1000], Loss: 0.5179\n",
      "Epoch [550/1000], Loss: 0.5191\n",
      "Epoch [551/1000], Loss: 0.5184\n",
      "Epoch [552/1000], Loss: 0.5210\n",
      "Epoch [553/1000], Loss: 0.5210\n",
      "Epoch [554/1000], Loss: 0.5196\n",
      "Epoch [555/1000], Loss: 0.5189\n",
      "Epoch [556/1000], Loss: 0.5186\n",
      "Epoch [557/1000], Loss: 0.5196\n",
      "Epoch [558/1000], Loss: 0.5172\n",
      "Epoch [559/1000], Loss: 0.5196\n",
      "Epoch [560/1000], Loss: 0.5179\n",
      "Epoch [561/1000], Loss: 0.5170\n",
      "Epoch [562/1000], Loss: 0.5181\n",
      "Epoch [563/1000], Loss: 0.5179\n",
      "Epoch [564/1000], Loss: 0.5172\n",
      "Epoch [565/1000], Loss: 0.5177\n",
      "Epoch [566/1000], Loss: 0.5196\n",
      "Epoch [567/1000], Loss: 0.5189\n",
      "Epoch [568/1000], Loss: 0.5179\n",
      "Epoch [569/1000], Loss: 0.5186\n",
      "Epoch [570/1000], Loss: 0.5191\n",
      "Epoch [571/1000], Loss: 0.5222\n",
      "Epoch [572/1000], Loss: 0.5189\n",
      "Epoch [573/1000], Loss: 0.5172\n",
      "Epoch [574/1000], Loss: 0.5189\n",
      "Epoch [575/1000], Loss: 0.5179\n",
      "Epoch [576/1000], Loss: 0.5167\n",
      "Epoch [577/1000], Loss: 0.5186\n",
      "Epoch [578/1000], Loss: 0.5179\n",
      "Epoch [579/1000], Loss: 0.5177\n",
      "Epoch [580/1000], Loss: 0.5189\n",
      "Epoch [581/1000], Loss: 0.5200\n",
      "Epoch [582/1000], Loss: 0.5189\n",
      "Epoch [583/1000], Loss: 0.5174\n",
      "Epoch [584/1000], Loss: 0.5191\n",
      "Epoch [585/1000], Loss: 0.5198\n",
      "Epoch [586/1000], Loss: 0.5200\n",
      "Epoch [587/1000], Loss: 0.5193\n",
      "Epoch [588/1000], Loss: 0.5198\n",
      "Epoch [589/1000], Loss: 0.5193\n",
      "Epoch [590/1000], Loss: 0.5177\n",
      "Epoch [591/1000], Loss: 0.5179\n",
      "Epoch [592/1000], Loss: 0.5200\n",
      "Epoch [593/1000], Loss: 0.5212\n",
      "Epoch [594/1000], Loss: 0.5170\n",
      "Epoch [595/1000], Loss: 0.5208\n",
      "Epoch [596/1000], Loss: 0.5177\n",
      "Epoch [597/1000], Loss: 0.5191\n",
      "Epoch [598/1000], Loss: 0.5174\n",
      "Epoch [599/1000], Loss: 0.5179\n",
      "Epoch [600/1000], Loss: 0.5196\n",
      "Epoch [601/1000], Loss: 0.5162\n",
      "Epoch [602/1000], Loss: 0.5186\n",
      "Epoch [603/1000], Loss: 0.5177\n",
      "Epoch [604/1000], Loss: 0.5170\n",
      "Epoch [605/1000], Loss: 0.5181\n",
      "Epoch [606/1000], Loss: 0.5186\n",
      "Epoch [607/1000], Loss: 0.5198\n",
      "Epoch [608/1000], Loss: 0.5186\n",
      "Epoch [609/1000], Loss: 0.5181\n",
      "Epoch [610/1000], Loss: 0.5170\n",
      "Epoch [611/1000], Loss: 0.5172\n",
      "Epoch [612/1000], Loss: 0.5193\n",
      "Epoch [613/1000], Loss: 0.5184\n",
      "Epoch [614/1000], Loss: 0.5198\n",
      "Epoch [615/1000], Loss: 0.5184\n",
      "Epoch [616/1000], Loss: 0.5191\n",
      "Epoch [617/1000], Loss: 0.5198\n",
      "Epoch [618/1000], Loss: 0.5184\n",
      "Epoch [619/1000], Loss: 0.5160\n",
      "Epoch [620/1000], Loss: 0.5208\n",
      "Epoch [621/1000], Loss: 0.5177\n",
      "Epoch [622/1000], Loss: 0.5186\n",
      "Epoch [623/1000], Loss: 0.5200\n",
      "Epoch [624/1000], Loss: 0.5196\n",
      "Epoch [625/1000], Loss: 0.5203\n",
      "Epoch [626/1000], Loss: 0.5198\n",
      "Epoch [627/1000], Loss: 0.5203\n",
      "Epoch [628/1000], Loss: 0.5186\n",
      "Epoch [629/1000], Loss: 0.5191\n",
      "Epoch [630/1000], Loss: 0.5198\n",
      "Epoch [631/1000], Loss: 0.5191\n",
      "Epoch [632/1000], Loss: 0.5196\n",
      "Epoch [633/1000], Loss: 0.5181\n",
      "Epoch [634/1000], Loss: 0.5193\n",
      "Epoch [635/1000], Loss: 0.5172\n",
      "Epoch [636/1000], Loss: 0.5179\n",
      "Epoch [637/1000], Loss: 0.5160\n",
      "Epoch [638/1000], Loss: 0.5179\n",
      "Epoch [639/1000], Loss: 0.5184\n",
      "Epoch [640/1000], Loss: 0.5189\n",
      "Epoch [641/1000], Loss: 0.5186\n",
      "Epoch [642/1000], Loss: 0.5165\n",
      "Epoch [643/1000], Loss: 0.5189\n",
      "Epoch [644/1000], Loss: 0.5184\n",
      "Epoch [645/1000], Loss: 0.5193\n",
      "Epoch [646/1000], Loss: 0.5196\n",
      "Epoch [647/1000], Loss: 0.5174\n",
      "Epoch [648/1000], Loss: 0.5196\n",
      "Epoch [649/1000], Loss: 0.5165\n",
      "Epoch [650/1000], Loss: 0.5189\n",
      "Epoch [651/1000], Loss: 0.5200\n",
      "Epoch [652/1000], Loss: 0.5203\n",
      "Epoch [653/1000], Loss: 0.5212\n",
      "Epoch [654/1000], Loss: 0.5191\n",
      "Epoch [655/1000], Loss: 0.5186\n",
      "Epoch [656/1000], Loss: 0.5186\n",
      "Epoch [657/1000], Loss: 0.5205\n",
      "Epoch [658/1000], Loss: 0.5184\n",
      "Epoch [659/1000], Loss: 0.5191\n",
      "Epoch [660/1000], Loss: 0.5203\n",
      "Epoch [661/1000], Loss: 0.5193\n",
      "Epoch [662/1000], Loss: 0.5193\n",
      "Epoch [663/1000], Loss: 0.5184\n",
      "Epoch [664/1000], Loss: 0.5167\n",
      "Epoch [665/1000], Loss: 0.5189\n",
      "Epoch [666/1000], Loss: 0.5184\n",
      "Epoch [667/1000], Loss: 0.5205\n",
      "Epoch [668/1000], Loss: 0.5184\n",
      "Epoch [669/1000], Loss: 0.5200\n",
      "Epoch [670/1000], Loss: 0.5198\n",
      "Epoch [671/1000], Loss: 0.5193\n",
      "Epoch [672/1000], Loss: 0.5167\n",
      "Epoch [673/1000], Loss: 0.5196\n",
      "Epoch [674/1000], Loss: 0.5193\n",
      "Epoch [675/1000], Loss: 0.5196\n",
      "Epoch [676/1000], Loss: 0.5189\n",
      "Epoch [677/1000], Loss: 0.5196\n",
      "Epoch [678/1000], Loss: 0.5191\n",
      "Epoch [679/1000], Loss: 0.5191\n",
      "Epoch [680/1000], Loss: 0.5191\n",
      "Epoch [681/1000], Loss: 0.5212\n",
      "Epoch [682/1000], Loss: 0.5179\n",
      "Epoch [683/1000], Loss: 0.5162\n",
      "Epoch [684/1000], Loss: 0.5189\n",
      "Epoch [685/1000], Loss: 0.5189\n",
      "Epoch [686/1000], Loss: 0.5179\n",
      "Epoch [687/1000], Loss: 0.5179\n",
      "Epoch [688/1000], Loss: 0.5172\n",
      "Epoch [689/1000], Loss: 0.5210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [690/1000], Loss: 0.5198\n",
      "Epoch [691/1000], Loss: 0.5170\n",
      "Epoch [692/1000], Loss: 0.5198\n",
      "Epoch [693/1000], Loss: 0.5191\n",
      "Epoch [694/1000], Loss: 0.5177\n",
      "Epoch [695/1000], Loss: 0.5181\n",
      "Epoch [696/1000], Loss: 0.5179\n",
      "Epoch [697/1000], Loss: 0.5181\n",
      "Epoch [698/1000], Loss: 0.5177\n",
      "Epoch [699/1000], Loss: 0.5174\n",
      "Epoch [700/1000], Loss: 0.5167\n",
      "Epoch [701/1000], Loss: 0.5200\n",
      "Epoch [702/1000], Loss: 0.5186\n",
      "Epoch [703/1000], Loss: 0.5196\n",
      "Epoch [704/1000], Loss: 0.5198\n",
      "Epoch [705/1000], Loss: 0.5198\n",
      "Epoch [706/1000], Loss: 0.5191\n",
      "Epoch [707/1000], Loss: 0.5165\n",
      "Epoch [708/1000], Loss: 0.5210\n",
      "Epoch [709/1000], Loss: 0.5184\n",
      "Epoch [710/1000], Loss: 0.5181\n",
      "Epoch [711/1000], Loss: 0.5200\n",
      "Epoch [712/1000], Loss: 0.5198\n",
      "Epoch [713/1000], Loss: 0.5177\n",
      "Epoch [714/1000], Loss: 0.5205\n",
      "Epoch [715/1000], Loss: 0.5193\n",
      "Epoch [716/1000], Loss: 0.5162\n",
      "Epoch [717/1000], Loss: 0.5184\n",
      "Epoch [718/1000], Loss: 0.5184\n",
      "Epoch [719/1000], Loss: 0.5165\n",
      "Epoch [720/1000], Loss: 0.5181\n",
      "Epoch [721/1000], Loss: 0.5179\n",
      "Epoch [722/1000], Loss: 0.5212\n",
      "Epoch [723/1000], Loss: 0.5198\n",
      "Epoch [724/1000], Loss: 0.5181\n",
      "Epoch [725/1000], Loss: 0.5198\n",
      "Epoch [726/1000], Loss: 0.5191\n",
      "Epoch [727/1000], Loss: 0.5186\n",
      "Epoch [728/1000], Loss: 0.5184\n",
      "Epoch [729/1000], Loss: 0.5184\n",
      "Epoch [730/1000], Loss: 0.5177\n",
      "Epoch [731/1000], Loss: 0.5191\n",
      "Epoch [732/1000], Loss: 0.5210\n",
      "Epoch [733/1000], Loss: 0.5186\n",
      "Epoch [734/1000], Loss: 0.5222\n",
      "Epoch [735/1000], Loss: 0.5181\n",
      "Epoch [736/1000], Loss: 0.5179\n",
      "Epoch [737/1000], Loss: 0.5174\n",
      "Epoch [738/1000], Loss: 0.5210\n",
      "Epoch [739/1000], Loss: 0.5200\n",
      "Epoch [740/1000], Loss: 0.5174\n",
      "Epoch [741/1000], Loss: 0.5181\n",
      "Epoch [742/1000], Loss: 0.5186\n",
      "Epoch [743/1000], Loss: 0.5200\n",
      "Epoch [744/1000], Loss: 0.5181\n",
      "Epoch [745/1000], Loss: 0.5186\n",
      "Epoch [746/1000], Loss: 0.5177\n",
      "Epoch [747/1000], Loss: 0.5184\n",
      "Epoch [748/1000], Loss: 0.5179\n",
      "Epoch [749/1000], Loss: 0.5191\n",
      "Epoch [750/1000], Loss: 0.5198\n",
      "Epoch [751/1000], Loss: 0.5184\n",
      "Epoch [752/1000], Loss: 0.5172\n",
      "Epoch [753/1000], Loss: 0.5167\n",
      "Epoch [754/1000], Loss: 0.5177\n",
      "Epoch [755/1000], Loss: 0.5191\n",
      "Epoch [756/1000], Loss: 0.5170\n",
      "Epoch [757/1000], Loss: 0.5181\n",
      "Epoch [758/1000], Loss: 0.5189\n",
      "Epoch [759/1000], Loss: 0.5193\n",
      "Epoch [760/1000], Loss: 0.5172\n",
      "Epoch [761/1000], Loss: 0.5191\n",
      "Epoch [762/1000], Loss: 0.5186\n",
      "Epoch [763/1000], Loss: 0.5177\n",
      "Epoch [764/1000], Loss: 0.5167\n",
      "Epoch [765/1000], Loss: 0.5181\n",
      "Epoch [766/1000], Loss: 0.5181\n",
      "Epoch [767/1000], Loss: 0.5170\n",
      "Epoch [768/1000], Loss: 0.5170\n",
      "Epoch [769/1000], Loss: 0.5200\n",
      "Epoch [770/1000], Loss: 0.5189\n",
      "Epoch [771/1000], Loss: 0.5167\n",
      "Epoch [772/1000], Loss: 0.5181\n",
      "Epoch [773/1000], Loss: 0.5189\n",
      "Epoch [774/1000], Loss: 0.5184\n",
      "Epoch [775/1000], Loss: 0.5184\n",
      "Epoch [776/1000], Loss: 0.5179\n",
      "Epoch [777/1000], Loss: 0.5181\n",
      "Epoch [778/1000], Loss: 0.5203\n",
      "Epoch [779/1000], Loss: 0.5203\n",
      "Epoch [780/1000], Loss: 0.5200\n",
      "Epoch [781/1000], Loss: 0.5177\n",
      "Epoch [782/1000], Loss: 0.5193\n",
      "Epoch [783/1000], Loss: 0.5189\n",
      "Epoch [784/1000], Loss: 0.5196\n",
      "Epoch [785/1000], Loss: 0.5193\n",
      "Epoch [786/1000], Loss: 0.5172\n",
      "Epoch [787/1000], Loss: 0.5189\n",
      "Epoch [788/1000], Loss: 0.5198\n",
      "Epoch [789/1000], Loss: 0.5172\n",
      "Epoch [790/1000], Loss: 0.5177\n",
      "Epoch [791/1000], Loss: 0.5196\n",
      "Epoch [792/1000], Loss: 0.5200\n",
      "Epoch [793/1000], Loss: 0.5186\n",
      "Epoch [794/1000], Loss: 0.5203\n",
      "Epoch [795/1000], Loss: 0.5198\n",
      "Epoch [796/1000], Loss: 0.5196\n",
      "Epoch [797/1000], Loss: 0.5203\n",
      "Epoch [798/1000], Loss: 0.5170\n",
      "Epoch [799/1000], Loss: 0.5174\n",
      "Epoch [800/1000], Loss: 0.5181\n",
      "Epoch [801/1000], Loss: 0.5186\n",
      "Epoch [802/1000], Loss: 0.5217\n",
      "Epoch [803/1000], Loss: 0.5193\n",
      "Epoch [804/1000], Loss: 0.5200\n",
      "Epoch [805/1000], Loss: 0.5174\n",
      "Epoch [806/1000], Loss: 0.5162\n",
      "Epoch [807/1000], Loss: 0.5165\n",
      "Epoch [808/1000], Loss: 0.5200\n",
      "Epoch [809/1000], Loss: 0.5174\n",
      "Epoch [810/1000], Loss: 0.5186\n",
      "Epoch [811/1000], Loss: 0.5198\n",
      "Epoch [812/1000], Loss: 0.5170\n",
      "Epoch [813/1000], Loss: 0.5203\n",
      "Epoch [814/1000], Loss: 0.5210\n",
      "Epoch [815/1000], Loss: 0.5208\n",
      "Epoch [816/1000], Loss: 0.5198\n",
      "Epoch [817/1000], Loss: 0.5179\n",
      "Epoch [818/1000], Loss: 0.5191\n",
      "Epoch [819/1000], Loss: 0.5189\n",
      "Epoch [820/1000], Loss: 0.5200\n",
      "Epoch [821/1000], Loss: 0.5181\n",
      "Epoch [822/1000], Loss: 0.5208\n",
      "Epoch [823/1000], Loss: 0.5191\n",
      "Epoch [824/1000], Loss: 0.5196\n",
      "Epoch [825/1000], Loss: 0.5170\n",
      "Epoch [826/1000], Loss: 0.5184\n",
      "Epoch [827/1000], Loss: 0.5186\n",
      "Epoch [828/1000], Loss: 0.5205\n",
      "Epoch [829/1000], Loss: 0.5193\n",
      "Epoch [830/1000], Loss: 0.5170\n",
      "Epoch [831/1000], Loss: 0.5198\n",
      "Epoch [832/1000], Loss: 0.5191\n",
      "Epoch [833/1000], Loss: 0.5167\n",
      "Epoch [834/1000], Loss: 0.5212\n",
      "Epoch [835/1000], Loss: 0.5189\n",
      "Epoch [836/1000], Loss: 0.5179\n",
      "Epoch [837/1000], Loss: 0.5181\n",
      "Epoch [838/1000], Loss: 0.5174\n",
      "Epoch [839/1000], Loss: 0.5193\n",
      "Epoch [840/1000], Loss: 0.5170\n",
      "Epoch [841/1000], Loss: 0.5196\n",
      "Epoch [842/1000], Loss: 0.5179\n",
      "Epoch [843/1000], Loss: 0.5198\n",
      "Epoch [844/1000], Loss: 0.5189\n",
      "Epoch [845/1000], Loss: 0.5172\n",
      "Epoch [846/1000], Loss: 0.5189\n",
      "Epoch [847/1000], Loss: 0.5193\n",
      "Epoch [848/1000], Loss: 0.5191\n",
      "Epoch [849/1000], Loss: 0.5203\n",
      "Epoch [850/1000], Loss: 0.5184\n",
      "Epoch [851/1000], Loss: 0.5177\n",
      "Epoch [852/1000], Loss: 0.5179\n",
      "Epoch [853/1000], Loss: 0.5179\n",
      "Epoch [854/1000], Loss: 0.5165\n",
      "Epoch [855/1000], Loss: 0.5191\n",
      "Epoch [856/1000], Loss: 0.5186\n",
      "Epoch [857/1000], Loss: 0.5184\n",
      "Epoch [858/1000], Loss: 0.5184\n",
      "Epoch [859/1000], Loss: 0.5203\n",
      "Epoch [860/1000], Loss: 0.5184\n",
      "Epoch [861/1000], Loss: 0.5193\n",
      "Epoch [862/1000], Loss: 0.5186\n",
      "Epoch [863/1000], Loss: 0.5193\n",
      "Epoch [864/1000], Loss: 0.5179\n",
      "Epoch [865/1000], Loss: 0.5177\n",
      "Epoch [866/1000], Loss: 0.5189\n",
      "Epoch [867/1000], Loss: 0.5167\n",
      "Epoch [868/1000], Loss: 0.5165\n",
      "Epoch [869/1000], Loss: 0.5198\n",
      "Epoch [870/1000], Loss: 0.5165\n",
      "Epoch [871/1000], Loss: 0.5181\n",
      "Epoch [872/1000], Loss: 0.5191\n",
      "Epoch [873/1000], Loss: 0.5200\n",
      "Epoch [874/1000], Loss: 0.5167\n",
      "Epoch [875/1000], Loss: 0.5215\n",
      "Epoch [876/1000], Loss: 0.5184\n",
      "Epoch [877/1000], Loss: 0.5198\n",
      "Epoch [878/1000], Loss: 0.5170\n",
      "Epoch [879/1000], Loss: 0.5172\n",
      "Epoch [880/1000], Loss: 0.5184\n",
      "Epoch [881/1000], Loss: 0.5189\n",
      "Epoch [882/1000], Loss: 0.5170\n",
      "Epoch [883/1000], Loss: 0.5196\n",
      "Epoch [884/1000], Loss: 0.5189\n",
      "Epoch [885/1000], Loss: 0.5200\n",
      "Epoch [886/1000], Loss: 0.5191\n",
      "Epoch [887/1000], Loss: 0.5174\n",
      "Epoch [888/1000], Loss: 0.5198\n",
      "Epoch [889/1000], Loss: 0.5220\n",
      "Epoch [890/1000], Loss: 0.5179\n",
      "Epoch [891/1000], Loss: 0.5205\n",
      "Epoch [892/1000], Loss: 0.5193\n",
      "Epoch [893/1000], Loss: 0.5193\n",
      "Epoch [894/1000], Loss: 0.5172\n",
      "Epoch [895/1000], Loss: 0.5167\n",
      "Epoch [896/1000], Loss: 0.5186\n",
      "Epoch [897/1000], Loss: 0.5200\n",
      "Epoch [898/1000], Loss: 0.5172\n",
      "Epoch [899/1000], Loss: 0.5196\n",
      "Epoch [900/1000], Loss: 0.5184\n",
      "Epoch [901/1000], Loss: 0.5193\n",
      "Epoch [902/1000], Loss: 0.5186\n",
      "Epoch [903/1000], Loss: 0.5181\n",
      "Epoch [904/1000], Loss: 0.5172\n",
      "Epoch [905/1000], Loss: 0.5193\n",
      "Epoch [906/1000], Loss: 0.5181\n",
      "Epoch [907/1000], Loss: 0.5177\n",
      "Epoch [908/1000], Loss: 0.5174\n",
      "Epoch [909/1000], Loss: 0.5189\n",
      "Epoch [910/1000], Loss: 0.5193\n",
      "Epoch [911/1000], Loss: 0.5186\n",
      "Epoch [912/1000], Loss: 0.5184\n",
      "Epoch [913/1000], Loss: 0.5181\n",
      "Epoch [914/1000], Loss: 0.5181\n",
      "Epoch [915/1000], Loss: 0.5203\n",
      "Epoch [916/1000], Loss: 0.5181\n",
      "Epoch [917/1000], Loss: 0.5203\n",
      "Epoch [918/1000], Loss: 0.5184\n",
      "Epoch [919/1000], Loss: 0.5198\n",
      "Epoch [920/1000], Loss: 0.5181\n",
      "Epoch [921/1000], Loss: 0.5198\n",
      "Epoch [922/1000], Loss: 0.5179\n",
      "Epoch [923/1000], Loss: 0.5191\n",
      "Epoch [924/1000], Loss: 0.5179\n",
      "Epoch [925/1000], Loss: 0.5198\n",
      "Epoch [926/1000], Loss: 0.5174\n",
      "Epoch [927/1000], Loss: 0.5177\n",
      "Epoch [928/1000], Loss: 0.5172\n",
      "Epoch [929/1000], Loss: 0.5217\n",
      "Epoch [930/1000], Loss: 0.5191\n",
      "Epoch [931/1000], Loss: 0.5189\n",
      "Epoch [932/1000], Loss: 0.5181\n",
      "Epoch [933/1000], Loss: 0.5196\n",
      "Epoch [934/1000], Loss: 0.5196\n",
      "Epoch [935/1000], Loss: 0.5196\n",
      "Epoch [936/1000], Loss: 0.5174\n",
      "Epoch [937/1000], Loss: 0.5170\n",
      "Epoch [938/1000], Loss: 0.5172\n",
      "Epoch [939/1000], Loss: 0.5196\n",
      "Epoch [940/1000], Loss: 0.5172\n",
      "Epoch [941/1000], Loss: 0.5208\n",
      "Epoch [942/1000], Loss: 0.5177\n",
      "Epoch [943/1000], Loss: 0.5189\n",
      "Epoch [944/1000], Loss: 0.5215\n",
      "Epoch [945/1000], Loss: 0.5174\n",
      "Epoch [946/1000], Loss: 0.5172\n",
      "Epoch [947/1000], Loss: 0.5181\n",
      "Epoch [948/1000], Loss: 0.5184\n",
      "Epoch [949/1000], Loss: 0.5177\n",
      "Epoch [950/1000], Loss: 0.5217\n",
      "Epoch [951/1000], Loss: 0.5170\n",
      "Epoch [952/1000], Loss: 0.5193\n",
      "Epoch [953/1000], Loss: 0.5186\n",
      "Epoch [954/1000], Loss: 0.5191\n",
      "Epoch [955/1000], Loss: 0.5200\n",
      "Epoch [956/1000], Loss: 0.5191\n",
      "Epoch [957/1000], Loss: 0.5193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [958/1000], Loss: 0.5170\n",
      "Epoch [959/1000], Loss: 0.5165\n",
      "Epoch [960/1000], Loss: 0.5191\n",
      "Epoch [961/1000], Loss: 0.5177\n",
      "Epoch [962/1000], Loss: 0.5196\n",
      "Epoch [963/1000], Loss: 0.5191\n",
      "Epoch [964/1000], Loss: 0.5200\n",
      "Epoch [965/1000], Loss: 0.5172\n",
      "Epoch [966/1000], Loss: 0.5191\n",
      "Epoch [967/1000], Loss: 0.5189\n",
      "Epoch [968/1000], Loss: 0.5177\n",
      "Epoch [969/1000], Loss: 0.5184\n",
      "Epoch [970/1000], Loss: 0.5181\n",
      "Epoch [971/1000], Loss: 0.5181\n",
      "Epoch [972/1000], Loss: 0.5198\n",
      "Epoch [973/1000], Loss: 0.5177\n",
      "Epoch [974/1000], Loss: 0.5196\n",
      "Epoch [975/1000], Loss: 0.5189\n",
      "Epoch [976/1000], Loss: 0.5208\n",
      "Epoch [977/1000], Loss: 0.5189\n",
      "Epoch [978/1000], Loss: 0.5186\n",
      "Epoch [979/1000], Loss: 0.5179\n",
      "Epoch [980/1000], Loss: 0.5196\n",
      "Epoch [981/1000], Loss: 0.5189\n",
      "Epoch [982/1000], Loss: 0.5189\n",
      "Epoch [983/1000], Loss: 0.5174\n",
      "Epoch [984/1000], Loss: 0.5205\n",
      "Epoch [985/1000], Loss: 0.5193\n",
      "Epoch [986/1000], Loss: 0.5189\n",
      "Epoch [987/1000], Loss: 0.5184\n",
      "Epoch [988/1000], Loss: 0.5158\n",
      "Epoch [989/1000], Loss: 0.5189\n",
      "Epoch [990/1000], Loss: 0.5179\n",
      "Epoch [991/1000], Loss: 0.5162\n",
      "Epoch [992/1000], Loss: 0.5189\n",
      "Epoch [993/1000], Loss: 0.5181\n",
      "Epoch [994/1000], Loss: 0.5215\n",
      "Epoch [995/1000], Loss: 0.5177\n",
      "Epoch [996/1000], Loss: 0.5189\n",
      "Epoch [997/1000], Loss: 0.5174\n",
      "Epoch [998/1000], Loss: 0.5200\n",
      "Epoch [999/1000], Loss: 0.5181\n",
      "Epoch [1000/1000], Loss: 0.5205\n",
      "Accuracy of the network on the 1000 validation data: 50.30 %\n",
      "Training model with batch_size: 205, lr :10.0, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.4401\n",
      "Epoch [2/1000], Loss: 0.4542\n",
      "Epoch [3/1000], Loss: 0.4546\n",
      "Epoch [4/1000], Loss: 0.4544\n",
      "Epoch [5/1000], Loss: 0.4523\n",
      "Epoch [6/1000], Loss: 0.4546\n",
      "Epoch [7/1000], Loss: 0.4523\n",
      "Epoch [8/1000], Loss: 0.4508\n",
      "Epoch [9/1000], Loss: 0.4515\n",
      "Epoch [10/1000], Loss: 0.4539\n",
      "Epoch [11/1000], Loss: 0.4501\n",
      "Epoch [12/1000], Loss: 0.4532\n",
      "Epoch [13/1000], Loss: 0.4522\n",
      "Epoch [14/1000], Loss: 0.4544\n",
      "Epoch [15/1000], Loss: 0.4511\n",
      "Epoch [16/1000], Loss: 0.4527\n",
      "Epoch [17/1000], Loss: 0.4523\n",
      "Epoch [18/1000], Loss: 0.4515\n",
      "Epoch [19/1000], Loss: 0.4537\n",
      "Epoch [20/1000], Loss: 0.4527\n",
      "Epoch [21/1000], Loss: 0.4518\n",
      "Epoch [22/1000], Loss: 0.4534\n",
      "Epoch [23/1000], Loss: 0.4527\n",
      "Epoch [24/1000], Loss: 0.4527\n",
      "Epoch [25/1000], Loss: 0.4532\n",
      "Epoch [26/1000], Loss: 0.4494\n",
      "Epoch [27/1000], Loss: 0.4518\n",
      "Epoch [28/1000], Loss: 0.4527\n",
      "Epoch [29/1000], Loss: 0.4534\n",
      "Epoch [30/1000], Loss: 0.4553\n",
      "Epoch [31/1000], Loss: 0.4553\n",
      "Epoch [32/1000], Loss: 0.4537\n",
      "Epoch [33/1000], Loss: 0.4542\n",
      "Epoch [34/1000], Loss: 0.4530\n",
      "Epoch [35/1000], Loss: 0.4527\n",
      "Epoch [36/1000], Loss: 0.4537\n",
      "Epoch [37/1000], Loss: 0.4549\n",
      "Epoch [38/1000], Loss: 0.4532\n",
      "Epoch [39/1000], Loss: 0.4563\n",
      "Epoch [40/1000], Loss: 0.4530\n",
      "Epoch [41/1000], Loss: 0.4551\n",
      "Epoch [42/1000], Loss: 0.4525\n",
      "Epoch [43/1000], Loss: 0.4534\n",
      "Epoch [44/1000], Loss: 0.4508\n",
      "Epoch [45/1000], Loss: 0.4520\n",
      "Epoch [46/1000], Loss: 0.4511\n",
      "Epoch [47/1000], Loss: 0.4534\n",
      "Epoch [48/1000], Loss: 0.4527\n",
      "Epoch [49/1000], Loss: 0.4561\n",
      "Epoch [50/1000], Loss: 0.4551\n",
      "Epoch [51/1000], Loss: 0.4542\n",
      "Epoch [52/1000], Loss: 0.4542\n",
      "Epoch [53/1000], Loss: 0.4539\n",
      "Epoch [54/1000], Loss: 0.4525\n",
      "Epoch [55/1000], Loss: 0.4532\n",
      "Epoch [56/1000], Loss: 0.4549\n",
      "Epoch [57/1000], Loss: 0.4546\n",
      "Epoch [58/1000], Loss: 0.4530\n",
      "Epoch [59/1000], Loss: 0.4522\n",
      "Epoch [60/1000], Loss: 0.4549\n",
      "Epoch [61/1000], Loss: 0.4532\n",
      "Epoch [62/1000], Loss: 0.4527\n",
      "Epoch [63/1000], Loss: 0.4542\n",
      "Epoch [64/1000], Loss: 0.4532\n",
      "Epoch [65/1000], Loss: 0.4522\n",
      "Epoch [66/1000], Loss: 0.4534\n",
      "Epoch [67/1000], Loss: 0.4520\n",
      "Epoch [68/1000], Loss: 0.4556\n",
      "Epoch [69/1000], Loss: 0.4537\n",
      "Epoch [70/1000], Loss: 0.4523\n",
      "Epoch [71/1000], Loss: 0.4525\n",
      "Epoch [72/1000], Loss: 0.4523\n",
      "Epoch [73/1000], Loss: 0.4518\n",
      "Epoch [74/1000], Loss: 0.4527\n",
      "Epoch [75/1000], Loss: 0.4551\n",
      "Epoch [76/1000], Loss: 0.4539\n",
      "Epoch [77/1000], Loss: 0.4534\n",
      "Epoch [78/1000], Loss: 0.4532\n",
      "Epoch [79/1000], Loss: 0.4532\n",
      "Epoch [80/1000], Loss: 0.4542\n",
      "Epoch [81/1000], Loss: 0.4530\n",
      "Epoch [82/1000], Loss: 0.4525\n",
      "Epoch [83/1000], Loss: 0.4546\n",
      "Epoch [84/1000], Loss: 0.4537\n",
      "Epoch [85/1000], Loss: 0.4525\n",
      "Epoch [86/1000], Loss: 0.4568\n",
      "Epoch [87/1000], Loss: 0.4530\n",
      "Epoch [88/1000], Loss: 0.4530\n",
      "Epoch [89/1000], Loss: 0.4546\n",
      "Epoch [90/1000], Loss: 0.4530\n",
      "Epoch [91/1000], Loss: 0.4534\n",
      "Epoch [92/1000], Loss: 0.4513\n",
      "Epoch [93/1000], Loss: 0.4522\n",
      "Epoch [94/1000], Loss: 0.4532\n",
      "Epoch [95/1000], Loss: 0.4532\n",
      "Epoch [96/1000], Loss: 0.4549\n",
      "Epoch [97/1000], Loss: 0.4534\n",
      "Epoch [98/1000], Loss: 0.4523\n",
      "Epoch [99/1000], Loss: 0.4530\n",
      "Epoch [100/1000], Loss: 0.4534\n",
      "Epoch [101/1000], Loss: 0.4546\n",
      "Epoch [102/1000], Loss: 0.4544\n",
      "Epoch [103/1000], Loss: 0.4530\n",
      "Epoch [104/1000], Loss: 0.4546\n",
      "Epoch [105/1000], Loss: 0.4534\n",
      "Epoch [106/1000], Loss: 0.4544\n",
      "Epoch [107/1000], Loss: 0.4549\n",
      "Epoch [108/1000], Loss: 0.4539\n",
      "Epoch [109/1000], Loss: 0.4534\n",
      "Epoch [110/1000], Loss: 0.4518\n",
      "Epoch [111/1000], Loss: 0.4515\n",
      "Epoch [112/1000], Loss: 0.4544\n",
      "Epoch [113/1000], Loss: 0.4527\n",
      "Epoch [114/1000], Loss: 0.4539\n",
      "Epoch [115/1000], Loss: 0.4549\n",
      "Epoch [116/1000], Loss: 0.4530\n",
      "Epoch [117/1000], Loss: 0.4546\n",
      "Epoch [118/1000], Loss: 0.4525\n",
      "Epoch [119/1000], Loss: 0.4556\n",
      "Epoch [120/1000], Loss: 0.4544\n",
      "Epoch [121/1000], Loss: 0.4558\n",
      "Epoch [122/1000], Loss: 0.4553\n",
      "Epoch [123/1000], Loss: 0.4556\n",
      "Epoch [124/1000], Loss: 0.4546\n",
      "Epoch [125/1000], Loss: 0.4520\n",
      "Epoch [126/1000], Loss: 0.4534\n",
      "Epoch [127/1000], Loss: 0.4532\n",
      "Epoch [128/1000], Loss: 0.4537\n",
      "Epoch [129/1000], Loss: 0.4549\n",
      "Epoch [130/1000], Loss: 0.4518\n",
      "Epoch [131/1000], Loss: 0.4530\n",
      "Epoch [132/1000], Loss: 0.4553\n",
      "Epoch [133/1000], Loss: 0.4549\n",
      "Epoch [134/1000], Loss: 0.4542\n",
      "Epoch [135/1000], Loss: 0.4534\n",
      "Epoch [136/1000], Loss: 0.4530\n",
      "Epoch [137/1000], Loss: 0.4530\n",
      "Epoch [138/1000], Loss: 0.4515\n",
      "Epoch [139/1000], Loss: 0.4532\n",
      "Epoch [140/1000], Loss: 0.4527\n",
      "Epoch [141/1000], Loss: 0.4551\n",
      "Epoch [142/1000], Loss: 0.4546\n",
      "Epoch [143/1000], Loss: 0.4534\n",
      "Epoch [144/1000], Loss: 0.4537\n",
      "Epoch [145/1000], Loss: 0.4542\n",
      "Epoch [146/1000], Loss: 0.4530\n",
      "Epoch [147/1000], Loss: 0.4537\n",
      "Epoch [148/1000], Loss: 0.4539\n",
      "Epoch [149/1000], Loss: 0.4544\n",
      "Epoch [150/1000], Loss: 0.4542\n",
      "Epoch [151/1000], Loss: 0.4549\n",
      "Epoch [152/1000], Loss: 0.4534\n",
      "Epoch [153/1000], Loss: 0.4511\n",
      "Epoch [154/1000], Loss: 0.4551\n",
      "Epoch [155/1000], Loss: 0.4544\n",
      "Epoch [156/1000], Loss: 0.4520\n",
      "Epoch [157/1000], Loss: 0.4527\n",
      "Epoch [158/1000], Loss: 0.4542\n",
      "Epoch [159/1000], Loss: 0.4523\n",
      "Epoch [160/1000], Loss: 0.4556\n",
      "Epoch [161/1000], Loss: 0.4527\n",
      "Epoch [162/1000], Loss: 0.4549\n",
      "Epoch [163/1000], Loss: 0.4530\n",
      "Epoch [164/1000], Loss: 0.4534\n",
      "Epoch [165/1000], Loss: 0.4532\n",
      "Epoch [166/1000], Loss: 0.4542\n",
      "Epoch [167/1000], Loss: 0.4525\n",
      "Epoch [168/1000], Loss: 0.4527\n",
      "Epoch [169/1000], Loss: 0.4530\n",
      "Epoch [170/1000], Loss: 0.4530\n",
      "Epoch [171/1000], Loss: 0.4532\n",
      "Epoch [172/1000], Loss: 0.4506\n",
      "Epoch [173/1000], Loss: 0.4508\n",
      "Epoch [174/1000], Loss: 0.4513\n",
      "Epoch [175/1000], Loss: 0.4539\n",
      "Epoch [176/1000], Loss: 0.4530\n",
      "Epoch [177/1000], Loss: 0.4551\n",
      "Epoch [178/1000], Loss: 0.4549\n",
      "Epoch [179/1000], Loss: 0.4542\n",
      "Epoch [180/1000], Loss: 0.4515\n",
      "Epoch [181/1000], Loss: 0.4544\n",
      "Epoch [182/1000], Loss: 0.4527\n",
      "Epoch [183/1000], Loss: 0.4544\n",
      "Epoch [184/1000], Loss: 0.4556\n",
      "Epoch [185/1000], Loss: 0.4513\n",
      "Epoch [186/1000], Loss: 0.4539\n",
      "Epoch [187/1000], Loss: 0.4525\n",
      "Epoch [188/1000], Loss: 0.4534\n",
      "Epoch [189/1000], Loss: 0.4539\n",
      "Epoch [190/1000], Loss: 0.4527\n",
      "Epoch [191/1000], Loss: 0.4520\n",
      "Epoch [192/1000], Loss: 0.4518\n",
      "Epoch [193/1000], Loss: 0.4558\n",
      "Epoch [194/1000], Loss: 0.4537\n",
      "Epoch [195/1000], Loss: 0.4551\n",
      "Epoch [196/1000], Loss: 0.4534\n",
      "Epoch [197/1000], Loss: 0.4549\n",
      "Epoch [198/1000], Loss: 0.4534\n",
      "Epoch [199/1000], Loss: 0.4537\n",
      "Epoch [200/1000], Loss: 0.4525\n",
      "Epoch [201/1000], Loss: 0.4527\n",
      "Epoch [202/1000], Loss: 0.4539\n",
      "Epoch [203/1000], Loss: 0.4527\n",
      "Epoch [204/1000], Loss: 0.4532\n",
      "Epoch [205/1000], Loss: 0.4522\n",
      "Epoch [206/1000], Loss: 0.4539\n",
      "Epoch [207/1000], Loss: 0.4523\n",
      "Epoch [208/1000], Loss: 0.4508\n",
      "Epoch [209/1000], Loss: 0.4546\n",
      "Epoch [210/1000], Loss: 0.4546\n",
      "Epoch [211/1000], Loss: 0.4523\n",
      "Epoch [212/1000], Loss: 0.4518\n",
      "Epoch [213/1000], Loss: 0.4549\n",
      "Epoch [214/1000], Loss: 0.4544\n",
      "Epoch [215/1000], Loss: 0.4539\n",
      "Epoch [216/1000], Loss: 0.4530\n",
      "Epoch [217/1000], Loss: 0.4532\n",
      "Epoch [218/1000], Loss: 0.4561\n",
      "Epoch [219/1000], Loss: 0.4532\n",
      "Epoch [220/1000], Loss: 0.4544\n",
      "Epoch [221/1000], Loss: 0.4530\n",
      "Epoch [222/1000], Loss: 0.4527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [223/1000], Loss: 0.4506\n",
      "Epoch [224/1000], Loss: 0.4542\n",
      "Epoch [225/1000], Loss: 0.4530\n",
      "Epoch [226/1000], Loss: 0.4515\n",
      "Epoch [227/1000], Loss: 0.4532\n",
      "Epoch [228/1000], Loss: 0.4527\n",
      "Epoch [229/1000], Loss: 0.4508\n",
      "Epoch [230/1000], Loss: 0.4518\n",
      "Epoch [231/1000], Loss: 0.4558\n",
      "Epoch [232/1000], Loss: 0.4527\n",
      "Epoch [233/1000], Loss: 0.4549\n",
      "Epoch [234/1000], Loss: 0.4530\n",
      "Epoch [235/1000], Loss: 0.4534\n",
      "Epoch [236/1000], Loss: 0.4513\n",
      "Epoch [237/1000], Loss: 0.4530\n",
      "Epoch [238/1000], Loss: 0.4537\n",
      "Epoch [239/1000], Loss: 0.4534\n",
      "Epoch [240/1000], Loss: 0.4553\n",
      "Epoch [241/1000], Loss: 0.4530\n",
      "Epoch [242/1000], Loss: 0.4537\n",
      "Epoch [243/1000], Loss: 0.4530\n",
      "Epoch [244/1000], Loss: 0.4549\n",
      "Epoch [245/1000], Loss: 0.4556\n",
      "Epoch [246/1000], Loss: 0.4537\n",
      "Epoch [247/1000], Loss: 0.4530\n",
      "Epoch [248/1000], Loss: 0.4537\n",
      "Epoch [249/1000], Loss: 0.4515\n",
      "Epoch [250/1000], Loss: 0.4551\n",
      "Epoch [251/1000], Loss: 0.4520\n",
      "Epoch [252/1000], Loss: 0.4530\n",
      "Epoch [253/1000], Loss: 0.4532\n",
      "Epoch [254/1000], Loss: 0.4520\n",
      "Epoch [255/1000], Loss: 0.4537\n",
      "Epoch [256/1000], Loss: 0.4542\n",
      "Epoch [257/1000], Loss: 0.4544\n",
      "Epoch [258/1000], Loss: 0.4542\n",
      "Epoch [259/1000], Loss: 0.4539\n",
      "Epoch [260/1000], Loss: 0.4549\n",
      "Epoch [261/1000], Loss: 0.4544\n",
      "Epoch [262/1000], Loss: 0.4506\n",
      "Epoch [263/1000], Loss: 0.4546\n",
      "Epoch [264/1000], Loss: 0.4537\n",
      "Epoch [265/1000], Loss: 0.4537\n",
      "Epoch [266/1000], Loss: 0.4523\n",
      "Epoch [267/1000], Loss: 0.4532\n",
      "Epoch [268/1000], Loss: 0.4527\n",
      "Epoch [269/1000], Loss: 0.4544\n",
      "Epoch [270/1000], Loss: 0.4527\n",
      "Epoch [271/1000], Loss: 0.4534\n",
      "Epoch [272/1000], Loss: 0.4534\n",
      "Epoch [273/1000], Loss: 0.4532\n",
      "Epoch [274/1000], Loss: 0.4532\n",
      "Epoch [275/1000], Loss: 0.4546\n",
      "Epoch [276/1000], Loss: 0.4544\n",
      "Epoch [277/1000], Loss: 0.4546\n",
      "Epoch [278/1000], Loss: 0.4527\n",
      "Epoch [279/1000], Loss: 0.4539\n",
      "Epoch [280/1000], Loss: 0.4537\n",
      "Epoch [281/1000], Loss: 0.4523\n",
      "Epoch [282/1000], Loss: 0.4534\n",
      "Epoch [283/1000], Loss: 0.4539\n",
      "Epoch [284/1000], Loss: 0.4551\n",
      "Epoch [285/1000], Loss: 0.4563\n",
      "Epoch [286/1000], Loss: 0.4530\n",
      "Epoch [287/1000], Loss: 0.4553\n",
      "Epoch [288/1000], Loss: 0.4530\n",
      "Epoch [289/1000], Loss: 0.4556\n",
      "Epoch [290/1000], Loss: 0.4546\n",
      "Epoch [291/1000], Loss: 0.4549\n",
      "Epoch [292/1000], Loss: 0.4530\n",
      "Epoch [293/1000], Loss: 0.4518\n",
      "Epoch [294/1000], Loss: 0.4534\n",
      "Epoch [295/1000], Loss: 0.4539\n",
      "Epoch [296/1000], Loss: 0.4546\n",
      "Epoch [297/1000], Loss: 0.4518\n",
      "Epoch [298/1000], Loss: 0.4534\n",
      "Epoch [299/1000], Loss: 0.4522\n",
      "Epoch [300/1000], Loss: 0.4546\n",
      "Epoch [301/1000], Loss: 0.4539\n",
      "Epoch [302/1000], Loss: 0.4523\n",
      "Epoch [303/1000], Loss: 0.4525\n",
      "Epoch [304/1000], Loss: 0.4542\n",
      "Epoch [305/1000], Loss: 0.4522\n",
      "Epoch [306/1000], Loss: 0.4523\n",
      "Epoch [307/1000], Loss: 0.4565\n",
      "Epoch [308/1000], Loss: 0.4534\n",
      "Epoch [309/1000], Loss: 0.4534\n",
      "Epoch [310/1000], Loss: 0.4523\n",
      "Epoch [311/1000], Loss: 0.4534\n",
      "Epoch [312/1000], Loss: 0.4542\n",
      "Epoch [313/1000], Loss: 0.4542\n",
      "Epoch [314/1000], Loss: 0.4542\n",
      "Epoch [315/1000], Loss: 0.4525\n",
      "Epoch [316/1000], Loss: 0.4530\n",
      "Epoch [317/1000], Loss: 0.4539\n",
      "Epoch [318/1000], Loss: 0.4527\n",
      "Epoch [319/1000], Loss: 0.4525\n",
      "Epoch [320/1000], Loss: 0.4561\n",
      "Epoch [321/1000], Loss: 0.4544\n",
      "Epoch [322/1000], Loss: 0.4551\n",
      "Epoch [323/1000], Loss: 0.4525\n",
      "Epoch [324/1000], Loss: 0.4556\n",
      "Epoch [325/1000], Loss: 0.4523\n",
      "Epoch [326/1000], Loss: 0.4525\n",
      "Epoch [327/1000], Loss: 0.4546\n",
      "Epoch [328/1000], Loss: 0.4546\n",
      "Epoch [329/1000], Loss: 0.4532\n",
      "Epoch [330/1000], Loss: 0.4537\n",
      "Epoch [331/1000], Loss: 0.4527\n",
      "Epoch [332/1000], Loss: 0.4523\n",
      "Epoch [333/1000], Loss: 0.4542\n",
      "Epoch [334/1000], Loss: 0.4539\n",
      "Epoch [335/1000], Loss: 0.4532\n",
      "Epoch [336/1000], Loss: 0.4561\n",
      "Epoch [337/1000], Loss: 0.4537\n",
      "Epoch [338/1000], Loss: 0.4532\n",
      "Epoch [339/1000], Loss: 0.4537\n",
      "Epoch [340/1000], Loss: 0.4549\n",
      "Epoch [341/1000], Loss: 0.4530\n",
      "Epoch [342/1000], Loss: 0.4537\n",
      "Epoch [343/1000], Loss: 0.4551\n",
      "Epoch [344/1000], Loss: 0.4539\n",
      "Epoch [345/1000], Loss: 0.4520\n",
      "Epoch [346/1000], Loss: 0.4530\n",
      "Epoch [347/1000], Loss: 0.4527\n",
      "Epoch [348/1000], Loss: 0.4532\n",
      "Epoch [349/1000], Loss: 0.4534\n",
      "Epoch [350/1000], Loss: 0.4534\n",
      "Epoch [351/1000], Loss: 0.4537\n",
      "Epoch [352/1000], Loss: 0.4530\n",
      "Epoch [353/1000], Loss: 0.4527\n",
      "Epoch [354/1000], Loss: 0.4520\n",
      "Epoch [355/1000], Loss: 0.4530\n",
      "Epoch [356/1000], Loss: 0.4539\n",
      "Epoch [357/1000], Loss: 0.4539\n",
      "Epoch [358/1000], Loss: 0.4546\n",
      "Epoch [359/1000], Loss: 0.4546\n",
      "Epoch [360/1000], Loss: 0.4515\n",
      "Epoch [361/1000], Loss: 0.4532\n",
      "Epoch [362/1000], Loss: 0.4501\n",
      "Epoch [363/1000], Loss: 0.4525\n",
      "Epoch [364/1000], Loss: 0.4556\n",
      "Epoch [365/1000], Loss: 0.4513\n",
      "Epoch [366/1000], Loss: 0.4523\n",
      "Epoch [367/1000], Loss: 0.4568\n",
      "Epoch [368/1000], Loss: 0.4532\n",
      "Epoch [369/1000], Loss: 0.4532\n",
      "Epoch [370/1000], Loss: 0.4525\n",
      "Epoch [371/1000], Loss: 0.4520\n",
      "Epoch [372/1000], Loss: 0.4520\n",
      "Epoch [373/1000], Loss: 0.4515\n",
      "Epoch [374/1000], Loss: 0.4530\n",
      "Epoch [375/1000], Loss: 0.4518\n",
      "Epoch [376/1000], Loss: 0.4549\n",
      "Epoch [377/1000], Loss: 0.4525\n",
      "Epoch [378/1000], Loss: 0.4518\n",
      "Epoch [379/1000], Loss: 0.4537\n",
      "Epoch [380/1000], Loss: 0.4527\n",
      "Epoch [381/1000], Loss: 0.4527\n",
      "Epoch [382/1000], Loss: 0.4525\n",
      "Epoch [383/1000], Loss: 0.4542\n",
      "Epoch [384/1000], Loss: 0.4537\n",
      "Epoch [385/1000], Loss: 0.4525\n",
      "Epoch [386/1000], Loss: 0.4542\n",
      "Epoch [387/1000], Loss: 0.4542\n",
      "Epoch [388/1000], Loss: 0.4534\n",
      "Epoch [389/1000], Loss: 0.4542\n",
      "Epoch [390/1000], Loss: 0.4553\n",
      "Epoch [391/1000], Loss: 0.4537\n",
      "Epoch [392/1000], Loss: 0.4542\n",
      "Epoch [393/1000], Loss: 0.4534\n",
      "Epoch [394/1000], Loss: 0.4544\n",
      "Epoch [395/1000], Loss: 0.4553\n",
      "Epoch [396/1000], Loss: 0.4539\n",
      "Epoch [397/1000], Loss: 0.4532\n",
      "Epoch [398/1000], Loss: 0.4527\n",
      "Epoch [399/1000], Loss: 0.4522\n",
      "Epoch [400/1000], Loss: 0.4553\n",
      "Epoch [401/1000], Loss: 0.4530\n",
      "Epoch [402/1000], Loss: 0.4539\n",
      "Epoch [403/1000], Loss: 0.4532\n",
      "Epoch [404/1000], Loss: 0.4530\n",
      "Epoch [405/1000], Loss: 0.4537\n",
      "Epoch [406/1000], Loss: 0.4532\n",
      "Epoch [407/1000], Loss: 0.4544\n",
      "Epoch [408/1000], Loss: 0.4549\n",
      "Epoch [409/1000], Loss: 0.4532\n",
      "Epoch [410/1000], Loss: 0.4532\n",
      "Epoch [411/1000], Loss: 0.4556\n",
      "Epoch [412/1000], Loss: 0.4506\n",
      "Epoch [413/1000], Loss: 0.4553\n",
      "Epoch [414/1000], Loss: 0.4539\n",
      "Epoch [415/1000], Loss: 0.4518\n",
      "Epoch [416/1000], Loss: 0.4544\n",
      "Epoch [417/1000], Loss: 0.4549\n",
      "Epoch [418/1000], Loss: 0.4525\n",
      "Epoch [419/1000], Loss: 0.4523\n",
      "Epoch [420/1000], Loss: 0.4525\n",
      "Epoch [421/1000], Loss: 0.4527\n",
      "Epoch [422/1000], Loss: 0.4537\n",
      "Epoch [423/1000], Loss: 0.4539\n",
      "Epoch [424/1000], Loss: 0.4522\n",
      "Epoch [425/1000], Loss: 0.4546\n",
      "Epoch [426/1000], Loss: 0.4546\n",
      "Epoch [427/1000], Loss: 0.4530\n",
      "Epoch [428/1000], Loss: 0.4525\n",
      "Epoch [429/1000], Loss: 0.4525\n",
      "Epoch [430/1000], Loss: 0.4539\n",
      "Epoch [431/1000], Loss: 0.4539\n",
      "Epoch [432/1000], Loss: 0.4539\n",
      "Epoch [433/1000], Loss: 0.4539\n",
      "Epoch [434/1000], Loss: 0.4534\n",
      "Epoch [435/1000], Loss: 0.4537\n",
      "Epoch [436/1000], Loss: 0.4537\n",
      "Epoch [437/1000], Loss: 0.4539\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 57.50 %\n",
      "Training model with batch_size: 205, lr :10.0, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2752\n",
      "Epoch [2/1000], Loss: 0.2556\n",
      "Epoch [3/1000], Loss: 0.2536\n",
      "Epoch [4/1000], Loss: 0.2579\n",
      "Epoch [5/1000], Loss: 0.2596\n",
      "Epoch [6/1000], Loss: 0.2601\n",
      "Epoch [7/1000], Loss: 0.2546\n",
      "Epoch [8/1000], Loss: 0.2543\n",
      "Epoch [9/1000], Loss: 0.2513\n",
      "Epoch [10/1000], Loss: 0.2494\n",
      "Epoch [11/1000], Loss: 0.2491\n",
      "Epoch [12/1000], Loss: 0.2346\n",
      "Epoch [13/1000], Loss: 0.2332\n",
      "Epoch [14/1000], Loss: 0.2365\n",
      "Epoch [15/1000], Loss: 0.2229\n",
      "Epoch [16/1000], Loss: 0.2241\n",
      "Epoch [17/1000], Loss: 0.2263\n",
      "Epoch [18/1000], Loss: 0.2207\n",
      "Epoch [19/1000], Loss: 0.2200\n",
      "Epoch [20/1000], Loss: 0.2582\n",
      "Epoch [21/1000], Loss: 0.2672\n",
      "Epoch [22/1000], Loss: 0.2382\n",
      "Epoch [23/1000], Loss: 0.2435\n",
      "Epoch [24/1000], Loss: 0.2307\n",
      "Epoch [25/1000], Loss: 0.2258\n",
      "Epoch [26/1000], Loss: 0.2249\n",
      "Epoch [27/1000], Loss: 0.2208\n",
      "Epoch [28/1000], Loss: 0.2192\n",
      "Epoch [29/1000], Loss: 0.2219\n",
      "Epoch [30/1000], Loss: 0.2172\n",
      "Epoch [31/1000], Loss: 0.2187\n",
      "Epoch [32/1000], Loss: 0.2151\n",
      "Epoch [33/1000], Loss: 0.2134\n",
      "Epoch [34/1000], Loss: 0.2270\n",
      "Epoch [35/1000], Loss: 0.2147\n",
      "Epoch [36/1000], Loss: 0.2132\n",
      "Epoch [37/1000], Loss: 0.2104\n",
      "Epoch [38/1000], Loss: 0.2053\n",
      "Epoch [39/1000], Loss: 0.2175\n",
      "Epoch [40/1000], Loss: 0.2273\n",
      "Epoch [41/1000], Loss: 0.2327\n",
      "Epoch [42/1000], Loss: 0.2265\n",
      "Epoch [43/1000], Loss: 0.2136\n",
      "Epoch [44/1000], Loss: 0.2132\n",
      "Epoch [45/1000], Loss: 0.2020\n",
      "Epoch [46/1000], Loss: 0.2079\n",
      "Epoch [47/1000], Loss: 0.1930\n",
      "Epoch [48/1000], Loss: 0.2327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/1000], Loss: 0.2379\n",
      "Epoch [50/1000], Loss: 0.2288\n",
      "Epoch [51/1000], Loss: 0.2224\n",
      "Epoch [52/1000], Loss: 0.2294\n",
      "Epoch [53/1000], Loss: 0.2177\n",
      "Epoch [54/1000], Loss: 0.2146\n",
      "Epoch [55/1000], Loss: 0.2065\n",
      "Epoch [56/1000], Loss: 0.2063\n",
      "Epoch [57/1000], Loss: 0.2114\n",
      "Epoch [58/1000], Loss: 0.2061\n",
      "Epoch [59/1000], Loss: 0.2015\n",
      "Epoch [60/1000], Loss: 0.2122\n",
      "Epoch [61/1000], Loss: 0.2165\n",
      "Epoch [62/1000], Loss: 0.1982\n",
      "Epoch [63/1000], Loss: 0.1919\n",
      "Epoch [64/1000], Loss: 0.1824\n",
      "Epoch [65/1000], Loss: 0.2092\n",
      "Epoch [66/1000], Loss: 0.2398\n",
      "Epoch [67/1000], Loss: 0.2295\n",
      "Epoch [68/1000], Loss: 0.2347\n",
      "Epoch [69/1000], Loss: 0.2156\n",
      "Epoch [70/1000], Loss: 0.2150\n",
      "Epoch [71/1000], Loss: 0.2128\n",
      "Epoch [72/1000], Loss: 0.2205\n",
      "Epoch [73/1000], Loss: 0.2116\n",
      "Epoch [74/1000], Loss: 0.2181\n",
      "Epoch [75/1000], Loss: 0.2106\n",
      "Epoch [76/1000], Loss: 0.2111\n",
      "Epoch [77/1000], Loss: 0.2153\n",
      "Epoch [78/1000], Loss: 0.2179\n",
      "Epoch [79/1000], Loss: 0.2115\n",
      "Epoch [80/1000], Loss: 0.2138\n",
      "Epoch [81/1000], Loss: 0.2127\n",
      "Epoch [82/1000], Loss: 0.2149\n",
      "Epoch [83/1000], Loss: 0.2132\n",
      "Epoch [84/1000], Loss: 0.2116\n",
      "Epoch [85/1000], Loss: 0.2151\n",
      "Epoch [86/1000], Loss: 0.2122\n",
      "Epoch [87/1000], Loss: 0.2243\n",
      "Epoch [88/1000], Loss: 0.2158\n",
      "Epoch [89/1000], Loss: 0.2063\n",
      "Epoch [90/1000], Loss: 0.2261\n",
      "Epoch [91/1000], Loss: 0.2056\n",
      "Epoch [92/1000], Loss: 0.1996\n",
      "Epoch [93/1000], Loss: 0.2432\n",
      "Epoch [94/1000], Loss: 0.2287\n",
      "Epoch [95/1000], Loss: 0.2060\n",
      "Epoch [96/1000], Loss: 0.2116\n",
      "Epoch [97/1000], Loss: 0.2152\n",
      "Epoch [98/1000], Loss: 0.2055\n",
      "Epoch [99/1000], Loss: 0.1999\n",
      "Epoch [100/1000], Loss: 0.2130\n",
      "Epoch [101/1000], Loss: 0.2144\n",
      "Epoch [102/1000], Loss: 0.2044\n",
      "Epoch [103/1000], Loss: 0.2079\n",
      "Epoch [104/1000], Loss: 0.2035\n",
      "Epoch [105/1000], Loss: 0.1989\n",
      "Epoch [106/1000], Loss: 0.2020\n",
      "Epoch [107/1000], Loss: 0.2033\n",
      "Epoch [108/1000], Loss: 0.1980\n",
      "Epoch [109/1000], Loss: 0.1998\n",
      "Epoch [110/1000], Loss: 0.2030\n",
      "Epoch [111/1000], Loss: 0.2405\n",
      "Epoch [112/1000], Loss: 0.2273\n",
      "Epoch [113/1000], Loss: 0.2082\n",
      "Epoch [114/1000], Loss: 0.1992\n",
      "Epoch [115/1000], Loss: 0.1972\n",
      "Epoch [116/1000], Loss: 0.1971\n",
      "Epoch [117/1000], Loss: 0.1957\n",
      "Epoch [118/1000], Loss: 0.2015\n",
      "Epoch [119/1000], Loss: 0.1996\n",
      "Epoch [120/1000], Loss: 0.2000\n",
      "Epoch [121/1000], Loss: 0.1961\n",
      "Epoch [122/1000], Loss: 0.1967\n",
      "Epoch [123/1000], Loss: 0.1938\n",
      "Epoch [124/1000], Loss: 0.1926\n",
      "Epoch [125/1000], Loss: 0.2031\n",
      "Epoch [126/1000], Loss: 0.2014\n",
      "Epoch [127/1000], Loss: 0.1763\n",
      "Epoch [128/1000], Loss: 0.1790\n",
      "Epoch [129/1000], Loss: 0.2013\n",
      "Epoch [130/1000], Loss: 0.1876\n",
      "Epoch [131/1000], Loss: 0.1938\n",
      "Epoch [132/1000], Loss: 0.2132\n",
      "Epoch [133/1000], Loss: 0.2150\n",
      "Epoch [134/1000], Loss: 0.2075\n",
      "Epoch [135/1000], Loss: 0.2010\n",
      "Epoch [136/1000], Loss: 0.1809\n",
      "Epoch [137/1000], Loss: 0.2019\n",
      "Epoch [138/1000], Loss: 0.2295\n",
      "Epoch [139/1000], Loss: 0.2450\n",
      "Epoch [140/1000], Loss: 0.2256\n",
      "Epoch [141/1000], Loss: 0.2231\n",
      "Epoch [142/1000], Loss: 0.2155\n",
      "Epoch [143/1000], Loss: 0.1808\n",
      "Epoch [144/1000], Loss: 0.1751\n",
      "Epoch [145/1000], Loss: 0.1722\n",
      "Epoch [146/1000], Loss: 0.1789\n",
      "Epoch [147/1000], Loss: 0.1780\n",
      "Epoch [148/1000], Loss: 0.1686\n",
      "Epoch [149/1000], Loss: 0.1882\n",
      "Epoch [150/1000], Loss: 0.1737\n",
      "Epoch [151/1000], Loss: 0.1847\n",
      "Epoch [152/1000], Loss: 0.1894\n",
      "Epoch [153/1000], Loss: 0.1739\n",
      "Epoch [154/1000], Loss: 0.1669\n",
      "Epoch [155/1000], Loss: 0.2086\n",
      "Epoch [156/1000], Loss: 0.2495\n",
      "Epoch [157/1000], Loss: 0.2462\n",
      "Epoch [158/1000], Loss: 0.2374\n",
      "Epoch [159/1000], Loss: 0.2487\n",
      "Epoch [160/1000], Loss: 0.2237\n",
      "Epoch [161/1000], Loss: 0.2323\n",
      "Epoch [162/1000], Loss: 0.2230\n",
      "Epoch [163/1000], Loss: 0.2093\n",
      "Epoch [164/1000], Loss: 0.1956\n",
      "Epoch [165/1000], Loss: 0.1895\n",
      "Epoch [166/1000], Loss: 0.1998\n",
      "Epoch [167/1000], Loss: 0.1934\n",
      "Epoch [168/1000], Loss: 0.1929\n",
      "Epoch [169/1000], Loss: 0.1961\n",
      "Epoch [170/1000], Loss: 0.1919\n",
      "Epoch [171/1000], Loss: 0.1891\n",
      "Epoch [172/1000], Loss: 0.1909\n",
      "Epoch [173/1000], Loss: 0.1879\n",
      "Epoch [174/1000], Loss: 0.1884\n",
      "Epoch [175/1000], Loss: 0.2078\n",
      "Epoch [176/1000], Loss: 0.1905\n",
      "Epoch [177/1000], Loss: 0.1883\n",
      "Epoch [178/1000], Loss: 0.1884\n",
      "Epoch [179/1000], Loss: 0.1944\n",
      "Epoch [180/1000], Loss: 0.1899\n",
      "Epoch [181/1000], Loss: 0.1903\n",
      "Epoch [182/1000], Loss: 0.1895\n",
      "Epoch [183/1000], Loss: 0.1887\n",
      "Epoch [184/1000], Loss: 0.1866\n",
      "Epoch [185/1000], Loss: 0.1872\n",
      "Epoch [186/1000], Loss: 0.1836\n",
      "Epoch [187/1000], Loss: 0.1873\n",
      "Epoch [188/1000], Loss: 0.1847\n",
      "Epoch [189/1000], Loss: 0.1851\n",
      "Epoch [190/1000], Loss: 0.1852\n",
      "Epoch [191/1000], Loss: 0.1840\n",
      "Epoch [192/1000], Loss: 0.1840\n",
      "Epoch [193/1000], Loss: 0.1964\n",
      "Epoch [194/1000], Loss: 0.1839\n",
      "Epoch [195/1000], Loss: 0.1833\n",
      "Epoch [196/1000], Loss: 0.1843\n",
      "Epoch [197/1000], Loss: 0.1793\n",
      "Epoch [198/1000], Loss: 0.1848\n",
      "Epoch [199/1000], Loss: 0.1829\n",
      "Epoch [200/1000], Loss: 0.1753\n",
      "Epoch [201/1000], Loss: 0.1709\n",
      "Epoch [202/1000], Loss: 0.1761\n",
      "Epoch [203/1000], Loss: 0.1728\n",
      "Epoch [204/1000], Loss: 0.1835\n",
      "Epoch [205/1000], Loss: 0.1697\n",
      "Epoch [206/1000], Loss: 0.1686\n",
      "Epoch [207/1000], Loss: 0.1792\n",
      "Epoch [208/1000], Loss: 0.1699\n",
      "Epoch [209/1000], Loss: 0.1715\n",
      "Epoch [210/1000], Loss: 0.1764\n",
      "Epoch [211/1000], Loss: 0.1902\n",
      "Epoch [212/1000], Loss: 0.1743\n",
      "Epoch [213/1000], Loss: 0.1709\n",
      "Epoch [214/1000], Loss: 0.1737\n",
      "Epoch [215/1000], Loss: 0.1600\n",
      "Epoch [216/1000], Loss: 0.1839\n",
      "Epoch [217/1000], Loss: 0.1699\n",
      "Epoch [218/1000], Loss: 0.2192\n",
      "Epoch [219/1000], Loss: 0.2101\n",
      "Epoch [220/1000], Loss: 0.2034\n",
      "Epoch [221/1000], Loss: 0.1746\n",
      "Epoch [222/1000], Loss: 0.1592\n",
      "Epoch [223/1000], Loss: 0.1737\n",
      "Epoch [224/1000], Loss: 0.1644\n",
      "Epoch [225/1000], Loss: 0.1583\n",
      "Epoch [226/1000], Loss: 0.1671\n",
      "Epoch [227/1000], Loss: 0.1621\n",
      "Epoch [228/1000], Loss: 0.1545\n",
      "Epoch [229/1000], Loss: 0.1591\n",
      "Epoch [230/1000], Loss: 0.2169\n",
      "Epoch [231/1000], Loss: 0.1816\n",
      "Epoch [232/1000], Loss: 0.2103\n",
      "Epoch [233/1000], Loss: 0.2327\n",
      "Epoch [234/1000], Loss: 0.2101\n",
      "Epoch [235/1000], Loss: 0.1743\n",
      "Epoch [236/1000], Loss: 0.1576\n",
      "Epoch [237/1000], Loss: 0.1531\n",
      "Epoch [238/1000], Loss: 0.1556\n",
      "Epoch [239/1000], Loss: 0.1596\n",
      "Epoch [240/1000], Loss: 0.1601\n",
      "Epoch [241/1000], Loss: 0.1725\n",
      "Epoch [242/1000], Loss: 0.1629\n",
      "Epoch [243/1000], Loss: 0.1680\n",
      "Epoch [244/1000], Loss: 0.1638\n",
      "Epoch [245/1000], Loss: 0.1549\n",
      "Epoch [246/1000], Loss: 0.1602\n",
      "Epoch [247/1000], Loss: 0.1607\n",
      "Epoch [248/1000], Loss: 0.2098\n",
      "Epoch [249/1000], Loss: 0.2366\n",
      "Epoch [250/1000], Loss: 0.2526\n",
      "Epoch [251/1000], Loss: 0.2505\n",
      "Epoch [252/1000], Loss: 0.2196\n",
      "Epoch [253/1000], Loss: 0.1748\n",
      "Epoch [254/1000], Loss: 0.1653\n",
      "Epoch [255/1000], Loss: 0.1666\n",
      "Epoch [256/1000], Loss: 0.1597\n",
      "Epoch [257/1000], Loss: 0.1629\n",
      "Epoch [258/1000], Loss: 0.1564\n",
      "Epoch [259/1000], Loss: 0.1699\n",
      "Epoch [260/1000], Loss: 0.1524\n",
      "Epoch [261/1000], Loss: 0.1569\n",
      "Epoch [262/1000], Loss: 0.1584\n",
      "Epoch [263/1000], Loss: 0.1561\n",
      "Epoch [264/1000], Loss: 0.1528\n",
      "Epoch [265/1000], Loss: 0.1547\n",
      "Epoch [266/1000], Loss: 0.1550\n",
      "Epoch [267/1000], Loss: 0.1519\n",
      "Epoch [268/1000], Loss: 0.1598\n",
      "Epoch [269/1000], Loss: 0.1650\n",
      "Epoch [270/1000], Loss: 0.1570\n",
      "Epoch [271/1000], Loss: 0.1524\n",
      "Epoch [272/1000], Loss: 0.1770\n",
      "Epoch [273/1000], Loss: 0.1752\n",
      "Epoch [274/1000], Loss: 0.1628\n",
      "Epoch [275/1000], Loss: 0.1646\n",
      "Epoch [276/1000], Loss: 0.1571\n",
      "Epoch [277/1000], Loss: 0.1517\n",
      "Epoch [278/1000], Loss: 0.1578\n",
      "Epoch [279/1000], Loss: 0.1536\n",
      "Epoch [280/1000], Loss: 0.1529\n",
      "Epoch [281/1000], Loss: 0.1516\n",
      "Epoch [282/1000], Loss: 0.1531\n",
      "Epoch [283/1000], Loss: 0.1787\n",
      "Epoch [284/1000], Loss: 0.1614\n",
      "Epoch [285/1000], Loss: 0.1620\n",
      "Epoch [286/1000], Loss: 0.1550\n",
      "Epoch [287/1000], Loss: 0.1555\n",
      "Epoch [288/1000], Loss: 0.1528\n",
      "Epoch [289/1000], Loss: 0.1718\n",
      "Epoch [290/1000], Loss: 0.1540\n",
      "Epoch [291/1000], Loss: 0.1557\n",
      "Epoch [292/1000], Loss: 0.1602\n",
      "Epoch [293/1000], Loss: 0.1679\n",
      "Epoch [294/1000], Loss: 0.1636\n",
      "Epoch [295/1000], Loss: 0.1556\n",
      "Epoch [296/1000], Loss: 0.1524\n",
      "Epoch [297/1000], Loss: 0.1637\n",
      "Epoch [298/1000], Loss: 0.1566\n",
      "Epoch [299/1000], Loss: 0.1498\n",
      "Epoch [300/1000], Loss: 0.1510\n",
      "Epoch [301/1000], Loss: 0.1552\n",
      "Epoch [302/1000], Loss: 0.1544\n",
      "Epoch [303/1000], Loss: 0.1600\n",
      "Epoch [304/1000], Loss: 0.1602\n",
      "Epoch [305/1000], Loss: 0.1695\n",
      "Epoch [306/1000], Loss: 0.1719\n",
      "Epoch [307/1000], Loss: 0.1735\n",
      "Epoch [308/1000], Loss: 0.1546\n",
      "Epoch [309/1000], Loss: 0.1539\n",
      "Epoch [310/1000], Loss: 0.1506\n",
      "Epoch [311/1000], Loss: 0.1594\n",
      "Epoch [312/1000], Loss: 0.1669\n",
      "Epoch [313/1000], Loss: 0.1787\n",
      "Epoch [314/1000], Loss: 0.1657\n",
      "Epoch [315/1000], Loss: 0.1511\n",
      "Epoch [316/1000], Loss: 0.1629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [317/1000], Loss: 0.1543\n",
      "Epoch [318/1000], Loss: 0.1551\n",
      "Epoch [319/1000], Loss: 0.1571\n",
      "Epoch [320/1000], Loss: 0.1522\n",
      "Epoch [321/1000], Loss: 0.1500\n",
      "Epoch [322/1000], Loss: 0.1542\n",
      "Epoch [323/1000], Loss: 0.1622\n",
      "Epoch [324/1000], Loss: 0.1567\n",
      "Epoch [325/1000], Loss: 0.1620\n",
      "Epoch [326/1000], Loss: 0.1556\n",
      "Epoch [327/1000], Loss: 0.1533\n",
      "Epoch [328/1000], Loss: 0.1552\n",
      "Epoch [329/1000], Loss: 0.1527\n",
      "Epoch [330/1000], Loss: 0.1543\n",
      "Epoch [331/1000], Loss: 0.1572\n",
      "Epoch [332/1000], Loss: 0.1518\n",
      "Epoch [333/1000], Loss: 0.1614\n",
      "Epoch [334/1000], Loss: 0.1649\n",
      "Epoch [335/1000], Loss: 0.1613\n",
      "Epoch [336/1000], Loss: 0.1510\n",
      "Epoch [337/1000], Loss: 0.1604\n",
      "Epoch [338/1000], Loss: 0.1624\n",
      "Epoch [339/1000], Loss: 0.1557\n",
      "Epoch [340/1000], Loss: 0.1539\n",
      "Epoch [341/1000], Loss: 0.1557\n",
      "Epoch [342/1000], Loss: 0.1522\n",
      "Epoch [343/1000], Loss: 0.1545\n",
      "Epoch [344/1000], Loss: 0.1491\n",
      "Epoch [345/1000], Loss: 0.1577\n",
      "Epoch [346/1000], Loss: 0.1477\n",
      "Epoch [347/1000], Loss: 0.1582\n",
      "Epoch [348/1000], Loss: 0.1563\n",
      "Epoch [349/1000], Loss: 0.1621\n",
      "Epoch [350/1000], Loss: 0.1507\n",
      "Epoch [351/1000], Loss: 0.1700\n",
      "Epoch [352/1000], Loss: 0.1581\n",
      "Epoch [353/1000], Loss: 0.1579\n",
      "Epoch [354/1000], Loss: 0.1782\n",
      "Epoch [355/1000], Loss: 0.1579\n",
      "Epoch [356/1000], Loss: 0.2012\n",
      "Epoch [357/1000], Loss: 0.1873\n",
      "Epoch [358/1000], Loss: 0.1925\n",
      "Epoch [359/1000], Loss: 0.2041\n",
      "Epoch [360/1000], Loss: 0.1909\n",
      "Epoch [361/1000], Loss: 0.1962\n",
      "Epoch [362/1000], Loss: 0.1956\n",
      "Epoch [363/1000], Loss: 0.2020\n",
      "Epoch [364/1000], Loss: 0.1978\n",
      "Epoch [365/1000], Loss: 0.1958\n",
      "Epoch [366/1000], Loss: 0.1863\n",
      "Epoch [367/1000], Loss: 0.1897\n",
      "Epoch [368/1000], Loss: 0.1841\n",
      "Epoch [369/1000], Loss: 0.1896\n",
      "Epoch [370/1000], Loss: 0.1866\n",
      "Epoch [371/1000], Loss: 0.1875\n",
      "Epoch [372/1000], Loss: 0.1899\n",
      "Epoch [373/1000], Loss: 0.1955\n",
      "Epoch [374/1000], Loss: 0.1891\n",
      "Epoch [375/1000], Loss: 0.1921\n",
      "Epoch [376/1000], Loss: 0.1874\n",
      "Epoch [377/1000], Loss: 0.1832\n",
      "Epoch [378/1000], Loss: 0.2039\n",
      "Epoch [379/1000], Loss: 0.2143\n",
      "Epoch [380/1000], Loss: 0.2058\n",
      "Epoch [381/1000], Loss: 0.1981\n",
      "Epoch [382/1000], Loss: 0.1979\n",
      "Epoch [383/1000], Loss: 0.1961\n",
      "Epoch [384/1000], Loss: 0.1941\n",
      "Epoch [385/1000], Loss: 0.1885\n",
      "Epoch [386/1000], Loss: 0.1931\n",
      "Epoch [387/1000], Loss: 0.1896\n",
      "Epoch [388/1000], Loss: 0.1900\n",
      "Epoch [389/1000], Loss: 0.1860\n",
      "Epoch [390/1000], Loss: 0.1924\n",
      "Epoch [391/1000], Loss: 0.1897\n",
      "Epoch [392/1000], Loss: 0.1956\n",
      "Epoch [393/1000], Loss: 0.1933\n",
      "Epoch [394/1000], Loss: 0.1847\n",
      "Epoch [395/1000], Loss: 0.1857\n",
      "Epoch [396/1000], Loss: 0.1861\n",
      "Epoch [397/1000], Loss: 0.1829\n",
      "Epoch [398/1000], Loss: 0.1888\n",
      "Epoch [399/1000], Loss: 0.1899\n",
      "Epoch [400/1000], Loss: 0.1856\n",
      "Epoch [401/1000], Loss: 0.1861\n",
      "Epoch [402/1000], Loss: 0.1808\n",
      "Epoch [403/1000], Loss: 0.1793\n",
      "Epoch [404/1000], Loss: 0.1784\n",
      "Epoch [405/1000], Loss: 0.1836\n",
      "Epoch [406/1000], Loss: 0.1762\n",
      "Epoch [407/1000], Loss: 0.1778\n",
      "Epoch [408/1000], Loss: 0.1814\n",
      "Epoch [409/1000], Loss: 0.1836\n",
      "Epoch [410/1000], Loss: 0.1927\n",
      "Epoch [411/1000], Loss: 0.1950\n",
      "Epoch [412/1000], Loss: 0.1886\n",
      "Epoch [413/1000], Loss: 0.1879\n",
      "Epoch [414/1000], Loss: 0.1854\n",
      "Epoch [415/1000], Loss: 0.1878\n",
      "Epoch [416/1000], Loss: 0.1857\n",
      "Epoch [417/1000], Loss: 0.1847\n",
      "Epoch [418/1000], Loss: 0.1863\n",
      "Epoch [419/1000], Loss: 0.1857\n",
      "Epoch [420/1000], Loss: 0.1936\n",
      "Epoch [421/1000], Loss: 0.1886\n",
      "Epoch [422/1000], Loss: 0.1940\n",
      "Epoch [423/1000], Loss: 0.1948\n",
      "Epoch [424/1000], Loss: 0.1871\n",
      "Epoch [425/1000], Loss: 0.1817\n",
      "Epoch [426/1000], Loss: 0.1835\n",
      "Epoch [427/1000], Loss: 0.1845\n",
      "Epoch [428/1000], Loss: 0.1851\n",
      "Epoch [429/1000], Loss: 0.1891\n",
      "Epoch [430/1000], Loss: 0.1911\n",
      "Epoch [431/1000], Loss: 0.1920\n",
      "Epoch [432/1000], Loss: 0.1842\n",
      "Epoch [433/1000], Loss: 0.1844\n",
      "Epoch [434/1000], Loss: 0.1945\n",
      "Epoch [435/1000], Loss: 0.1805\n",
      "Epoch [436/1000], Loss: 0.1831\n",
      "Epoch [437/1000], Loss: 0.1800\n",
      "Epoch [438/1000], Loss: 0.1813\n",
      "Epoch [439/1000], Loss: 0.1827\n",
      "Epoch [440/1000], Loss: 0.1795\n",
      "Epoch [441/1000], Loss: 0.1791\n",
      "Epoch [442/1000], Loss: 0.1796\n",
      "Epoch [443/1000], Loss: 0.1805\n",
      "Epoch [444/1000], Loss: 0.1802\n",
      "Epoch [445/1000], Loss: 0.1924\n",
      "Epoch [446/1000], Loss: 0.1823\n",
      "Epoch [447/1000], Loss: 0.1878\n",
      "Epoch [448/1000], Loss: 0.1835\n",
      "Epoch [449/1000], Loss: 0.1831\n",
      "Epoch [450/1000], Loss: 0.1853\n",
      "Epoch [451/1000], Loss: 0.1857\n",
      "Epoch [452/1000], Loss: 0.1860\n",
      "Epoch [453/1000], Loss: 0.1887\n",
      "Epoch [454/1000], Loss: 0.1777\n",
      "Epoch [455/1000], Loss: 0.1870\n",
      "Epoch [456/1000], Loss: 0.1858\n",
      "Epoch [457/1000], Loss: 0.1817\n",
      "Epoch [458/1000], Loss: 0.1844\n",
      "Epoch [459/1000], Loss: 0.1792\n",
      "Epoch [460/1000], Loss: 0.1863\n",
      "Epoch [461/1000], Loss: 0.1911\n",
      "Epoch [462/1000], Loss: 0.1849\n",
      "Epoch [463/1000], Loss: 0.1850\n",
      "Epoch [464/1000], Loss: 0.1864\n",
      "Epoch [465/1000], Loss: 0.1873\n",
      "Epoch [466/1000], Loss: 0.1875\n",
      "Epoch [467/1000], Loss: 0.1877\n",
      "Epoch [468/1000], Loss: 0.1842\n",
      "Epoch [469/1000], Loss: 0.1885\n",
      "Epoch [470/1000], Loss: 0.1863\n",
      "Epoch [471/1000], Loss: 0.1850\n",
      "Epoch [472/1000], Loss: 0.1880\n",
      "Epoch [473/1000], Loss: 0.1860\n",
      "Epoch [474/1000], Loss: 0.1829\n",
      "Epoch [475/1000], Loss: 0.1866\n",
      "Epoch [476/1000], Loss: 0.1847\n",
      "Epoch [477/1000], Loss: 0.1827\n",
      "Epoch [478/1000], Loss: 0.1841\n",
      "Epoch [479/1000], Loss: 0.1836\n",
      "Epoch [480/1000], Loss: 0.1853\n",
      "Epoch [481/1000], Loss: 0.1822\n",
      "Epoch [482/1000], Loss: 0.1806\n",
      "Epoch [483/1000], Loss: 0.1895\n",
      "Epoch [484/1000], Loss: 0.1827\n",
      "Epoch [485/1000], Loss: 0.1871\n",
      "Epoch [486/1000], Loss: 0.1863\n",
      "Epoch [487/1000], Loss: 0.1878\n",
      "Epoch [488/1000], Loss: 0.1837\n",
      "Epoch [489/1000], Loss: 0.1827\n",
      "Epoch [490/1000], Loss: 0.1891\n",
      "Epoch [491/1000], Loss: 0.1800\n",
      "Epoch [492/1000], Loss: 0.1840\n",
      "Epoch [493/1000], Loss: 0.1864\n",
      "Epoch [494/1000], Loss: 0.1893\n",
      "Epoch [495/1000], Loss: 0.1886\n",
      "Epoch [496/1000], Loss: 0.1840\n",
      "Epoch [497/1000], Loss: 0.1795\n",
      "Epoch [498/1000], Loss: 0.1796\n",
      "Epoch [499/1000], Loss: 0.1792\n",
      "Epoch [500/1000], Loss: 0.1773\n",
      "Epoch [501/1000], Loss: 0.1779\n",
      "Epoch [502/1000], Loss: 0.1836\n",
      "Epoch [503/1000], Loss: 0.1777\n",
      "Epoch [504/1000], Loss: 0.1790\n",
      "Epoch [505/1000], Loss: 0.1775\n",
      "Epoch [506/1000], Loss: 0.1793\n",
      "Epoch [507/1000], Loss: 0.1739\n",
      "Epoch [508/1000], Loss: 0.1789\n",
      "Epoch [509/1000], Loss: 0.1758\n",
      "Epoch [510/1000], Loss: 0.1839\n",
      "Epoch [511/1000], Loss: 0.1846\n",
      "Epoch [512/1000], Loss: 0.1865\n",
      "Epoch [513/1000], Loss: 0.1874\n",
      "Epoch [514/1000], Loss: 0.1827\n",
      "Epoch [515/1000], Loss: 0.1815\n",
      "Epoch [516/1000], Loss: 0.1818\n",
      "Epoch [517/1000], Loss: 0.1819\n",
      "Epoch [518/1000], Loss: 0.1779\n",
      "Epoch [519/1000], Loss: 0.1755\n",
      "Epoch [520/1000], Loss: 0.1805\n",
      "Epoch [521/1000], Loss: 0.1745\n",
      "Epoch [522/1000], Loss: 0.1754\n",
      "Epoch [523/1000], Loss: 0.1791\n",
      "Epoch [524/1000], Loss: 0.1770\n",
      "Epoch [525/1000], Loss: 0.1772\n",
      "Epoch [526/1000], Loss: 0.1765\n",
      "Epoch [527/1000], Loss: 0.1769\n",
      "Epoch [528/1000], Loss: 0.1814\n",
      "Epoch [529/1000], Loss: 0.1793\n",
      "Epoch [530/1000], Loss: 0.1772\n",
      "Epoch [531/1000], Loss: 0.1747\n",
      "Epoch [532/1000], Loss: 0.1770\n",
      "Epoch [533/1000], Loss: 0.1740\n",
      "Epoch [534/1000], Loss: 0.1804\n",
      "Epoch [535/1000], Loss: 0.1792\n",
      "Epoch [536/1000], Loss: 0.1763\n",
      "Epoch [537/1000], Loss: 0.1749\n",
      "Epoch [538/1000], Loss: 0.1768\n",
      "Epoch [539/1000], Loss: 0.1738\n",
      "Epoch [540/1000], Loss: 0.1794\n",
      "Epoch [541/1000], Loss: 0.1771\n",
      "Epoch [542/1000], Loss: 0.1789\n",
      "Epoch [543/1000], Loss: 0.1772\n",
      "Epoch [544/1000], Loss: 0.1752\n",
      "Epoch [545/1000], Loss: 0.1788\n",
      "Epoch [546/1000], Loss: 0.1780\n",
      "Epoch [547/1000], Loss: 0.1751\n",
      "Epoch [548/1000], Loss: 0.1772\n",
      "Epoch [549/1000], Loss: 0.1759\n",
      "Epoch [550/1000], Loss: 0.1736\n",
      "Epoch [551/1000], Loss: 0.1760\n",
      "Epoch [552/1000], Loss: 0.1805\n",
      "Epoch [553/1000], Loss: 0.1761\n",
      "Epoch [554/1000], Loss: 0.1754\n",
      "Epoch [555/1000], Loss: 0.1748\n",
      "Epoch [556/1000], Loss: 0.1726\n",
      "Epoch [557/1000], Loss: 0.1733\n",
      "Epoch [558/1000], Loss: 0.1734\n",
      "Epoch [559/1000], Loss: 0.1761\n",
      "Epoch [560/1000], Loss: 0.1783\n",
      "Epoch [561/1000], Loss: 0.1746\n",
      "Epoch [562/1000], Loss: 0.1724\n",
      "Epoch [563/1000], Loss: 0.1770\n",
      "Epoch [564/1000], Loss: 0.1893\n",
      "Epoch [565/1000], Loss: 0.1832\n",
      "Epoch [566/1000], Loss: 0.1794\n",
      "Epoch [567/1000], Loss: 0.1834\n",
      "Epoch [568/1000], Loss: 0.1762\n",
      "Epoch [569/1000], Loss: 0.1782\n",
      "Epoch [570/1000], Loss: 0.1710\n",
      "Epoch [571/1000], Loss: 0.1815\n",
      "Epoch [572/1000], Loss: 0.1744\n",
      "Epoch [573/1000], Loss: 0.1718\n",
      "Epoch [574/1000], Loss: 0.1713\n",
      "Epoch [575/1000], Loss: 0.1773\n",
      "Epoch [576/1000], Loss: 0.1760\n",
      "Epoch [577/1000], Loss: 0.1744\n",
      "Epoch [578/1000], Loss: 0.1807\n",
      "Epoch [579/1000], Loss: 0.1774\n",
      "Epoch [580/1000], Loss: 0.1724\n",
      "Epoch [581/1000], Loss: 0.1726\n",
      "Epoch [582/1000], Loss: 0.1721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [583/1000], Loss: 0.1723\n",
      "Epoch [584/1000], Loss: 0.1783\n",
      "Epoch [585/1000], Loss: 0.1781\n",
      "Epoch [586/1000], Loss: 0.1757\n",
      "Epoch [587/1000], Loss: 0.1750\n",
      "Epoch [588/1000], Loss: 0.1772\n",
      "Epoch [589/1000], Loss: 0.1760\n",
      "Epoch [590/1000], Loss: 0.1750\n",
      "Epoch [591/1000], Loss: 0.1755\n",
      "Epoch [592/1000], Loss: 0.1748\n",
      "Epoch [593/1000], Loss: 0.1727\n",
      "Epoch [594/1000], Loss: 0.1732\n",
      "Epoch [595/1000], Loss: 0.1714\n",
      "Epoch [596/1000], Loss: 0.1741\n",
      "Epoch [597/1000], Loss: 0.1761\n",
      "Epoch [598/1000], Loss: 0.1762\n",
      "Epoch [599/1000], Loss: 0.1719\n",
      "Epoch [600/1000], Loss: 0.1751\n",
      "Epoch [601/1000], Loss: 0.1736\n",
      "Epoch [602/1000], Loss: 0.1743\n",
      "Epoch [603/1000], Loss: 0.1714\n",
      "Epoch [604/1000], Loss: 0.1733\n",
      "Epoch [605/1000], Loss: 0.1741\n",
      "Epoch [606/1000], Loss: 0.1755\n",
      "Epoch [607/1000], Loss: 0.1712\n",
      "Epoch [608/1000], Loss: 0.1814\n",
      "Epoch [609/1000], Loss: 0.1816\n",
      "Epoch [610/1000], Loss: 0.1766\n",
      "Epoch [611/1000], Loss: 0.1709\n",
      "Epoch [612/1000], Loss: 0.1753\n",
      "Epoch [613/1000], Loss: 0.1743\n",
      "Epoch [614/1000], Loss: 0.1715\n",
      "Epoch [615/1000], Loss: 0.1727\n",
      "Epoch [616/1000], Loss: 0.1763\n",
      "Epoch [617/1000], Loss: 0.1755\n",
      "Epoch [618/1000], Loss: 0.1748\n",
      "Epoch [619/1000], Loss: 0.1797\n",
      "Epoch [620/1000], Loss: 0.1746\n",
      "Epoch [621/1000], Loss: 0.1755\n",
      "Epoch [622/1000], Loss: 0.1739\n",
      "Epoch [623/1000], Loss: 0.1761\n",
      "Epoch [624/1000], Loss: 0.1749\n",
      "Epoch [625/1000], Loss: 0.1778\n",
      "Epoch [626/1000], Loss: 0.1772\n",
      "Epoch [627/1000], Loss: 0.1714\n",
      "Epoch [628/1000], Loss: 0.1710\n",
      "Epoch [629/1000], Loss: 0.1842\n",
      "Epoch [630/1000], Loss: 0.1770\n",
      "Epoch [631/1000], Loss: 0.1731\n",
      "Epoch [632/1000], Loss: 0.1761\n",
      "Epoch [633/1000], Loss: 0.1733\n",
      "Epoch [634/1000], Loss: 0.1786\n",
      "Epoch [635/1000], Loss: 0.1722\n",
      "Epoch [636/1000], Loss: 0.1771\n",
      "Epoch [637/1000], Loss: 0.1787\n",
      "Epoch [638/1000], Loss: 0.1757\n",
      "Epoch [639/1000], Loss: 0.1754\n",
      "Epoch [640/1000], Loss: 0.1779\n",
      "Epoch [641/1000], Loss: 0.1741\n",
      "Epoch [642/1000], Loss: 0.1738\n",
      "Epoch [643/1000], Loss: 0.1761\n",
      "Epoch [644/1000], Loss: 0.1737\n",
      "Epoch [645/1000], Loss: 0.1760\n",
      "Epoch [646/1000], Loss: 0.1729\n",
      "Epoch [647/1000], Loss: 0.1745\n",
      "Epoch [648/1000], Loss: 0.1737\n",
      "Epoch [649/1000], Loss: 0.1790\n",
      "Epoch [650/1000], Loss: 0.1834\n",
      "Epoch [651/1000], Loss: 0.1862\n",
      "Epoch [652/1000], Loss: 0.1834\n",
      "Epoch [653/1000], Loss: 0.1826\n",
      "Epoch [654/1000], Loss: 0.1803\n",
      "Epoch [655/1000], Loss: 0.1840\n",
      "Epoch [656/1000], Loss: 0.1836\n",
      "Epoch [657/1000], Loss: 0.1750\n",
      "Epoch [658/1000], Loss: 0.1748\n",
      "Epoch [659/1000], Loss: 0.1733\n",
      "Epoch [660/1000], Loss: 0.1835\n",
      "Epoch [661/1000], Loss: 0.1850\n",
      "Epoch [662/1000], Loss: 0.1824\n",
      "Epoch [663/1000], Loss: 0.1760\n",
      "Epoch [664/1000], Loss: 0.1815\n",
      "Epoch [665/1000], Loss: 0.1763\n",
      "Epoch [666/1000], Loss: 0.1687\n",
      "Epoch [667/1000], Loss: 0.1727\n",
      "Epoch [668/1000], Loss: 0.1894\n",
      "Epoch [669/1000], Loss: 0.1914\n",
      "Epoch [670/1000], Loss: 0.1880\n",
      "Epoch [671/1000], Loss: 0.1889\n",
      "Epoch [672/1000], Loss: 0.1774\n",
      "Epoch [673/1000], Loss: 0.1726\n",
      "Epoch [674/1000], Loss: 0.1759\n",
      "Epoch [675/1000], Loss: 0.1755\n",
      "Epoch [676/1000], Loss: 0.1753\n",
      "Epoch [677/1000], Loss: 0.1742\n",
      "Epoch [678/1000], Loss: 0.1702\n",
      "Epoch [679/1000], Loss: 0.1679\n",
      "Epoch [680/1000], Loss: 0.1707\n",
      "Epoch [681/1000], Loss: 0.1761\n",
      "Epoch [682/1000], Loss: 0.1707\n",
      "Epoch [683/1000], Loss: 0.1745\n",
      "Epoch [684/1000], Loss: 0.1715\n",
      "Epoch [685/1000], Loss: 0.1719\n",
      "Epoch [686/1000], Loss: 0.1683\n",
      "Epoch [687/1000], Loss: 0.1697\n",
      "Epoch [688/1000], Loss: 0.1738\n",
      "Epoch [689/1000], Loss: 0.1713\n",
      "Epoch [690/1000], Loss: 0.1765\n",
      "Epoch [691/1000], Loss: 0.1713\n",
      "Epoch [692/1000], Loss: 0.1727\n",
      "Epoch [693/1000], Loss: 0.1752\n",
      "Epoch [694/1000], Loss: 0.1716\n",
      "Epoch [695/1000], Loss: 0.1692\n",
      "Epoch [696/1000], Loss: 0.1704\n",
      "Epoch [697/1000], Loss: 0.1766\n",
      "Epoch [698/1000], Loss: 0.1758\n",
      "Epoch [699/1000], Loss: 0.1710\n",
      "Epoch [700/1000], Loss: 0.1698\n",
      "Epoch [701/1000], Loss: 0.1721\n",
      "Epoch [702/1000], Loss: 0.1722\n",
      "Epoch [703/1000], Loss: 0.1787\n",
      "Epoch [704/1000], Loss: 0.1730\n",
      "Epoch [705/1000], Loss: 0.1705\n",
      "Epoch [706/1000], Loss: 0.1734\n",
      "Epoch [707/1000], Loss: 0.1722\n",
      "Epoch [708/1000], Loss: 0.1700\n",
      "Epoch [709/1000], Loss: 0.1729\n",
      "Epoch [710/1000], Loss: 0.1717\n",
      "Epoch [711/1000], Loss: 0.1723\n",
      "Epoch [712/1000], Loss: 0.1767\n",
      "Epoch [713/1000], Loss: 0.1712\n",
      "Epoch [714/1000], Loss: 0.1729\n",
      "Epoch [715/1000], Loss: 0.1693\n",
      "Epoch [716/1000], Loss: 0.1745\n",
      "Epoch [717/1000], Loss: 0.1710\n",
      "Epoch [718/1000], Loss: 0.1762\n",
      "Epoch [719/1000], Loss: 0.1709\n",
      "Epoch [720/1000], Loss: 0.1686\n",
      "Epoch [721/1000], Loss: 0.1714\n",
      "Epoch [722/1000], Loss: 0.1718\n",
      "Epoch [723/1000], Loss: 0.1716\n",
      "Epoch [724/1000], Loss: 0.1709\n",
      "Epoch [725/1000], Loss: 0.1723\n",
      "Epoch [726/1000], Loss: 0.1790\n",
      "Epoch [727/1000], Loss: 0.1708\n",
      "Epoch [728/1000], Loss: 0.1715\n",
      "Epoch [729/1000], Loss: 0.1726\n",
      "Epoch [730/1000], Loss: 0.1702\n",
      "Epoch [731/1000], Loss: 0.1774\n",
      "Epoch [732/1000], Loss: 0.1721\n",
      "Epoch [733/1000], Loss: 0.1740\n",
      "Epoch [734/1000], Loss: 0.1720\n",
      "Epoch [735/1000], Loss: 0.1734\n",
      "Epoch [736/1000], Loss: 0.1775\n",
      "Epoch [737/1000], Loss: 0.1731\n",
      "Epoch [738/1000], Loss: 0.1703\n",
      "Epoch [739/1000], Loss: 0.1716\n",
      "Epoch [740/1000], Loss: 0.1696\n",
      "Epoch [741/1000], Loss: 0.1699\n",
      "Epoch [742/1000], Loss: 0.1727\n",
      "Epoch [743/1000], Loss: 0.1760\n",
      "Epoch [744/1000], Loss: 0.1770\n",
      "Epoch [745/1000], Loss: 0.1710\n",
      "Epoch [746/1000], Loss: 0.1679\n",
      "Epoch [747/1000], Loss: 0.1712\n",
      "Epoch [748/1000], Loss: 0.1728\n",
      "Epoch [749/1000], Loss: 0.1692\n",
      "Epoch [750/1000], Loss: 0.1706\n",
      "Epoch [751/1000], Loss: 0.1762\n",
      "Epoch [752/1000], Loss: 0.1741\n",
      "Epoch [753/1000], Loss: 0.1739\n",
      "Epoch [754/1000], Loss: 0.1703\n",
      "Epoch [755/1000], Loss: 0.1697\n",
      "Epoch [756/1000], Loss: 0.1752\n",
      "Epoch [757/1000], Loss: 0.1727\n",
      "Epoch [758/1000], Loss: 0.1837\n",
      "Epoch [759/1000], Loss: 0.1824\n",
      "Epoch [760/1000], Loss: 0.1782\n",
      "Epoch [761/1000], Loss: 0.1721\n",
      "Epoch [762/1000], Loss: 0.1726\n",
      "Epoch [763/1000], Loss: 0.1770\n",
      "Epoch [764/1000], Loss: 0.1714\n",
      "Epoch [765/1000], Loss: 0.1712\n",
      "Epoch [766/1000], Loss: 0.1721\n",
      "Epoch [767/1000], Loss: 0.1714\n",
      "Epoch [768/1000], Loss: 0.1731\n",
      "Epoch [769/1000], Loss: 0.1743\n",
      "Epoch [770/1000], Loss: 0.1723\n",
      "Epoch [771/1000], Loss: 0.1710\n",
      "Epoch [772/1000], Loss: 0.1731\n",
      "Epoch [773/1000], Loss: 0.1748\n",
      "Epoch [774/1000], Loss: 0.1727\n",
      "Epoch [775/1000], Loss: 0.1785\n",
      "Epoch [776/1000], Loss: 0.1783\n",
      "Epoch [777/1000], Loss: 0.1742\n",
      "Epoch [778/1000], Loss: 0.1718\n",
      "Epoch [779/1000], Loss: 0.1778\n",
      "Epoch [780/1000], Loss: 0.1774\n",
      "Epoch [781/1000], Loss: 0.1753\n",
      "Epoch [782/1000], Loss: 0.1741\n",
      "Epoch [783/1000], Loss: 0.1748\n",
      "Epoch [784/1000], Loss: 0.1765\n",
      "Epoch [785/1000], Loss: 0.1721\n",
      "Epoch [786/1000], Loss: 0.1724\n",
      "Epoch [787/1000], Loss: 0.1708\n",
      "Epoch [788/1000], Loss: 0.1719\n",
      "Epoch [789/1000], Loss: 0.1730\n",
      "Epoch [790/1000], Loss: 0.1713\n",
      "Epoch [791/1000], Loss: 0.1691\n",
      "Epoch [792/1000], Loss: 0.1699\n",
      "Epoch [793/1000], Loss: 0.1680\n",
      "Epoch [794/1000], Loss: 0.1729\n",
      "Epoch [795/1000], Loss: 0.1712\n",
      "Epoch [796/1000], Loss: 0.1737\n",
      "Epoch [797/1000], Loss: 0.1738\n",
      "Epoch [798/1000], Loss: 0.1774\n",
      "Epoch [799/1000], Loss: 0.1740\n",
      "Epoch [800/1000], Loss: 0.1734\n",
      "Epoch [801/1000], Loss: 0.1883\n",
      "Epoch [802/1000], Loss: 0.1849\n",
      "Epoch [803/1000], Loss: 0.1808\n",
      "Epoch [804/1000], Loss: 0.1734\n",
      "Epoch [805/1000], Loss: 0.1716\n",
      "Epoch [806/1000], Loss: 0.1730\n",
      "Epoch [807/1000], Loss: 0.1745\n",
      "Epoch [808/1000], Loss: 0.1738\n",
      "Epoch [809/1000], Loss: 0.1714\n",
      "Epoch [810/1000], Loss: 0.1713\n",
      "Epoch [811/1000], Loss: 0.1701\n",
      "Epoch [812/1000], Loss: 0.1756\n",
      "Epoch [813/1000], Loss: 0.1757\n",
      "Epoch [814/1000], Loss: 0.1840\n",
      "Epoch [815/1000], Loss: 0.1733\n",
      "Epoch [816/1000], Loss: 0.1691\n",
      "Epoch [817/1000], Loss: 0.1749\n",
      "Epoch [818/1000], Loss: 0.1764\n",
      "Epoch [819/1000], Loss: 0.1701\n",
      "Epoch [820/1000], Loss: 0.1719\n",
      "Epoch [821/1000], Loss: 0.1768\n",
      "Epoch [822/1000], Loss: 0.1785\n",
      "Epoch [823/1000], Loss: 0.1680\n",
      "Epoch [824/1000], Loss: 0.1707\n",
      "Epoch [825/1000], Loss: 0.1704\n",
      "Epoch [826/1000], Loss: 0.1726\n",
      "Epoch [827/1000], Loss: 0.1705\n",
      "Epoch [828/1000], Loss: 0.1734\n",
      "Epoch [829/1000], Loss: 0.1690\n",
      "Epoch [830/1000], Loss: 0.1704\n",
      "Epoch [831/1000], Loss: 0.1713\n",
      "Epoch [832/1000], Loss: 0.1694\n",
      "Epoch [833/1000], Loss: 0.1720\n",
      "Epoch [834/1000], Loss: 0.1706\n",
      "Epoch [835/1000], Loss: 0.1698\n",
      "Epoch [836/1000], Loss: 0.1765\n",
      "Epoch [837/1000], Loss: 0.1727\n",
      "Epoch [838/1000], Loss: 0.1706\n",
      "Epoch [839/1000], Loss: 0.1799\n",
      "Epoch [840/1000], Loss: 0.1689\n",
      "Epoch [841/1000], Loss: 0.1734\n",
      "Epoch [842/1000], Loss: 0.1745\n",
      "Epoch [843/1000], Loss: 0.1712\n",
      "Epoch [844/1000], Loss: 0.1705\n",
      "Epoch [845/1000], Loss: 0.1688\n",
      "Epoch [846/1000], Loss: 0.1695\n",
      "Epoch [847/1000], Loss: 0.1698\n",
      "Epoch [848/1000], Loss: 0.1696\n",
      "Epoch [849/1000], Loss: 0.1715\n",
      "Epoch [850/1000], Loss: 0.1698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [851/1000], Loss: 0.1722\n",
      "Epoch [852/1000], Loss: 0.1715\n",
      "Epoch [853/1000], Loss: 0.1688\n",
      "Epoch [854/1000], Loss: 0.1720\n",
      "Epoch [855/1000], Loss: 0.1751\n",
      "Epoch [856/1000], Loss: 0.1740\n",
      "Epoch [857/1000], Loss: 0.1723\n",
      "Epoch [858/1000], Loss: 0.1688\n",
      "Epoch [859/1000], Loss: 0.1707\n",
      "Epoch [860/1000], Loss: 0.1741\n",
      "Epoch [861/1000], Loss: 0.1675\n",
      "Epoch [862/1000], Loss: 0.1702\n",
      "Epoch [863/1000], Loss: 0.1737\n",
      "Epoch [864/1000], Loss: 0.1717\n",
      "Epoch [865/1000], Loss: 0.1715\n",
      "Epoch [866/1000], Loss: 0.1686\n",
      "Epoch [867/1000], Loss: 0.1775\n",
      "Epoch [868/1000], Loss: 0.1701\n",
      "Epoch [869/1000], Loss: 0.1689\n",
      "Epoch [870/1000], Loss: 0.1708\n",
      "Epoch [871/1000], Loss: 0.1717\n",
      "Epoch [872/1000], Loss: 0.1720\n",
      "Epoch [873/1000], Loss: 0.1731\n",
      "Epoch [874/1000], Loss: 0.1706\n",
      "Epoch [875/1000], Loss: 0.1685\n",
      "Epoch [876/1000], Loss: 0.1733\n",
      "Epoch [877/1000], Loss: 0.1727\n",
      "Epoch [878/1000], Loss: 0.1780\n",
      "Epoch [879/1000], Loss: 0.1720\n",
      "Epoch [880/1000], Loss: 0.1709\n",
      "Epoch [881/1000], Loss: 0.1792\n",
      "Epoch [882/1000], Loss: 0.1706\n",
      "Epoch [883/1000], Loss: 0.1731\n",
      "Epoch [884/1000], Loss: 0.1707\n",
      "Epoch [885/1000], Loss: 0.1715\n",
      "Epoch [886/1000], Loss: 0.1709\n",
      "Epoch [887/1000], Loss: 0.1694\n",
      "Epoch [888/1000], Loss: 0.1710\n",
      "Epoch [889/1000], Loss: 0.1730\n",
      "Epoch [890/1000], Loss: 0.1697\n",
      "Epoch [891/1000], Loss: 0.1726\n",
      "Epoch [892/1000], Loss: 0.1721\n",
      "Epoch [893/1000], Loss: 0.1713\n",
      "Epoch [894/1000], Loss: 0.1672\n",
      "Epoch [895/1000], Loss: 0.1707\n",
      "Epoch [896/1000], Loss: 0.1729\n",
      "Epoch [897/1000], Loss: 0.1700\n",
      "Epoch [898/1000], Loss: 0.1768\n",
      "Epoch [899/1000], Loss: 0.1704\n",
      "Epoch [900/1000], Loss: 0.1718\n",
      "Epoch [901/1000], Loss: 0.1692\n",
      "Epoch [902/1000], Loss: 0.1707\n",
      "Epoch [903/1000], Loss: 0.1688\n",
      "Epoch [904/1000], Loss: 0.1711\n",
      "Epoch [905/1000], Loss: 0.1723\n",
      "Epoch [906/1000], Loss: 0.1684\n",
      "Epoch [907/1000], Loss: 0.1730\n",
      "Epoch [908/1000], Loss: 0.1835\n",
      "Epoch [909/1000], Loss: 0.1713\n",
      "Epoch [910/1000], Loss: 0.1732\n",
      "Epoch [911/1000], Loss: 0.1696\n",
      "Epoch [912/1000], Loss: 0.1713\n",
      "Epoch [913/1000], Loss: 0.1754\n",
      "Epoch [914/1000], Loss: 0.1678\n",
      "Epoch [915/1000], Loss: 0.1713\n",
      "Epoch [916/1000], Loss: 0.1704\n",
      "Epoch [917/1000], Loss: 0.1705\n",
      "Epoch [918/1000], Loss: 0.1721\n",
      "Epoch [919/1000], Loss: 0.1721\n",
      "Epoch [920/1000], Loss: 0.1696\n",
      "Epoch [921/1000], Loss: 0.1704\n",
      "Epoch [922/1000], Loss: 0.1689\n",
      "Epoch [923/1000], Loss: 0.1725\n",
      "Epoch [924/1000], Loss: 0.1710\n",
      "Epoch [925/1000], Loss: 0.1701\n",
      "Epoch [926/1000], Loss: 0.1722\n",
      "Epoch [927/1000], Loss: 0.1718\n",
      "Epoch [928/1000], Loss: 0.1739\n",
      "Epoch [929/1000], Loss: 0.1755\n",
      "Epoch [930/1000], Loss: 0.1814\n",
      "Epoch [931/1000], Loss: 0.1950\n",
      "Epoch [932/1000], Loss: 0.1912\n",
      "Epoch [933/1000], Loss: 0.1873\n",
      "Epoch [934/1000], Loss: 0.1848\n",
      "Epoch [935/1000], Loss: 0.1791\n",
      "Epoch [936/1000], Loss: 0.1728\n",
      "Epoch [937/1000], Loss: 0.1752\n",
      "Epoch [938/1000], Loss: 0.1817\n",
      "Epoch [939/1000], Loss: 0.1891\n",
      "Epoch [940/1000], Loss: 0.1761\n",
      "Epoch [941/1000], Loss: 0.1797\n",
      "Epoch [942/1000], Loss: 0.1802\n",
      "Epoch [943/1000], Loss: 0.1750\n",
      "Epoch [944/1000], Loss: 0.1698\n",
      "Epoch [945/1000], Loss: 0.1712\n",
      "Epoch [946/1000], Loss: 0.1704\n",
      "Epoch [947/1000], Loss: 0.1738\n",
      "Epoch [948/1000], Loss: 0.1744\n",
      "Epoch [949/1000], Loss: 0.1738\n",
      "Epoch [950/1000], Loss: 0.1697\n",
      "Epoch [951/1000], Loss: 0.1728\n",
      "Epoch [952/1000], Loss: 0.1766\n",
      "Epoch [953/1000], Loss: 0.1774\n",
      "Epoch [954/1000], Loss: 0.1723\n",
      "Epoch [955/1000], Loss: 0.1678\n",
      "Epoch [956/1000], Loss: 0.1691\n",
      "Epoch [957/1000], Loss: 0.1700\n",
      "Epoch [958/1000], Loss: 0.1726\n",
      "Epoch [959/1000], Loss: 0.1718\n",
      "Epoch [960/1000], Loss: 0.1685\n",
      "Epoch [961/1000], Loss: 0.1684\n",
      "Epoch [962/1000], Loss: 0.1719\n",
      "Epoch [963/1000], Loss: 0.1702\n",
      "Epoch [964/1000], Loss: 0.1692\n",
      "Epoch [965/1000], Loss: 0.1707\n",
      "Epoch [966/1000], Loss: 0.1715\n",
      "Epoch [967/1000], Loss: 0.1810\n",
      "Epoch [968/1000], Loss: 0.1780\n",
      "Epoch [969/1000], Loss: 0.1749\n",
      "Epoch [970/1000], Loss: 0.1708\n",
      "Epoch [971/1000], Loss: 0.1712\n",
      "Epoch [972/1000], Loss: 0.1764\n",
      "Epoch [973/1000], Loss: 0.1704\n",
      "Epoch [974/1000], Loss: 0.1722\n",
      "Epoch [975/1000], Loss: 0.1714\n",
      "Epoch [976/1000], Loss: 0.1679\n",
      "Epoch [977/1000], Loss: 0.1718\n",
      "Epoch [978/1000], Loss: 0.1716\n",
      "Epoch [979/1000], Loss: 0.1692\n",
      "Epoch [980/1000], Loss: 0.1701\n",
      "Epoch [981/1000], Loss: 0.1739\n",
      "Epoch [982/1000], Loss: 0.1687\n",
      "Epoch [983/1000], Loss: 0.1667\n",
      "Epoch [984/1000], Loss: 0.1708\n",
      "Epoch [985/1000], Loss: 0.1813\n",
      "Epoch [986/1000], Loss: 0.1691\n",
      "Epoch [987/1000], Loss: 0.1709\n",
      "Epoch [988/1000], Loss: 0.1772\n",
      "Epoch [989/1000], Loss: 0.1733\n",
      "Epoch [990/1000], Loss: 0.1696\n",
      "Epoch [991/1000], Loss: 0.1688\n",
      "Epoch [992/1000], Loss: 0.1711\n",
      "Epoch [993/1000], Loss: 0.1717\n",
      "Epoch [994/1000], Loss: 0.1704\n",
      "Epoch [995/1000], Loss: 0.1674\n",
      "Epoch [996/1000], Loss: 0.1718\n",
      "Epoch [997/1000], Loss: 0.1689\n",
      "Epoch [998/1000], Loss: 0.1730\n",
      "Epoch [999/1000], Loss: 0.1717\n",
      "Epoch [1000/1000], Loss: 0.1685\n",
      "Accuracy of the network on the 1000 validation data: 72.40 %\n",
      "Training model with batch_size: 302, lr :0.001, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.2813\n",
      "Epoch [2/1000], Loss: 0.2742\n",
      "Epoch [3/1000], Loss: 0.2697\n",
      "Epoch [4/1000], Loss: 0.2672\n",
      "Epoch [5/1000], Loss: 0.2647\n",
      "Epoch [6/1000], Loss: 0.2629\n",
      "Epoch [7/1000], Loss: 0.2617\n",
      "Epoch [8/1000], Loss: 0.2600\n",
      "Epoch [9/1000], Loss: 0.2595\n",
      "Epoch [10/1000], Loss: 0.2586\n",
      "Epoch [11/1000], Loss: 0.2580\n",
      "Epoch [12/1000], Loss: 0.2562\n",
      "Epoch [13/1000], Loss: 0.2562\n",
      "Epoch [14/1000], Loss: 0.2552\n",
      "Epoch [15/1000], Loss: 0.2551\n",
      "Epoch [16/1000], Loss: 0.2542\n",
      "Epoch [17/1000], Loss: 0.2541\n",
      "Epoch [18/1000], Loss: 0.2534\n",
      "Epoch [19/1000], Loss: 0.2543\n",
      "Epoch [20/1000], Loss: 0.2537\n",
      "Epoch [21/1000], Loss: 0.2535\n",
      "Epoch [22/1000], Loss: 0.2531\n",
      "Epoch [23/1000], Loss: 0.2524\n",
      "Epoch [24/1000], Loss: 0.2521\n",
      "Epoch [25/1000], Loss: 0.2520\n",
      "Epoch [26/1000], Loss: 0.2514\n",
      "Epoch [27/1000], Loss: 0.2519\n",
      "Epoch [28/1000], Loss: 0.2514\n",
      "Epoch [29/1000], Loss: 0.2509\n",
      "Epoch [30/1000], Loss: 0.2510\n",
      "Epoch [31/1000], Loss: 0.2510\n",
      "Epoch [32/1000], Loss: 0.2510\n",
      "Epoch [33/1000], Loss: 0.2500\n",
      "Epoch [34/1000], Loss: 0.2508\n",
      "Epoch [35/1000], Loss: 0.2501\n",
      "Epoch [36/1000], Loss: 0.2504\n",
      "Epoch [37/1000], Loss: 0.2497\n",
      "Epoch [38/1000], Loss: 0.2494\n",
      "Epoch [39/1000], Loss: 0.2499\n",
      "Epoch [40/1000], Loss: 0.2503\n",
      "Epoch [41/1000], Loss: 0.2494\n",
      "Epoch [42/1000], Loss: 0.2505\n",
      "Epoch [43/1000], Loss: 0.2498\n",
      "Epoch [44/1000], Loss: 0.2491\n",
      "Epoch [45/1000], Loss: 0.2507\n",
      "Epoch [46/1000], Loss: 0.2491\n",
      "Epoch [47/1000], Loss: 0.2495\n",
      "Epoch [48/1000], Loss: 0.2492\n",
      "Epoch [49/1000], Loss: 0.2492\n",
      "Epoch [50/1000], Loss: 0.2490\n",
      "Epoch [51/1000], Loss: 0.2495\n",
      "Epoch [52/1000], Loss: 0.2494\n",
      "Epoch [53/1000], Loss: 0.2491\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 62.90 %\n",
      "Training model with batch_size: 302, lr :0.001, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.2657\n",
      "Epoch [2/1000], Loss: 0.2555\n",
      "Epoch [3/1000], Loss: 0.2521\n",
      "Epoch [4/1000], Loss: 0.2503\n",
      "Epoch [5/1000], Loss: 0.2487\n",
      "Epoch [6/1000], Loss: 0.2492\n",
      "Epoch [7/1000], Loss: 0.2474\n",
      "Epoch [8/1000], Loss: 0.2469\n",
      "Epoch [9/1000], Loss: 0.2468\n",
      "Epoch [10/1000], Loss: 0.2458\n",
      "Epoch [11/1000], Loss: 0.2435\n",
      "Epoch [12/1000], Loss: 0.2439\n",
      "Epoch [13/1000], Loss: 0.2429\n",
      "Epoch [14/1000], Loss: 0.2425\n",
      "Epoch [15/1000], Loss: 0.2410\n",
      "Epoch [16/1000], Loss: 0.2410\n",
      "Epoch [17/1000], Loss: 0.2386\n",
      "Epoch [18/1000], Loss: 0.2385\n",
      "Epoch [19/1000], Loss: 0.2363\n",
      "Epoch [20/1000], Loss: 0.2358\n",
      "Epoch [21/1000], Loss: 0.2340\n",
      "Epoch [22/1000], Loss: 0.2330\n",
      "Epoch [23/1000], Loss: 0.2294\n",
      "Epoch [24/1000], Loss: 0.2285\n",
      "Epoch [25/1000], Loss: 0.2257\n",
      "Epoch [26/1000], Loss: 0.2249\n",
      "Epoch [27/1000], Loss: 0.2230\n",
      "Epoch [28/1000], Loss: 0.2184\n",
      "Epoch [29/1000], Loss: 0.2174\n",
      "Epoch [30/1000], Loss: 0.2128\n",
      "Epoch [31/1000], Loss: 0.2105\n",
      "Epoch [32/1000], Loss: 0.2064\n",
      "Epoch [33/1000], Loss: 0.2026\n",
      "Epoch [34/1000], Loss: 0.1995\n",
      "Epoch [35/1000], Loss: 0.1933\n",
      "Epoch [36/1000], Loss: 0.1887\n",
      "Epoch [37/1000], Loss: 0.1831\n",
      "Epoch [38/1000], Loss: 0.1786\n",
      "Epoch [39/1000], Loss: 0.1731\n",
      "Epoch [40/1000], Loss: 0.1667\n",
      "Epoch [41/1000], Loss: 0.1621\n",
      "Epoch [42/1000], Loss: 0.1561\n",
      "Epoch [43/1000], Loss: 0.1516\n",
      "Epoch [44/1000], Loss: 0.1451\n",
      "Epoch [45/1000], Loss: 0.1386\n",
      "Epoch [46/1000], Loss: 0.1323\n",
      "Epoch [47/1000], Loss: 0.1287\n",
      "Epoch [48/1000], Loss: 0.1222\n",
      "Epoch [49/1000], Loss: 0.1161\n",
      "Epoch [50/1000], Loss: 0.1124\n",
      "Epoch [51/1000], Loss: 0.1072\n",
      "Epoch [52/1000], Loss: 0.1019\n",
      "Epoch [53/1000], Loss: 0.0973\n",
      "Epoch [54/1000], Loss: 0.0934\n",
      "Epoch [55/1000], Loss: 0.0896\n",
      "Epoch [56/1000], Loss: 0.0845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/1000], Loss: 0.0804\n",
      "Epoch [58/1000], Loss: 0.0764\n",
      "Epoch [59/1000], Loss: 0.0733\n",
      "Epoch [60/1000], Loss: 0.0698\n",
      "Epoch [61/1000], Loss: 0.0658\n",
      "Epoch [62/1000], Loss: 0.0628\n",
      "Epoch [63/1000], Loss: 0.0598\n",
      "Epoch [64/1000], Loss: 0.0571\n",
      "Epoch [65/1000], Loss: 0.0549\n",
      "Epoch [66/1000], Loss: 0.0512\n",
      "Epoch [67/1000], Loss: 0.0493\n",
      "Epoch [68/1000], Loss: 0.0468\n",
      "Epoch [69/1000], Loss: 0.0454\n",
      "Epoch [70/1000], Loss: 0.0432\n",
      "Epoch [71/1000], Loss: 0.0410\n",
      "Epoch [72/1000], Loss: 0.0390\n",
      "Epoch [73/1000], Loss: 0.0375\n",
      "Epoch [74/1000], Loss: 0.0356\n",
      "Epoch [75/1000], Loss: 0.0343\n",
      "Epoch [76/1000], Loss: 0.0322\n",
      "Epoch [77/1000], Loss: 0.0317\n",
      "Epoch [78/1000], Loss: 0.0296\n",
      "Epoch [79/1000], Loss: 0.0288\n",
      "Epoch [80/1000], Loss: 0.0275\n",
      "Epoch [81/1000], Loss: 0.0263\n",
      "Epoch [82/1000], Loss: 0.0258\n",
      "Epoch [83/1000], Loss: 0.0244\n",
      "Epoch [84/1000], Loss: 0.0230\n",
      "Epoch [85/1000], Loss: 0.0222\n",
      "Epoch [86/1000], Loss: 0.0212\n",
      "Epoch [87/1000], Loss: 0.0200\n",
      "Epoch [88/1000], Loss: 0.0198\n",
      "Epoch [89/1000], Loss: 0.0189\n",
      "Epoch [90/1000], Loss: 0.0182\n",
      "Epoch [91/1000], Loss: 0.0174\n",
      "Epoch [92/1000], Loss: 0.0169\n",
      "Epoch [93/1000], Loss: 0.0162\n",
      "Epoch [94/1000], Loss: 0.0156\n",
      "Epoch [95/1000], Loss: 0.0152\n",
      "Epoch [96/1000], Loss: 0.0144\n",
      "Epoch [97/1000], Loss: 0.0140\n",
      "Epoch [98/1000], Loss: 0.0136\n",
      "Epoch [99/1000], Loss: 0.0132\n",
      "Epoch [100/1000], Loss: 0.0126\n",
      "Epoch [101/1000], Loss: 0.0125\n",
      "Epoch [102/1000], Loss: 0.0118\n",
      "Epoch [103/1000], Loss: 0.0115\n",
      "Epoch [104/1000], Loss: 0.0112\n",
      "Epoch [105/1000], Loss: 0.0109\n",
      "Epoch [106/1000], Loss: 0.0106\n",
      "Epoch [107/1000], Loss: 0.0102\n",
      "Epoch [108/1000], Loss: 0.0097\n",
      "Epoch [109/1000], Loss: 0.0098\n",
      "Epoch [110/1000], Loss: 0.0092\n",
      "Epoch [111/1000], Loss: 0.0089\n",
      "Epoch [112/1000], Loss: 0.0086\n",
      "Epoch [113/1000], Loss: 0.0085\n",
      "Epoch [114/1000], Loss: 0.0086\n",
      "Epoch [115/1000], Loss: 0.0083\n",
      "Epoch [116/1000], Loss: 0.0080\n",
      "Epoch [117/1000], Loss: 0.0076\n",
      "Epoch [118/1000], Loss: 0.0074\n",
      "Epoch [119/1000], Loss: 0.0072\n",
      "Epoch [120/1000], Loss: 0.0072\n",
      "Epoch [121/1000], Loss: 0.0068\n",
      "Epoch [122/1000], Loss: 0.0067\n",
      "Epoch [123/1000], Loss: 0.0066\n",
      "Epoch [124/1000], Loss: 0.0063\n",
      "Epoch [125/1000], Loss: 0.0062\n",
      "Epoch [126/1000], Loss: 0.0060\n",
      "Epoch [127/1000], Loss: 0.0058\n",
      "Epoch [128/1000], Loss: 0.0058\n",
      "Epoch [129/1000], Loss: 0.0056\n",
      "Epoch [130/1000], Loss: 0.0055\n",
      "Epoch [131/1000], Loss: 0.0054\n",
      "Epoch [132/1000], Loss: 0.0056\n",
      "Epoch [133/1000], Loss: 0.0053\n",
      "Epoch [134/1000], Loss: 0.0050\n",
      "Epoch [135/1000], Loss: 0.0049\n",
      "Epoch [136/1000], Loss: 0.0049\n",
      "Epoch [137/1000], Loss: 0.0047\n",
      "Epoch [138/1000], Loss: 0.0047\n",
      "Epoch [139/1000], Loss: 0.0045\n",
      "Epoch [140/1000], Loss: 0.0045\n",
      "Epoch [141/1000], Loss: 0.0043\n",
      "Epoch [142/1000], Loss: 0.0042\n",
      "Epoch [143/1000], Loss: 0.0041\n",
      "Epoch [144/1000], Loss: 0.0041\n",
      "Epoch [145/1000], Loss: 0.0040\n",
      "Epoch [146/1000], Loss: 0.0041\n",
      "Epoch [147/1000], Loss: 0.0039\n",
      "Epoch [148/1000], Loss: 0.0037\n",
      "Epoch [149/1000], Loss: 0.0037\n",
      "Epoch [150/1000], Loss: 0.0037\n",
      "Epoch [151/1000], Loss: 0.0039\n",
      "Epoch [152/1000], Loss: 0.0035\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 302, lr :0.001, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.2543\n",
      "Epoch [2/1000], Loss: 0.2498\n",
      "Epoch [3/1000], Loss: 0.2493\n",
      "Epoch [4/1000], Loss: 0.2469\n",
      "Epoch [5/1000], Loss: 0.2461\n",
      "Epoch [6/1000], Loss: 0.2457\n",
      "Epoch [7/1000], Loss: 0.2442\n",
      "Epoch [8/1000], Loss: 0.2439\n",
      "Epoch [9/1000], Loss: 0.2418\n",
      "Epoch [10/1000], Loss: 0.2405\n",
      "Epoch [11/1000], Loss: 0.2392\n",
      "Epoch [12/1000], Loss: 0.2371\n",
      "Epoch [13/1000], Loss: 0.2351\n",
      "Epoch [14/1000], Loss: 0.2326\n",
      "Epoch [15/1000], Loss: 0.2321\n",
      "Epoch [16/1000], Loss: 0.2285\n",
      "Epoch [17/1000], Loss: 0.2268\n",
      "Epoch [18/1000], Loss: 0.2257\n",
      "Epoch [19/1000], Loss: 0.2228\n",
      "Epoch [20/1000], Loss: 0.2195\n",
      "Epoch [21/1000], Loss: 0.2158\n",
      "Epoch [22/1000], Loss: 0.2133\n",
      "Epoch [23/1000], Loss: 0.2102\n",
      "Epoch [24/1000], Loss: 0.2080\n",
      "Epoch [25/1000], Loss: 0.2029\n",
      "Epoch [26/1000], Loss: 0.2005\n",
      "Epoch [27/1000], Loss: 0.1965\n",
      "Epoch [28/1000], Loss: 0.1928\n",
      "Epoch [29/1000], Loss: 0.1887\n",
      "Epoch [30/1000], Loss: 0.1860\n",
      "Epoch [31/1000], Loss: 0.1837\n",
      "Epoch [32/1000], Loss: 0.1801\n",
      "Epoch [33/1000], Loss: 0.1766\n",
      "Epoch [34/1000], Loss: 0.1725\n",
      "Epoch [35/1000], Loss: 0.1689\n",
      "Epoch [36/1000], Loss: 0.1657\n",
      "Epoch [37/1000], Loss: 0.1612\n",
      "Epoch [38/1000], Loss: 0.1582\n",
      "Epoch [39/1000], Loss: 0.1533\n",
      "Epoch [40/1000], Loss: 0.1523\n",
      "Epoch [41/1000], Loss: 0.1481\n",
      "Epoch [42/1000], Loss: 0.1442\n",
      "Epoch [43/1000], Loss: 0.1415\n",
      "Epoch [44/1000], Loss: 0.1391\n",
      "Epoch [45/1000], Loss: 0.1363\n",
      "Epoch [46/1000], Loss: 0.1345\n",
      "Epoch [47/1000], Loss: 0.1300\n",
      "Epoch [48/1000], Loss: 0.1272\n",
      "Epoch [49/1000], Loss: 0.1244\n",
      "Epoch [50/1000], Loss: 0.1223\n",
      "Epoch [51/1000], Loss: 0.1199\n",
      "Epoch [52/1000], Loss: 0.1161\n",
      "Epoch [53/1000], Loss: 0.1148\n",
      "Epoch [54/1000], Loss: 0.1100\n",
      "Epoch [55/1000], Loss: 0.1100\n",
      "Epoch [56/1000], Loss: 0.1064\n",
      "Epoch [57/1000], Loss: 0.1060\n",
      "Epoch [58/1000], Loss: 0.1025\n",
      "Epoch [59/1000], Loss: 0.0999\n",
      "Epoch [60/1000], Loss: 0.0975\n",
      "Epoch [61/1000], Loss: 0.0960\n",
      "Epoch [62/1000], Loss: 0.0925\n",
      "Epoch [63/1000], Loss: 0.0901\n",
      "Epoch [64/1000], Loss: 0.0903\n",
      "Epoch [65/1000], Loss: 0.0857\n",
      "Epoch [66/1000], Loss: 0.0847\n",
      "Epoch [67/1000], Loss: 0.0831\n",
      "Epoch [68/1000], Loss: 0.0787\n",
      "Epoch [69/1000], Loss: 0.0764\n",
      "Epoch [70/1000], Loss: 0.0769\n",
      "Epoch [71/1000], Loss: 0.0740\n",
      "Epoch [72/1000], Loss: 0.0725\n",
      "Epoch [73/1000], Loss: 0.0703\n",
      "Epoch [74/1000], Loss: 0.0685\n",
      "Epoch [75/1000], Loss: 0.0674\n",
      "Epoch [76/1000], Loss: 0.0647\n",
      "Epoch [77/1000], Loss: 0.0630\n",
      "Epoch [78/1000], Loss: 0.0634\n",
      "Epoch [79/1000], Loss: 0.0603\n",
      "Epoch [80/1000], Loss: 0.0588\n",
      "Epoch [81/1000], Loss: 0.0564\n",
      "Epoch [82/1000], Loss: 0.0564\n",
      "Epoch [83/1000], Loss: 0.0548\n",
      "Epoch [84/1000], Loss: 0.0533\n",
      "Epoch [85/1000], Loss: 0.0518\n",
      "Epoch [86/1000], Loss: 0.0514\n",
      "Epoch [87/1000], Loss: 0.0490\n",
      "Epoch [88/1000], Loss: 0.0486\n",
      "Epoch [89/1000], Loss: 0.0468\n",
      "Epoch [90/1000], Loss: 0.0462\n",
      "Epoch [91/1000], Loss: 0.0453\n",
      "Epoch [92/1000], Loss: 0.0438\n",
      "Epoch [93/1000], Loss: 0.0418\n",
      "Epoch [94/1000], Loss: 0.0427\n",
      "Epoch [95/1000], Loss: 0.0403\n",
      "Epoch [96/1000], Loss: 0.0403\n",
      "Epoch [97/1000], Loss: 0.0385\n",
      "Epoch [98/1000], Loss: 0.0376\n",
      "Epoch [99/1000], Loss: 0.0357\n",
      "Epoch [100/1000], Loss: 0.0352\n",
      "Epoch [101/1000], Loss: 0.0347\n",
      "Epoch [102/1000], Loss: 0.0330\n",
      "Epoch [103/1000], Loss: 0.0322\n",
      "Epoch [104/1000], Loss: 0.0319\n",
      "Epoch [105/1000], Loss: 0.0311\n",
      "Epoch [106/1000], Loss: 0.0295\n",
      "Epoch [107/1000], Loss: 0.0282\n",
      "Epoch [108/1000], Loss: 0.0293\n",
      "Epoch [109/1000], Loss: 0.0282\n",
      "Epoch [110/1000], Loss: 0.0263\n",
      "Epoch [111/1000], Loss: 0.0248\n",
      "Epoch [112/1000], Loss: 0.0239\n",
      "Epoch [113/1000], Loss: 0.0246\n",
      "Epoch [114/1000], Loss: 0.0225\n",
      "Epoch [115/1000], Loss: 0.0212\n",
      "Epoch [116/1000], Loss: 0.0206\n",
      "Epoch [117/1000], Loss: 0.0190\n",
      "Epoch [118/1000], Loss: 0.0193\n",
      "Epoch [119/1000], Loss: 0.0186\n",
      "Epoch [120/1000], Loss: 0.0172\n",
      "Epoch [121/1000], Loss: 0.0171\n",
      "Epoch [122/1000], Loss: 0.0168\n",
      "Epoch [123/1000], Loss: 0.0153\n",
      "Epoch [124/1000], Loss: 0.0154\n",
      "Epoch [125/1000], Loss: 0.0149\n",
      "Epoch [126/1000], Loss: 0.0144\n",
      "Epoch [127/1000], Loss: 0.0138\n",
      "Epoch [128/1000], Loss: 0.0133\n",
      "Epoch [129/1000], Loss: 0.0131\n",
      "Epoch [130/1000], Loss: 0.0127\n",
      "Epoch [131/1000], Loss: 0.0121\n",
      "Epoch [132/1000], Loss: 0.0112\n",
      "Epoch [133/1000], Loss: 0.0108\n",
      "Epoch [134/1000], Loss: 0.0112\n",
      "Epoch [135/1000], Loss: 0.0106\n",
      "Epoch [136/1000], Loss: 0.0101\n",
      "Epoch [137/1000], Loss: 0.0094\n",
      "Epoch [138/1000], Loss: 0.0093\n",
      "Epoch [139/1000], Loss: 0.0092\n",
      "Epoch [140/1000], Loss: 0.0088\n",
      "Epoch [141/1000], Loss: 0.0082\n",
      "Epoch [142/1000], Loss: 0.0084\n",
      "Epoch [143/1000], Loss: 0.0078\n",
      "Epoch [144/1000], Loss: 0.0075\n",
      "Epoch [145/1000], Loss: 0.0077\n",
      "Epoch [146/1000], Loss: 0.0072\n",
      "Epoch [147/1000], Loss: 0.0075\n",
      "Epoch [148/1000], Loss: 0.0065\n",
      "Epoch [149/1000], Loss: 0.0067\n",
      "Epoch [150/1000], Loss: 0.0064\n",
      "Epoch [151/1000], Loss: 0.0059\n",
      "Epoch [152/1000], Loss: 0.0057\n",
      "Epoch [153/1000], Loss: 0.0058\n",
      "Epoch [154/1000], Loss: 0.0056\n",
      "Epoch [155/1000], Loss: 0.0052\n",
      "Epoch [156/1000], Loss: 0.0051\n",
      "Epoch [157/1000], Loss: 0.0047\n",
      "Epoch [158/1000], Loss: 0.0046\n",
      "Epoch [159/1000], Loss: 0.0046\n",
      "Epoch [160/1000], Loss: 0.0046\n",
      "Epoch [161/1000], Loss: 0.0042\n",
      "Epoch [162/1000], Loss: 0.0056\n",
      "Epoch [163/1000], Loss: 0.0041\n",
      "Epoch [164/1000], Loss: 0.0040\n",
      "Epoch [165/1000], Loss: 0.0039\n",
      "Epoch [166/1000], Loss: 0.0038\n",
      "Epoch [167/1000], Loss: 0.0038\n",
      "Epoch [168/1000], Loss: 0.0035\n",
      "Epoch [169/1000], Loss: 0.0033\n",
      "Epoch [170/1000], Loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [171/1000], Loss: 0.0032\n",
      "Epoch [172/1000], Loss: 0.0030\n",
      "Epoch [173/1000], Loss: 0.0029\n",
      "Epoch [174/1000], Loss: 0.0028\n",
      "Epoch [175/1000], Loss: 0.0027\n",
      "Epoch [176/1000], Loss: 0.0029\n",
      "Epoch [177/1000], Loss: 0.0027\n",
      "Epoch [178/1000], Loss: 0.0027\n",
      "Epoch [179/1000], Loss: 0.0027\n",
      "Epoch [180/1000], Loss: 0.0024\n",
      "Epoch [181/1000], Loss: 0.0022\n",
      "Epoch [182/1000], Loss: 0.0024\n",
      "Epoch [183/1000], Loss: 0.0021\n",
      "Epoch [184/1000], Loss: 0.0022\n",
      "Epoch [185/1000], Loss: 0.0021\n",
      "Epoch [186/1000], Loss: 0.0020\n",
      "Epoch [187/1000], Loss: 0.0020\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 302, lr :0.001, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2784\n",
      "Epoch [2/1000], Loss: 0.2789\n",
      "Epoch [3/1000], Loss: 0.2778\n",
      "Epoch [4/1000], Loss: 0.2782\n",
      "Epoch [5/1000], Loss: 0.2779\n",
      "Epoch [6/1000], Loss: 0.2777\n",
      "Epoch [7/1000], Loss: 0.2770\n",
      "Epoch [8/1000], Loss: 0.2776\n",
      "Epoch [9/1000], Loss: 0.2773\n",
      "Epoch [10/1000], Loss: 0.2761\n",
      "Epoch [11/1000], Loss: 0.2760\n",
      "Epoch [12/1000], Loss: 0.2766\n",
      "Epoch [13/1000], Loss: 0.2750\n",
      "Epoch [14/1000], Loss: 0.2758\n",
      "Epoch [15/1000], Loss: 0.2754\n",
      "Epoch [16/1000], Loss: 0.2752\n",
      "Epoch [17/1000], Loss: 0.2750\n",
      "Epoch [18/1000], Loss: 0.2751\n",
      "Epoch [19/1000], Loss: 0.2746\n",
      "Epoch [20/1000], Loss: 0.2744\n",
      "Epoch [21/1000], Loss: 0.2748\n",
      "Epoch [22/1000], Loss: 0.2747\n",
      "Epoch [23/1000], Loss: 0.2737\n",
      "Epoch [24/1000], Loss: 0.2734\n",
      "Epoch [25/1000], Loss: 0.2738\n",
      "Epoch [26/1000], Loss: 0.2731\n",
      "Epoch [27/1000], Loss: 0.2729\n",
      "Epoch [28/1000], Loss: 0.2728\n",
      "Epoch [29/1000], Loss: 0.2729\n",
      "Epoch [30/1000], Loss: 0.2732\n",
      "Epoch [31/1000], Loss: 0.2723\n",
      "Epoch [32/1000], Loss: 0.2726\n",
      "Epoch [33/1000], Loss: 0.2719\n",
      "Epoch [34/1000], Loss: 0.2722\n",
      "Epoch [35/1000], Loss: 0.2716\n",
      "Epoch [36/1000], Loss: 0.2717\n",
      "Epoch [37/1000], Loss: 0.2716\n",
      "Epoch [38/1000], Loss: 0.2709\n",
      "Epoch [39/1000], Loss: 0.2710\n",
      "Epoch [40/1000], Loss: 0.2705\n",
      "Epoch [41/1000], Loss: 0.2700\n",
      "Epoch [42/1000], Loss: 0.2700\n",
      "Epoch [43/1000], Loss: 0.2709\n",
      "Epoch [44/1000], Loss: 0.2703\n",
      "Epoch [45/1000], Loss: 0.2700\n",
      "Epoch [46/1000], Loss: 0.2698\n",
      "Epoch [47/1000], Loss: 0.2695\n",
      "Epoch [48/1000], Loss: 0.2694\n",
      "Epoch [49/1000], Loss: 0.2686\n",
      "Epoch [50/1000], Loss: 0.2689\n",
      "Epoch [51/1000], Loss: 0.2686\n",
      "Epoch [52/1000], Loss: 0.2688\n",
      "Epoch [53/1000], Loss: 0.2683\n",
      "Epoch [54/1000], Loss: 0.2686\n",
      "Epoch [55/1000], Loss: 0.2691\n",
      "Epoch [56/1000], Loss: 0.2682\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 43.70 %\n",
      "Training model with batch_size: 302, lr :0.01, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.2533\n",
      "Epoch [2/1000], Loss: 0.2484\n",
      "Epoch [3/1000], Loss: 0.2450\n",
      "Epoch [4/1000], Loss: 0.2468\n",
      "Epoch [5/1000], Loss: 0.2472\n",
      "Epoch [6/1000], Loss: 0.2448\n",
      "Epoch [7/1000], Loss: 0.2438\n",
      "Epoch [8/1000], Loss: 0.2434\n",
      "Epoch [9/1000], Loss: 0.2429\n",
      "Epoch [10/1000], Loss: 0.2429\n",
      "Epoch [11/1000], Loss: 0.2416\n",
      "Epoch [12/1000], Loss: 0.2416\n",
      "Epoch [13/1000], Loss: 0.2409\n",
      "Epoch [14/1000], Loss: 0.2417\n",
      "Epoch [15/1000], Loss: 0.2399\n",
      "Epoch [16/1000], Loss: 0.2389\n",
      "Epoch [17/1000], Loss: 0.2381\n",
      "Epoch [18/1000], Loss: 0.2375\n",
      "Epoch [19/1000], Loss: 0.2375\n",
      "Epoch [20/1000], Loss: 0.2372\n",
      "Epoch [21/1000], Loss: 0.2362\n",
      "Epoch [22/1000], Loss: 0.2375\n",
      "Epoch [23/1000], Loss: 0.2350\n",
      "Epoch [24/1000], Loss: 0.2349\n",
      "Epoch [25/1000], Loss: 0.2336\n",
      "Epoch [26/1000], Loss: 0.2338\n",
      "Epoch [27/1000], Loss: 0.2332\n",
      "Epoch [28/1000], Loss: 0.2304\n",
      "Epoch [29/1000], Loss: 0.2301\n",
      "Epoch [30/1000], Loss: 0.2291\n",
      "Epoch [31/1000], Loss: 0.2286\n",
      "Epoch [32/1000], Loss: 0.2274\n",
      "Epoch [33/1000], Loss: 0.2267\n",
      "Epoch [34/1000], Loss: 0.2253\n",
      "Epoch [35/1000], Loss: 0.2261\n",
      "Epoch [36/1000], Loss: 0.2237\n",
      "Epoch [37/1000], Loss: 0.2225\n",
      "Epoch [38/1000], Loss: 0.2230\n",
      "Epoch [39/1000], Loss: 0.2207\n",
      "Epoch [40/1000], Loss: 0.2207\n",
      "Epoch [41/1000], Loss: 0.2209\n",
      "Epoch [42/1000], Loss: 0.2195\n",
      "Epoch [43/1000], Loss: 0.2186\n",
      "Epoch [44/1000], Loss: 0.2172\n",
      "Epoch [45/1000], Loss: 0.2159\n",
      "Epoch [46/1000], Loss: 0.2168\n",
      "Epoch [47/1000], Loss: 0.2136\n",
      "Epoch [48/1000], Loss: 0.2134\n",
      "Epoch [49/1000], Loss: 0.2129\n",
      "Epoch [50/1000], Loss: 0.2111\n",
      "Epoch [51/1000], Loss: 0.2105\n",
      "Epoch [52/1000], Loss: 0.2101\n",
      "Epoch [53/1000], Loss: 0.2096\n",
      "Epoch [54/1000], Loss: 0.2080\n",
      "Epoch [55/1000], Loss: 0.2065\n",
      "Epoch [56/1000], Loss: 0.2049\n",
      "Epoch [57/1000], Loss: 0.2054\n",
      "Epoch [58/1000], Loss: 0.2044\n",
      "Epoch [59/1000], Loss: 0.2036\n",
      "Epoch [60/1000], Loss: 0.2033\n",
      "Epoch [61/1000], Loss: 0.2014\n",
      "Epoch [62/1000], Loss: 0.2015\n",
      "Epoch [63/1000], Loss: 0.1993\n",
      "Epoch [64/1000], Loss: 0.1978\n",
      "Epoch [65/1000], Loss: 0.1999\n",
      "Epoch [66/1000], Loss: 0.1971\n",
      "Epoch [67/1000], Loss: 0.1966\n",
      "Epoch [68/1000], Loss: 0.1959\n",
      "Epoch [69/1000], Loss: 0.1945\n",
      "Epoch [70/1000], Loss: 0.1918\n",
      "Epoch [71/1000], Loss: 0.1930\n",
      "Epoch [72/1000], Loss: 0.1926\n",
      "Epoch [73/1000], Loss: 0.1921\n",
      "Epoch [74/1000], Loss: 0.1904\n",
      "Epoch [75/1000], Loss: 0.1886\n",
      "Epoch [76/1000], Loss: 0.1898\n",
      "Epoch [77/1000], Loss: 0.1876\n",
      "Epoch [78/1000], Loss: 0.1886\n",
      "Epoch [79/1000], Loss: 0.1861\n",
      "Epoch [80/1000], Loss: 0.1860\n",
      "Epoch [81/1000], Loss: 0.1860\n",
      "Epoch [82/1000], Loss: 0.1855\n",
      "Epoch [83/1000], Loss: 0.1841\n",
      "Epoch [84/1000], Loss: 0.1840\n",
      "Epoch [85/1000], Loss: 0.1833\n",
      "Epoch [86/1000], Loss: 0.1833\n",
      "Epoch [87/1000], Loss: 0.1808\n",
      "Epoch [88/1000], Loss: 0.1795\n",
      "Epoch [89/1000], Loss: 0.1791\n",
      "Epoch [90/1000], Loss: 0.1792\n",
      "Epoch [91/1000], Loss: 0.1782\n",
      "Epoch [92/1000], Loss: 0.1768\n",
      "Epoch [93/1000], Loss: 0.1762\n",
      "Epoch [94/1000], Loss: 0.1773\n",
      "Epoch [95/1000], Loss: 0.1765\n",
      "Epoch [96/1000], Loss: 0.1746\n",
      "Epoch [97/1000], Loss: 0.1744\n",
      "Epoch [98/1000], Loss: 0.1725\n",
      "Epoch [99/1000], Loss: 0.1757\n",
      "Epoch [100/1000], Loss: 0.1731\n",
      "Epoch [101/1000], Loss: 0.1717\n",
      "Epoch [102/1000], Loss: 0.1707\n",
      "Epoch [103/1000], Loss: 0.1702\n",
      "Epoch [104/1000], Loss: 0.1695\n",
      "Epoch [105/1000], Loss: 0.1686\n",
      "Epoch [106/1000], Loss: 0.1693\n",
      "Epoch [107/1000], Loss: 0.1683\n",
      "Epoch [108/1000], Loss: 0.1679\n",
      "Epoch [109/1000], Loss: 0.1667\n",
      "Epoch [110/1000], Loss: 0.1656\n",
      "Epoch [111/1000], Loss: 0.1662\n",
      "Epoch [112/1000], Loss: 0.1653\n",
      "Epoch [113/1000], Loss: 0.1636\n",
      "Epoch [114/1000], Loss: 0.1636\n",
      "Epoch [115/1000], Loss: 0.1632\n",
      "Epoch [116/1000], Loss: 0.1625\n",
      "Epoch [117/1000], Loss: 0.1634\n",
      "Epoch [118/1000], Loss: 0.1619\n",
      "Epoch [119/1000], Loss: 0.1629\n",
      "Epoch [120/1000], Loss: 0.1587\n",
      "Epoch [121/1000], Loss: 0.1611\n",
      "Epoch [122/1000], Loss: 0.1586\n",
      "Epoch [123/1000], Loss: 0.1589\n",
      "Epoch [124/1000], Loss: 0.1591\n",
      "Epoch [125/1000], Loss: 0.1573\n",
      "Epoch [126/1000], Loss: 0.1562\n",
      "Epoch [127/1000], Loss: 0.1561\n",
      "Epoch [128/1000], Loss: 0.1562\n",
      "Epoch [129/1000], Loss: 0.1548\n",
      "Epoch [130/1000], Loss: 0.1536\n",
      "Epoch [131/1000], Loss: 0.1554\n",
      "Epoch [132/1000], Loss: 0.1541\n",
      "Epoch [133/1000], Loss: 0.1528\n",
      "Epoch [134/1000], Loss: 0.1545\n",
      "Epoch [135/1000], Loss: 0.1533\n",
      "Epoch [136/1000], Loss: 0.1522\n",
      "Epoch [137/1000], Loss: 0.1522\n",
      "Epoch [138/1000], Loss: 0.1500\n",
      "Epoch [139/1000], Loss: 0.1504\n",
      "Epoch [140/1000], Loss: 0.1517\n",
      "Epoch [141/1000], Loss: 0.1481\n",
      "Epoch [142/1000], Loss: 0.1489\n",
      "Epoch [143/1000], Loss: 0.1474\n",
      "Epoch [144/1000], Loss: 0.1488\n",
      "Epoch [145/1000], Loss: 0.1476\n",
      "Epoch [146/1000], Loss: 0.1488\n",
      "Epoch [147/1000], Loss: 0.1470\n",
      "Epoch [148/1000], Loss: 0.1450\n",
      "Epoch [149/1000], Loss: 0.1448\n",
      "Epoch [150/1000], Loss: 0.1455\n",
      "Epoch [151/1000], Loss: 0.1434\n",
      "Epoch [152/1000], Loss: 0.1445\n",
      "Epoch [153/1000], Loss: 0.1437\n",
      "Epoch [154/1000], Loss: 0.1424\n",
      "Epoch [155/1000], Loss: 0.1435\n",
      "Epoch [156/1000], Loss: 0.1416\n",
      "Epoch [157/1000], Loss: 0.1399\n",
      "Epoch [158/1000], Loss: 0.1400\n",
      "Epoch [159/1000], Loss: 0.1414\n",
      "Epoch [160/1000], Loss: 0.1394\n",
      "Epoch [161/1000], Loss: 0.1377\n",
      "Epoch [162/1000], Loss: 0.1390\n",
      "Epoch [163/1000], Loss: 0.1385\n",
      "Epoch [164/1000], Loss: 0.1374\n",
      "Epoch [165/1000], Loss: 0.1374\n",
      "Epoch [166/1000], Loss: 0.1363\n",
      "Epoch [167/1000], Loss: 0.1358\n",
      "Epoch [168/1000], Loss: 0.1358\n",
      "Epoch [169/1000], Loss: 0.1344\n",
      "Epoch [170/1000], Loss: 0.1346\n",
      "Epoch [171/1000], Loss: 0.1334\n",
      "Epoch [172/1000], Loss: 0.1338\n",
      "Epoch [173/1000], Loss: 0.1320\n",
      "Epoch [174/1000], Loss: 0.1319\n",
      "Epoch [175/1000], Loss: 0.1334\n",
      "Epoch [176/1000], Loss: 0.1323\n",
      "Epoch [177/1000], Loss: 0.1308\n",
      "Epoch [178/1000], Loss: 0.1308\n",
      "Epoch [179/1000], Loss: 0.1307\n",
      "Epoch [180/1000], Loss: 0.1291\n",
      "Epoch [181/1000], Loss: 0.1298\n",
      "Epoch [182/1000], Loss: 0.1285\n",
      "Epoch [183/1000], Loss: 0.1280\n",
      "Epoch [184/1000], Loss: 0.1280\n",
      "Epoch [185/1000], Loss: 0.1283\n",
      "Epoch [186/1000], Loss: 0.1274\n",
      "Epoch [187/1000], Loss: 0.1275\n",
      "Epoch [188/1000], Loss: 0.1266\n",
      "Epoch [189/1000], Loss: 0.1248\n",
      "Epoch [190/1000], Loss: 0.1258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [191/1000], Loss: 0.1232\n",
      "Epoch [192/1000], Loss: 0.1242\n",
      "Epoch [193/1000], Loss: 0.1233\n",
      "Epoch [194/1000], Loss: 0.1222\n",
      "Epoch [195/1000], Loss: 0.1243\n",
      "Epoch [196/1000], Loss: 0.1215\n",
      "Epoch [197/1000], Loss: 0.1212\n",
      "Epoch [198/1000], Loss: 0.1225\n",
      "Epoch [199/1000], Loss: 0.1209\n",
      "Epoch [200/1000], Loss: 0.1205\n",
      "Epoch [201/1000], Loss: 0.1189\n",
      "Epoch [202/1000], Loss: 0.1193\n",
      "Epoch [203/1000], Loss: 0.1178\n",
      "Epoch [204/1000], Loss: 0.1192\n",
      "Epoch [205/1000], Loss: 0.1182\n",
      "Epoch [206/1000], Loss: 0.1171\n",
      "Epoch [207/1000], Loss: 0.1170\n",
      "Epoch [208/1000], Loss: 0.1175\n",
      "Epoch [209/1000], Loss: 0.1162\n",
      "Epoch [210/1000], Loss: 0.1159\n",
      "Epoch [211/1000], Loss: 0.1153\n",
      "Epoch [212/1000], Loss: 0.1151\n",
      "Epoch [213/1000], Loss: 0.1130\n",
      "Epoch [214/1000], Loss: 0.1132\n",
      "Epoch [215/1000], Loss: 0.1116\n",
      "Epoch [216/1000], Loss: 0.1135\n",
      "Epoch [217/1000], Loss: 0.1123\n",
      "Epoch [218/1000], Loss: 0.1135\n",
      "Epoch [219/1000], Loss: 0.1110\n",
      "Epoch [220/1000], Loss: 0.1098\n",
      "Epoch [221/1000], Loss: 0.1098\n",
      "Epoch [222/1000], Loss: 0.1099\n",
      "Epoch [223/1000], Loss: 0.1091\n",
      "Epoch [224/1000], Loss: 0.1088\n",
      "Epoch [225/1000], Loss: 0.1093\n",
      "Epoch [226/1000], Loss: 0.1073\n",
      "Epoch [227/1000], Loss: 0.1065\n",
      "Epoch [228/1000], Loss: 0.1050\n",
      "Epoch [229/1000], Loss: 0.1051\n",
      "Epoch [230/1000], Loss: 0.1061\n",
      "Epoch [231/1000], Loss: 0.1045\n",
      "Epoch [232/1000], Loss: 0.1038\n",
      "Epoch [233/1000], Loss: 0.1039\n",
      "Epoch [234/1000], Loss: 0.1031\n",
      "Epoch [235/1000], Loss: 0.1031\n",
      "Epoch [236/1000], Loss: 0.1023\n",
      "Epoch [237/1000], Loss: 0.1025\n",
      "Epoch [238/1000], Loss: 0.1021\n",
      "Epoch [239/1000], Loss: 0.1010\n",
      "Epoch [240/1000], Loss: 0.1002\n",
      "Epoch [241/1000], Loss: 0.1011\n",
      "Epoch [242/1000], Loss: 0.0980\n",
      "Epoch [243/1000], Loss: 0.0989\n",
      "Epoch [244/1000], Loss: 0.0982\n",
      "Epoch [245/1000], Loss: 0.0985\n",
      "Epoch [246/1000], Loss: 0.0958\n",
      "Epoch [247/1000], Loss: 0.0979\n",
      "Epoch [248/1000], Loss: 0.0955\n",
      "Epoch [249/1000], Loss: 0.0946\n",
      "Epoch [250/1000], Loss: 0.0953\n",
      "Epoch [251/1000], Loss: 0.0950\n",
      "Epoch [252/1000], Loss: 0.0939\n",
      "Epoch [253/1000], Loss: 0.0934\n",
      "Epoch [254/1000], Loss: 0.0917\n",
      "Epoch [255/1000], Loss: 0.0912\n",
      "Epoch [256/1000], Loss: 0.0913\n",
      "Epoch [257/1000], Loss: 0.0905\n",
      "Epoch [258/1000], Loss: 0.0890\n",
      "Epoch [259/1000], Loss: 0.0886\n",
      "Epoch [260/1000], Loss: 0.0863\n",
      "Epoch [261/1000], Loss: 0.0872\n",
      "Epoch [262/1000], Loss: 0.0862\n",
      "Epoch [263/1000], Loss: 0.0871\n",
      "Epoch [264/1000], Loss: 0.0838\n",
      "Epoch [265/1000], Loss: 0.0844\n",
      "Epoch [266/1000], Loss: 0.0834\n",
      "Epoch [267/1000], Loss: 0.0830\n",
      "Epoch [268/1000], Loss: 0.0831\n",
      "Epoch [269/1000], Loss: 0.0815\n",
      "Epoch [270/1000], Loss: 0.0820\n",
      "Epoch [271/1000], Loss: 0.0807\n",
      "Epoch [272/1000], Loss: 0.0810\n",
      "Epoch [273/1000], Loss: 0.0807\n",
      "Epoch [274/1000], Loss: 0.0799\n",
      "Epoch [275/1000], Loss: 0.0788\n",
      "Epoch [276/1000], Loss: 0.0787\n",
      "Epoch [277/1000], Loss: 0.0774\n",
      "Epoch [278/1000], Loss: 0.0769\n",
      "Epoch [279/1000], Loss: 0.0771\n",
      "Epoch [280/1000], Loss: 0.0767\n",
      "Epoch [281/1000], Loss: 0.0758\n",
      "Epoch [282/1000], Loss: 0.0754\n",
      "Epoch [283/1000], Loss: 0.0752\n",
      "Epoch [284/1000], Loss: 0.0744\n",
      "Epoch [285/1000], Loss: 0.0732\n",
      "Epoch [286/1000], Loss: 0.0723\n",
      "Epoch [287/1000], Loss: 0.0724\n",
      "Epoch [288/1000], Loss: 0.0723\n",
      "Epoch [289/1000], Loss: 0.0709\n",
      "Epoch [290/1000], Loss: 0.0705\n",
      "Epoch [291/1000], Loss: 0.0695\n",
      "Epoch [292/1000], Loss: 0.0691\n",
      "Epoch [293/1000], Loss: 0.0686\n",
      "Epoch [294/1000], Loss: 0.0684\n",
      "Epoch [295/1000], Loss: 0.0683\n",
      "Epoch [296/1000], Loss: 0.0671\n",
      "Epoch [297/1000], Loss: 0.0665\n",
      "Epoch [298/1000], Loss: 0.0660\n",
      "Epoch [299/1000], Loss: 0.0650\n",
      "Epoch [300/1000], Loss: 0.0651\n",
      "Epoch [301/1000], Loss: 0.0640\n",
      "Epoch [302/1000], Loss: 0.0638\n",
      "Epoch [303/1000], Loss: 0.0635\n",
      "Epoch [304/1000], Loss: 0.0620\n",
      "Epoch [305/1000], Loss: 0.0624\n",
      "Epoch [306/1000], Loss: 0.0619\n",
      "Epoch [307/1000], Loss: 0.0619\n",
      "Epoch [308/1000], Loss: 0.0610\n",
      "Epoch [309/1000], Loss: 0.0611\n",
      "Epoch [310/1000], Loss: 0.0603\n",
      "Epoch [311/1000], Loss: 0.0588\n",
      "Epoch [312/1000], Loss: 0.0591\n",
      "Epoch [313/1000], Loss: 0.0593\n",
      "Epoch [314/1000], Loss: 0.0585\n",
      "Epoch [315/1000], Loss: 0.0582\n",
      "Epoch [316/1000], Loss: 0.0592\n",
      "Epoch [317/1000], Loss: 0.0570\n",
      "Epoch [318/1000], Loss: 0.0569\n",
      "Epoch [319/1000], Loss: 0.0572\n",
      "Epoch [320/1000], Loss: 0.0559\n",
      "Epoch [321/1000], Loss: 0.0557\n",
      "Epoch [322/1000], Loss: 0.0552\n",
      "Epoch [323/1000], Loss: 0.0554\n",
      "Epoch [324/1000], Loss: 0.0548\n",
      "Epoch [325/1000], Loss: 0.0543\n",
      "Epoch [326/1000], Loss: 0.0541\n",
      "Epoch [327/1000], Loss: 0.0535\n",
      "Epoch [328/1000], Loss: 0.0530\n",
      "Epoch [329/1000], Loss: 0.0522\n",
      "Epoch [330/1000], Loss: 0.0529\n",
      "Epoch [331/1000], Loss: 0.0520\n",
      "Epoch [332/1000], Loss: 0.0521\n",
      "Epoch [333/1000], Loss: 0.0519\n",
      "Epoch [334/1000], Loss: 0.0512\n",
      "Epoch [335/1000], Loss: 0.0517\n",
      "Epoch [336/1000], Loss: 0.0507\n",
      "Epoch [337/1000], Loss: 0.0501\n",
      "Epoch [338/1000], Loss: 0.0499\n",
      "Epoch [339/1000], Loss: 0.0497\n",
      "Epoch [340/1000], Loss: 0.0493\n",
      "Epoch [341/1000], Loss: 0.0493\n",
      "Epoch [342/1000], Loss: 0.0490\n",
      "Epoch [343/1000], Loss: 0.0486\n",
      "Epoch [344/1000], Loss: 0.0485\n",
      "Epoch [345/1000], Loss: 0.0473\n",
      "Epoch [346/1000], Loss: 0.0480\n",
      "Epoch [347/1000], Loss: 0.0470\n",
      "Epoch [348/1000], Loss: 0.0473\n",
      "Epoch [349/1000], Loss: 0.0466\n",
      "Epoch [350/1000], Loss: 0.0462\n",
      "Epoch [351/1000], Loss: 0.0459\n",
      "Epoch [352/1000], Loss: 0.0456\n",
      "Epoch [353/1000], Loss: 0.0453\n",
      "Epoch [354/1000], Loss: 0.0449\n",
      "Epoch [355/1000], Loss: 0.0450\n",
      "Epoch [356/1000], Loss: 0.0443\n",
      "Epoch [357/1000], Loss: 0.0438\n",
      "Epoch [358/1000], Loss: 0.0444\n",
      "Epoch [359/1000], Loss: 0.0437\n",
      "Epoch [360/1000], Loss: 0.0441\n",
      "Epoch [361/1000], Loss: 0.0432\n",
      "Epoch [362/1000], Loss: 0.0431\n",
      "Epoch [363/1000], Loss: 0.0426\n",
      "Epoch [364/1000], Loss: 0.0431\n",
      "Epoch [365/1000], Loss: 0.0427\n",
      "Epoch [366/1000], Loss: 0.0424\n",
      "Epoch [367/1000], Loss: 0.0427\n",
      "Epoch [368/1000], Loss: 0.0416\n",
      "Epoch [369/1000], Loss: 0.0416\n",
      "Epoch [370/1000], Loss: 0.0409\n",
      "Epoch [371/1000], Loss: 0.0405\n",
      "Epoch [372/1000], Loss: 0.0407\n",
      "Epoch [373/1000], Loss: 0.0405\n",
      "Epoch [374/1000], Loss: 0.0398\n",
      "Epoch [375/1000], Loss: 0.0398\n",
      "Epoch [376/1000], Loss: 0.0396\n",
      "Epoch [377/1000], Loss: 0.0398\n",
      "Epoch [378/1000], Loss: 0.0395\n",
      "Epoch [379/1000], Loss: 0.0389\n",
      "Epoch [380/1000], Loss: 0.0387\n",
      "Epoch [381/1000], Loss: 0.0381\n",
      "Epoch [382/1000], Loss: 0.0382\n",
      "Epoch [383/1000], Loss: 0.0381\n",
      "Epoch [384/1000], Loss: 0.0380\n",
      "Epoch [385/1000], Loss: 0.0376\n",
      "Epoch [386/1000], Loss: 0.0373\n",
      "Epoch [387/1000], Loss: 0.0371\n",
      "Epoch [388/1000], Loss: 0.0371\n",
      "Epoch [389/1000], Loss: 0.0368\n",
      "Epoch [390/1000], Loss: 0.0376\n",
      "Epoch [391/1000], Loss: 0.0363\n",
      "Epoch [392/1000], Loss: 0.0364\n",
      "Epoch [393/1000], Loss: 0.0359\n",
      "Epoch [394/1000], Loss: 0.0357\n",
      "Epoch [395/1000], Loss: 0.0357\n",
      "Epoch [396/1000], Loss: 0.0353\n",
      "Epoch [397/1000], Loss: 0.0355\n",
      "Epoch [398/1000], Loss: 0.0350\n",
      "Epoch [399/1000], Loss: 0.0345\n",
      "Epoch [400/1000], Loss: 0.0344\n",
      "Epoch [401/1000], Loss: 0.0340\n",
      "Epoch [402/1000], Loss: 0.0337\n",
      "Epoch [403/1000], Loss: 0.0334\n",
      "Epoch [404/1000], Loss: 0.0331\n",
      "Epoch [405/1000], Loss: 0.0332\n",
      "Epoch [406/1000], Loss: 0.0327\n",
      "Epoch [407/1000], Loss: 0.0323\n",
      "Epoch [408/1000], Loss: 0.0329\n",
      "Epoch [409/1000], Loss: 0.0325\n",
      "Epoch [410/1000], Loss: 0.0326\n",
      "Epoch [411/1000], Loss: 0.0326\n",
      "Epoch [412/1000], Loss: 0.0323\n",
      "Epoch [413/1000], Loss: 0.0320\n",
      "Epoch [414/1000], Loss: 0.0320\n",
      "Epoch [415/1000], Loss: 0.0317\n",
      "Epoch [416/1000], Loss: 0.0317\n",
      "Epoch [417/1000], Loss: 0.0312\n",
      "Epoch [418/1000], Loss: 0.0310\n",
      "Epoch [419/1000], Loss: 0.0305\n",
      "Epoch [420/1000], Loss: 0.0308\n",
      "Epoch [421/1000], Loss: 0.0306\n",
      "Epoch [422/1000], Loss: 0.0299\n",
      "Epoch [423/1000], Loss: 0.0306\n",
      "Epoch [424/1000], Loss: 0.0303\n",
      "Epoch [425/1000], Loss: 0.0298\n",
      "Epoch [426/1000], Loss: 0.0296\n",
      "Epoch [427/1000], Loss: 0.0298\n",
      "Epoch [428/1000], Loss: 0.0297\n",
      "Epoch [429/1000], Loss: 0.0291\n",
      "Epoch [430/1000], Loss: 0.0290\n",
      "Epoch [431/1000], Loss: 0.0292\n",
      "Epoch [432/1000], Loss: 0.0287\n",
      "Epoch [433/1000], Loss: 0.0287\n",
      "Epoch [434/1000], Loss: 0.0288\n",
      "Epoch [435/1000], Loss: 0.0287\n",
      "Epoch [436/1000], Loss: 0.0282\n",
      "Epoch [437/1000], Loss: 0.0280\n",
      "Epoch [438/1000], Loss: 0.0280\n",
      "Epoch [439/1000], Loss: 0.0277\n",
      "Epoch [440/1000], Loss: 0.0275\n",
      "Epoch [441/1000], Loss: 0.0274\n",
      "Epoch [442/1000], Loss: 0.0275\n",
      "Epoch [443/1000], Loss: 0.0271\n",
      "Epoch [444/1000], Loss: 0.0274\n",
      "Epoch [445/1000], Loss: 0.0270\n",
      "Epoch [446/1000], Loss: 0.0272\n",
      "Epoch [447/1000], Loss: 0.0265\n",
      "Epoch [448/1000], Loss: 0.0270\n",
      "Epoch [449/1000], Loss: 0.0266\n",
      "Epoch [450/1000], Loss: 0.0265\n",
      "Epoch [451/1000], Loss: 0.0264\n",
      "Epoch [452/1000], Loss: 0.0258\n",
      "Epoch [453/1000], Loss: 0.0255\n",
      "Epoch [454/1000], Loss: 0.0259\n",
      "Epoch [455/1000], Loss: 0.0255\n",
      "Epoch [456/1000], Loss: 0.0257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [457/1000], Loss: 0.0258\n",
      "Epoch [458/1000], Loss: 0.0254\n",
      "Epoch [459/1000], Loss: 0.0253\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 99.90 %\n",
      "Training model with batch_size: 302, lr :0.01, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.2575\n",
      "Epoch [2/1000], Loss: 0.2472\n",
      "Epoch [3/1000], Loss: 0.2459\n",
      "Epoch [4/1000], Loss: 0.2415\n",
      "Epoch [5/1000], Loss: 0.2363\n",
      "Epoch [6/1000], Loss: 0.2284\n",
      "Epoch [7/1000], Loss: 0.2200\n",
      "Epoch [8/1000], Loss: 0.2093\n",
      "Epoch [9/1000], Loss: 0.1969\n",
      "Epoch [10/1000], Loss: 0.1690\n",
      "Epoch [11/1000], Loss: 0.1267\n",
      "Epoch [12/1000], Loss: 0.0827\n",
      "Epoch [13/1000], Loss: 0.0543\n",
      "Epoch [14/1000], Loss: 0.0402\n",
      "Epoch [15/1000], Loss: 0.0305\n",
      "Epoch [16/1000], Loss: 0.0247\n",
      "Epoch [17/1000], Loss: 0.0180\n",
      "Epoch [18/1000], Loss: 0.0144\n",
      "Epoch [19/1000], Loss: 0.0107\n",
      "Epoch [20/1000], Loss: 0.0083\n",
      "Epoch [21/1000], Loss: 0.0068\n",
      "Epoch [22/1000], Loss: 0.0045\n",
      "Epoch [23/1000], Loss: 0.0034\n",
      "Epoch [24/1000], Loss: 0.0030\n",
      "Epoch [25/1000], Loss: 0.0027\n",
      "Epoch [26/1000], Loss: 0.0019\n",
      "Epoch [27/1000], Loss: 0.0017\n",
      "Epoch [28/1000], Loss: 0.0015\n",
      "Epoch [29/1000], Loss: 0.0013\n",
      "Epoch [30/1000], Loss: 0.0013\n",
      "Epoch [31/1000], Loss: 0.0013\n",
      "Epoch [32/1000], Loss: 0.0010\n",
      "Epoch [33/1000], Loss: 0.0009\n",
      "Epoch [34/1000], Loss: 0.0008\n",
      "Epoch [35/1000], Loss: 0.0008\n",
      "Epoch [36/1000], Loss: 0.0009\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 302, lr :0.01, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.2728\n",
      "Epoch [2/1000], Loss: 0.2466\n",
      "Epoch [3/1000], Loss: 0.2476\n",
      "Epoch [4/1000], Loss: 0.2404\n",
      "Epoch [5/1000], Loss: 0.2350\n",
      "Epoch [6/1000], Loss: 0.2223\n",
      "Epoch [7/1000], Loss: 0.2024\n",
      "Epoch [8/1000], Loss: 0.1700\n",
      "Epoch [9/1000], Loss: 0.1506\n",
      "Epoch [10/1000], Loss: 0.1123\n",
      "Epoch [11/1000], Loss: 0.0995\n",
      "Epoch [12/1000], Loss: 0.0786\n",
      "Epoch [13/1000], Loss: 0.0761\n",
      "Epoch [14/1000], Loss: 0.0526\n",
      "Epoch [15/1000], Loss: 0.0563\n",
      "Epoch [16/1000], Loss: 0.0395\n",
      "Epoch [17/1000], Loss: 0.0306\n",
      "Epoch [18/1000], Loss: 0.0267\n",
      "Epoch [19/1000], Loss: 0.0205\n",
      "Epoch [20/1000], Loss: 0.0377\n",
      "Epoch [21/1000], Loss: 0.0121\n",
      "Epoch [22/1000], Loss: 0.0101\n",
      "Epoch [23/1000], Loss: 0.0092\n",
      "Epoch [24/1000], Loss: 0.0073\n",
      "Epoch [25/1000], Loss: 0.0057\n",
      "Epoch [26/1000], Loss: 0.0052\n",
      "Epoch [27/1000], Loss: 0.0042\n",
      "Epoch [28/1000], Loss: 0.0036\n",
      "Epoch [29/1000], Loss: 0.0031\n",
      "Epoch [30/1000], Loss: 0.0146\n",
      "Epoch [31/1000], Loss: 0.0325\n",
      "Epoch [32/1000], Loss: 0.0026\n",
      "Epoch [33/1000], Loss: 0.0023\n",
      "Epoch [34/1000], Loss: 0.0024\n",
      "Epoch [35/1000], Loss: 0.0017\n",
      "Epoch [36/1000], Loss: 0.0015\n",
      "Epoch [37/1000], Loss: 0.0013\n",
      "Epoch [38/1000], Loss: 0.0013\n",
      "Epoch [39/1000], Loss: 0.0013\n",
      "Epoch [40/1000], Loss: 0.0010\n",
      "Epoch [41/1000], Loss: 0.0009\n",
      "Epoch [42/1000], Loss: 0.0009\n",
      "Epoch [43/1000], Loss: 0.0008\n",
      "Epoch [44/1000], Loss: 0.0008\n",
      "Epoch [45/1000], Loss: 0.0007\n",
      "Epoch [46/1000], Loss: 0.0007\n",
      "Epoch [47/1000], Loss: 0.0006\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 302, lr :0.01, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2769\n",
      "Epoch [2/1000], Loss: 0.2742\n",
      "Epoch [3/1000], Loss: 0.2716\n",
      "Epoch [4/1000], Loss: 0.2696\n",
      "Epoch [5/1000], Loss: 0.2682\n",
      "Epoch [6/1000], Loss: 0.2668\n",
      "Epoch [7/1000], Loss: 0.2650\n",
      "Epoch [8/1000], Loss: 0.2647\n",
      "Epoch [9/1000], Loss: 0.2638\n",
      "Epoch [10/1000], Loss: 0.2624\n",
      "Epoch [11/1000], Loss: 0.2619\n",
      "Epoch [12/1000], Loss: 0.2611\n",
      "Epoch [13/1000], Loss: 0.2604\n",
      "Epoch [14/1000], Loss: 0.2600\n",
      "Epoch [15/1000], Loss: 0.2594\n",
      "Epoch [16/1000], Loss: 0.2584\n",
      "Epoch [17/1000], Loss: 0.2576\n",
      "Epoch [18/1000], Loss: 0.2585\n",
      "Epoch [19/1000], Loss: 0.2578\n",
      "Epoch [20/1000], Loss: 0.2566\n",
      "Epoch [21/1000], Loss: 0.2558\n",
      "Epoch [22/1000], Loss: 0.2561\n",
      "Epoch [23/1000], Loss: 0.2558\n",
      "Epoch [24/1000], Loss: 0.2559\n",
      "Epoch [25/1000], Loss: 0.2549\n",
      "Epoch [26/1000], Loss: 0.2553\n",
      "Epoch [27/1000], Loss: 0.2552\n",
      "Epoch [28/1000], Loss: 0.2547\n",
      "Epoch [29/1000], Loss: 0.2549\n",
      "Epoch [30/1000], Loss: 0.2540\n",
      "Epoch [31/1000], Loss: 0.2533\n",
      "Epoch [32/1000], Loss: 0.2548\n",
      "Epoch [33/1000], Loss: 0.2532\n",
      "Epoch [34/1000], Loss: 0.2531\n",
      "Epoch [35/1000], Loss: 0.2540\n",
      "Epoch [36/1000], Loss: 0.2533\n",
      "Epoch [37/1000], Loss: 0.2528\n",
      "Epoch [38/1000], Loss: 0.2528\n",
      "Epoch [39/1000], Loss: 0.2524\n",
      "Epoch [40/1000], Loss: 0.2528\n",
      "Epoch [41/1000], Loss: 0.2527\n",
      "Epoch [42/1000], Loss: 0.2516\n",
      "Epoch [43/1000], Loss: 0.2531\n",
      "Epoch [44/1000], Loss: 0.2519\n",
      "Epoch [45/1000], Loss: 0.2525\n",
      "Epoch [46/1000], Loss: 0.2521\n",
      "Epoch [47/1000], Loss: 0.2524\n",
      "Epoch [48/1000], Loss: 0.2518\n",
      "Epoch [49/1000], Loss: 0.2512\n",
      "Epoch [50/1000], Loss: 0.2504\n",
      "Epoch [51/1000], Loss: 0.2515\n",
      "Epoch [52/1000], Loss: 0.2507\n",
      "Epoch [53/1000], Loss: 0.2511\n",
      "Epoch [54/1000], Loss: 0.2509\n",
      "Epoch [55/1000], Loss: 0.2511\n",
      "Epoch [56/1000], Loss: 0.2502\n",
      "Epoch [57/1000], Loss: 0.2511\n",
      "Epoch [58/1000], Loss: 0.2506\n",
      "Epoch [59/1000], Loss: 0.2505\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 61.40 %\n",
      "Training model with batch_size: 302, lr :0.1, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.2700\n",
      "Epoch [2/1000], Loss: 0.2469\n",
      "Epoch [3/1000], Loss: 0.2424\n",
      "Epoch [4/1000], Loss: 0.2319\n",
      "Epoch [5/1000], Loss: 0.2210\n",
      "Epoch [6/1000], Loss: 0.2037\n",
      "Epoch [7/1000], Loss: 0.1738\n",
      "Epoch [8/1000], Loss: 0.1578\n",
      "Epoch [9/1000], Loss: 0.1446\n",
      "Epoch [10/1000], Loss: 0.1244\n",
      "Epoch [11/1000], Loss: 0.1117\n",
      "Epoch [12/1000], Loss: 0.0938\n",
      "Epoch [13/1000], Loss: 0.0786\n",
      "Epoch [14/1000], Loss: 0.0663\n",
      "Epoch [15/1000], Loss: 0.0581\n",
      "Epoch [16/1000], Loss: 0.0462\n",
      "Epoch [17/1000], Loss: 0.0371\n",
      "Epoch [18/1000], Loss: 0.0290\n",
      "Epoch [19/1000], Loss: 0.0221\n",
      "Epoch [20/1000], Loss: 0.0255\n",
      "Epoch [21/1000], Loss: 0.0161\n",
      "Epoch [22/1000], Loss: 0.0146\n",
      "Epoch [23/1000], Loss: 0.0123\n",
      "Epoch [24/1000], Loss: 0.0111\n",
      "Epoch [25/1000], Loss: 0.0098\n",
      "Epoch [26/1000], Loss: 0.0092\n",
      "Epoch [27/1000], Loss: 0.0079\n",
      "Epoch [28/1000], Loss: 0.0071\n",
      "Epoch [29/1000], Loss: 0.0070\n",
      "Epoch [30/1000], Loss: 0.0061\n",
      "Epoch [31/1000], Loss: 0.0056\n",
      "Epoch [32/1000], Loss: 0.0052\n",
      "Epoch [33/1000], Loss: 0.0048\n",
      "Epoch [34/1000], Loss: 0.0047\n",
      "Epoch [35/1000], Loss: 0.0042\n",
      "Epoch [36/1000], Loss: 0.0066\n",
      "Epoch [37/1000], Loss: 0.0040\n",
      "Epoch [38/1000], Loss: 0.0038\n",
      "Epoch [39/1000], Loss: 0.0035\n",
      "Epoch [40/1000], Loss: 0.0034\n",
      "Epoch [41/1000], Loss: 0.0031\n",
      "Epoch [42/1000], Loss: 0.0030\n",
      "Epoch [43/1000], Loss: 0.0029\n",
      "Epoch [44/1000], Loss: 0.0028\n",
      "Epoch [45/1000], Loss: 0.0026\n",
      "Epoch [46/1000], Loss: 0.0027\n",
      "Epoch [47/1000], Loss: 0.0024\n",
      "Epoch [48/1000], Loss: 0.0024\n",
      "Epoch [49/1000], Loss: 0.0025\n",
      "Epoch [50/1000], Loss: 0.0023\n",
      "Epoch [51/1000], Loss: 0.0022\n",
      "Epoch [52/1000], Loss: 0.0021\n",
      "Epoch [53/1000], Loss: 0.0020\n",
      "Epoch [54/1000], Loss: 0.0021\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 302, lr :0.1, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.2854\n",
      "Epoch [2/1000], Loss: 0.2552\n",
      "Epoch [3/1000], Loss: 0.2512\n",
      "Epoch [4/1000], Loss: 0.2467\n",
      "Epoch [5/1000], Loss: 0.2450\n",
      "Epoch [6/1000], Loss: 0.2337\n",
      "Epoch [7/1000], Loss: 0.2191\n",
      "Epoch [8/1000], Loss: 0.1961\n",
      "Epoch [9/1000], Loss: 0.1784\n",
      "Epoch [10/1000], Loss: 0.1663\n",
      "Epoch [11/1000], Loss: 0.1477\n",
      "Epoch [12/1000], Loss: 0.1294\n",
      "Epoch [13/1000], Loss: 0.0961\n",
      "Epoch [14/1000], Loss: 0.0869\n",
      "Epoch [15/1000], Loss: 0.0667\n",
      "Epoch [16/1000], Loss: 0.0671\n",
      "Epoch [17/1000], Loss: 0.0470\n",
      "Epoch [18/1000], Loss: 0.0310\n",
      "Epoch [19/1000], Loss: 0.0241\n",
      "Epoch [20/1000], Loss: 0.0294\n",
      "Epoch [21/1000], Loss: 0.0107\n",
      "Epoch [22/1000], Loss: 0.0055\n",
      "Epoch [23/1000], Loss: 0.0040\n",
      "Epoch [24/1000], Loss: 0.0041\n",
      "Epoch [25/1000], Loss: 0.0030\n",
      "Epoch [26/1000], Loss: 0.0021\n",
      "Epoch [27/1000], Loss: 0.0010\n",
      "Epoch [28/1000], Loss: 0.0012\n",
      "Epoch [29/1000], Loss: 0.0006\n",
      "Epoch [30/1000], Loss: 0.0006\n",
      "Epoch [31/1000], Loss: 0.0007\n",
      "Epoch [32/1000], Loss: 0.0004\n",
      "Epoch [33/1000], Loss: 0.0004\n",
      "Epoch [34/1000], Loss: 0.0011\n",
      "Epoch [35/1000], Loss: 0.0007\n",
      "Epoch [36/1000], Loss: 0.0064\n",
      "Epoch [37/1000], Loss: 0.0035\n",
      "Epoch [38/1000], Loss: 0.0010\n",
      "Epoch [39/1000], Loss: 0.0042\n",
      "Epoch [40/1000], Loss: 0.0046\n",
      "Epoch [41/1000], Loss: 0.0042\n",
      "Epoch [42/1000], Loss: 0.0034\n",
      "Epoch [43/1000], Loss: 0.0043\n",
      "Epoch [44/1000], Loss: 0.0219\n",
      "Epoch [45/1000], Loss: 0.0349\n",
      "Epoch [46/1000], Loss: 0.0213\n",
      "Epoch [47/1000], Loss: 0.0088\n",
      "Epoch [48/1000], Loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/1000], Loss: 0.0031\n",
      "Epoch [50/1000], Loss: 0.0037\n",
      "Epoch [51/1000], Loss: 0.0024\n",
      "Epoch [52/1000], Loss: 0.0009\n",
      "Epoch [53/1000], Loss: 0.0003\n",
      "Epoch [54/1000], Loss: 0.0002\n",
      "Epoch [55/1000], Loss: 0.0002\n",
      "Epoch [56/1000], Loss: 0.0003\n",
      "Epoch [57/1000], Loss: 0.0001\n",
      "Epoch [58/1000], Loss: 0.0001\n",
      "Epoch [59/1000], Loss: 0.0001\n",
      "Epoch [60/1000], Loss: 0.0001\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 302, lr :0.1, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.5156\n",
      "Epoch [2/1000], Loss: 0.5370\n",
      "Epoch [3/1000], Loss: 0.5285\n",
      "Epoch [4/1000], Loss: 0.5270\n",
      "Epoch [5/1000], Loss: 0.5377\n",
      "Epoch [6/1000], Loss: 0.5246\n",
      "Epoch [7/1000], Loss: 0.5293\n",
      "Epoch [8/1000], Loss: 0.5270\n",
      "Epoch [9/1000], Loss: 0.5262\n",
      "Epoch [10/1000], Loss: 0.5393\n",
      "Epoch [11/1000], Loss: 0.5308\n",
      "Epoch [12/1000], Loss: 0.5300\n",
      "Epoch [13/1000], Loss: 0.5246\n",
      "Epoch [14/1000], Loss: 0.5308\n",
      "Epoch [15/1000], Loss: 0.5254\n",
      "Epoch [16/1000], Loss: 0.5324\n",
      "Epoch [17/1000], Loss: 0.5254\n",
      "Epoch [18/1000], Loss: 0.5324\n",
      "Epoch [19/1000], Loss: 0.5231\n",
      "Epoch [20/1000], Loss: 0.5216\n",
      "Epoch [21/1000], Loss: 0.5231\n",
      "Epoch [22/1000], Loss: 0.5300\n",
      "Epoch [23/1000], Loss: 0.5246\n",
      "Epoch [24/1000], Loss: 0.5270\n",
      "Epoch [25/1000], Loss: 0.5285\n",
      "Epoch [26/1000], Loss: 0.5239\n",
      "Epoch [27/1000], Loss: 0.5223\n",
      "Epoch [28/1000], Loss: 0.5285\n",
      "Epoch [29/1000], Loss: 0.5316\n",
      "Epoch [30/1000], Loss: 0.5324\n",
      "Epoch [31/1000], Loss: 0.5262\n",
      "Epoch [32/1000], Loss: 0.5246\n",
      "Epoch [33/1000], Loss: 0.5277\n",
      "Epoch [34/1000], Loss: 0.5316\n",
      "Epoch [35/1000], Loss: 0.5270\n",
      "Epoch [36/1000], Loss: 0.5293\n",
      "Epoch [37/1000], Loss: 0.5293\n",
      "Epoch [38/1000], Loss: 0.5223\n",
      "Epoch [39/1000], Loss: 0.5300\n",
      "Epoch [40/1000], Loss: 0.5277\n",
      "Epoch [41/1000], Loss: 0.5262\n",
      "Epoch [42/1000], Loss: 0.5246\n",
      "Epoch [43/1000], Loss: 0.5331\n",
      "Epoch [44/1000], Loss: 0.5324\n",
      "Epoch [45/1000], Loss: 0.5270\n",
      "Epoch [46/1000], Loss: 0.5316\n",
      "Epoch [47/1000], Loss: 0.5300\n",
      "Epoch [48/1000], Loss: 0.5277\n",
      "Epoch [49/1000], Loss: 0.5254\n",
      "Epoch [50/1000], Loss: 0.5300\n",
      "Epoch [51/1000], Loss: 0.5262\n",
      "Epoch [52/1000], Loss: 0.5246\n",
      "Epoch [53/1000], Loss: 0.5324\n",
      "Epoch [54/1000], Loss: 0.5270\n",
      "Epoch [55/1000], Loss: 0.5254\n",
      "Epoch [56/1000], Loss: 0.5316\n",
      "Epoch [57/1000], Loss: 0.5300\n",
      "Epoch [58/1000], Loss: 0.5277\n",
      "Epoch [59/1000], Loss: 0.5270\n",
      "Epoch [60/1000], Loss: 0.5347\n",
      "Epoch [61/1000], Loss: 0.5270\n",
      "Epoch [62/1000], Loss: 0.5239\n",
      "Epoch [63/1000], Loss: 0.5285\n",
      "Epoch [64/1000], Loss: 0.5347\n",
      "Epoch [65/1000], Loss: 0.5293\n",
      "Epoch [66/1000], Loss: 0.5293\n",
      "Epoch [67/1000], Loss: 0.5324\n",
      "Epoch [68/1000], Loss: 0.5308\n",
      "Epoch [69/1000], Loss: 0.5239\n",
      "Epoch [70/1000], Loss: 0.5277\n",
      "Epoch [71/1000], Loss: 0.5254\n",
      "Epoch [72/1000], Loss: 0.5254\n",
      "Epoch [73/1000], Loss: 0.5231\n",
      "Epoch [74/1000], Loss: 0.5285\n",
      "Epoch [75/1000], Loss: 0.5270\n",
      "Epoch [76/1000], Loss: 0.5331\n",
      "Epoch [77/1000], Loss: 0.5254\n",
      "Epoch [78/1000], Loss: 0.5300\n",
      "Epoch [79/1000], Loss: 0.5339\n",
      "Epoch [80/1000], Loss: 0.5262\n",
      "Epoch [81/1000], Loss: 0.5354\n",
      "Epoch [82/1000], Loss: 0.5231\n",
      "Epoch [83/1000], Loss: 0.5324\n",
      "Epoch [84/1000], Loss: 0.5316\n",
      "Epoch [85/1000], Loss: 0.5223\n",
      "Epoch [86/1000], Loss: 0.5262\n",
      "Epoch [87/1000], Loss: 0.5324\n",
      "Epoch [88/1000], Loss: 0.5262\n",
      "Epoch [89/1000], Loss: 0.5300\n",
      "Epoch [90/1000], Loss: 0.5316\n",
      "Epoch [91/1000], Loss: 0.5270\n",
      "Epoch [92/1000], Loss: 0.5270\n",
      "Epoch [93/1000], Loss: 0.5331\n",
      "Epoch [94/1000], Loss: 0.5300\n",
      "Epoch [95/1000], Loss: 0.5262\n",
      "Epoch [96/1000], Loss: 0.5277\n",
      "Epoch [97/1000], Loss: 0.5277\n",
      "Epoch [98/1000], Loss: 0.5277\n",
      "Epoch [99/1000], Loss: 0.5300\n",
      "Epoch [100/1000], Loss: 0.5347\n",
      "Epoch [101/1000], Loss: 0.5308\n",
      "Epoch [102/1000], Loss: 0.5331\n",
      "Epoch [103/1000], Loss: 0.5308\n",
      "Epoch [104/1000], Loss: 0.5277\n",
      "Epoch [105/1000], Loss: 0.5293\n",
      "Epoch [106/1000], Loss: 0.5262\n",
      "Epoch [107/1000], Loss: 0.5262\n",
      "Epoch [108/1000], Loss: 0.5331\n",
      "Epoch [109/1000], Loss: 0.5293\n",
      "Epoch [110/1000], Loss: 0.5277\n",
      "Epoch [111/1000], Loss: 0.5254\n",
      "Epoch [112/1000], Loss: 0.5308\n",
      "Epoch [113/1000], Loss: 0.5300\n",
      "Epoch [114/1000], Loss: 0.5331\n",
      "Epoch [115/1000], Loss: 0.5300\n",
      "Epoch [116/1000], Loss: 0.5254\n",
      "Epoch [117/1000], Loss: 0.5316\n",
      "Epoch [118/1000], Loss: 0.5277\n",
      "Epoch [119/1000], Loss: 0.5285\n",
      "Epoch [120/1000], Loss: 0.5277\n",
      "Epoch [121/1000], Loss: 0.5223\n",
      "Epoch [122/1000], Loss: 0.5324\n",
      "Epoch [123/1000], Loss: 0.5285\n",
      "Epoch [124/1000], Loss: 0.5254\n",
      "Epoch [125/1000], Loss: 0.5324\n",
      "Epoch [126/1000], Loss: 0.5239\n",
      "Epoch [127/1000], Loss: 0.5293\n",
      "Epoch [128/1000], Loss: 0.5231\n",
      "Epoch [129/1000], Loss: 0.5285\n",
      "Epoch [130/1000], Loss: 0.5223\n",
      "Epoch [131/1000], Loss: 0.5308\n",
      "Epoch [132/1000], Loss: 0.5293\n",
      "Epoch [133/1000], Loss: 0.5293\n",
      "Epoch [134/1000], Loss: 0.5285\n",
      "Epoch [135/1000], Loss: 0.5216\n",
      "Epoch [136/1000], Loss: 0.5216\n",
      "Epoch [137/1000], Loss: 0.5308\n",
      "Epoch [138/1000], Loss: 0.5316\n",
      "Epoch [139/1000], Loss: 0.5262\n",
      "Epoch [140/1000], Loss: 0.5293\n",
      "Epoch [141/1000], Loss: 0.5324\n",
      "Epoch [142/1000], Loss: 0.5277\n",
      "Epoch [143/1000], Loss: 0.5285\n",
      "Epoch [144/1000], Loss: 0.5262\n",
      "Epoch [145/1000], Loss: 0.5316\n",
      "Epoch [146/1000], Loss: 0.5324\n",
      "Epoch [147/1000], Loss: 0.5216\n",
      "Epoch [148/1000], Loss: 0.5239\n",
      "Epoch [149/1000], Loss: 0.5285\n",
      "Epoch [150/1000], Loss: 0.5354\n",
      "Epoch [151/1000], Loss: 0.5285\n",
      "Epoch [152/1000], Loss: 0.5270\n",
      "Epoch [153/1000], Loss: 0.5316\n",
      "Epoch [154/1000], Loss: 0.5293\n",
      "Epoch [155/1000], Loss: 0.5347\n",
      "Epoch [156/1000], Loss: 0.5316\n",
      "Epoch [157/1000], Loss: 0.5331\n",
      "Epoch [158/1000], Loss: 0.5370\n",
      "Epoch [159/1000], Loss: 0.5262\n",
      "Epoch [160/1000], Loss: 0.5308\n",
      "Epoch [161/1000], Loss: 0.5308\n",
      "Epoch [162/1000], Loss: 0.5339\n",
      "Epoch [163/1000], Loss: 0.5285\n",
      "Epoch [164/1000], Loss: 0.5262\n",
      "Epoch [165/1000], Loss: 0.5270\n",
      "Epoch [166/1000], Loss: 0.5293\n",
      "Epoch [167/1000], Loss: 0.5246\n",
      "Epoch [168/1000], Loss: 0.5339\n",
      "Epoch [169/1000], Loss: 0.5277\n",
      "Epoch [170/1000], Loss: 0.5339\n",
      "Epoch [171/1000], Loss: 0.5262\n",
      "Epoch [172/1000], Loss: 0.5239\n",
      "Epoch [173/1000], Loss: 0.5331\n",
      "Epoch [174/1000], Loss: 0.5362\n",
      "Epoch [175/1000], Loss: 0.5270\n",
      "Epoch [176/1000], Loss: 0.5316\n",
      "Epoch [177/1000], Loss: 0.5308\n",
      "Epoch [178/1000], Loss: 0.5277\n",
      "Epoch [179/1000], Loss: 0.5293\n",
      "Epoch [180/1000], Loss: 0.5285\n",
      "Epoch [181/1000], Loss: 0.5277\n",
      "Epoch [182/1000], Loss: 0.5316\n",
      "Epoch [183/1000], Loss: 0.5293\n",
      "Epoch [184/1000], Loss: 0.5324\n",
      "Epoch [185/1000], Loss: 0.5331\n",
      "Epoch [186/1000], Loss: 0.5246\n",
      "Epoch [187/1000], Loss: 0.5293\n",
      "Epoch [188/1000], Loss: 0.5293\n",
      "Epoch [189/1000], Loss: 0.5254\n",
      "Epoch [190/1000], Loss: 0.5347\n",
      "Epoch [191/1000], Loss: 0.5293\n",
      "Epoch [192/1000], Loss: 0.5300\n",
      "Epoch [193/1000], Loss: 0.5339\n",
      "Epoch [194/1000], Loss: 0.5216\n",
      "Epoch [195/1000], Loss: 0.5239\n",
      "Epoch [196/1000], Loss: 0.5339\n",
      "Epoch [197/1000], Loss: 0.5254\n",
      "Epoch [198/1000], Loss: 0.5300\n",
      "Epoch [199/1000], Loss: 0.5331\n",
      "Epoch [200/1000], Loss: 0.5308\n",
      "Epoch [201/1000], Loss: 0.5262\n",
      "Epoch [202/1000], Loss: 0.5277\n",
      "Epoch [203/1000], Loss: 0.5300\n",
      "Epoch [204/1000], Loss: 0.5262\n",
      "Epoch [205/1000], Loss: 0.5277\n",
      "Epoch [206/1000], Loss: 0.5277\n",
      "Epoch [207/1000], Loss: 0.5300\n",
      "Epoch [208/1000], Loss: 0.5262\n",
      "Epoch [209/1000], Loss: 0.5254\n",
      "Epoch [210/1000], Loss: 0.5347\n",
      "Epoch [211/1000], Loss: 0.5308\n",
      "Epoch [212/1000], Loss: 0.5239\n",
      "Epoch [213/1000], Loss: 0.5285\n",
      "Epoch [214/1000], Loss: 0.5277\n",
      "Epoch [215/1000], Loss: 0.5277\n",
      "Epoch [216/1000], Loss: 0.5293\n",
      "Epoch [217/1000], Loss: 0.5339\n",
      "Epoch [218/1000], Loss: 0.5277\n",
      "Epoch [219/1000], Loss: 0.5223\n",
      "Epoch [220/1000], Loss: 0.5270\n",
      "Epoch [221/1000], Loss: 0.5246\n",
      "Epoch [222/1000], Loss: 0.5223\n",
      "Epoch [223/1000], Loss: 0.5308\n",
      "Epoch [224/1000], Loss: 0.5285\n",
      "Epoch [225/1000], Loss: 0.5223\n",
      "Epoch [226/1000], Loss: 0.5285\n",
      "Epoch [227/1000], Loss: 0.5293\n",
      "Epoch [228/1000], Loss: 0.5262\n",
      "Epoch [229/1000], Loss: 0.5293\n",
      "Epoch [230/1000], Loss: 0.5216\n",
      "Epoch [231/1000], Loss: 0.5316\n",
      "Epoch [232/1000], Loss: 0.5308\n",
      "Epoch [233/1000], Loss: 0.5308\n",
      "Epoch [234/1000], Loss: 0.5254\n",
      "Epoch [235/1000], Loss: 0.5308\n",
      "Epoch [236/1000], Loss: 0.5285\n",
      "Epoch [237/1000], Loss: 0.5223\n",
      "Epoch [238/1000], Loss: 0.5231\n",
      "Epoch [239/1000], Loss: 0.5308\n",
      "Epoch [240/1000], Loss: 0.5308\n",
      "Epoch [241/1000], Loss: 0.5277\n",
      "Epoch [242/1000], Loss: 0.5347\n",
      "Epoch [243/1000], Loss: 0.5262\n",
      "Epoch [244/1000], Loss: 0.5293\n",
      "Epoch [245/1000], Loss: 0.5270\n",
      "Epoch [246/1000], Loss: 0.5316\n",
      "Epoch [247/1000], Loss: 0.5370\n",
      "Epoch [248/1000], Loss: 0.5300\n",
      "Epoch [249/1000], Loss: 0.5324\n",
      "Epoch [250/1000], Loss: 0.5285\n",
      "Epoch [251/1000], Loss: 0.5324\n",
      "Epoch [252/1000], Loss: 0.5277\n",
      "Epoch [253/1000], Loss: 0.5285\n",
      "Epoch [254/1000], Loss: 0.5239\n",
      "Epoch [255/1000], Loss: 0.5300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [256/1000], Loss: 0.5277\n",
      "Epoch [257/1000], Loss: 0.5300\n",
      "Epoch [258/1000], Loss: 0.5231\n",
      "Epoch [259/1000], Loss: 0.5324\n",
      "Epoch [260/1000], Loss: 0.5331\n",
      "Epoch [261/1000], Loss: 0.5246\n",
      "Epoch [262/1000], Loss: 0.5285\n",
      "Epoch [263/1000], Loss: 0.5300\n",
      "Epoch [264/1000], Loss: 0.5270\n",
      "Epoch [265/1000], Loss: 0.5316\n",
      "Epoch [266/1000], Loss: 0.5231\n",
      "Epoch [267/1000], Loss: 0.5277\n",
      "Epoch [268/1000], Loss: 0.5354\n",
      "Epoch [269/1000], Loss: 0.5270\n",
      "Epoch [270/1000], Loss: 0.5285\n",
      "Epoch [271/1000], Loss: 0.5308\n",
      "Epoch [272/1000], Loss: 0.5300\n",
      "Epoch [273/1000], Loss: 0.5293\n",
      "Epoch [274/1000], Loss: 0.5270\n",
      "Epoch [275/1000], Loss: 0.5362\n",
      "Epoch [276/1000], Loss: 0.5262\n",
      "Epoch [277/1000], Loss: 0.5277\n",
      "Epoch [278/1000], Loss: 0.5239\n",
      "Epoch [279/1000], Loss: 0.5293\n",
      "Epoch [280/1000], Loss: 0.5300\n",
      "Epoch [281/1000], Loss: 0.5262\n",
      "Epoch [282/1000], Loss: 0.5231\n",
      "Epoch [283/1000], Loss: 0.5300\n",
      "Epoch [284/1000], Loss: 0.5254\n",
      "Epoch [285/1000], Loss: 0.5285\n",
      "Epoch [286/1000], Loss: 0.5308\n",
      "Epoch [287/1000], Loss: 0.5293\n",
      "Epoch [288/1000], Loss: 0.5239\n",
      "Epoch [289/1000], Loss: 0.5270\n",
      "Epoch [290/1000], Loss: 0.5331\n",
      "Epoch [291/1000], Loss: 0.5293\n",
      "Epoch [292/1000], Loss: 0.5293\n",
      "Epoch [293/1000], Loss: 0.5339\n",
      "Epoch [294/1000], Loss: 0.5316\n",
      "Epoch [295/1000], Loss: 0.5231\n",
      "Epoch [296/1000], Loss: 0.5339\n",
      "Epoch [297/1000], Loss: 0.5270\n",
      "Epoch [298/1000], Loss: 0.5262\n",
      "Epoch [299/1000], Loss: 0.5270\n",
      "Epoch [300/1000], Loss: 0.5254\n",
      "Epoch [301/1000], Loss: 0.5308\n",
      "Epoch [302/1000], Loss: 0.5270\n",
      "Epoch [303/1000], Loss: 0.5308\n",
      "Epoch [304/1000], Loss: 0.5208\n",
      "Epoch [305/1000], Loss: 0.5270\n",
      "Epoch [306/1000], Loss: 0.5316\n",
      "Epoch [307/1000], Loss: 0.5277\n",
      "Epoch [308/1000], Loss: 0.5285\n",
      "Epoch [309/1000], Loss: 0.5277\n",
      "Epoch [310/1000], Loss: 0.5270\n",
      "Epoch [311/1000], Loss: 0.5285\n",
      "Epoch [312/1000], Loss: 0.5324\n",
      "Epoch [313/1000], Loss: 0.5239\n",
      "Epoch [314/1000], Loss: 0.5300\n",
      "Epoch [315/1000], Loss: 0.5308\n",
      "Epoch [316/1000], Loss: 0.5277\n",
      "Epoch [317/1000], Loss: 0.5254\n",
      "Epoch [318/1000], Loss: 0.5308\n",
      "Epoch [319/1000], Loss: 0.5216\n",
      "Epoch [320/1000], Loss: 0.5293\n",
      "Epoch [321/1000], Loss: 0.5293\n",
      "Epoch [322/1000], Loss: 0.5254\n",
      "Epoch [323/1000], Loss: 0.5270\n",
      "Epoch [324/1000], Loss: 0.5285\n",
      "Epoch [325/1000], Loss: 0.5239\n",
      "Epoch [326/1000], Loss: 0.5324\n",
      "Epoch [327/1000], Loss: 0.5208\n",
      "Epoch [328/1000], Loss: 0.5331\n",
      "Epoch [329/1000], Loss: 0.5285\n",
      "Epoch [330/1000], Loss: 0.5239\n",
      "Epoch [331/1000], Loss: 0.5354\n",
      "Epoch [332/1000], Loss: 0.5308\n",
      "Epoch [333/1000], Loss: 0.5254\n",
      "Epoch [334/1000], Loss: 0.5285\n",
      "Epoch [335/1000], Loss: 0.5239\n",
      "Epoch [336/1000], Loss: 0.5254\n",
      "Epoch [337/1000], Loss: 0.5316\n",
      "Epoch [338/1000], Loss: 0.5277\n",
      "Epoch [339/1000], Loss: 0.5324\n",
      "Epoch [340/1000], Loss: 0.5300\n",
      "Epoch [341/1000], Loss: 0.5262\n",
      "Epoch [342/1000], Loss: 0.5316\n",
      "Epoch [343/1000], Loss: 0.5270\n",
      "Epoch [344/1000], Loss: 0.5200\n",
      "Epoch [345/1000], Loss: 0.5324\n",
      "Epoch [346/1000], Loss: 0.5277\n",
      "Epoch [347/1000], Loss: 0.5300\n",
      "Epoch [348/1000], Loss: 0.5300\n",
      "Epoch [349/1000], Loss: 0.5216\n",
      "Epoch [350/1000], Loss: 0.5239\n",
      "Epoch [351/1000], Loss: 0.5300\n",
      "Epoch [352/1000], Loss: 0.5362\n",
      "Epoch [353/1000], Loss: 0.5285\n",
      "Epoch [354/1000], Loss: 0.5324\n",
      "Epoch [355/1000], Loss: 0.5308\n",
      "Epoch [356/1000], Loss: 0.5277\n",
      "Epoch [357/1000], Loss: 0.5293\n",
      "Epoch [358/1000], Loss: 0.5293\n",
      "Epoch [359/1000], Loss: 0.5300\n",
      "Epoch [360/1000], Loss: 0.5277\n",
      "Epoch [361/1000], Loss: 0.5262\n",
      "Epoch [362/1000], Loss: 0.5270\n",
      "Epoch [363/1000], Loss: 0.5277\n",
      "Epoch [364/1000], Loss: 0.5293\n",
      "Epoch [365/1000], Loss: 0.5277\n",
      "Epoch [366/1000], Loss: 0.5231\n",
      "Epoch [367/1000], Loss: 0.5300\n",
      "Epoch [368/1000], Loss: 0.5254\n",
      "Epoch [369/1000], Loss: 0.5293\n",
      "Epoch [370/1000], Loss: 0.5277\n",
      "Epoch [371/1000], Loss: 0.5316\n",
      "Epoch [372/1000], Loss: 0.5316\n",
      "Epoch [373/1000], Loss: 0.5324\n",
      "Epoch [374/1000], Loss: 0.5300\n",
      "Epoch [375/1000], Loss: 0.5262\n",
      "Epoch [376/1000], Loss: 0.5308\n",
      "Epoch [377/1000], Loss: 0.5331\n",
      "Epoch [378/1000], Loss: 0.5308\n",
      "Epoch [379/1000], Loss: 0.5316\n",
      "Epoch [380/1000], Loss: 0.5254\n",
      "Epoch [381/1000], Loss: 0.5270\n",
      "Epoch [382/1000], Loss: 0.5285\n",
      "Epoch [383/1000], Loss: 0.5285\n",
      "Epoch [384/1000], Loss: 0.5308\n",
      "Epoch [385/1000], Loss: 0.5300\n",
      "Epoch [386/1000], Loss: 0.5293\n",
      "Epoch [387/1000], Loss: 0.5316\n",
      "Epoch [388/1000], Loss: 0.5246\n",
      "Epoch [389/1000], Loss: 0.5231\n",
      "Epoch [390/1000], Loss: 0.5270\n",
      "Epoch [391/1000], Loss: 0.5308\n",
      "Epoch [392/1000], Loss: 0.5254\n",
      "Epoch [393/1000], Loss: 0.5270\n",
      "Epoch [394/1000], Loss: 0.5331\n",
      "Epoch [395/1000], Loss: 0.5316\n",
      "Epoch [396/1000], Loss: 0.5270\n",
      "Epoch [397/1000], Loss: 0.5285\n",
      "Epoch [398/1000], Loss: 0.5331\n",
      "Epoch [399/1000], Loss: 0.5308\n",
      "Epoch [400/1000], Loss: 0.5308\n",
      "Epoch [401/1000], Loss: 0.5331\n",
      "Epoch [402/1000], Loss: 0.5316\n",
      "Epoch [403/1000], Loss: 0.5293\n",
      "Epoch [404/1000], Loss: 0.5293\n",
      "Epoch [405/1000], Loss: 0.5308\n",
      "Epoch [406/1000], Loss: 0.5324\n",
      "Epoch [407/1000], Loss: 0.5324\n",
      "Epoch [408/1000], Loss: 0.5316\n",
      "Epoch [409/1000], Loss: 0.5254\n",
      "Epoch [410/1000], Loss: 0.5254\n",
      "Epoch [411/1000], Loss: 0.5300\n",
      "Epoch [412/1000], Loss: 0.5285\n",
      "Epoch [413/1000], Loss: 0.5246\n",
      "Epoch [414/1000], Loss: 0.5200\n",
      "Epoch [415/1000], Loss: 0.5300\n",
      "Epoch [416/1000], Loss: 0.5239\n",
      "Epoch [417/1000], Loss: 0.5285\n",
      "Epoch [418/1000], Loss: 0.5254\n",
      "Epoch [419/1000], Loss: 0.5262\n",
      "Epoch [420/1000], Loss: 0.5270\n",
      "Epoch [421/1000], Loss: 0.5254\n",
      "Epoch [422/1000], Loss: 0.5246\n",
      "Epoch [423/1000], Loss: 0.5285\n",
      "Epoch [424/1000], Loss: 0.5293\n",
      "Epoch [425/1000], Loss: 0.5254\n",
      "Epoch [426/1000], Loss: 0.5293\n",
      "Epoch [427/1000], Loss: 0.5285\n",
      "Epoch [428/1000], Loss: 0.5339\n",
      "Epoch [429/1000], Loss: 0.5208\n",
      "Epoch [430/1000], Loss: 0.5223\n",
      "Epoch [431/1000], Loss: 0.5246\n",
      "Epoch [432/1000], Loss: 0.5308\n",
      "Epoch [433/1000], Loss: 0.5193\n",
      "Epoch [434/1000], Loss: 0.5277\n",
      "Epoch [435/1000], Loss: 0.5293\n",
      "Epoch [436/1000], Loss: 0.5285\n",
      "Epoch [437/1000], Loss: 0.5339\n",
      "Epoch [438/1000], Loss: 0.5239\n",
      "Epoch [439/1000], Loss: 0.5308\n",
      "Epoch [440/1000], Loss: 0.5239\n",
      "Epoch [441/1000], Loss: 0.5308\n",
      "Epoch [442/1000], Loss: 0.5316\n",
      "Epoch [443/1000], Loss: 0.5316\n",
      "Epoch [444/1000], Loss: 0.5362\n",
      "Epoch [445/1000], Loss: 0.5285\n",
      "Epoch [446/1000], Loss: 0.5370\n",
      "Epoch [447/1000], Loss: 0.5331\n",
      "Epoch [448/1000], Loss: 0.5254\n",
      "Epoch [449/1000], Loss: 0.5285\n",
      "Epoch [450/1000], Loss: 0.5339\n",
      "Epoch [451/1000], Loss: 0.5293\n",
      "Epoch [452/1000], Loss: 0.5270\n",
      "Epoch [453/1000], Loss: 0.5277\n",
      "Epoch [454/1000], Loss: 0.5270\n",
      "Epoch [455/1000], Loss: 0.5331\n",
      "Epoch [456/1000], Loss: 0.5285\n",
      "Epoch [457/1000], Loss: 0.5262\n",
      "Epoch [458/1000], Loss: 0.5293\n",
      "Epoch [459/1000], Loss: 0.5285\n",
      "Epoch [460/1000], Loss: 0.5239\n",
      "Epoch [461/1000], Loss: 0.5254\n",
      "Epoch [462/1000], Loss: 0.5270\n",
      "Epoch [463/1000], Loss: 0.5246\n",
      "Epoch [464/1000], Loss: 0.5293\n",
      "Epoch [465/1000], Loss: 0.5324\n",
      "Epoch [466/1000], Loss: 0.5262\n",
      "Epoch [467/1000], Loss: 0.5300\n",
      "Epoch [468/1000], Loss: 0.5277\n",
      "Epoch [469/1000], Loss: 0.5254\n",
      "Epoch [470/1000], Loss: 0.5254\n",
      "Epoch [471/1000], Loss: 0.5362\n",
      "Epoch [472/1000], Loss: 0.5300\n",
      "Epoch [473/1000], Loss: 0.5277\n",
      "Epoch [474/1000], Loss: 0.5277\n",
      "Epoch [475/1000], Loss: 0.5300\n",
      "Epoch [476/1000], Loss: 0.5270\n",
      "Epoch [477/1000], Loss: 0.5262\n",
      "Epoch [478/1000], Loss: 0.5324\n",
      "Epoch [479/1000], Loss: 0.5246\n",
      "Epoch [480/1000], Loss: 0.5293\n",
      "Epoch [481/1000], Loss: 0.5300\n",
      "Epoch [482/1000], Loss: 0.5231\n",
      "Epoch [483/1000], Loss: 0.5293\n",
      "Epoch [484/1000], Loss: 0.5293\n",
      "Epoch [485/1000], Loss: 0.5308\n",
      "Epoch [486/1000], Loss: 0.5223\n",
      "Epoch [487/1000], Loss: 0.5262\n",
      "Epoch [488/1000], Loss: 0.5277\n",
      "Epoch [489/1000], Loss: 0.5277\n",
      "Epoch [490/1000], Loss: 0.5246\n",
      "Epoch [491/1000], Loss: 0.5254\n",
      "Epoch [492/1000], Loss: 0.5300\n",
      "Epoch [493/1000], Loss: 0.5285\n",
      "Epoch [494/1000], Loss: 0.5277\n",
      "Epoch [495/1000], Loss: 0.5262\n",
      "Epoch [496/1000], Loss: 0.5347\n",
      "Epoch [497/1000], Loss: 0.5293\n",
      "Epoch [498/1000], Loss: 0.5293\n",
      "Epoch [499/1000], Loss: 0.5300\n",
      "Epoch [500/1000], Loss: 0.5285\n",
      "Epoch [501/1000], Loss: 0.5285\n",
      "Epoch [502/1000], Loss: 0.5308\n",
      "Epoch [503/1000], Loss: 0.5254\n",
      "Epoch [504/1000], Loss: 0.5231\n",
      "Epoch [505/1000], Loss: 0.5277\n",
      "Epoch [506/1000], Loss: 0.5331\n",
      "Epoch [507/1000], Loss: 0.5324\n",
      "Epoch [508/1000], Loss: 0.5246\n",
      "Epoch [509/1000], Loss: 0.5300\n",
      "Epoch [510/1000], Loss: 0.5331\n",
      "Epoch [511/1000], Loss: 0.5262\n",
      "Epoch [512/1000], Loss: 0.5277\n",
      "Epoch [513/1000], Loss: 0.5270\n",
      "Epoch [514/1000], Loss: 0.5270\n",
      "Epoch [515/1000], Loss: 0.5277\n",
      "Epoch [516/1000], Loss: 0.5308\n",
      "Epoch [517/1000], Loss: 0.5316\n",
      "Epoch [518/1000], Loss: 0.5270\n",
      "Epoch [519/1000], Loss: 0.5347\n",
      "Epoch [520/1000], Loss: 0.5254\n",
      "Epoch [521/1000], Loss: 0.5293\n",
      "Epoch [522/1000], Loss: 0.5285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [523/1000], Loss: 0.5331\n",
      "Epoch [524/1000], Loss: 0.5331\n",
      "Epoch [525/1000], Loss: 0.5308\n",
      "Epoch [526/1000], Loss: 0.5316\n",
      "Epoch [527/1000], Loss: 0.5285\n",
      "Epoch [528/1000], Loss: 0.5285\n",
      "Epoch [529/1000], Loss: 0.5308\n",
      "Epoch [530/1000], Loss: 0.5285\n",
      "Epoch [531/1000], Loss: 0.5270\n",
      "Epoch [532/1000], Loss: 0.5277\n",
      "Epoch [533/1000], Loss: 0.5316\n",
      "Epoch [534/1000], Loss: 0.5277\n",
      "Epoch [535/1000], Loss: 0.5300\n",
      "Epoch [536/1000], Loss: 0.5300\n",
      "Epoch [537/1000], Loss: 0.5362\n",
      "Epoch [538/1000], Loss: 0.5285\n",
      "Epoch [539/1000], Loss: 0.5277\n",
      "Epoch [540/1000], Loss: 0.5246\n",
      "Epoch [541/1000], Loss: 0.5231\n",
      "Epoch [542/1000], Loss: 0.5339\n",
      "Epoch [543/1000], Loss: 0.5262\n",
      "Epoch [544/1000], Loss: 0.5285\n",
      "Epoch [545/1000], Loss: 0.5285\n",
      "Epoch [546/1000], Loss: 0.5316\n",
      "Epoch [547/1000], Loss: 0.5331\n",
      "Epoch [548/1000], Loss: 0.5277\n",
      "Epoch [549/1000], Loss: 0.5254\n",
      "Epoch [550/1000], Loss: 0.5246\n",
      "Epoch [551/1000], Loss: 0.5293\n",
      "Epoch [552/1000], Loss: 0.5285\n",
      "Epoch [553/1000], Loss: 0.5231\n",
      "Epoch [554/1000], Loss: 0.5293\n",
      "Epoch [555/1000], Loss: 0.5308\n",
      "Epoch [556/1000], Loss: 0.5285\n",
      "Epoch [557/1000], Loss: 0.5277\n",
      "Epoch [558/1000], Loss: 0.5193\n",
      "Epoch [559/1000], Loss: 0.5270\n",
      "Epoch [560/1000], Loss: 0.5316\n",
      "Epoch [561/1000], Loss: 0.5277\n",
      "Epoch [562/1000], Loss: 0.5316\n",
      "Epoch [563/1000], Loss: 0.5293\n",
      "Epoch [564/1000], Loss: 0.5339\n",
      "Epoch [565/1000], Loss: 0.5223\n",
      "Epoch [566/1000], Loss: 0.5331\n",
      "Epoch [567/1000], Loss: 0.5246\n",
      "Epoch [568/1000], Loss: 0.5285\n",
      "Epoch [569/1000], Loss: 0.5308\n",
      "Epoch [570/1000], Loss: 0.5339\n",
      "Epoch [571/1000], Loss: 0.5324\n",
      "Epoch [572/1000], Loss: 0.5239\n",
      "Epoch [573/1000], Loss: 0.5239\n",
      "Epoch [574/1000], Loss: 0.5293\n",
      "Epoch [575/1000], Loss: 0.5208\n",
      "Epoch [576/1000], Loss: 0.5223\n",
      "Epoch [577/1000], Loss: 0.5331\n",
      "Epoch [578/1000], Loss: 0.5285\n",
      "Epoch [579/1000], Loss: 0.5316\n",
      "Epoch [580/1000], Loss: 0.5231\n",
      "Epoch [581/1000], Loss: 0.5308\n",
      "Epoch [582/1000], Loss: 0.5293\n",
      "Epoch [583/1000], Loss: 0.5270\n",
      "Epoch [584/1000], Loss: 0.5308\n",
      "Epoch [585/1000], Loss: 0.5270\n",
      "Epoch [586/1000], Loss: 0.5300\n",
      "Epoch [587/1000], Loss: 0.5354\n",
      "Epoch [588/1000], Loss: 0.5300\n",
      "Epoch [589/1000], Loss: 0.5270\n",
      "Epoch [590/1000], Loss: 0.5293\n",
      "Epoch [591/1000], Loss: 0.5285\n",
      "Epoch [592/1000], Loss: 0.5370\n",
      "Epoch [593/1000], Loss: 0.5277\n",
      "Epoch [594/1000], Loss: 0.5231\n",
      "Epoch [595/1000], Loss: 0.5270\n",
      "Epoch [596/1000], Loss: 0.5293\n",
      "Epoch [597/1000], Loss: 0.5262\n",
      "Epoch [598/1000], Loss: 0.5300\n",
      "Epoch [599/1000], Loss: 0.5231\n",
      "Epoch [600/1000], Loss: 0.5324\n",
      "Epoch [601/1000], Loss: 0.5293\n",
      "Epoch [602/1000], Loss: 0.5300\n",
      "Epoch [603/1000], Loss: 0.5300\n",
      "Epoch [604/1000], Loss: 0.5331\n",
      "Epoch [605/1000], Loss: 0.5285\n",
      "Epoch [606/1000], Loss: 0.5308\n",
      "Epoch [607/1000], Loss: 0.5339\n",
      "Epoch [608/1000], Loss: 0.5246\n",
      "Epoch [609/1000], Loss: 0.5293\n",
      "Epoch [610/1000], Loss: 0.5254\n",
      "Epoch [611/1000], Loss: 0.5293\n",
      "Epoch [612/1000], Loss: 0.5293\n",
      "Epoch [613/1000], Loss: 0.5316\n",
      "Epoch [614/1000], Loss: 0.5339\n",
      "Epoch [615/1000], Loss: 0.5293\n",
      "Epoch [616/1000], Loss: 0.5293\n",
      "Epoch [617/1000], Loss: 0.5254\n",
      "Epoch [618/1000], Loss: 0.5254\n",
      "Epoch [619/1000], Loss: 0.5277\n",
      "Epoch [620/1000], Loss: 0.5293\n",
      "Epoch [621/1000], Loss: 0.5331\n",
      "Epoch [622/1000], Loss: 0.5262\n",
      "Epoch [623/1000], Loss: 0.5254\n",
      "Epoch [624/1000], Loss: 0.5293\n",
      "Epoch [625/1000], Loss: 0.5300\n",
      "Epoch [626/1000], Loss: 0.5200\n",
      "Epoch [627/1000], Loss: 0.5308\n",
      "Epoch [628/1000], Loss: 0.5293\n",
      "Epoch [629/1000], Loss: 0.5300\n",
      "Epoch [630/1000], Loss: 0.5262\n",
      "Epoch [631/1000], Loss: 0.5270\n",
      "Epoch [632/1000], Loss: 0.5308\n",
      "Epoch [633/1000], Loss: 0.5231\n",
      "Epoch [634/1000], Loss: 0.5277\n",
      "Epoch [635/1000], Loss: 0.5293\n",
      "Epoch [636/1000], Loss: 0.5270\n",
      "Epoch [637/1000], Loss: 0.5277\n",
      "Epoch [638/1000], Loss: 0.5254\n",
      "Epoch [639/1000], Loss: 0.5277\n",
      "Epoch [640/1000], Loss: 0.5308\n",
      "Epoch [641/1000], Loss: 0.5324\n",
      "Epoch [642/1000], Loss: 0.5270\n",
      "Epoch [643/1000], Loss: 0.5254\n",
      "Epoch [644/1000], Loss: 0.5262\n",
      "Epoch [645/1000], Loss: 0.5277\n",
      "Epoch [646/1000], Loss: 0.5216\n",
      "Epoch [647/1000], Loss: 0.5285\n",
      "Epoch [648/1000], Loss: 0.5285\n",
      "Epoch [649/1000], Loss: 0.5262\n",
      "Epoch [650/1000], Loss: 0.5300\n",
      "Epoch [651/1000], Loss: 0.5300\n",
      "Epoch [652/1000], Loss: 0.5270\n",
      "Epoch [653/1000], Loss: 0.5300\n",
      "Epoch [654/1000], Loss: 0.5362\n",
      "Epoch [655/1000], Loss: 0.5254\n",
      "Epoch [656/1000], Loss: 0.5270\n",
      "Epoch [657/1000], Loss: 0.5246\n",
      "Epoch [658/1000], Loss: 0.5254\n",
      "Epoch [659/1000], Loss: 0.5300\n",
      "Epoch [660/1000], Loss: 0.5254\n",
      "Epoch [661/1000], Loss: 0.5239\n",
      "Epoch [662/1000], Loss: 0.5331\n",
      "Epoch [663/1000], Loss: 0.5293\n",
      "Epoch [664/1000], Loss: 0.5231\n",
      "Epoch [665/1000], Loss: 0.5324\n",
      "Epoch [666/1000], Loss: 0.5300\n",
      "Epoch [667/1000], Loss: 0.5308\n",
      "Epoch [668/1000], Loss: 0.5354\n",
      "Epoch [669/1000], Loss: 0.5262\n",
      "Epoch [670/1000], Loss: 0.5285\n",
      "Epoch [671/1000], Loss: 0.5277\n",
      "Epoch [672/1000], Loss: 0.5300\n",
      "Epoch [673/1000], Loss: 0.5331\n",
      "Epoch [674/1000], Loss: 0.5277\n",
      "Epoch [675/1000], Loss: 0.5385\n",
      "Epoch [676/1000], Loss: 0.5293\n",
      "Epoch [677/1000], Loss: 0.5277\n",
      "Epoch [678/1000], Loss: 0.5300\n",
      "Epoch [679/1000], Loss: 0.5254\n",
      "Epoch [680/1000], Loss: 0.5300\n",
      "Epoch [681/1000], Loss: 0.5316\n",
      "Epoch [682/1000], Loss: 0.5308\n",
      "Epoch [683/1000], Loss: 0.5285\n",
      "Epoch [684/1000], Loss: 0.5324\n",
      "Epoch [685/1000], Loss: 0.5285\n",
      "Epoch [686/1000], Loss: 0.5254\n",
      "Epoch [687/1000], Loss: 0.5324\n",
      "Epoch [688/1000], Loss: 0.5246\n",
      "Epoch [689/1000], Loss: 0.5285\n",
      "Epoch [690/1000], Loss: 0.5216\n",
      "Epoch [691/1000], Loss: 0.5262\n",
      "Epoch [692/1000], Loss: 0.5300\n",
      "Epoch [693/1000], Loss: 0.5293\n",
      "Epoch [694/1000], Loss: 0.5331\n",
      "Epoch [695/1000], Loss: 0.5270\n",
      "Epoch [696/1000], Loss: 0.5300\n",
      "Epoch [697/1000], Loss: 0.5300\n",
      "Epoch [698/1000], Loss: 0.5308\n",
      "Epoch [699/1000], Loss: 0.5300\n",
      "Epoch [700/1000], Loss: 0.5300\n",
      "Epoch [701/1000], Loss: 0.5246\n",
      "Epoch [702/1000], Loss: 0.5262\n",
      "Epoch [703/1000], Loss: 0.5239\n",
      "Epoch [704/1000], Loss: 0.5216\n",
      "Epoch [705/1000], Loss: 0.5308\n",
      "Epoch [706/1000], Loss: 0.5285\n",
      "Epoch [707/1000], Loss: 0.5277\n",
      "Epoch [708/1000], Loss: 0.5308\n",
      "Epoch [709/1000], Loss: 0.5300\n",
      "Epoch [710/1000], Loss: 0.5270\n",
      "Epoch [711/1000], Loss: 0.5277\n",
      "Epoch [712/1000], Loss: 0.5262\n",
      "Epoch [713/1000], Loss: 0.5270\n",
      "Epoch [714/1000], Loss: 0.5308\n",
      "Epoch [715/1000], Loss: 0.5300\n",
      "Epoch [716/1000], Loss: 0.5270\n",
      "Epoch [717/1000], Loss: 0.5277\n",
      "Epoch [718/1000], Loss: 0.5339\n",
      "Epoch [719/1000], Loss: 0.5231\n",
      "Epoch [720/1000], Loss: 0.5277\n",
      "Epoch [721/1000], Loss: 0.5246\n",
      "Epoch [722/1000], Loss: 0.5231\n",
      "Epoch [723/1000], Loss: 0.5270\n",
      "Epoch [724/1000], Loss: 0.5223\n",
      "Epoch [725/1000], Loss: 0.5277\n",
      "Epoch [726/1000], Loss: 0.5316\n",
      "Epoch [727/1000], Loss: 0.5277\n",
      "Epoch [728/1000], Loss: 0.5316\n",
      "Epoch [729/1000], Loss: 0.5293\n",
      "Epoch [730/1000], Loss: 0.5308\n",
      "Epoch [731/1000], Loss: 0.5239\n",
      "Epoch [732/1000], Loss: 0.5300\n",
      "Epoch [733/1000], Loss: 0.5277\n",
      "Epoch [734/1000], Loss: 0.5277\n",
      "Epoch [735/1000], Loss: 0.5277\n",
      "Epoch [736/1000], Loss: 0.5300\n",
      "Epoch [737/1000], Loss: 0.5308\n",
      "Epoch [738/1000], Loss: 0.5246\n",
      "Epoch [739/1000], Loss: 0.5300\n",
      "Epoch [740/1000], Loss: 0.5308\n",
      "Epoch [741/1000], Loss: 0.5285\n",
      "Epoch [742/1000], Loss: 0.5262\n",
      "Epoch [743/1000], Loss: 0.5293\n",
      "Epoch [744/1000], Loss: 0.5293\n",
      "Epoch [745/1000], Loss: 0.5331\n",
      "Epoch [746/1000], Loss: 0.5246\n",
      "Epoch [747/1000], Loss: 0.5347\n",
      "Epoch [748/1000], Loss: 0.5324\n",
      "Epoch [749/1000], Loss: 0.5208\n",
      "Epoch [750/1000], Loss: 0.5246\n",
      "Epoch [751/1000], Loss: 0.5300\n",
      "Epoch [752/1000], Loss: 0.5285\n",
      "Epoch [753/1000], Loss: 0.5277\n",
      "Epoch [754/1000], Loss: 0.5316\n",
      "Epoch [755/1000], Loss: 0.5193\n",
      "Epoch [756/1000], Loss: 0.5223\n",
      "Epoch [757/1000], Loss: 0.5300\n",
      "Epoch [758/1000], Loss: 0.5254\n",
      "Epoch [759/1000], Loss: 0.5293\n",
      "Epoch [760/1000], Loss: 0.5277\n",
      "Epoch [761/1000], Loss: 0.5262\n",
      "Epoch [762/1000], Loss: 0.5254\n",
      "Epoch [763/1000], Loss: 0.5300\n",
      "Epoch [764/1000], Loss: 0.5285\n",
      "Epoch [765/1000], Loss: 0.5277\n",
      "Epoch [766/1000], Loss: 0.5347\n",
      "Epoch [767/1000], Loss: 0.5254\n",
      "Epoch [768/1000], Loss: 0.5308\n",
      "Epoch [769/1000], Loss: 0.5254\n",
      "Epoch [770/1000], Loss: 0.5300\n",
      "Epoch [771/1000], Loss: 0.5285\n",
      "Epoch [772/1000], Loss: 0.5285\n",
      "Epoch [773/1000], Loss: 0.5285\n",
      "Epoch [774/1000], Loss: 0.5308\n",
      "Epoch [775/1000], Loss: 0.5331\n",
      "Epoch [776/1000], Loss: 0.5270\n",
      "Epoch [777/1000], Loss: 0.5300\n",
      "Epoch [778/1000], Loss: 0.5270\n",
      "Epoch [779/1000], Loss: 0.5300\n",
      "Epoch [780/1000], Loss: 0.5370\n",
      "Epoch [781/1000], Loss: 0.5339\n",
      "Epoch [782/1000], Loss: 0.5262\n",
      "Epoch [783/1000], Loss: 0.5270\n",
      "Epoch [784/1000], Loss: 0.5277\n",
      "Epoch [785/1000], Loss: 0.5316\n",
      "Epoch [786/1000], Loss: 0.5324\n",
      "Epoch [787/1000], Loss: 0.5293\n",
      "Epoch [788/1000], Loss: 0.5308\n",
      "Epoch [789/1000], Loss: 0.5354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [790/1000], Loss: 0.5331\n",
      "Epoch [791/1000], Loss: 0.5239\n",
      "Epoch [792/1000], Loss: 0.5277\n",
      "Epoch [793/1000], Loss: 0.5254\n",
      "Epoch [794/1000], Loss: 0.5270\n",
      "Epoch [795/1000], Loss: 0.5339\n",
      "Epoch [796/1000], Loss: 0.5293\n",
      "Epoch [797/1000], Loss: 0.5316\n",
      "Epoch [798/1000], Loss: 0.5285\n",
      "Epoch [799/1000], Loss: 0.5262\n",
      "Epoch [800/1000], Loss: 0.5254\n",
      "Epoch [801/1000], Loss: 0.5300\n",
      "Epoch [802/1000], Loss: 0.5308\n",
      "Epoch [803/1000], Loss: 0.5277\n",
      "Epoch [804/1000], Loss: 0.5277\n",
      "Epoch [805/1000], Loss: 0.5293\n",
      "Epoch [806/1000], Loss: 0.5277\n",
      "Epoch [807/1000], Loss: 0.5285\n",
      "Epoch [808/1000], Loss: 0.5277\n",
      "Epoch [809/1000], Loss: 0.5285\n",
      "Epoch [810/1000], Loss: 0.5285\n",
      "Epoch [811/1000], Loss: 0.5308\n",
      "Epoch [812/1000], Loss: 0.5239\n",
      "Epoch [813/1000], Loss: 0.5300\n",
      "Epoch [814/1000], Loss: 0.5316\n",
      "Epoch [815/1000], Loss: 0.5262\n",
      "Epoch [816/1000], Loss: 0.5308\n",
      "Epoch [817/1000], Loss: 0.5316\n",
      "Epoch [818/1000], Loss: 0.5308\n",
      "Epoch [819/1000], Loss: 0.5285\n",
      "Epoch [820/1000], Loss: 0.5285\n",
      "Epoch [821/1000], Loss: 0.5370\n",
      "Epoch [822/1000], Loss: 0.5246\n",
      "Epoch [823/1000], Loss: 0.5285\n",
      "Epoch [824/1000], Loss: 0.5285\n",
      "Epoch [825/1000], Loss: 0.5347\n",
      "Epoch [826/1000], Loss: 0.5324\n",
      "Epoch [827/1000], Loss: 0.5239\n",
      "Epoch [828/1000], Loss: 0.5262\n",
      "Epoch [829/1000], Loss: 0.5262\n",
      "Epoch [830/1000], Loss: 0.5331\n",
      "Epoch [831/1000], Loss: 0.5254\n",
      "Epoch [832/1000], Loss: 0.5324\n",
      "Epoch [833/1000], Loss: 0.5293\n",
      "Epoch [834/1000], Loss: 0.5293\n",
      "Epoch [835/1000], Loss: 0.5254\n",
      "Epoch [836/1000], Loss: 0.5254\n",
      "Epoch [837/1000], Loss: 0.5254\n",
      "Epoch [838/1000], Loss: 0.5277\n",
      "Epoch [839/1000], Loss: 0.5246\n",
      "Epoch [840/1000], Loss: 0.5339\n",
      "Epoch [841/1000], Loss: 0.5262\n",
      "Epoch [842/1000], Loss: 0.5300\n",
      "Epoch [843/1000], Loss: 0.5270\n",
      "Epoch [844/1000], Loss: 0.5270\n",
      "Epoch [845/1000], Loss: 0.5262\n",
      "Epoch [846/1000], Loss: 0.5316\n",
      "Epoch [847/1000], Loss: 0.5262\n",
      "Epoch [848/1000], Loss: 0.5293\n",
      "Epoch [849/1000], Loss: 0.5285\n",
      "Epoch [850/1000], Loss: 0.5254\n",
      "Epoch [851/1000], Loss: 0.5293\n",
      "Epoch [852/1000], Loss: 0.5293\n",
      "Epoch [853/1000], Loss: 0.5293\n",
      "Epoch [854/1000], Loss: 0.5316\n",
      "Epoch [855/1000], Loss: 0.5347\n",
      "Epoch [856/1000], Loss: 0.5308\n",
      "Epoch [857/1000], Loss: 0.5285\n",
      "Epoch [858/1000], Loss: 0.5246\n",
      "Epoch [859/1000], Loss: 0.5347\n",
      "Epoch [860/1000], Loss: 0.5300\n",
      "Epoch [861/1000], Loss: 0.5231\n",
      "Epoch [862/1000], Loss: 0.5324\n",
      "Epoch [863/1000], Loss: 0.5324\n",
      "Epoch [864/1000], Loss: 0.5216\n",
      "Epoch [865/1000], Loss: 0.5285\n",
      "Epoch [866/1000], Loss: 0.5293\n",
      "Epoch [867/1000], Loss: 0.5370\n",
      "Epoch [868/1000], Loss: 0.5262\n",
      "Epoch [869/1000], Loss: 0.5270\n",
      "Epoch [870/1000], Loss: 0.5300\n",
      "Epoch [871/1000], Loss: 0.5270\n",
      "Epoch [872/1000], Loss: 0.5231\n",
      "Epoch [873/1000], Loss: 0.5316\n",
      "Epoch [874/1000], Loss: 0.5246\n",
      "Epoch [875/1000], Loss: 0.5254\n",
      "Epoch [876/1000], Loss: 0.5362\n",
      "Epoch [877/1000], Loss: 0.5277\n",
      "Epoch [878/1000], Loss: 0.5308\n",
      "Epoch [879/1000], Loss: 0.5239\n",
      "Epoch [880/1000], Loss: 0.5270\n",
      "Epoch [881/1000], Loss: 0.5324\n",
      "Epoch [882/1000], Loss: 0.5308\n",
      "Epoch [883/1000], Loss: 0.5308\n",
      "Epoch [884/1000], Loss: 0.5324\n",
      "Epoch [885/1000], Loss: 0.5339\n",
      "Epoch [886/1000], Loss: 0.5324\n",
      "Epoch [887/1000], Loss: 0.5308\n",
      "Epoch [888/1000], Loss: 0.5270\n",
      "Epoch [889/1000], Loss: 0.5339\n",
      "Epoch [890/1000], Loss: 0.5277\n",
      "Epoch [891/1000], Loss: 0.5316\n",
      "Epoch [892/1000], Loss: 0.5331\n",
      "Epoch [893/1000], Loss: 0.5216\n",
      "Epoch [894/1000], Loss: 0.5308\n",
      "Epoch [895/1000], Loss: 0.5270\n",
      "Epoch [896/1000], Loss: 0.5300\n",
      "Epoch [897/1000], Loss: 0.5270\n",
      "Epoch [898/1000], Loss: 0.5254\n",
      "Epoch [899/1000], Loss: 0.5324\n",
      "Epoch [900/1000], Loss: 0.5246\n",
      "Epoch [901/1000], Loss: 0.5254\n",
      "Epoch [902/1000], Loss: 0.5231\n",
      "Epoch [903/1000], Loss: 0.5277\n",
      "Epoch [904/1000], Loss: 0.5285\n",
      "Epoch [905/1000], Loss: 0.5324\n",
      "Epoch [906/1000], Loss: 0.5262\n",
      "Epoch [907/1000], Loss: 0.5300\n",
      "Epoch [908/1000], Loss: 0.5246\n",
      "Epoch [909/1000], Loss: 0.5270\n",
      "Epoch [910/1000], Loss: 0.5308\n",
      "Epoch [911/1000], Loss: 0.5246\n",
      "Epoch [912/1000], Loss: 0.5339\n",
      "Epoch [913/1000], Loss: 0.5316\n",
      "Epoch [914/1000], Loss: 0.5331\n",
      "Epoch [915/1000], Loss: 0.5285\n",
      "Epoch [916/1000], Loss: 0.5270\n",
      "Epoch [917/1000], Loss: 0.5300\n",
      "Epoch [918/1000], Loss: 0.5331\n",
      "Epoch [919/1000], Loss: 0.5270\n",
      "Epoch [920/1000], Loss: 0.5331\n",
      "Epoch [921/1000], Loss: 0.5193\n",
      "Epoch [922/1000], Loss: 0.5362\n",
      "Epoch [923/1000], Loss: 0.5223\n",
      "Epoch [924/1000], Loss: 0.5262\n",
      "Epoch [925/1000], Loss: 0.5254\n",
      "Epoch [926/1000], Loss: 0.5208\n",
      "Epoch [927/1000], Loss: 0.5324\n",
      "Epoch [928/1000], Loss: 0.5300\n",
      "Epoch [929/1000], Loss: 0.5285\n",
      "Epoch [930/1000], Loss: 0.5185\n",
      "Epoch [931/1000], Loss: 0.5347\n",
      "Epoch [932/1000], Loss: 0.5239\n",
      "Epoch [933/1000], Loss: 0.5254\n",
      "Epoch [934/1000], Loss: 0.5285\n",
      "Epoch [935/1000], Loss: 0.5293\n",
      "Epoch [936/1000], Loss: 0.5223\n",
      "Epoch [937/1000], Loss: 0.5277\n",
      "Epoch [938/1000], Loss: 0.5246\n",
      "Epoch [939/1000], Loss: 0.5270\n",
      "Epoch [940/1000], Loss: 0.5331\n",
      "Epoch [941/1000], Loss: 0.5293\n",
      "Epoch [942/1000], Loss: 0.5362\n",
      "Epoch [943/1000], Loss: 0.5254\n",
      "Epoch [944/1000], Loss: 0.5308\n",
      "Epoch [945/1000], Loss: 0.5246\n",
      "Epoch [946/1000], Loss: 0.5324\n",
      "Epoch [947/1000], Loss: 0.5316\n",
      "Epoch [948/1000], Loss: 0.5262\n",
      "Epoch [949/1000], Loss: 0.5270\n",
      "Epoch [950/1000], Loss: 0.5293\n",
      "Epoch [951/1000], Loss: 0.5239\n",
      "Epoch [952/1000], Loss: 0.5285\n",
      "Epoch [953/1000], Loss: 0.5231\n",
      "Epoch [954/1000], Loss: 0.5308\n",
      "Epoch [955/1000], Loss: 0.5362\n",
      "Epoch [956/1000], Loss: 0.5223\n",
      "Epoch [957/1000], Loss: 0.5331\n",
      "Epoch [958/1000], Loss: 0.5285\n",
      "Epoch [959/1000], Loss: 0.5300\n",
      "Epoch [960/1000], Loss: 0.5324\n",
      "Epoch [961/1000], Loss: 0.5270\n",
      "Epoch [962/1000], Loss: 0.5239\n",
      "Epoch [963/1000], Loss: 0.5308\n",
      "Epoch [964/1000], Loss: 0.5277\n",
      "Epoch [965/1000], Loss: 0.5293\n",
      "Epoch [966/1000], Loss: 0.5300\n",
      "Epoch [967/1000], Loss: 0.5300\n",
      "Epoch [968/1000], Loss: 0.5277\n",
      "Epoch [969/1000], Loss: 0.5308\n",
      "Epoch [970/1000], Loss: 0.5300\n",
      "Epoch [971/1000], Loss: 0.5293\n",
      "Epoch [972/1000], Loss: 0.5277\n",
      "Epoch [973/1000], Loss: 0.5270\n",
      "Epoch [974/1000], Loss: 0.5254\n",
      "Epoch [975/1000], Loss: 0.5300\n",
      "Epoch [976/1000], Loss: 0.5300\n",
      "Epoch [977/1000], Loss: 0.5285\n",
      "Epoch [978/1000], Loss: 0.5308\n",
      "Epoch [979/1000], Loss: 0.5316\n",
      "Epoch [980/1000], Loss: 0.5239\n",
      "Epoch [981/1000], Loss: 0.5262\n",
      "Epoch [982/1000], Loss: 0.5300\n",
      "Epoch [983/1000], Loss: 0.5293\n",
      "Epoch [984/1000], Loss: 0.5254\n",
      "Epoch [985/1000], Loss: 0.5316\n",
      "Epoch [986/1000], Loss: 0.5300\n",
      "Epoch [987/1000], Loss: 0.5308\n",
      "Epoch [988/1000], Loss: 0.5347\n",
      "Epoch [989/1000], Loss: 0.5331\n",
      "Epoch [990/1000], Loss: 0.5339\n",
      "Epoch [991/1000], Loss: 0.5300\n",
      "Epoch [992/1000], Loss: 0.5216\n",
      "Epoch [993/1000], Loss: 0.5193\n",
      "Epoch [994/1000], Loss: 0.5216\n",
      "Epoch [995/1000], Loss: 0.5293\n",
      "Epoch [996/1000], Loss: 0.5300\n",
      "Epoch [997/1000], Loss: 0.5270\n",
      "Epoch [998/1000], Loss: 0.5239\n",
      "Epoch [999/1000], Loss: 0.5300\n",
      "Epoch [1000/1000], Loss: 0.5339\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 302, lr :0.1, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2632\n",
      "Epoch [2/1000], Loss: 0.2555\n",
      "Epoch [3/1000], Loss: 0.2527\n",
      "Epoch [4/1000], Loss: 0.2505\n",
      "Epoch [5/1000], Loss: 0.2499\n",
      "Epoch [6/1000], Loss: 0.2494\n",
      "Epoch [7/1000], Loss: 0.2489\n",
      "Epoch [8/1000], Loss: 0.2489\n",
      "Epoch [9/1000], Loss: 0.2475\n",
      "Epoch [10/1000], Loss: 0.2466\n",
      "Epoch [11/1000], Loss: 0.2472\n",
      "Epoch [12/1000], Loss: 0.2454\n",
      "Epoch [13/1000], Loss: 0.2475\n",
      "Epoch [14/1000], Loss: 0.2459\n",
      "Epoch [15/1000], Loss: 0.2471\n",
      "Epoch [16/1000], Loss: 0.2472\n",
      "Epoch [17/1000], Loss: 0.2471\n",
      "Epoch [18/1000], Loss: 0.2469\n",
      "Epoch [19/1000], Loss: 0.2465\n",
      "Epoch [20/1000], Loss: 0.2448\n",
      "Epoch [21/1000], Loss: 0.2448\n",
      "Epoch [22/1000], Loss: 0.2466\n",
      "Epoch [23/1000], Loss: 0.2449\n",
      "Epoch [24/1000], Loss: 0.2455\n",
      "Epoch [25/1000], Loss: 0.2458\n",
      "Epoch [26/1000], Loss: 0.2443\n",
      "Epoch [27/1000], Loss: 0.2454\n",
      "Epoch [28/1000], Loss: 0.2451\n",
      "Epoch [29/1000], Loss: 0.2443\n",
      "Epoch [30/1000], Loss: 0.2453\n",
      "Epoch [31/1000], Loss: 0.2439\n",
      "Epoch [32/1000], Loss: 0.2441\n",
      "Epoch [33/1000], Loss: 0.2441\n",
      "Epoch [34/1000], Loss: 0.2421\n",
      "Epoch [35/1000], Loss: 0.2447\n",
      "Epoch [36/1000], Loss: 0.2438\n",
      "Epoch [37/1000], Loss: 0.2428\n",
      "Epoch [38/1000], Loss: 0.2422\n",
      "Epoch [39/1000], Loss: 0.2430\n",
      "Epoch [40/1000], Loss: 0.2419\n",
      "Epoch [41/1000], Loss: 0.2418\n",
      "Epoch [42/1000], Loss: 0.2425\n",
      "Epoch [43/1000], Loss: 0.2405\n",
      "Epoch [44/1000], Loss: 0.2417\n",
      "Epoch [45/1000], Loss: 0.2419\n",
      "Epoch [46/1000], Loss: 0.2427\n",
      "Epoch [47/1000], Loss: 0.2413\n",
      "Epoch [48/1000], Loss: 0.2410\n",
      "Epoch [49/1000], Loss: 0.2405\n",
      "Epoch [50/1000], Loss: 0.2407\n",
      "Epoch [51/1000], Loss: 0.2407\n",
      "Epoch [52/1000], Loss: 0.2401\n",
      "Epoch [53/1000], Loss: 0.2408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/1000], Loss: 0.2391\n",
      "Epoch [55/1000], Loss: 0.2378\n",
      "Epoch [56/1000], Loss: 0.2376\n",
      "Epoch [57/1000], Loss: 0.2381\n",
      "Epoch [58/1000], Loss: 0.2383\n",
      "Epoch [59/1000], Loss: 0.2370\n",
      "Epoch [60/1000], Loss: 0.2383\n",
      "Epoch [61/1000], Loss: 0.2395\n",
      "Epoch [62/1000], Loss: 0.2367\n",
      "Epoch [63/1000], Loss: 0.2373\n",
      "Epoch [64/1000], Loss: 0.2358\n",
      "Epoch [65/1000], Loss: 0.2370\n",
      "Epoch [66/1000], Loss: 0.2351\n",
      "Epoch [67/1000], Loss: 0.2341\n",
      "Epoch [68/1000], Loss: 0.2348\n",
      "Epoch [69/1000], Loss: 0.2343\n",
      "Epoch [70/1000], Loss: 0.2340\n",
      "Epoch [71/1000], Loss: 0.2335\n",
      "Epoch [72/1000], Loss: 0.2339\n",
      "Epoch [73/1000], Loss: 0.2332\n",
      "Epoch [74/1000], Loss: 0.2329\n",
      "Epoch [75/1000], Loss: 0.2314\n",
      "Epoch [76/1000], Loss: 0.2302\n",
      "Epoch [77/1000], Loss: 0.2306\n",
      "Epoch [78/1000], Loss: 0.2312\n",
      "Epoch [79/1000], Loss: 0.2299\n",
      "Epoch [80/1000], Loss: 0.2299\n",
      "Epoch [81/1000], Loss: 0.2276\n",
      "Epoch [82/1000], Loss: 0.2270\n",
      "Epoch [83/1000], Loss: 0.2297\n",
      "Epoch [84/1000], Loss: 0.2285\n",
      "Epoch [85/1000], Loss: 0.2268\n",
      "Epoch [86/1000], Loss: 0.2262\n",
      "Epoch [87/1000], Loss: 0.2245\n",
      "Epoch [88/1000], Loss: 0.2262\n",
      "Epoch [89/1000], Loss: 0.2249\n",
      "Epoch [90/1000], Loss: 0.2232\n",
      "Epoch [91/1000], Loss: 0.2246\n",
      "Epoch [92/1000], Loss: 0.2235\n",
      "Epoch [93/1000], Loss: 0.2224\n",
      "Epoch [94/1000], Loss: 0.2217\n",
      "Epoch [95/1000], Loss: 0.2219\n",
      "Epoch [96/1000], Loss: 0.2217\n",
      "Epoch [97/1000], Loss: 0.2212\n",
      "Epoch [98/1000], Loss: 0.2195\n",
      "Epoch [99/1000], Loss: 0.2190\n",
      "Epoch [100/1000], Loss: 0.2185\n",
      "Epoch [101/1000], Loss: 0.2157\n",
      "Epoch [102/1000], Loss: 0.2165\n",
      "Epoch [103/1000], Loss: 0.2162\n",
      "Epoch [104/1000], Loss: 0.2166\n",
      "Epoch [105/1000], Loss: 0.2146\n",
      "Epoch [106/1000], Loss: 0.2145\n",
      "Epoch [107/1000], Loss: 0.2142\n",
      "Epoch [108/1000], Loss: 0.2130\n",
      "Epoch [109/1000], Loss: 0.2140\n",
      "Epoch [110/1000], Loss: 0.2125\n",
      "Epoch [111/1000], Loss: 0.2094\n",
      "Epoch [112/1000], Loss: 0.2131\n",
      "Epoch [113/1000], Loss: 0.2110\n",
      "Epoch [114/1000], Loss: 0.2093\n",
      "Epoch [115/1000], Loss: 0.2088\n",
      "Epoch [116/1000], Loss: 0.2073\n",
      "Epoch [117/1000], Loss: 0.2066\n",
      "Epoch [118/1000], Loss: 0.2062\n",
      "Epoch [119/1000], Loss: 0.2043\n",
      "Epoch [120/1000], Loss: 0.2051\n",
      "Epoch [121/1000], Loss: 0.2023\n",
      "Epoch [122/1000], Loss: 0.2017\n",
      "Epoch [123/1000], Loss: 0.2000\n",
      "Epoch [124/1000], Loss: 0.1987\n",
      "Epoch [125/1000], Loss: 0.2000\n",
      "Epoch [126/1000], Loss: 0.1979\n",
      "Epoch [127/1000], Loss: 0.1970\n",
      "Epoch [128/1000], Loss: 0.1968\n",
      "Epoch [129/1000], Loss: 0.1934\n",
      "Epoch [130/1000], Loss: 0.1941\n",
      "Epoch [131/1000], Loss: 0.1921\n",
      "Epoch [132/1000], Loss: 0.1916\n",
      "Epoch [133/1000], Loss: 0.1917\n",
      "Epoch [134/1000], Loss: 0.1890\n",
      "Epoch [135/1000], Loss: 0.1873\n",
      "Epoch [136/1000], Loss: 0.1871\n",
      "Epoch [137/1000], Loss: 0.1852\n",
      "Epoch [138/1000], Loss: 0.1837\n",
      "Epoch [139/1000], Loss: 0.1824\n",
      "Epoch [140/1000], Loss: 0.1827\n",
      "Epoch [141/1000], Loss: 0.1805\n",
      "Epoch [142/1000], Loss: 0.1772\n",
      "Epoch [143/1000], Loss: 0.1753\n",
      "Epoch [144/1000], Loss: 0.1736\n",
      "Epoch [145/1000], Loss: 0.1728\n",
      "Epoch [146/1000], Loss: 0.1709\n",
      "Epoch [147/1000], Loss: 0.1710\n",
      "Epoch [148/1000], Loss: 0.1676\n",
      "Epoch [149/1000], Loss: 0.1667\n",
      "Epoch [150/1000], Loss: 0.1642\n",
      "Epoch [151/1000], Loss: 0.1634\n",
      "Epoch [152/1000], Loss: 0.1627\n",
      "Epoch [153/1000], Loss: 0.1589\n",
      "Epoch [154/1000], Loss: 0.1582\n",
      "Epoch [155/1000], Loss: 0.1545\n",
      "Epoch [156/1000], Loss: 0.1544\n",
      "Epoch [157/1000], Loss: 0.1529\n",
      "Epoch [158/1000], Loss: 0.1520\n",
      "Epoch [159/1000], Loss: 0.1515\n",
      "Epoch [160/1000], Loss: 0.1480\n",
      "Epoch [161/1000], Loss: 0.1478\n",
      "Epoch [162/1000], Loss: 0.1462\n",
      "Epoch [163/1000], Loss: 0.1459\n",
      "Epoch [164/1000], Loss: 0.1420\n",
      "Epoch [165/1000], Loss: 0.1409\n",
      "Epoch [166/1000], Loss: 0.1394\n",
      "Epoch [167/1000], Loss: 0.1374\n",
      "Epoch [168/1000], Loss: 0.1375\n",
      "Epoch [169/1000], Loss: 0.1433\n",
      "Epoch [170/1000], Loss: 0.1332\n",
      "Epoch [171/1000], Loss: 0.1314\n",
      "Epoch [172/1000], Loss: 0.1312\n",
      "Epoch [173/1000], Loss: 0.1307\n",
      "Epoch [174/1000], Loss: 0.1283\n",
      "Epoch [175/1000], Loss: 0.1241\n",
      "Epoch [176/1000], Loss: 0.1235\n",
      "Epoch [177/1000], Loss: 0.1246\n",
      "Epoch [178/1000], Loss: 0.1236\n",
      "Epoch [179/1000], Loss: 0.1266\n",
      "Epoch [180/1000], Loss: 0.1230\n",
      "Epoch [181/1000], Loss: 0.1165\n",
      "Epoch [182/1000], Loss: 0.1138\n",
      "Epoch [183/1000], Loss: 0.1112\n",
      "Epoch [184/1000], Loss: 0.1097\n",
      "Epoch [185/1000], Loss: 0.1115\n",
      "Epoch [186/1000], Loss: 0.1076\n",
      "Epoch [187/1000], Loss: 0.1096\n",
      "Epoch [188/1000], Loss: 0.1094\n",
      "Epoch [189/1000], Loss: 0.1060\n",
      "Epoch [190/1000], Loss: 0.1084\n",
      "Epoch [191/1000], Loss: 0.1040\n",
      "Epoch [192/1000], Loss: 0.1010\n",
      "Epoch [193/1000], Loss: 0.1032\n",
      "Epoch [194/1000], Loss: 0.1004\n",
      "Epoch [195/1000], Loss: 0.0918\n",
      "Epoch [196/1000], Loss: 0.0914\n",
      "Epoch [197/1000], Loss: 0.0897\n",
      "Epoch [198/1000], Loss: 0.0926\n",
      "Epoch [199/1000], Loss: 0.0868\n",
      "Epoch [200/1000], Loss: 0.0877\n",
      "Epoch [201/1000], Loss: 0.0871\n",
      "Epoch [202/1000], Loss: 0.0857\n",
      "Epoch [203/1000], Loss: 0.0801\n",
      "Epoch [204/1000], Loss: 0.0796\n",
      "Epoch [205/1000], Loss: 0.0751\n",
      "Epoch [206/1000], Loss: 0.0801\n",
      "Epoch [207/1000], Loss: 0.0805\n",
      "Epoch [208/1000], Loss: 0.0802\n",
      "Epoch [209/1000], Loss: 0.0756\n",
      "Epoch [210/1000], Loss: 0.0819\n",
      "Epoch [211/1000], Loss: 0.0692\n",
      "Epoch [212/1000], Loss: 0.0750\n",
      "Epoch [213/1000], Loss: 0.0702\n",
      "Epoch [214/1000], Loss: 0.0772\n",
      "Epoch [215/1000], Loss: 0.0726\n",
      "Epoch [216/1000], Loss: 0.0645\n",
      "Epoch [217/1000], Loss: 0.0756\n",
      "Epoch [218/1000], Loss: 0.0644\n",
      "Epoch [219/1000], Loss: 0.0599\n",
      "Epoch [220/1000], Loss: 0.0615\n",
      "Epoch [221/1000], Loss: 0.0678\n",
      "Epoch [222/1000], Loss: 0.0656\n",
      "Epoch [223/1000], Loss: 0.0615\n",
      "Epoch [224/1000], Loss: 0.0566\n",
      "Epoch [225/1000], Loss: 0.0623\n",
      "Epoch [226/1000], Loss: 0.0540\n",
      "Epoch [227/1000], Loss: 0.0699\n",
      "Epoch [228/1000], Loss: 0.0664\n",
      "Epoch [229/1000], Loss: 0.0589\n",
      "Epoch [230/1000], Loss: 0.0671\n",
      "Epoch [231/1000], Loss: 0.0464\n",
      "Epoch [232/1000], Loss: 0.0485\n",
      "Epoch [233/1000], Loss: 0.0563\n",
      "Epoch [234/1000], Loss: 0.0473\n",
      "Epoch [235/1000], Loss: 0.0498\n",
      "Epoch [236/1000], Loss: 0.0554\n",
      "Epoch [237/1000], Loss: 0.0467\n",
      "Epoch [238/1000], Loss: 0.0464\n",
      "Epoch [239/1000], Loss: 0.0400\n",
      "Epoch [240/1000], Loss: 0.0442\n",
      "Epoch [241/1000], Loss: 0.0555\n",
      "Epoch [242/1000], Loss: 0.0398\n",
      "Epoch [243/1000], Loss: 0.0426\n",
      "Epoch [244/1000], Loss: 0.0421\n",
      "Epoch [245/1000], Loss: 0.0614\n",
      "Epoch [246/1000], Loss: 0.0352\n",
      "Epoch [247/1000], Loss: 0.0431\n",
      "Epoch [248/1000], Loss: 0.0437\n",
      "Epoch [249/1000], Loss: 0.0411\n",
      "Epoch [250/1000], Loss: 0.0383\n",
      "Epoch [251/1000], Loss: 0.0397\n",
      "Epoch [252/1000], Loss: 0.0441\n",
      "Epoch [253/1000], Loss: 0.0414\n",
      "Epoch [254/1000], Loss: 0.0377\n",
      "Epoch [255/1000], Loss: 0.0363\n",
      "Epoch [256/1000], Loss: 0.0321\n",
      "Epoch [257/1000], Loss: 0.0321\n",
      "Epoch [258/1000], Loss: 0.0296\n",
      "Epoch [259/1000], Loss: 0.0298\n",
      "Epoch [260/1000], Loss: 0.0260\n",
      "Epoch [261/1000], Loss: 0.0337\n",
      "Epoch [262/1000], Loss: 0.0290\n",
      "Epoch [263/1000], Loss: 0.0307\n",
      "Epoch [264/1000], Loss: 0.0318\n",
      "Epoch [265/1000], Loss: 0.0359\n",
      "Epoch [266/1000], Loss: 0.0276\n",
      "Epoch [267/1000], Loss: 0.0250\n",
      "Epoch [268/1000], Loss: 0.0223\n",
      "Epoch [269/1000], Loss: 0.0251\n",
      "Epoch [270/1000], Loss: 0.0272\n",
      "Epoch [271/1000], Loss: 0.0264\n",
      "Epoch [272/1000], Loss: 0.0379\n",
      "Epoch [273/1000], Loss: 0.0395\n",
      "Epoch [274/1000], Loss: 0.0228\n",
      "Epoch [275/1000], Loss: 0.0372\n",
      "Epoch [276/1000], Loss: 0.0232\n",
      "Epoch [277/1000], Loss: 0.0195\n",
      "Epoch [278/1000], Loss: 0.0252\n",
      "Epoch [279/1000], Loss: 0.0229\n",
      "Epoch [280/1000], Loss: 0.0231\n",
      "Epoch [281/1000], Loss: 0.0183\n",
      "Epoch [282/1000], Loss: 0.0418\n",
      "Epoch [283/1000], Loss: 0.0195\n",
      "Epoch [284/1000], Loss: 0.0214\n",
      "Epoch [285/1000], Loss: 0.0197\n",
      "Epoch [286/1000], Loss: 0.0220\n",
      "Epoch [287/1000], Loss: 0.0172\n",
      "Epoch [288/1000], Loss: 0.0181\n",
      "Epoch [289/1000], Loss: 0.0158\n",
      "Epoch [290/1000], Loss: 0.0223\n",
      "Epoch [291/1000], Loss: 0.0158\n",
      "Epoch [292/1000], Loss: 0.0173\n",
      "Epoch [293/1000], Loss: 0.0147\n",
      "Epoch [294/1000], Loss: 0.0149\n",
      "Epoch [295/1000], Loss: 0.0148\n",
      "Epoch [296/1000], Loss: 0.0215\n",
      "Epoch [297/1000], Loss: 0.0191\n",
      "Epoch [298/1000], Loss: 0.0142\n",
      "Epoch [299/1000], Loss: 0.0145\n",
      "Epoch [300/1000], Loss: 0.0149\n",
      "Epoch [301/1000], Loss: 0.0163\n",
      "Epoch [302/1000], Loss: 0.0391\n",
      "Epoch [303/1000], Loss: 0.0156\n",
      "Epoch [304/1000], Loss: 0.0145\n",
      "Epoch [305/1000], Loss: 0.0124\n",
      "Epoch [306/1000], Loss: 0.0123\n",
      "Epoch [307/1000], Loss: 0.0124\n",
      "Epoch [308/1000], Loss: 0.0139\n",
      "Epoch [309/1000], Loss: 0.0125\n",
      "Epoch [310/1000], Loss: 0.0150\n",
      "Epoch [311/1000], Loss: 0.0176\n",
      "Epoch [312/1000], Loss: 0.0139\n",
      "Epoch [313/1000], Loss: 0.0116\n",
      "Epoch [314/1000], Loss: 0.0146\n",
      "Epoch [315/1000], Loss: 0.0107\n",
      "Epoch [316/1000], Loss: 0.0117\n",
      "Epoch [317/1000], Loss: 0.0148\n",
      "Epoch [318/1000], Loss: 0.0106\n",
      "Epoch [319/1000], Loss: 0.0127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [320/1000], Loss: 0.0111\n",
      "Epoch [321/1000], Loss: 0.0104\n",
      "Epoch [322/1000], Loss: 0.0112\n",
      "Epoch [323/1000], Loss: 0.0106\n",
      "Epoch [324/1000], Loss: 0.0096\n",
      "Epoch [325/1000], Loss: 0.0140\n",
      "Epoch [326/1000], Loss: 0.0107\n",
      "Epoch [327/1000], Loss: 0.0249\n",
      "Epoch [328/1000], Loss: 0.0176\n",
      "Epoch [329/1000], Loss: 0.0139\n",
      "Epoch [330/1000], Loss: 0.0095\n",
      "Epoch [331/1000], Loss: 0.0090\n",
      "Epoch [332/1000], Loss: 0.0091\n",
      "Epoch [333/1000], Loss: 0.0109\n",
      "Epoch [334/1000], Loss: 0.0090\n",
      "Epoch [335/1000], Loss: 0.0088\n",
      "Epoch [336/1000], Loss: 0.0090\n",
      "Epoch [337/1000], Loss: 0.0095\n",
      "Epoch [338/1000], Loss: 0.0085\n",
      "Epoch [339/1000], Loss: 0.0084\n",
      "Epoch [340/1000], Loss: 0.0087\n",
      "Epoch [341/1000], Loss: 0.0081\n",
      "Epoch [342/1000], Loss: 0.0079\n",
      "Epoch [343/1000], Loss: 0.0080\n",
      "Epoch [344/1000], Loss: 0.0089\n",
      "Epoch [345/1000], Loss: 0.0077\n",
      "Epoch [346/1000], Loss: 0.0088\n",
      "Epoch [347/1000], Loss: 0.0083\n",
      "Epoch [348/1000], Loss: 0.0077\n",
      "Epoch [349/1000], Loss: 0.0076\n",
      "Epoch [350/1000], Loss: 0.0085\n",
      "Epoch [351/1000], Loss: 0.0075\n",
      "Epoch [352/1000], Loss: 0.0073\n",
      "Epoch [353/1000], Loss: 0.0090\n",
      "Epoch [354/1000], Loss: 0.0069\n",
      "Epoch [355/1000], Loss: 0.0083\n",
      "Epoch [356/1000], Loss: 0.0077\n",
      "Epoch [357/1000], Loss: 0.0067\n",
      "Epoch [358/1000], Loss: 0.0262\n",
      "Epoch [359/1000], Loss: 0.0068\n",
      "Epoch [360/1000], Loss: 0.0067\n",
      "Epoch [361/1000], Loss: 0.0089\n",
      "Epoch [362/1000], Loss: 0.0063\n",
      "Epoch [363/1000], Loss: 0.0066\n",
      "Epoch [364/1000], Loss: 0.0063\n",
      "Epoch [365/1000], Loss: 0.0060\n",
      "Epoch [366/1000], Loss: 0.0063\n",
      "Epoch [367/1000], Loss: 0.0060\n",
      "Epoch [368/1000], Loss: 0.0057\n",
      "Epoch [369/1000], Loss: 0.0066\n",
      "Epoch [370/1000], Loss: 0.0060\n",
      "Epoch [371/1000], Loss: 0.0059\n",
      "Epoch [372/1000], Loss: 0.0060\n",
      "Epoch [373/1000], Loss: 0.0059\n",
      "Epoch [374/1000], Loss: 0.0060\n",
      "Epoch [375/1000], Loss: 0.0057\n",
      "Epoch [376/1000], Loss: 0.0053\n",
      "Epoch [377/1000], Loss: 0.0055\n",
      "Epoch [378/1000], Loss: 0.0056\n",
      "Epoch [379/1000], Loss: 0.0054\n",
      "Epoch [380/1000], Loss: 0.0053\n",
      "Epoch [381/1000], Loss: 0.0055\n",
      "Epoch [382/1000], Loss: 0.0055\n",
      "Epoch [383/1000], Loss: 0.0052\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 302, lr :1.0, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.5032\n",
      "Epoch [2/1000], Loss: 0.5270\n",
      "Epoch [3/1000], Loss: 0.5316\n",
      "Epoch [4/1000], Loss: 0.5293\n",
      "Epoch [5/1000], Loss: 0.5331\n",
      "Epoch [6/1000], Loss: 0.5277\n",
      "Epoch [7/1000], Loss: 0.5262\n",
      "Epoch [8/1000], Loss: 0.5285\n",
      "Epoch [9/1000], Loss: 0.5239\n",
      "Epoch [10/1000], Loss: 0.5308\n",
      "Epoch [11/1000], Loss: 0.5308\n",
      "Epoch [12/1000], Loss: 0.5293\n",
      "Epoch [13/1000], Loss: 0.5324\n",
      "Epoch [14/1000], Loss: 0.5285\n",
      "Epoch [15/1000], Loss: 0.5293\n",
      "Epoch [16/1000], Loss: 0.5293\n",
      "Epoch [17/1000], Loss: 0.5254\n",
      "Epoch [18/1000], Loss: 0.5300\n",
      "Epoch [19/1000], Loss: 0.5262\n",
      "Epoch [20/1000], Loss: 0.5324\n",
      "Epoch [21/1000], Loss: 0.5347\n",
      "Epoch [22/1000], Loss: 0.5339\n",
      "Epoch [23/1000], Loss: 0.5231\n",
      "Epoch [24/1000], Loss: 0.5347\n",
      "Epoch [25/1000], Loss: 0.5331\n",
      "Epoch [26/1000], Loss: 0.5285\n",
      "Epoch [27/1000], Loss: 0.5270\n",
      "Epoch [28/1000], Loss: 0.5262\n",
      "Epoch [29/1000], Loss: 0.5270\n",
      "Epoch [30/1000], Loss: 0.5216\n",
      "Epoch [31/1000], Loss: 0.5293\n",
      "Epoch [32/1000], Loss: 0.5339\n",
      "Epoch [33/1000], Loss: 0.5308\n",
      "Epoch [34/1000], Loss: 0.5246\n",
      "Epoch [35/1000], Loss: 0.5239\n",
      "Epoch [36/1000], Loss: 0.5262\n",
      "Epoch [37/1000], Loss: 0.5316\n",
      "Epoch [38/1000], Loss: 0.5270\n",
      "Epoch [39/1000], Loss: 0.5316\n",
      "Epoch [40/1000], Loss: 0.5223\n",
      "Epoch [41/1000], Loss: 0.5300\n",
      "Epoch [42/1000], Loss: 0.5285\n",
      "Epoch [43/1000], Loss: 0.5262\n",
      "Epoch [44/1000], Loss: 0.5293\n",
      "Epoch [45/1000], Loss: 0.5293\n",
      "Epoch [46/1000], Loss: 0.5293\n",
      "Epoch [47/1000], Loss: 0.5293\n",
      "Epoch [48/1000], Loss: 0.5285\n",
      "Epoch [49/1000], Loss: 0.5262\n",
      "Epoch [50/1000], Loss: 0.5254\n",
      "Epoch [51/1000], Loss: 0.5285\n",
      "Epoch [52/1000], Loss: 0.5370\n",
      "Epoch [53/1000], Loss: 0.5300\n",
      "Epoch [54/1000], Loss: 0.5300\n",
      "Epoch [55/1000], Loss: 0.5308\n",
      "Epoch [56/1000], Loss: 0.5254\n",
      "Epoch [57/1000], Loss: 0.5239\n",
      "Epoch [58/1000], Loss: 0.5316\n",
      "Epoch [59/1000], Loss: 0.5262\n",
      "Epoch [60/1000], Loss: 0.5285\n",
      "Epoch [61/1000], Loss: 0.5254\n",
      "Epoch [62/1000], Loss: 0.5208\n",
      "Epoch [63/1000], Loss: 0.5285\n",
      "Epoch [64/1000], Loss: 0.5246\n",
      "Epoch [65/1000], Loss: 0.5277\n",
      "Epoch [66/1000], Loss: 0.5377\n",
      "Epoch [67/1000], Loss: 0.5254\n",
      "Epoch [68/1000], Loss: 0.5239\n",
      "Epoch [69/1000], Loss: 0.5293\n",
      "Epoch [70/1000], Loss: 0.5300\n",
      "Epoch [71/1000], Loss: 0.5254\n",
      "Epoch [72/1000], Loss: 0.5300\n",
      "Epoch [73/1000], Loss: 0.5308\n",
      "Epoch [74/1000], Loss: 0.5277\n",
      "Epoch [75/1000], Loss: 0.5285\n",
      "Epoch [76/1000], Loss: 0.5331\n",
      "Epoch [77/1000], Loss: 0.5223\n",
      "Epoch [78/1000], Loss: 0.5254\n",
      "Epoch [79/1000], Loss: 0.5223\n",
      "Epoch [80/1000], Loss: 0.5308\n",
      "Epoch [81/1000], Loss: 0.5270\n",
      "Epoch [82/1000], Loss: 0.5270\n",
      "Epoch [83/1000], Loss: 0.5293\n",
      "Epoch [84/1000], Loss: 0.5270\n",
      "Epoch [85/1000], Loss: 0.5285\n",
      "Epoch [86/1000], Loss: 0.5216\n",
      "Epoch [87/1000], Loss: 0.5324\n",
      "Epoch [88/1000], Loss: 0.5277\n",
      "Epoch [89/1000], Loss: 0.5262\n",
      "Epoch [90/1000], Loss: 0.5293\n",
      "Epoch [91/1000], Loss: 0.5262\n",
      "Epoch [92/1000], Loss: 0.5270\n",
      "Epoch [93/1000], Loss: 0.5347\n",
      "Epoch [94/1000], Loss: 0.5308\n",
      "Epoch [95/1000], Loss: 0.5239\n",
      "Epoch [96/1000], Loss: 0.5293\n",
      "Epoch [97/1000], Loss: 0.5293\n",
      "Epoch [98/1000], Loss: 0.5277\n",
      "Epoch [99/1000], Loss: 0.5254\n",
      "Epoch [100/1000], Loss: 0.5270\n",
      "Epoch [101/1000], Loss: 0.5270\n",
      "Epoch [102/1000], Loss: 0.5239\n",
      "Epoch [103/1000], Loss: 0.5231\n",
      "Epoch [104/1000], Loss: 0.5239\n",
      "Epoch [105/1000], Loss: 0.5216\n",
      "Epoch [106/1000], Loss: 0.5308\n",
      "Epoch [107/1000], Loss: 0.5254\n",
      "Epoch [108/1000], Loss: 0.5254\n",
      "Epoch [109/1000], Loss: 0.5316\n",
      "Epoch [110/1000], Loss: 0.5277\n",
      "Epoch [111/1000], Loss: 0.5231\n",
      "Epoch [112/1000], Loss: 0.5270\n",
      "Epoch [113/1000], Loss: 0.5254\n",
      "Epoch [114/1000], Loss: 0.5262\n",
      "Epoch [115/1000], Loss: 0.5254\n",
      "Epoch [116/1000], Loss: 0.5254\n",
      "Epoch [117/1000], Loss: 0.5231\n",
      "Epoch [118/1000], Loss: 0.5308\n",
      "Epoch [119/1000], Loss: 0.5316\n",
      "Epoch [120/1000], Loss: 0.5300\n",
      "Epoch [121/1000], Loss: 0.5285\n",
      "Epoch [122/1000], Loss: 0.5270\n",
      "Epoch [123/1000], Loss: 0.5339\n",
      "Epoch [124/1000], Loss: 0.5293\n",
      "Epoch [125/1000], Loss: 0.5246\n",
      "Epoch [126/1000], Loss: 0.5331\n",
      "Epoch [127/1000], Loss: 0.5246\n",
      "Epoch [128/1000], Loss: 0.5270\n",
      "Epoch [129/1000], Loss: 0.5270\n",
      "Epoch [130/1000], Loss: 0.5223\n",
      "Epoch [131/1000], Loss: 0.5270\n",
      "Epoch [132/1000], Loss: 0.5362\n",
      "Epoch [133/1000], Loss: 0.5285\n",
      "Epoch [134/1000], Loss: 0.5308\n",
      "Epoch [135/1000], Loss: 0.5277\n",
      "Epoch [136/1000], Loss: 0.5331\n",
      "Epoch [137/1000], Loss: 0.5254\n",
      "Epoch [138/1000], Loss: 0.5324\n",
      "Epoch [139/1000], Loss: 0.5239\n",
      "Epoch [140/1000], Loss: 0.5246\n",
      "Epoch [141/1000], Loss: 0.5285\n",
      "Epoch [142/1000], Loss: 0.5300\n",
      "Epoch [143/1000], Loss: 0.5324\n",
      "Epoch [144/1000], Loss: 0.5316\n",
      "Epoch [145/1000], Loss: 0.5308\n",
      "Epoch [146/1000], Loss: 0.5223\n",
      "Epoch [147/1000], Loss: 0.5308\n",
      "Epoch [148/1000], Loss: 0.5231\n",
      "Epoch [149/1000], Loss: 0.5223\n",
      "Epoch [150/1000], Loss: 0.5262\n",
      "Epoch [151/1000], Loss: 0.5300\n",
      "Epoch [152/1000], Loss: 0.5331\n",
      "Epoch [153/1000], Loss: 0.5208\n",
      "Epoch [154/1000], Loss: 0.5239\n",
      "Epoch [155/1000], Loss: 0.5339\n",
      "Epoch [156/1000], Loss: 0.5270\n",
      "Epoch [157/1000], Loss: 0.5270\n",
      "Epoch [158/1000], Loss: 0.5331\n",
      "Epoch [159/1000], Loss: 0.5339\n",
      "Epoch [160/1000], Loss: 0.5293\n",
      "Epoch [161/1000], Loss: 0.5331\n",
      "Epoch [162/1000], Loss: 0.5231\n",
      "Epoch [163/1000], Loss: 0.5293\n",
      "Epoch [164/1000], Loss: 0.5300\n",
      "Epoch [165/1000], Loss: 0.5246\n",
      "Epoch [166/1000], Loss: 0.5277\n",
      "Epoch [167/1000], Loss: 0.5270\n",
      "Epoch [168/1000], Loss: 0.5324\n",
      "Epoch [169/1000], Loss: 0.5300\n",
      "Epoch [170/1000], Loss: 0.5324\n",
      "Epoch [171/1000], Loss: 0.5277\n",
      "Epoch [172/1000], Loss: 0.5293\n",
      "Epoch [173/1000], Loss: 0.5246\n",
      "Epoch [174/1000], Loss: 0.5308\n",
      "Epoch [175/1000], Loss: 0.5231\n",
      "Epoch [176/1000], Loss: 0.5331\n",
      "Epoch [177/1000], Loss: 0.5354\n",
      "Epoch [178/1000], Loss: 0.5308\n",
      "Epoch [179/1000], Loss: 0.5246\n",
      "Epoch [180/1000], Loss: 0.5324\n",
      "Epoch [181/1000], Loss: 0.5300\n",
      "Epoch [182/1000], Loss: 0.5239\n",
      "Epoch [183/1000], Loss: 0.5270\n",
      "Epoch [184/1000], Loss: 0.5246\n",
      "Epoch [185/1000], Loss: 0.5293\n",
      "Epoch [186/1000], Loss: 0.5246\n",
      "Epoch [187/1000], Loss: 0.5254\n",
      "Epoch [188/1000], Loss: 0.5285\n",
      "Epoch [189/1000], Loss: 0.5231\n",
      "Epoch [190/1000], Loss: 0.5316\n",
      "Epoch [191/1000], Loss: 0.5293\n",
      "Epoch [192/1000], Loss: 0.5370\n",
      "Epoch [193/1000], Loss: 0.5277\n",
      "Epoch [194/1000], Loss: 0.5254\n",
      "Epoch [195/1000], Loss: 0.5262\n",
      "Epoch [196/1000], Loss: 0.5262\n",
      "Epoch [197/1000], Loss: 0.5285\n",
      "Epoch [198/1000], Loss: 0.5300\n",
      "Epoch [199/1000], Loss: 0.5324\n",
      "Epoch [200/1000], Loss: 0.5262\n",
      "Epoch [201/1000], Loss: 0.5262\n",
      "Epoch [202/1000], Loss: 0.5277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [203/1000], Loss: 0.5285\n",
      "Epoch [204/1000], Loss: 0.5285\n",
      "Epoch [205/1000], Loss: 0.5262\n",
      "Epoch [206/1000], Loss: 0.5293\n",
      "Epoch [207/1000], Loss: 0.5270\n",
      "Epoch [208/1000], Loss: 0.5308\n",
      "Epoch [209/1000], Loss: 0.5246\n",
      "Epoch [210/1000], Loss: 0.5277\n",
      "Epoch [211/1000], Loss: 0.5300\n",
      "Epoch [212/1000], Loss: 0.5254\n",
      "Epoch [213/1000], Loss: 0.5254\n",
      "Epoch [214/1000], Loss: 0.5231\n",
      "Epoch [215/1000], Loss: 0.5316\n",
      "Epoch [216/1000], Loss: 0.5262\n",
      "Epoch [217/1000], Loss: 0.5216\n",
      "Epoch [218/1000], Loss: 0.5354\n",
      "Epoch [219/1000], Loss: 0.5246\n",
      "Epoch [220/1000], Loss: 0.5270\n",
      "Epoch [221/1000], Loss: 0.5285\n",
      "Epoch [222/1000], Loss: 0.5308\n",
      "Epoch [223/1000], Loss: 0.5316\n",
      "Epoch [224/1000], Loss: 0.5246\n",
      "Epoch [225/1000], Loss: 0.5208\n",
      "Epoch [226/1000], Loss: 0.5300\n",
      "Epoch [227/1000], Loss: 0.5300\n",
      "Epoch [228/1000], Loss: 0.5239\n",
      "Epoch [229/1000], Loss: 0.5277\n",
      "Epoch [230/1000], Loss: 0.5308\n",
      "Epoch [231/1000], Loss: 0.5277\n",
      "Epoch [232/1000], Loss: 0.5316\n",
      "Epoch [233/1000], Loss: 0.5231\n",
      "Epoch [234/1000], Loss: 0.5370\n",
      "Epoch [235/1000], Loss: 0.5270\n",
      "Epoch [236/1000], Loss: 0.5339\n",
      "Epoch [237/1000], Loss: 0.5316\n",
      "Epoch [238/1000], Loss: 0.5300\n",
      "Epoch [239/1000], Loss: 0.5316\n",
      "Epoch [240/1000], Loss: 0.5270\n",
      "Epoch [241/1000], Loss: 0.5293\n",
      "Epoch [242/1000], Loss: 0.5239\n",
      "Epoch [243/1000], Loss: 0.5293\n",
      "Epoch [244/1000], Loss: 0.5316\n",
      "Epoch [245/1000], Loss: 0.5246\n",
      "Epoch [246/1000], Loss: 0.5285\n",
      "Epoch [247/1000], Loss: 0.5254\n",
      "Epoch [248/1000], Loss: 0.5300\n",
      "Epoch [249/1000], Loss: 0.5285\n",
      "Epoch [250/1000], Loss: 0.5300\n",
      "Epoch [251/1000], Loss: 0.5277\n",
      "Epoch [252/1000], Loss: 0.5293\n",
      "Epoch [253/1000], Loss: 0.5246\n",
      "Epoch [254/1000], Loss: 0.5246\n",
      "Epoch [255/1000], Loss: 0.5316\n",
      "Epoch [256/1000], Loss: 0.5277\n",
      "Epoch [257/1000], Loss: 0.5324\n",
      "Epoch [258/1000], Loss: 0.5316\n",
      "Epoch [259/1000], Loss: 0.5293\n",
      "Epoch [260/1000], Loss: 0.5324\n",
      "Epoch [261/1000], Loss: 0.5308\n",
      "Epoch [262/1000], Loss: 0.5293\n",
      "Epoch [263/1000], Loss: 0.5231\n",
      "Epoch [264/1000], Loss: 0.5262\n",
      "Epoch [265/1000], Loss: 0.5277\n",
      "Epoch [266/1000], Loss: 0.5293\n",
      "Epoch [267/1000], Loss: 0.5270\n",
      "Epoch [268/1000], Loss: 0.5246\n",
      "Epoch [269/1000], Loss: 0.5293\n",
      "Epoch [270/1000], Loss: 0.5362\n",
      "Epoch [271/1000], Loss: 0.5277\n",
      "Epoch [272/1000], Loss: 0.5300\n",
      "Epoch [273/1000], Loss: 0.5293\n",
      "Epoch [274/1000], Loss: 0.5208\n",
      "Epoch [275/1000], Loss: 0.5354\n",
      "Epoch [276/1000], Loss: 0.5293\n",
      "Epoch [277/1000], Loss: 0.5277\n",
      "Epoch [278/1000], Loss: 0.5300\n",
      "Epoch [279/1000], Loss: 0.5277\n",
      "Epoch [280/1000], Loss: 0.5239\n",
      "Epoch [281/1000], Loss: 0.5293\n",
      "Epoch [282/1000], Loss: 0.5285\n",
      "Epoch [283/1000], Loss: 0.5185\n",
      "Epoch [284/1000], Loss: 0.5262\n",
      "Epoch [285/1000], Loss: 0.5239\n",
      "Epoch [286/1000], Loss: 0.5231\n",
      "Epoch [287/1000], Loss: 0.5331\n",
      "Epoch [288/1000], Loss: 0.5293\n",
      "Epoch [289/1000], Loss: 0.5339\n",
      "Epoch [290/1000], Loss: 0.5293\n",
      "Epoch [291/1000], Loss: 0.5316\n",
      "Epoch [292/1000], Loss: 0.5270\n",
      "Epoch [293/1000], Loss: 0.5262\n",
      "Epoch [294/1000], Loss: 0.5277\n",
      "Epoch [295/1000], Loss: 0.5285\n",
      "Epoch [296/1000], Loss: 0.5277\n",
      "Epoch [297/1000], Loss: 0.5277\n",
      "Epoch [298/1000], Loss: 0.5285\n",
      "Epoch [299/1000], Loss: 0.5308\n",
      "Epoch [300/1000], Loss: 0.5239\n",
      "Epoch [301/1000], Loss: 0.5254\n",
      "Epoch [302/1000], Loss: 0.5285\n",
      "Epoch [303/1000], Loss: 0.5293\n",
      "Epoch [304/1000], Loss: 0.5300\n",
      "Epoch [305/1000], Loss: 0.5285\n",
      "Epoch [306/1000], Loss: 0.5270\n",
      "Epoch [307/1000], Loss: 0.5277\n",
      "Epoch [308/1000], Loss: 0.5308\n",
      "Epoch [309/1000], Loss: 0.5277\n",
      "Epoch [310/1000], Loss: 0.5308\n",
      "Epoch [311/1000], Loss: 0.5300\n",
      "Epoch [312/1000], Loss: 0.5308\n",
      "Epoch [313/1000], Loss: 0.5293\n",
      "Epoch [314/1000], Loss: 0.5308\n",
      "Epoch [315/1000], Loss: 0.5293\n",
      "Epoch [316/1000], Loss: 0.5300\n",
      "Epoch [317/1000], Loss: 0.5277\n",
      "Epoch [318/1000], Loss: 0.5216\n",
      "Epoch [319/1000], Loss: 0.5362\n",
      "Epoch [320/1000], Loss: 0.5277\n",
      "Epoch [321/1000], Loss: 0.5254\n",
      "Epoch [322/1000], Loss: 0.5262\n",
      "Epoch [323/1000], Loss: 0.5308\n",
      "Epoch [324/1000], Loss: 0.5331\n",
      "Epoch [325/1000], Loss: 0.5285\n",
      "Epoch [326/1000], Loss: 0.5285\n",
      "Epoch [327/1000], Loss: 0.5285\n",
      "Epoch [328/1000], Loss: 0.5277\n",
      "Epoch [329/1000], Loss: 0.5324\n",
      "Epoch [330/1000], Loss: 0.5308\n",
      "Epoch [331/1000], Loss: 0.5262\n",
      "Epoch [332/1000], Loss: 0.5270\n",
      "Epoch [333/1000], Loss: 0.5316\n",
      "Epoch [334/1000], Loss: 0.5324\n",
      "Epoch [335/1000], Loss: 0.5324\n",
      "Epoch [336/1000], Loss: 0.5254\n",
      "Epoch [337/1000], Loss: 0.5239\n",
      "Epoch [338/1000], Loss: 0.5208\n",
      "Epoch [339/1000], Loss: 0.5262\n",
      "Epoch [340/1000], Loss: 0.5316\n",
      "Epoch [341/1000], Loss: 0.5277\n",
      "Epoch [342/1000], Loss: 0.5308\n",
      "Epoch [343/1000], Loss: 0.5277\n",
      "Epoch [344/1000], Loss: 0.5354\n",
      "Epoch [345/1000], Loss: 0.5270\n",
      "Epoch [346/1000], Loss: 0.5270\n",
      "Epoch [347/1000], Loss: 0.5324\n",
      "Epoch [348/1000], Loss: 0.5216\n",
      "Epoch [349/1000], Loss: 0.5285\n",
      "Epoch [350/1000], Loss: 0.5293\n",
      "Epoch [351/1000], Loss: 0.5300\n",
      "Epoch [352/1000], Loss: 0.5300\n",
      "Epoch [353/1000], Loss: 0.5339\n",
      "Epoch [354/1000], Loss: 0.5270\n",
      "Epoch [355/1000], Loss: 0.5293\n",
      "Epoch [356/1000], Loss: 0.5300\n",
      "Epoch [357/1000], Loss: 0.5254\n",
      "Epoch [358/1000], Loss: 0.5254\n",
      "Epoch [359/1000], Loss: 0.5347\n",
      "Epoch [360/1000], Loss: 0.5277\n",
      "Epoch [361/1000], Loss: 0.5293\n",
      "Epoch [362/1000], Loss: 0.5331\n",
      "Epoch [363/1000], Loss: 0.5246\n",
      "Epoch [364/1000], Loss: 0.5246\n",
      "Epoch [365/1000], Loss: 0.5231\n",
      "Epoch [366/1000], Loss: 0.5285\n",
      "Epoch [367/1000], Loss: 0.5262\n",
      "Epoch [368/1000], Loss: 0.5324\n",
      "Epoch [369/1000], Loss: 0.5270\n",
      "Epoch [370/1000], Loss: 0.5324\n",
      "Epoch [371/1000], Loss: 0.5285\n",
      "Epoch [372/1000], Loss: 0.5347\n",
      "Epoch [373/1000], Loss: 0.5293\n",
      "Epoch [374/1000], Loss: 0.5231\n",
      "Epoch [375/1000], Loss: 0.5270\n",
      "Epoch [376/1000], Loss: 0.5262\n",
      "Epoch [377/1000], Loss: 0.5331\n",
      "Epoch [378/1000], Loss: 0.5246\n",
      "Epoch [379/1000], Loss: 0.5293\n",
      "Epoch [380/1000], Loss: 0.5270\n",
      "Epoch [381/1000], Loss: 0.5331\n",
      "Epoch [382/1000], Loss: 0.5300\n",
      "Epoch [383/1000], Loss: 0.5293\n",
      "Epoch [384/1000], Loss: 0.5308\n",
      "Epoch [385/1000], Loss: 0.5254\n",
      "Epoch [386/1000], Loss: 0.5246\n",
      "Epoch [387/1000], Loss: 0.5293\n",
      "Epoch [388/1000], Loss: 0.5246\n",
      "Epoch [389/1000], Loss: 0.5246\n",
      "Epoch [390/1000], Loss: 0.5254\n",
      "Epoch [391/1000], Loss: 0.5339\n",
      "Epoch [392/1000], Loss: 0.5331\n",
      "Epoch [393/1000], Loss: 0.5246\n",
      "Epoch [394/1000], Loss: 0.5254\n",
      "Epoch [395/1000], Loss: 0.5270\n",
      "Epoch [396/1000], Loss: 0.5308\n",
      "Epoch [397/1000], Loss: 0.5277\n",
      "Epoch [398/1000], Loss: 0.5270\n",
      "Epoch [399/1000], Loss: 0.5354\n",
      "Epoch [400/1000], Loss: 0.5300\n",
      "Epoch [401/1000], Loss: 0.5262\n",
      "Epoch [402/1000], Loss: 0.5308\n",
      "Epoch [403/1000], Loss: 0.5277\n",
      "Epoch [404/1000], Loss: 0.5223\n",
      "Epoch [405/1000], Loss: 0.5277\n",
      "Epoch [406/1000], Loss: 0.5277\n",
      "Epoch [407/1000], Loss: 0.5293\n",
      "Epoch [408/1000], Loss: 0.5239\n",
      "Epoch [409/1000], Loss: 0.5254\n",
      "Epoch [410/1000], Loss: 0.5300\n",
      "Epoch [411/1000], Loss: 0.5262\n",
      "Epoch [412/1000], Loss: 0.5316\n",
      "Epoch [413/1000], Loss: 0.5223\n",
      "Epoch [414/1000], Loss: 0.5293\n",
      "Epoch [415/1000], Loss: 0.5293\n",
      "Epoch [416/1000], Loss: 0.5293\n",
      "Epoch [417/1000], Loss: 0.5339\n",
      "Epoch [418/1000], Loss: 0.5277\n",
      "Epoch [419/1000], Loss: 0.5285\n",
      "Epoch [420/1000], Loss: 0.5277\n",
      "Epoch [421/1000], Loss: 0.5293\n",
      "Epoch [422/1000], Loss: 0.5216\n",
      "Epoch [423/1000], Loss: 0.5300\n",
      "Epoch [424/1000], Loss: 0.5246\n",
      "Epoch [425/1000], Loss: 0.5285\n",
      "Epoch [426/1000], Loss: 0.5293\n",
      "Epoch [427/1000], Loss: 0.5277\n",
      "Epoch [428/1000], Loss: 0.5246\n",
      "Epoch [429/1000], Loss: 0.5370\n",
      "Epoch [430/1000], Loss: 0.5285\n",
      "Epoch [431/1000], Loss: 0.5262\n",
      "Epoch [432/1000], Loss: 0.5316\n",
      "Epoch [433/1000], Loss: 0.5316\n",
      "Epoch [434/1000], Loss: 0.5293\n",
      "Epoch [435/1000], Loss: 0.5246\n",
      "Epoch [436/1000], Loss: 0.5270\n",
      "Epoch [437/1000], Loss: 0.5254\n",
      "Epoch [438/1000], Loss: 0.5270\n",
      "Epoch [439/1000], Loss: 0.5254\n",
      "Epoch [440/1000], Loss: 0.5270\n",
      "Epoch [441/1000], Loss: 0.5270\n",
      "Epoch [442/1000], Loss: 0.5254\n",
      "Epoch [443/1000], Loss: 0.5331\n",
      "Epoch [444/1000], Loss: 0.5277\n",
      "Epoch [445/1000], Loss: 0.5277\n",
      "Epoch [446/1000], Loss: 0.5293\n",
      "Epoch [447/1000], Loss: 0.5216\n",
      "Epoch [448/1000], Loss: 0.5193\n",
      "Epoch [449/1000], Loss: 0.5293\n",
      "Epoch [450/1000], Loss: 0.5293\n",
      "Epoch [451/1000], Loss: 0.5223\n",
      "Epoch [452/1000], Loss: 0.5316\n",
      "Epoch [453/1000], Loss: 0.5270\n",
      "Epoch [454/1000], Loss: 0.5262\n",
      "Epoch [455/1000], Loss: 0.5277\n",
      "Epoch [456/1000], Loss: 0.5354\n",
      "Epoch [457/1000], Loss: 0.5277\n",
      "Epoch [458/1000], Loss: 0.5270\n",
      "Epoch [459/1000], Loss: 0.5362\n",
      "Epoch [460/1000], Loss: 0.5239\n",
      "Epoch [461/1000], Loss: 0.5285\n",
      "Epoch [462/1000], Loss: 0.5262\n",
      "Epoch [463/1000], Loss: 0.5308\n",
      "Epoch [464/1000], Loss: 0.5300\n",
      "Epoch [465/1000], Loss: 0.5270\n",
      "Epoch [466/1000], Loss: 0.5308\n",
      "Epoch [467/1000], Loss: 0.5270\n",
      "Epoch [468/1000], Loss: 0.5277\n",
      "Epoch [469/1000], Loss: 0.5277\n",
      "Epoch [470/1000], Loss: 0.5300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [471/1000], Loss: 0.5308\n",
      "Epoch [472/1000], Loss: 0.5254\n",
      "Epoch [473/1000], Loss: 0.5324\n",
      "Epoch [474/1000], Loss: 0.5262\n",
      "Epoch [475/1000], Loss: 0.5246\n",
      "Epoch [476/1000], Loss: 0.5285\n",
      "Epoch [477/1000], Loss: 0.5231\n",
      "Epoch [478/1000], Loss: 0.5254\n",
      "Epoch [479/1000], Loss: 0.5293\n",
      "Epoch [480/1000], Loss: 0.5308\n",
      "Epoch [481/1000], Loss: 0.5300\n",
      "Epoch [482/1000], Loss: 0.5277\n",
      "Epoch [483/1000], Loss: 0.5293\n",
      "Epoch [484/1000], Loss: 0.5293\n",
      "Epoch [485/1000], Loss: 0.5285\n",
      "Epoch [486/1000], Loss: 0.5285\n",
      "Epoch [487/1000], Loss: 0.5208\n",
      "Epoch [488/1000], Loss: 0.5300\n",
      "Epoch [489/1000], Loss: 0.5262\n",
      "Epoch [490/1000], Loss: 0.5347\n",
      "Epoch [491/1000], Loss: 0.5270\n",
      "Epoch [492/1000], Loss: 0.5246\n",
      "Epoch [493/1000], Loss: 0.5331\n",
      "Epoch [494/1000], Loss: 0.5277\n",
      "Epoch [495/1000], Loss: 0.5270\n",
      "Epoch [496/1000], Loss: 0.5316\n",
      "Epoch [497/1000], Loss: 0.5254\n",
      "Epoch [498/1000], Loss: 0.5231\n",
      "Epoch [499/1000], Loss: 0.5293\n",
      "Epoch [500/1000], Loss: 0.5277\n",
      "Epoch [501/1000], Loss: 0.5270\n",
      "Epoch [502/1000], Loss: 0.5254\n",
      "Epoch [503/1000], Loss: 0.5316\n",
      "Epoch [504/1000], Loss: 0.5270\n",
      "Epoch [505/1000], Loss: 0.5316\n",
      "Epoch [506/1000], Loss: 0.5308\n",
      "Epoch [507/1000], Loss: 0.5262\n",
      "Epoch [508/1000], Loss: 0.5262\n",
      "Epoch [509/1000], Loss: 0.5293\n",
      "Epoch [510/1000], Loss: 0.5300\n",
      "Epoch [511/1000], Loss: 0.5293\n",
      "Epoch [512/1000], Loss: 0.5277\n",
      "Epoch [513/1000], Loss: 0.5277\n",
      "Epoch [514/1000], Loss: 0.5331\n",
      "Epoch [515/1000], Loss: 0.5293\n",
      "Epoch [516/1000], Loss: 0.5285\n",
      "Epoch [517/1000], Loss: 0.5316\n",
      "Epoch [518/1000], Loss: 0.5262\n",
      "Epoch [519/1000], Loss: 0.5277\n",
      "Epoch [520/1000], Loss: 0.5316\n",
      "Epoch [521/1000], Loss: 0.5308\n",
      "Epoch [522/1000], Loss: 0.5331\n",
      "Epoch [523/1000], Loss: 0.5277\n",
      "Epoch [524/1000], Loss: 0.5270\n",
      "Epoch [525/1000], Loss: 0.5293\n",
      "Epoch [526/1000], Loss: 0.5270\n",
      "Epoch [527/1000], Loss: 0.5293\n",
      "Epoch [528/1000], Loss: 0.5293\n",
      "Epoch [529/1000], Loss: 0.5262\n",
      "Epoch [530/1000], Loss: 0.5270\n",
      "Epoch [531/1000], Loss: 0.5285\n",
      "Epoch [532/1000], Loss: 0.5254\n",
      "Epoch [533/1000], Loss: 0.5316\n",
      "Epoch [534/1000], Loss: 0.5347\n",
      "Epoch [535/1000], Loss: 0.5293\n",
      "Epoch [536/1000], Loss: 0.5277\n",
      "Epoch [537/1000], Loss: 0.5316\n",
      "Epoch [538/1000], Loss: 0.5285\n",
      "Epoch [539/1000], Loss: 0.5216\n",
      "Epoch [540/1000], Loss: 0.5316\n",
      "Epoch [541/1000], Loss: 0.5300\n",
      "Epoch [542/1000], Loss: 0.5324\n",
      "Epoch [543/1000], Loss: 0.5246\n",
      "Epoch [544/1000], Loss: 0.5293\n",
      "Epoch [545/1000], Loss: 0.5262\n",
      "Epoch [546/1000], Loss: 0.5262\n",
      "Epoch [547/1000], Loss: 0.5300\n",
      "Epoch [548/1000], Loss: 0.5316\n",
      "Epoch [549/1000], Loss: 0.5246\n",
      "Epoch [550/1000], Loss: 0.5308\n",
      "Epoch [551/1000], Loss: 0.5293\n",
      "Epoch [552/1000], Loss: 0.5277\n",
      "Epoch [553/1000], Loss: 0.5347\n",
      "Epoch [554/1000], Loss: 0.5293\n",
      "Epoch [555/1000], Loss: 0.5316\n",
      "Epoch [556/1000], Loss: 0.5262\n",
      "Epoch [557/1000], Loss: 0.5285\n",
      "Epoch [558/1000], Loss: 0.5339\n",
      "Epoch [559/1000], Loss: 0.5277\n",
      "Epoch [560/1000], Loss: 0.5254\n",
      "Epoch [561/1000], Loss: 0.5239\n",
      "Epoch [562/1000], Loss: 0.5324\n",
      "Epoch [563/1000], Loss: 0.5246\n",
      "Epoch [564/1000], Loss: 0.5270\n",
      "Epoch [565/1000], Loss: 0.5308\n",
      "Epoch [566/1000], Loss: 0.5246\n",
      "Epoch [567/1000], Loss: 0.5293\n",
      "Epoch [568/1000], Loss: 0.5254\n",
      "Epoch [569/1000], Loss: 0.5331\n",
      "Epoch [570/1000], Loss: 0.5285\n",
      "Epoch [571/1000], Loss: 0.5239\n",
      "Epoch [572/1000], Loss: 0.5316\n",
      "Epoch [573/1000], Loss: 0.5316\n",
      "Epoch [574/1000], Loss: 0.5300\n",
      "Epoch [575/1000], Loss: 0.5277\n",
      "Epoch [576/1000], Loss: 0.5277\n",
      "Epoch [577/1000], Loss: 0.5231\n",
      "Epoch [578/1000], Loss: 0.5300\n",
      "Epoch [579/1000], Loss: 0.5300\n",
      "Epoch [580/1000], Loss: 0.5300\n",
      "Epoch [581/1000], Loss: 0.5239\n",
      "Epoch [582/1000], Loss: 0.5293\n",
      "Epoch [583/1000], Loss: 0.5339\n",
      "Epoch [584/1000], Loss: 0.5239\n",
      "Epoch [585/1000], Loss: 0.5277\n",
      "Epoch [586/1000], Loss: 0.5262\n",
      "Epoch [587/1000], Loss: 0.5277\n",
      "Epoch [588/1000], Loss: 0.5208\n",
      "Epoch [589/1000], Loss: 0.5300\n",
      "Epoch [590/1000], Loss: 0.5254\n",
      "Epoch [591/1000], Loss: 0.5277\n",
      "Epoch [592/1000], Loss: 0.5300\n",
      "Epoch [593/1000], Loss: 0.5239\n",
      "Epoch [594/1000], Loss: 0.5262\n",
      "Epoch [595/1000], Loss: 0.5316\n",
      "Epoch [596/1000], Loss: 0.5370\n",
      "Epoch [597/1000], Loss: 0.5308\n",
      "Epoch [598/1000], Loss: 0.5262\n",
      "Epoch [599/1000], Loss: 0.5239\n",
      "Epoch [600/1000], Loss: 0.5270\n",
      "Epoch [601/1000], Loss: 0.5293\n",
      "Epoch [602/1000], Loss: 0.5262\n",
      "Epoch [603/1000], Loss: 0.5362\n",
      "Epoch [604/1000], Loss: 0.5231\n",
      "Epoch [605/1000], Loss: 0.5270\n",
      "Epoch [606/1000], Loss: 0.5246\n",
      "Epoch [607/1000], Loss: 0.5339\n",
      "Epoch [608/1000], Loss: 0.5239\n",
      "Epoch [609/1000], Loss: 0.5262\n",
      "Epoch [610/1000], Loss: 0.5331\n",
      "Epoch [611/1000], Loss: 0.5300\n",
      "Epoch [612/1000], Loss: 0.5270\n",
      "Epoch [613/1000], Loss: 0.5270\n",
      "Epoch [614/1000], Loss: 0.5277\n",
      "Epoch [615/1000], Loss: 0.5293\n",
      "Epoch [616/1000], Loss: 0.5277\n",
      "Epoch [617/1000], Loss: 0.5262\n",
      "Epoch [618/1000], Loss: 0.5316\n",
      "Epoch [619/1000], Loss: 0.5316\n",
      "Epoch [620/1000], Loss: 0.5277\n",
      "Epoch [621/1000], Loss: 0.5216\n",
      "Epoch [622/1000], Loss: 0.5270\n",
      "Epoch [623/1000], Loss: 0.5285\n",
      "Epoch [624/1000], Loss: 0.5285\n",
      "Epoch [625/1000], Loss: 0.5316\n",
      "Epoch [626/1000], Loss: 0.5277\n",
      "Epoch [627/1000], Loss: 0.5293\n",
      "Epoch [628/1000], Loss: 0.5254\n",
      "Epoch [629/1000], Loss: 0.5293\n",
      "Epoch [630/1000], Loss: 0.5293\n",
      "Epoch [631/1000], Loss: 0.5293\n",
      "Epoch [632/1000], Loss: 0.5339\n",
      "Epoch [633/1000], Loss: 0.5254\n",
      "Epoch [634/1000], Loss: 0.5262\n",
      "Epoch [635/1000], Loss: 0.5347\n",
      "Epoch [636/1000], Loss: 0.5246\n",
      "Epoch [637/1000], Loss: 0.5277\n",
      "Epoch [638/1000], Loss: 0.5262\n",
      "Epoch [639/1000], Loss: 0.5293\n",
      "Epoch [640/1000], Loss: 0.5316\n",
      "Epoch [641/1000], Loss: 0.5262\n",
      "Epoch [642/1000], Loss: 0.5324\n",
      "Epoch [643/1000], Loss: 0.5347\n",
      "Epoch [644/1000], Loss: 0.5270\n",
      "Epoch [645/1000], Loss: 0.5223\n",
      "Epoch [646/1000], Loss: 0.5246\n",
      "Epoch [647/1000], Loss: 0.5277\n",
      "Epoch [648/1000], Loss: 0.5277\n",
      "Epoch [649/1000], Loss: 0.5239\n",
      "Epoch [650/1000], Loss: 0.5347\n",
      "Epoch [651/1000], Loss: 0.5254\n",
      "Epoch [652/1000], Loss: 0.5324\n",
      "Epoch [653/1000], Loss: 0.5200\n",
      "Epoch [654/1000], Loss: 0.5231\n",
      "Epoch [655/1000], Loss: 0.5285\n",
      "Epoch [656/1000], Loss: 0.5254\n",
      "Epoch [657/1000], Loss: 0.5324\n",
      "Epoch [658/1000], Loss: 0.5339\n",
      "Epoch [659/1000], Loss: 0.5262\n",
      "Epoch [660/1000], Loss: 0.5277\n",
      "Epoch [661/1000], Loss: 0.5308\n",
      "Epoch [662/1000], Loss: 0.5231\n",
      "Epoch [663/1000], Loss: 0.5339\n",
      "Epoch [664/1000], Loss: 0.5254\n",
      "Epoch [665/1000], Loss: 0.5331\n",
      "Epoch [666/1000], Loss: 0.5246\n",
      "Epoch [667/1000], Loss: 0.5293\n",
      "Epoch [668/1000], Loss: 0.5331\n",
      "Epoch [669/1000], Loss: 0.5308\n",
      "Epoch [670/1000], Loss: 0.5339\n",
      "Epoch [671/1000], Loss: 0.5262\n",
      "Epoch [672/1000], Loss: 0.5285\n",
      "Epoch [673/1000], Loss: 0.5239\n",
      "Epoch [674/1000], Loss: 0.5308\n",
      "Epoch [675/1000], Loss: 0.5239\n",
      "Epoch [676/1000], Loss: 0.5308\n",
      "Epoch [677/1000], Loss: 0.5285\n",
      "Epoch [678/1000], Loss: 0.5300\n",
      "Epoch [679/1000], Loss: 0.5231\n",
      "Epoch [680/1000], Loss: 0.5239\n",
      "Epoch [681/1000], Loss: 0.5324\n",
      "Epoch [682/1000], Loss: 0.5270\n",
      "Epoch [683/1000], Loss: 0.5316\n",
      "Epoch [684/1000], Loss: 0.5285\n",
      "Epoch [685/1000], Loss: 0.5277\n",
      "Epoch [686/1000], Loss: 0.5316\n",
      "Epoch [687/1000], Loss: 0.5254\n",
      "Epoch [688/1000], Loss: 0.5331\n",
      "Epoch [689/1000], Loss: 0.5347\n",
      "Epoch [690/1000], Loss: 0.5277\n",
      "Epoch [691/1000], Loss: 0.5246\n",
      "Epoch [692/1000], Loss: 0.5270\n",
      "Epoch [693/1000], Loss: 0.5246\n",
      "Epoch [694/1000], Loss: 0.5339\n",
      "Epoch [695/1000], Loss: 0.5277\n",
      "Epoch [696/1000], Loss: 0.5246\n",
      "Epoch [697/1000], Loss: 0.5246\n",
      "Epoch [698/1000], Loss: 0.5354\n",
      "Epoch [699/1000], Loss: 0.5270\n",
      "Epoch [700/1000], Loss: 0.5270\n",
      "Epoch [701/1000], Loss: 0.5270\n",
      "Epoch [702/1000], Loss: 0.5239\n",
      "Epoch [703/1000], Loss: 0.5324\n",
      "Epoch [704/1000], Loss: 0.5316\n",
      "Epoch [705/1000], Loss: 0.5316\n",
      "Epoch [706/1000], Loss: 0.5246\n",
      "Epoch [707/1000], Loss: 0.5293\n",
      "Epoch [708/1000], Loss: 0.5285\n",
      "Epoch [709/1000], Loss: 0.5246\n",
      "Epoch [710/1000], Loss: 0.5208\n",
      "Epoch [711/1000], Loss: 0.5347\n",
      "Epoch [712/1000], Loss: 0.5285\n",
      "Epoch [713/1000], Loss: 0.5246\n",
      "Epoch [714/1000], Loss: 0.5270\n",
      "Epoch [715/1000], Loss: 0.5277\n",
      "Epoch [716/1000], Loss: 0.5277\n",
      "Epoch [717/1000], Loss: 0.5270\n",
      "Epoch [718/1000], Loss: 0.5300\n",
      "Epoch [719/1000], Loss: 0.5216\n",
      "Epoch [720/1000], Loss: 0.5277\n",
      "Epoch [721/1000], Loss: 0.5300\n",
      "Epoch [722/1000], Loss: 0.5285\n",
      "Epoch [723/1000], Loss: 0.5270\n",
      "Epoch [724/1000], Loss: 0.5331\n",
      "Epoch [725/1000], Loss: 0.5239\n",
      "Epoch [726/1000], Loss: 0.5285\n",
      "Epoch [727/1000], Loss: 0.5223\n",
      "Epoch [728/1000], Loss: 0.5270\n",
      "Epoch [729/1000], Loss: 0.5285\n",
      "Epoch [730/1000], Loss: 0.5270\n",
      "Epoch [731/1000], Loss: 0.5300\n",
      "Epoch [732/1000], Loss: 0.5262\n",
      "Epoch [733/1000], Loss: 0.5277\n",
      "Epoch [734/1000], Loss: 0.5285\n",
      "Epoch [735/1000], Loss: 0.5293\n",
      "Epoch [736/1000], Loss: 0.5300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [737/1000], Loss: 0.5324\n",
      "Epoch [738/1000], Loss: 0.5300\n",
      "Epoch [739/1000], Loss: 0.5239\n",
      "Epoch [740/1000], Loss: 0.5270\n",
      "Epoch [741/1000], Loss: 0.5300\n",
      "Epoch [742/1000], Loss: 0.5277\n",
      "Epoch [743/1000], Loss: 0.5246\n",
      "Epoch [744/1000], Loss: 0.5285\n",
      "Epoch [745/1000], Loss: 0.5270\n",
      "Epoch [746/1000], Loss: 0.5216\n",
      "Epoch [747/1000], Loss: 0.5262\n",
      "Epoch [748/1000], Loss: 0.5270\n",
      "Epoch [749/1000], Loss: 0.5262\n",
      "Epoch [750/1000], Loss: 0.5239\n",
      "Epoch [751/1000], Loss: 0.5285\n",
      "Epoch [752/1000], Loss: 0.5324\n",
      "Epoch [753/1000], Loss: 0.5254\n",
      "Epoch [754/1000], Loss: 0.5331\n",
      "Epoch [755/1000], Loss: 0.5316\n",
      "Epoch [756/1000], Loss: 0.5300\n",
      "Epoch [757/1000], Loss: 0.5300\n",
      "Epoch [758/1000], Loss: 0.5262\n",
      "Epoch [759/1000], Loss: 0.5285\n",
      "Epoch [760/1000], Loss: 0.5262\n",
      "Epoch [761/1000], Loss: 0.5277\n",
      "Epoch [762/1000], Loss: 0.5262\n",
      "Epoch [763/1000], Loss: 0.5277\n",
      "Epoch [764/1000], Loss: 0.5339\n",
      "Epoch [765/1000], Loss: 0.5293\n",
      "Epoch [766/1000], Loss: 0.5339\n",
      "Epoch [767/1000], Loss: 0.5293\n",
      "Epoch [768/1000], Loss: 0.5262\n",
      "Epoch [769/1000], Loss: 0.5324\n",
      "Epoch [770/1000], Loss: 0.5331\n",
      "Epoch [771/1000], Loss: 0.5316\n",
      "Epoch [772/1000], Loss: 0.5331\n",
      "Epoch [773/1000], Loss: 0.5316\n",
      "Epoch [774/1000], Loss: 0.5308\n",
      "Epoch [775/1000], Loss: 0.5308\n",
      "Epoch [776/1000], Loss: 0.5300\n",
      "Epoch [777/1000], Loss: 0.5223\n",
      "Epoch [778/1000], Loss: 0.5223\n",
      "Epoch [779/1000], Loss: 0.5254\n",
      "Epoch [780/1000], Loss: 0.5262\n",
      "Epoch [781/1000], Loss: 0.5254\n",
      "Epoch [782/1000], Loss: 0.5277\n",
      "Epoch [783/1000], Loss: 0.5277\n",
      "Epoch [784/1000], Loss: 0.5300\n",
      "Epoch [785/1000], Loss: 0.5231\n",
      "Epoch [786/1000], Loss: 0.5277\n",
      "Epoch [787/1000], Loss: 0.5262\n",
      "Epoch [788/1000], Loss: 0.5223\n",
      "Epoch [789/1000], Loss: 0.5285\n",
      "Epoch [790/1000], Loss: 0.5277\n",
      "Epoch [791/1000], Loss: 0.5270\n",
      "Epoch [792/1000], Loss: 0.5324\n",
      "Epoch [793/1000], Loss: 0.5316\n",
      "Epoch [794/1000], Loss: 0.5277\n",
      "Epoch [795/1000], Loss: 0.5254\n",
      "Epoch [796/1000], Loss: 0.5339\n",
      "Epoch [797/1000], Loss: 0.5277\n",
      "Epoch [798/1000], Loss: 0.5308\n",
      "Epoch [799/1000], Loss: 0.5262\n",
      "Epoch [800/1000], Loss: 0.5254\n",
      "Epoch [801/1000], Loss: 0.5339\n",
      "Epoch [802/1000], Loss: 0.5239\n",
      "Epoch [803/1000], Loss: 0.5308\n",
      "Epoch [804/1000], Loss: 0.5270\n",
      "Epoch [805/1000], Loss: 0.5239\n",
      "Epoch [806/1000], Loss: 0.5270\n",
      "Epoch [807/1000], Loss: 0.5231\n",
      "Epoch [808/1000], Loss: 0.5277\n",
      "Epoch [809/1000], Loss: 0.5285\n",
      "Epoch [810/1000], Loss: 0.5239\n",
      "Epoch [811/1000], Loss: 0.5300\n",
      "Epoch [812/1000], Loss: 0.5270\n",
      "Epoch [813/1000], Loss: 0.5339\n",
      "Epoch [814/1000], Loss: 0.5277\n",
      "Epoch [815/1000], Loss: 0.5254\n",
      "Epoch [816/1000], Loss: 0.5331\n",
      "Epoch [817/1000], Loss: 0.5300\n",
      "Epoch [818/1000], Loss: 0.5293\n",
      "Epoch [819/1000], Loss: 0.5293\n",
      "Epoch [820/1000], Loss: 0.5246\n",
      "Epoch [821/1000], Loss: 0.5277\n",
      "Epoch [822/1000], Loss: 0.5239\n",
      "Epoch [823/1000], Loss: 0.5231\n",
      "Epoch [824/1000], Loss: 0.5285\n",
      "Epoch [825/1000], Loss: 0.5285\n",
      "Epoch [826/1000], Loss: 0.5293\n",
      "Epoch [827/1000], Loss: 0.5300\n",
      "Epoch [828/1000], Loss: 0.5293\n",
      "Epoch [829/1000], Loss: 0.5331\n",
      "Epoch [830/1000], Loss: 0.5324\n",
      "Epoch [831/1000], Loss: 0.5300\n",
      "Epoch [832/1000], Loss: 0.5239\n",
      "Epoch [833/1000], Loss: 0.5246\n",
      "Epoch [834/1000], Loss: 0.5324\n",
      "Epoch [835/1000], Loss: 0.5293\n",
      "Epoch [836/1000], Loss: 0.5277\n",
      "Epoch [837/1000], Loss: 0.5270\n",
      "Epoch [838/1000], Loss: 0.5223\n",
      "Epoch [839/1000], Loss: 0.5262\n",
      "Epoch [840/1000], Loss: 0.5339\n",
      "Epoch [841/1000], Loss: 0.5324\n",
      "Epoch [842/1000], Loss: 0.5277\n",
      "Epoch [843/1000], Loss: 0.5293\n",
      "Epoch [844/1000], Loss: 0.5277\n",
      "Epoch [845/1000], Loss: 0.5239\n",
      "Epoch [846/1000], Loss: 0.5293\n",
      "Epoch [847/1000], Loss: 0.5293\n",
      "Epoch [848/1000], Loss: 0.5285\n",
      "Epoch [849/1000], Loss: 0.5254\n",
      "Epoch [850/1000], Loss: 0.5246\n",
      "Epoch [851/1000], Loss: 0.5362\n",
      "Epoch [852/1000], Loss: 0.5300\n",
      "Epoch [853/1000], Loss: 0.5285\n",
      "Epoch [854/1000], Loss: 0.5239\n",
      "Epoch [855/1000], Loss: 0.5270\n",
      "Epoch [856/1000], Loss: 0.5277\n",
      "Epoch [857/1000], Loss: 0.5293\n",
      "Epoch [858/1000], Loss: 0.5270\n",
      "Epoch [859/1000], Loss: 0.5277\n",
      "Epoch [860/1000], Loss: 0.5324\n",
      "Epoch [861/1000], Loss: 0.5208\n",
      "Epoch [862/1000], Loss: 0.5308\n",
      "Epoch [863/1000], Loss: 0.5308\n",
      "Epoch [864/1000], Loss: 0.5231\n",
      "Epoch [865/1000], Loss: 0.5285\n",
      "Epoch [866/1000], Loss: 0.5277\n",
      "Epoch [867/1000], Loss: 0.5285\n",
      "Epoch [868/1000], Loss: 0.5262\n",
      "Epoch [869/1000], Loss: 0.5254\n",
      "Epoch [870/1000], Loss: 0.5316\n",
      "Epoch [871/1000], Loss: 0.5308\n",
      "Epoch [872/1000], Loss: 0.5316\n",
      "Epoch [873/1000], Loss: 0.5246\n",
      "Epoch [874/1000], Loss: 0.5246\n",
      "Epoch [875/1000], Loss: 0.5300\n",
      "Epoch [876/1000], Loss: 0.5285\n",
      "Epoch [877/1000], Loss: 0.5293\n",
      "Epoch [878/1000], Loss: 0.5324\n",
      "Epoch [879/1000], Loss: 0.5262\n",
      "Epoch [880/1000], Loss: 0.5293\n",
      "Epoch [881/1000], Loss: 0.5331\n",
      "Epoch [882/1000], Loss: 0.5270\n",
      "Epoch [883/1000], Loss: 0.5300\n",
      "Epoch [884/1000], Loss: 0.5300\n",
      "Epoch [885/1000], Loss: 0.5285\n",
      "Epoch [886/1000], Loss: 0.5293\n",
      "Epoch [887/1000], Loss: 0.5331\n",
      "Epoch [888/1000], Loss: 0.5324\n",
      "Epoch [889/1000], Loss: 0.5293\n",
      "Epoch [890/1000], Loss: 0.5231\n",
      "Epoch [891/1000], Loss: 0.5262\n",
      "Epoch [892/1000], Loss: 0.5300\n",
      "Epoch [893/1000], Loss: 0.5285\n",
      "Epoch [894/1000], Loss: 0.5270\n",
      "Epoch [895/1000], Loss: 0.5293\n",
      "Epoch [896/1000], Loss: 0.5231\n",
      "Epoch [897/1000], Loss: 0.5246\n",
      "Epoch [898/1000], Loss: 0.5262\n",
      "Epoch [899/1000], Loss: 0.5324\n",
      "Epoch [900/1000], Loss: 0.5300\n",
      "Epoch [901/1000], Loss: 0.5277\n",
      "Epoch [902/1000], Loss: 0.5293\n",
      "Epoch [903/1000], Loss: 0.5347\n",
      "Epoch [904/1000], Loss: 0.5223\n",
      "Epoch [905/1000], Loss: 0.5324\n",
      "Epoch [906/1000], Loss: 0.5254\n",
      "Epoch [907/1000], Loss: 0.5293\n",
      "Epoch [908/1000], Loss: 0.5223\n",
      "Epoch [909/1000], Loss: 0.5293\n",
      "Epoch [910/1000], Loss: 0.5300\n",
      "Epoch [911/1000], Loss: 0.5377\n",
      "Epoch [912/1000], Loss: 0.5270\n",
      "Epoch [913/1000], Loss: 0.5308\n",
      "Epoch [914/1000], Loss: 0.5354\n",
      "Epoch [915/1000], Loss: 0.5285\n",
      "Epoch [916/1000], Loss: 0.5308\n",
      "Epoch [917/1000], Loss: 0.5246\n",
      "Epoch [918/1000], Loss: 0.5339\n",
      "Epoch [919/1000], Loss: 0.5262\n",
      "Epoch [920/1000], Loss: 0.5262\n",
      "Epoch [921/1000], Loss: 0.5246\n",
      "Epoch [922/1000], Loss: 0.5231\n",
      "Epoch [923/1000], Loss: 0.5300\n",
      "Epoch [924/1000], Loss: 0.5339\n",
      "Epoch [925/1000], Loss: 0.5300\n",
      "Epoch [926/1000], Loss: 0.5308\n",
      "Epoch [927/1000], Loss: 0.5285\n",
      "Epoch [928/1000], Loss: 0.5285\n",
      "Epoch [929/1000], Loss: 0.5285\n",
      "Epoch [930/1000], Loss: 0.5293\n",
      "Epoch [931/1000], Loss: 0.5254\n",
      "Epoch [932/1000], Loss: 0.5324\n",
      "Epoch [933/1000], Loss: 0.5246\n",
      "Epoch [934/1000], Loss: 0.5223\n",
      "Epoch [935/1000], Loss: 0.5300\n",
      "Epoch [936/1000], Loss: 0.5293\n",
      "Epoch [937/1000], Loss: 0.5324\n",
      "Epoch [938/1000], Loss: 0.5316\n",
      "Epoch [939/1000], Loss: 0.5270\n",
      "Epoch [940/1000], Loss: 0.5316\n",
      "Epoch [941/1000], Loss: 0.5246\n",
      "Epoch [942/1000], Loss: 0.5293\n",
      "Epoch [943/1000], Loss: 0.5277\n",
      "Epoch [944/1000], Loss: 0.5316\n",
      "Epoch [945/1000], Loss: 0.5231\n",
      "Epoch [946/1000], Loss: 0.5246\n",
      "Epoch [947/1000], Loss: 0.5316\n",
      "Epoch [948/1000], Loss: 0.5300\n",
      "Epoch [949/1000], Loss: 0.5308\n",
      "Epoch [950/1000], Loss: 0.5270\n",
      "Epoch [951/1000], Loss: 0.5324\n",
      "Epoch [952/1000], Loss: 0.5231\n",
      "Epoch [953/1000], Loss: 0.5277\n",
      "Epoch [954/1000], Loss: 0.5293\n",
      "Epoch [955/1000], Loss: 0.5316\n",
      "Epoch [956/1000], Loss: 0.5254\n",
      "Epoch [957/1000], Loss: 0.5316\n",
      "Epoch [958/1000], Loss: 0.5246\n",
      "Epoch [959/1000], Loss: 0.5324\n",
      "Epoch [960/1000], Loss: 0.5285\n",
      "Epoch [961/1000], Loss: 0.5277\n",
      "Epoch [962/1000], Loss: 0.5254\n",
      "Epoch [963/1000], Loss: 0.5239\n",
      "Epoch [964/1000], Loss: 0.5285\n",
      "Epoch [965/1000], Loss: 0.5254\n",
      "Epoch [966/1000], Loss: 0.5316\n",
      "Epoch [967/1000], Loss: 0.5277\n",
      "Epoch [968/1000], Loss: 0.5270\n",
      "Epoch [969/1000], Loss: 0.5270\n",
      "Epoch [970/1000], Loss: 0.5300\n",
      "Epoch [971/1000], Loss: 0.5262\n",
      "Epoch [972/1000], Loss: 0.5277\n",
      "Epoch [973/1000], Loss: 0.5254\n",
      "Epoch [974/1000], Loss: 0.5308\n",
      "Epoch [975/1000], Loss: 0.5285\n",
      "Epoch [976/1000], Loss: 0.5354\n",
      "Epoch [977/1000], Loss: 0.5308\n",
      "Epoch [978/1000], Loss: 0.5262\n",
      "Epoch [979/1000], Loss: 0.5254\n",
      "Epoch [980/1000], Loss: 0.5370\n",
      "Epoch [981/1000], Loss: 0.5254\n",
      "Epoch [982/1000], Loss: 0.5285\n",
      "Epoch [983/1000], Loss: 0.5293\n",
      "Epoch [984/1000], Loss: 0.5308\n",
      "Epoch [985/1000], Loss: 0.5316\n",
      "Epoch [986/1000], Loss: 0.5293\n",
      "Epoch [987/1000], Loss: 0.5308\n",
      "Epoch [988/1000], Loss: 0.5293\n",
      "Epoch [989/1000], Loss: 0.5270\n",
      "Epoch [990/1000], Loss: 0.5293\n",
      "Epoch [991/1000], Loss: 0.5246\n",
      "Epoch [992/1000], Loss: 0.5285\n",
      "Epoch [993/1000], Loss: 0.5254\n",
      "Epoch [994/1000], Loss: 0.5293\n",
      "Epoch [995/1000], Loss: 0.5293\n",
      "Epoch [996/1000], Loss: 0.5316\n",
      "Epoch [997/1000], Loss: 0.5246\n",
      "Epoch [998/1000], Loss: 0.5246\n",
      "Epoch [999/1000], Loss: 0.5246\n",
      "Epoch [1000/1000], Loss: 0.5347\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 302, lr :1.0, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.5121\n",
      "Epoch [2/1000], Loss: 0.5254\n",
      "Epoch [3/1000], Loss: 0.5324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/1000], Loss: 0.5293\n",
      "Epoch [5/1000], Loss: 0.5331\n",
      "Epoch [6/1000], Loss: 0.5254\n",
      "Epoch [7/1000], Loss: 0.5354\n",
      "Epoch [8/1000], Loss: 0.5262\n",
      "Epoch [9/1000], Loss: 0.5285\n",
      "Epoch [10/1000], Loss: 0.5293\n",
      "Epoch [11/1000], Loss: 0.5277\n",
      "Epoch [12/1000], Loss: 0.5285\n",
      "Epoch [13/1000], Loss: 0.5246\n",
      "Epoch [14/1000], Loss: 0.5270\n",
      "Epoch [15/1000], Loss: 0.5277\n",
      "Epoch [16/1000], Loss: 0.5324\n",
      "Epoch [17/1000], Loss: 0.5300\n",
      "Epoch [18/1000], Loss: 0.5254\n",
      "Epoch [19/1000], Loss: 0.5324\n",
      "Epoch [20/1000], Loss: 0.5308\n",
      "Epoch [21/1000], Loss: 0.5246\n",
      "Epoch [22/1000], Loss: 0.5316\n",
      "Epoch [23/1000], Loss: 0.5300\n",
      "Epoch [24/1000], Loss: 0.5308\n",
      "Epoch [25/1000], Loss: 0.5285\n",
      "Epoch [26/1000], Loss: 0.5293\n",
      "Epoch [27/1000], Loss: 0.5262\n",
      "Epoch [28/1000], Loss: 0.5293\n",
      "Epoch [29/1000], Loss: 0.5316\n",
      "Epoch [30/1000], Loss: 0.5254\n",
      "Epoch [31/1000], Loss: 0.5216\n",
      "Epoch [32/1000], Loss: 0.5246\n",
      "Epoch [33/1000], Loss: 0.5316\n",
      "Epoch [34/1000], Loss: 0.5308\n",
      "Epoch [35/1000], Loss: 0.5254\n",
      "Epoch [36/1000], Loss: 0.5324\n",
      "Epoch [37/1000], Loss: 0.5293\n",
      "Epoch [38/1000], Loss: 0.5262\n",
      "Epoch [39/1000], Loss: 0.5270\n",
      "Epoch [40/1000], Loss: 0.5223\n",
      "Epoch [41/1000], Loss: 0.5293\n",
      "Epoch [42/1000], Loss: 0.5270\n",
      "Epoch [43/1000], Loss: 0.5316\n",
      "Epoch [44/1000], Loss: 0.5300\n",
      "Epoch [45/1000], Loss: 0.5262\n",
      "Epoch [46/1000], Loss: 0.5285\n",
      "Epoch [47/1000], Loss: 0.5300\n",
      "Epoch [48/1000], Loss: 0.5262\n",
      "Epoch [49/1000], Loss: 0.5246\n",
      "Epoch [50/1000], Loss: 0.5300\n",
      "Epoch [51/1000], Loss: 0.5316\n",
      "Epoch [52/1000], Loss: 0.5262\n",
      "Epoch [53/1000], Loss: 0.5277\n",
      "Epoch [54/1000], Loss: 0.5293\n",
      "Epoch [55/1000], Loss: 0.5300\n",
      "Epoch [56/1000], Loss: 0.5246\n",
      "Epoch [57/1000], Loss: 0.5277\n",
      "Epoch [58/1000], Loss: 0.5262\n",
      "Epoch [59/1000], Loss: 0.5308\n",
      "Epoch [60/1000], Loss: 0.5285\n",
      "Epoch [61/1000], Loss: 0.5277\n",
      "Epoch [62/1000], Loss: 0.5324\n",
      "Epoch [63/1000], Loss: 0.5300\n",
      "Epoch [64/1000], Loss: 0.5300\n",
      "Epoch [65/1000], Loss: 0.5262\n",
      "Epoch [66/1000], Loss: 0.5254\n",
      "Epoch [67/1000], Loss: 0.5300\n",
      "Epoch [68/1000], Loss: 0.5285\n",
      "Epoch [69/1000], Loss: 0.5293\n",
      "Epoch [70/1000], Loss: 0.5285\n",
      "Epoch [71/1000], Loss: 0.5285\n",
      "Epoch [72/1000], Loss: 0.5316\n",
      "Epoch [73/1000], Loss: 0.5270\n",
      "Epoch [74/1000], Loss: 0.5285\n",
      "Epoch [75/1000], Loss: 0.5308\n",
      "Epoch [76/1000], Loss: 0.5254\n",
      "Epoch [77/1000], Loss: 0.5300\n",
      "Epoch [78/1000], Loss: 0.5285\n",
      "Epoch [79/1000], Loss: 0.5324\n",
      "Epoch [80/1000], Loss: 0.5293\n",
      "Epoch [81/1000], Loss: 0.5277\n",
      "Epoch [82/1000], Loss: 0.5316\n",
      "Epoch [83/1000], Loss: 0.5254\n",
      "Epoch [84/1000], Loss: 0.5347\n",
      "Epoch [85/1000], Loss: 0.5331\n",
      "Epoch [86/1000], Loss: 0.5331\n",
      "Epoch [87/1000], Loss: 0.5231\n",
      "Epoch [88/1000], Loss: 0.5300\n",
      "Epoch [89/1000], Loss: 0.5246\n",
      "Epoch [90/1000], Loss: 0.5285\n",
      "Epoch [91/1000], Loss: 0.5262\n",
      "Epoch [92/1000], Loss: 0.5285\n",
      "Epoch [93/1000], Loss: 0.5285\n",
      "Epoch [94/1000], Loss: 0.5216\n",
      "Epoch [95/1000], Loss: 0.5285\n",
      "Epoch [96/1000], Loss: 0.5285\n",
      "Epoch [97/1000], Loss: 0.5316\n",
      "Epoch [98/1000], Loss: 0.5277\n",
      "Epoch [99/1000], Loss: 0.5285\n",
      "Epoch [100/1000], Loss: 0.5370\n",
      "Epoch [101/1000], Loss: 0.5277\n",
      "Epoch [102/1000], Loss: 0.5246\n",
      "Epoch [103/1000], Loss: 0.5277\n",
      "Epoch [104/1000], Loss: 0.5239\n",
      "Epoch [105/1000], Loss: 0.5300\n",
      "Epoch [106/1000], Loss: 0.5308\n",
      "Epoch [107/1000], Loss: 0.5270\n",
      "Epoch [108/1000], Loss: 0.5254\n",
      "Epoch [109/1000], Loss: 0.5293\n",
      "Epoch [110/1000], Loss: 0.5270\n",
      "Epoch [111/1000], Loss: 0.5246\n",
      "Epoch [112/1000], Loss: 0.5285\n",
      "Epoch [113/1000], Loss: 0.5285\n",
      "Epoch [114/1000], Loss: 0.5370\n",
      "Epoch [115/1000], Loss: 0.5262\n",
      "Epoch [116/1000], Loss: 0.5308\n",
      "Epoch [117/1000], Loss: 0.5262\n",
      "Epoch [118/1000], Loss: 0.5308\n",
      "Epoch [119/1000], Loss: 0.5277\n",
      "Epoch [120/1000], Loss: 0.5324\n",
      "Epoch [121/1000], Loss: 0.5254\n",
      "Epoch [122/1000], Loss: 0.5270\n",
      "Epoch [123/1000], Loss: 0.5331\n",
      "Epoch [124/1000], Loss: 0.5293\n",
      "Epoch [125/1000], Loss: 0.5277\n",
      "Epoch [126/1000], Loss: 0.5277\n",
      "Epoch [127/1000], Loss: 0.5285\n",
      "Epoch [128/1000], Loss: 0.5347\n",
      "Epoch [129/1000], Loss: 0.5277\n",
      "Epoch [130/1000], Loss: 0.5308\n",
      "Epoch [131/1000], Loss: 0.5270\n",
      "Epoch [132/1000], Loss: 0.5277\n",
      "Epoch [133/1000], Loss: 0.5285\n",
      "Epoch [134/1000], Loss: 0.5270\n",
      "Epoch [135/1000], Loss: 0.5270\n",
      "Epoch [136/1000], Loss: 0.5231\n",
      "Epoch [137/1000], Loss: 0.5285\n",
      "Epoch [138/1000], Loss: 0.5285\n",
      "Epoch [139/1000], Loss: 0.5270\n",
      "Epoch [140/1000], Loss: 0.5308\n",
      "Epoch [141/1000], Loss: 0.5300\n",
      "Epoch [142/1000], Loss: 0.5254\n",
      "Epoch [143/1000], Loss: 0.5246\n",
      "Epoch [144/1000], Loss: 0.5300\n",
      "Epoch [145/1000], Loss: 0.5308\n",
      "Epoch [146/1000], Loss: 0.5262\n",
      "Epoch [147/1000], Loss: 0.5308\n",
      "Epoch [148/1000], Loss: 0.5300\n",
      "Epoch [149/1000], Loss: 0.5362\n",
      "Epoch [150/1000], Loss: 0.5293\n",
      "Epoch [151/1000], Loss: 0.5262\n",
      "Epoch [152/1000], Loss: 0.5262\n",
      "Epoch [153/1000], Loss: 0.5270\n",
      "Epoch [154/1000], Loss: 0.5308\n",
      "Epoch [155/1000], Loss: 0.5300\n",
      "Epoch [156/1000], Loss: 0.5300\n",
      "Epoch [157/1000], Loss: 0.5270\n",
      "Epoch [158/1000], Loss: 0.5208\n",
      "Epoch [159/1000], Loss: 0.5331\n",
      "Epoch [160/1000], Loss: 0.5277\n",
      "Epoch [161/1000], Loss: 0.5300\n",
      "Epoch [162/1000], Loss: 0.5270\n",
      "Epoch [163/1000], Loss: 0.5277\n",
      "Epoch [164/1000], Loss: 0.5308\n",
      "Epoch [165/1000], Loss: 0.5324\n",
      "Epoch [166/1000], Loss: 0.5324\n",
      "Epoch [167/1000], Loss: 0.5339\n",
      "Epoch [168/1000], Loss: 0.5262\n",
      "Epoch [169/1000], Loss: 0.5223\n",
      "Epoch [170/1000], Loss: 0.5270\n",
      "Epoch [171/1000], Loss: 0.5285\n",
      "Epoch [172/1000], Loss: 0.5370\n",
      "Epoch [173/1000], Loss: 0.5277\n",
      "Epoch [174/1000], Loss: 0.5331\n",
      "Epoch [175/1000], Loss: 0.5285\n",
      "Epoch [176/1000], Loss: 0.5285\n",
      "Epoch [177/1000], Loss: 0.5270\n",
      "Epoch [178/1000], Loss: 0.5293\n",
      "Epoch [179/1000], Loss: 0.5300\n",
      "Epoch [180/1000], Loss: 0.5262\n",
      "Epoch [181/1000], Loss: 0.5270\n",
      "Epoch [182/1000], Loss: 0.5308\n",
      "Epoch [183/1000], Loss: 0.5254\n",
      "Epoch [184/1000], Loss: 0.5339\n",
      "Epoch [185/1000], Loss: 0.5293\n",
      "Epoch [186/1000], Loss: 0.5239\n",
      "Epoch [187/1000], Loss: 0.5308\n",
      "Epoch [188/1000], Loss: 0.5277\n",
      "Epoch [189/1000], Loss: 0.5300\n",
      "Epoch [190/1000], Loss: 0.5254\n",
      "Epoch [191/1000], Loss: 0.5277\n",
      "Epoch [192/1000], Loss: 0.5262\n",
      "Epoch [193/1000], Loss: 0.5339\n",
      "Epoch [194/1000], Loss: 0.5223\n",
      "Epoch [195/1000], Loss: 0.5308\n",
      "Epoch [196/1000], Loss: 0.5277\n",
      "Epoch [197/1000], Loss: 0.5270\n",
      "Epoch [198/1000], Loss: 0.5293\n",
      "Epoch [199/1000], Loss: 0.5308\n",
      "Epoch [200/1000], Loss: 0.5293\n",
      "Epoch [201/1000], Loss: 0.5246\n",
      "Epoch [202/1000], Loss: 0.5277\n",
      "Epoch [203/1000], Loss: 0.5324\n",
      "Epoch [204/1000], Loss: 0.5262\n",
      "Epoch [205/1000], Loss: 0.5324\n",
      "Epoch [206/1000], Loss: 0.5285\n",
      "Epoch [207/1000], Loss: 0.5285\n",
      "Epoch [208/1000], Loss: 0.5277\n",
      "Epoch [209/1000], Loss: 0.5300\n",
      "Epoch [210/1000], Loss: 0.5262\n",
      "Epoch [211/1000], Loss: 0.5193\n",
      "Epoch [212/1000], Loss: 0.5254\n",
      "Epoch [213/1000], Loss: 0.5339\n",
      "Epoch [214/1000], Loss: 0.5285\n",
      "Epoch [215/1000], Loss: 0.5216\n",
      "Epoch [216/1000], Loss: 0.5331\n",
      "Epoch [217/1000], Loss: 0.5331\n",
      "Epoch [218/1000], Loss: 0.5331\n",
      "Epoch [219/1000], Loss: 0.5254\n",
      "Epoch [220/1000], Loss: 0.5277\n",
      "Epoch [221/1000], Loss: 0.5239\n",
      "Epoch [222/1000], Loss: 0.5200\n",
      "Epoch [223/1000], Loss: 0.5308\n",
      "Epoch [224/1000], Loss: 0.5300\n",
      "Epoch [225/1000], Loss: 0.5193\n",
      "Epoch [226/1000], Loss: 0.5300\n",
      "Epoch [227/1000], Loss: 0.5262\n",
      "Epoch [228/1000], Loss: 0.5223\n",
      "Epoch [229/1000], Loss: 0.5270\n",
      "Epoch [230/1000], Loss: 0.5285\n",
      "Epoch [231/1000], Loss: 0.5262\n",
      "Epoch [232/1000], Loss: 0.5316\n",
      "Epoch [233/1000], Loss: 0.5277\n",
      "Epoch [234/1000], Loss: 0.5331\n",
      "Epoch [235/1000], Loss: 0.5316\n",
      "Epoch [236/1000], Loss: 0.5262\n",
      "Epoch [237/1000], Loss: 0.5347\n",
      "Epoch [238/1000], Loss: 0.5316\n",
      "Epoch [239/1000], Loss: 0.5239\n",
      "Epoch [240/1000], Loss: 0.5254\n",
      "Epoch [241/1000], Loss: 0.5293\n",
      "Epoch [242/1000], Loss: 0.5239\n",
      "Epoch [243/1000], Loss: 0.5293\n",
      "Epoch [244/1000], Loss: 0.5285\n",
      "Epoch [245/1000], Loss: 0.5308\n",
      "Epoch [246/1000], Loss: 0.5231\n",
      "Epoch [247/1000], Loss: 0.5277\n",
      "Epoch [248/1000], Loss: 0.5285\n",
      "Epoch [249/1000], Loss: 0.5231\n",
      "Epoch [250/1000], Loss: 0.5254\n",
      "Epoch [251/1000], Loss: 0.5331\n",
      "Epoch [252/1000], Loss: 0.5293\n",
      "Epoch [253/1000], Loss: 0.5316\n",
      "Epoch [254/1000], Loss: 0.5293\n",
      "Epoch [255/1000], Loss: 0.5239\n",
      "Epoch [256/1000], Loss: 0.5293\n",
      "Epoch [257/1000], Loss: 0.5277\n",
      "Epoch [258/1000], Loss: 0.5285\n",
      "Epoch [259/1000], Loss: 0.5246\n",
      "Epoch [260/1000], Loss: 0.5239\n",
      "Epoch [261/1000], Loss: 0.5262\n",
      "Epoch [262/1000], Loss: 0.5262\n",
      "Epoch [263/1000], Loss: 0.5285\n",
      "Epoch [264/1000], Loss: 0.5246\n",
      "Epoch [265/1000], Loss: 0.5208\n",
      "Epoch [266/1000], Loss: 0.5270\n",
      "Epoch [267/1000], Loss: 0.5293\n",
      "Epoch [268/1000], Loss: 0.5370\n",
      "Epoch [269/1000], Loss: 0.5308\n",
      "Epoch [270/1000], Loss: 0.5262\n",
      "Epoch [271/1000], Loss: 0.5262\n",
      "Epoch [272/1000], Loss: 0.5277\n",
      "Epoch [273/1000], Loss: 0.5285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [274/1000], Loss: 0.5308\n",
      "Epoch [275/1000], Loss: 0.5331\n",
      "Epoch [276/1000], Loss: 0.5339\n",
      "Epoch [277/1000], Loss: 0.5246\n",
      "Epoch [278/1000], Loss: 0.5347\n",
      "Epoch [279/1000], Loss: 0.5285\n",
      "Epoch [280/1000], Loss: 0.5277\n",
      "Epoch [281/1000], Loss: 0.5223\n",
      "Epoch [282/1000], Loss: 0.5254\n",
      "Epoch [283/1000], Loss: 0.5262\n",
      "Epoch [284/1000], Loss: 0.5316\n",
      "Epoch [285/1000], Loss: 0.5300\n",
      "Epoch [286/1000], Loss: 0.5308\n",
      "Epoch [287/1000], Loss: 0.5300\n",
      "Epoch [288/1000], Loss: 0.5324\n",
      "Epoch [289/1000], Loss: 0.5331\n",
      "Epoch [290/1000], Loss: 0.5239\n",
      "Epoch [291/1000], Loss: 0.5324\n",
      "Epoch [292/1000], Loss: 0.5293\n",
      "Epoch [293/1000], Loss: 0.5285\n",
      "Epoch [294/1000], Loss: 0.5316\n",
      "Epoch [295/1000], Loss: 0.5223\n",
      "Epoch [296/1000], Loss: 0.5277\n",
      "Epoch [297/1000], Loss: 0.5300\n",
      "Epoch [298/1000], Loss: 0.5339\n",
      "Epoch [299/1000], Loss: 0.5239\n",
      "Epoch [300/1000], Loss: 0.5300\n",
      "Epoch [301/1000], Loss: 0.5324\n",
      "Epoch [302/1000], Loss: 0.5239\n",
      "Epoch [303/1000], Loss: 0.5200\n",
      "Epoch [304/1000], Loss: 0.5277\n",
      "Epoch [305/1000], Loss: 0.5285\n",
      "Epoch [306/1000], Loss: 0.5262\n",
      "Epoch [307/1000], Loss: 0.5277\n",
      "Epoch [308/1000], Loss: 0.5308\n",
      "Epoch [309/1000], Loss: 0.5300\n",
      "Epoch [310/1000], Loss: 0.5293\n",
      "Epoch [311/1000], Loss: 0.5300\n",
      "Epoch [312/1000], Loss: 0.5324\n",
      "Epoch [313/1000], Loss: 0.5223\n",
      "Epoch [314/1000], Loss: 0.5293\n",
      "Epoch [315/1000], Loss: 0.5254\n",
      "Epoch [316/1000], Loss: 0.5246\n",
      "Epoch [317/1000], Loss: 0.5339\n",
      "Epoch [318/1000], Loss: 0.5239\n",
      "Epoch [319/1000], Loss: 0.5300\n",
      "Epoch [320/1000], Loss: 0.5270\n",
      "Epoch [321/1000], Loss: 0.5216\n",
      "Epoch [322/1000], Loss: 0.5339\n",
      "Epoch [323/1000], Loss: 0.5270\n",
      "Epoch [324/1000], Loss: 0.5270\n",
      "Epoch [325/1000], Loss: 0.5308\n",
      "Epoch [326/1000], Loss: 0.5254\n",
      "Epoch [327/1000], Loss: 0.5300\n",
      "Epoch [328/1000], Loss: 0.5324\n",
      "Epoch [329/1000], Loss: 0.5308\n",
      "Epoch [330/1000], Loss: 0.5308\n",
      "Epoch [331/1000], Loss: 0.5231\n",
      "Epoch [332/1000], Loss: 0.5277\n",
      "Epoch [333/1000], Loss: 0.5262\n",
      "Epoch [334/1000], Loss: 0.5300\n",
      "Epoch [335/1000], Loss: 0.5285\n",
      "Epoch [336/1000], Loss: 0.5285\n",
      "Epoch [337/1000], Loss: 0.5331\n",
      "Epoch [338/1000], Loss: 0.5324\n",
      "Epoch [339/1000], Loss: 0.5254\n",
      "Epoch [340/1000], Loss: 0.5285\n",
      "Epoch [341/1000], Loss: 0.5331\n",
      "Epoch [342/1000], Loss: 0.5262\n",
      "Epoch [343/1000], Loss: 0.5300\n",
      "Epoch [344/1000], Loss: 0.5277\n",
      "Epoch [345/1000], Loss: 0.5316\n",
      "Epoch [346/1000], Loss: 0.5293\n",
      "Epoch [347/1000], Loss: 0.5239\n",
      "Epoch [348/1000], Loss: 0.5216\n",
      "Epoch [349/1000], Loss: 0.5270\n",
      "Epoch [350/1000], Loss: 0.5262\n",
      "Epoch [351/1000], Loss: 0.5300\n",
      "Epoch [352/1000], Loss: 0.5239\n",
      "Epoch [353/1000], Loss: 0.5254\n",
      "Epoch [354/1000], Loss: 0.5270\n",
      "Epoch [355/1000], Loss: 0.5270\n",
      "Epoch [356/1000], Loss: 0.5293\n",
      "Epoch [357/1000], Loss: 0.5339\n",
      "Epoch [358/1000], Loss: 0.5270\n",
      "Epoch [359/1000], Loss: 0.5262\n",
      "Epoch [360/1000], Loss: 0.5300\n",
      "Epoch [361/1000], Loss: 0.5277\n",
      "Epoch [362/1000], Loss: 0.5270\n",
      "Epoch [363/1000], Loss: 0.5254\n",
      "Epoch [364/1000], Loss: 0.5277\n",
      "Epoch [365/1000], Loss: 0.5239\n",
      "Epoch [366/1000], Loss: 0.5239\n",
      "Epoch [367/1000], Loss: 0.5300\n",
      "Epoch [368/1000], Loss: 0.5331\n",
      "Epoch [369/1000], Loss: 0.5300\n",
      "Epoch [370/1000], Loss: 0.5277\n",
      "Epoch [371/1000], Loss: 0.5246\n",
      "Epoch [372/1000], Loss: 0.5262\n",
      "Epoch [373/1000], Loss: 0.5370\n",
      "Epoch [374/1000], Loss: 0.5324\n",
      "Epoch [375/1000], Loss: 0.5285\n",
      "Epoch [376/1000], Loss: 0.5270\n",
      "Epoch [377/1000], Loss: 0.5270\n",
      "Epoch [378/1000], Loss: 0.5246\n",
      "Epoch [379/1000], Loss: 0.5316\n",
      "Epoch [380/1000], Loss: 0.5246\n",
      "Epoch [381/1000], Loss: 0.5331\n",
      "Epoch [382/1000], Loss: 0.5246\n",
      "Epoch [383/1000], Loss: 0.5316\n",
      "Epoch [384/1000], Loss: 0.5216\n",
      "Epoch [385/1000], Loss: 0.5285\n",
      "Epoch [386/1000], Loss: 0.5270\n",
      "Epoch [387/1000], Loss: 0.5308\n",
      "Epoch [388/1000], Loss: 0.5293\n",
      "Epoch [389/1000], Loss: 0.5300\n",
      "Epoch [390/1000], Loss: 0.5293\n",
      "Epoch [391/1000], Loss: 0.5216\n",
      "Epoch [392/1000], Loss: 0.5300\n",
      "Epoch [393/1000], Loss: 0.5246\n",
      "Epoch [394/1000], Loss: 0.5277\n",
      "Epoch [395/1000], Loss: 0.5300\n",
      "Epoch [396/1000], Loss: 0.5354\n",
      "Epoch [397/1000], Loss: 0.5270\n",
      "Epoch [398/1000], Loss: 0.5270\n",
      "Epoch [399/1000], Loss: 0.5308\n",
      "Epoch [400/1000], Loss: 0.5231\n",
      "Epoch [401/1000], Loss: 0.5308\n",
      "Epoch [402/1000], Loss: 0.5293\n",
      "Epoch [403/1000], Loss: 0.5277\n",
      "Epoch [404/1000], Loss: 0.5262\n",
      "Epoch [405/1000], Loss: 0.5277\n",
      "Epoch [406/1000], Loss: 0.5270\n",
      "Epoch [407/1000], Loss: 0.5270\n",
      "Epoch [408/1000], Loss: 0.5277\n",
      "Epoch [409/1000], Loss: 0.5316\n",
      "Epoch [410/1000], Loss: 0.5331\n",
      "Epoch [411/1000], Loss: 0.5293\n",
      "Epoch [412/1000], Loss: 0.5262\n",
      "Epoch [413/1000], Loss: 0.5293\n",
      "Epoch [414/1000], Loss: 0.5316\n",
      "Epoch [415/1000], Loss: 0.5339\n",
      "Epoch [416/1000], Loss: 0.5270\n",
      "Epoch [417/1000], Loss: 0.5300\n",
      "Epoch [418/1000], Loss: 0.5308\n",
      "Epoch [419/1000], Loss: 0.5308\n",
      "Epoch [420/1000], Loss: 0.5277\n",
      "Epoch [421/1000], Loss: 0.5324\n",
      "Epoch [422/1000], Loss: 0.5347\n",
      "Epoch [423/1000], Loss: 0.5285\n",
      "Epoch [424/1000], Loss: 0.5254\n",
      "Epoch [425/1000], Loss: 0.5293\n",
      "Epoch [426/1000], Loss: 0.5277\n",
      "Epoch [427/1000], Loss: 0.5254\n",
      "Epoch [428/1000], Loss: 0.5270\n",
      "Epoch [429/1000], Loss: 0.5362\n",
      "Epoch [430/1000], Loss: 0.5324\n",
      "Epoch [431/1000], Loss: 0.5254\n",
      "Epoch [432/1000], Loss: 0.5293\n",
      "Epoch [433/1000], Loss: 0.5270\n",
      "Epoch [434/1000], Loss: 0.5339\n",
      "Epoch [435/1000], Loss: 0.5316\n",
      "Epoch [436/1000], Loss: 0.5277\n",
      "Epoch [437/1000], Loss: 0.5285\n",
      "Epoch [438/1000], Loss: 0.5216\n",
      "Epoch [439/1000], Loss: 0.5300\n",
      "Epoch [440/1000], Loss: 0.5216\n",
      "Epoch [441/1000], Loss: 0.5285\n",
      "Epoch [442/1000], Loss: 0.5300\n",
      "Epoch [443/1000], Loss: 0.5285\n",
      "Epoch [444/1000], Loss: 0.5254\n",
      "Epoch [445/1000], Loss: 0.5285\n",
      "Epoch [446/1000], Loss: 0.5300\n",
      "Epoch [447/1000], Loss: 0.5316\n",
      "Epoch [448/1000], Loss: 0.5277\n",
      "Epoch [449/1000], Loss: 0.5254\n",
      "Epoch [450/1000], Loss: 0.5270\n",
      "Epoch [451/1000], Loss: 0.5254\n",
      "Epoch [452/1000], Loss: 0.5347\n",
      "Epoch [453/1000], Loss: 0.5331\n",
      "Epoch [454/1000], Loss: 0.5277\n",
      "Epoch [455/1000], Loss: 0.5277\n",
      "Epoch [456/1000], Loss: 0.5300\n",
      "Epoch [457/1000], Loss: 0.5316\n",
      "Epoch [458/1000], Loss: 0.5239\n",
      "Epoch [459/1000], Loss: 0.5308\n",
      "Epoch [460/1000], Loss: 0.5316\n",
      "Epoch [461/1000], Loss: 0.5331\n",
      "Epoch [462/1000], Loss: 0.5331\n",
      "Epoch [463/1000], Loss: 0.5254\n",
      "Epoch [464/1000], Loss: 0.5324\n",
      "Epoch [465/1000], Loss: 0.5270\n",
      "Epoch [466/1000], Loss: 0.5308\n",
      "Epoch [467/1000], Loss: 0.5285\n",
      "Epoch [468/1000], Loss: 0.5285\n",
      "Epoch [469/1000], Loss: 0.5270\n",
      "Epoch [470/1000], Loss: 0.5254\n",
      "Epoch [471/1000], Loss: 0.5277\n",
      "Epoch [472/1000], Loss: 0.5254\n",
      "Epoch [473/1000], Loss: 0.5300\n",
      "Epoch [474/1000], Loss: 0.5316\n",
      "Epoch [475/1000], Loss: 0.5293\n",
      "Epoch [476/1000], Loss: 0.5231\n",
      "Epoch [477/1000], Loss: 0.5270\n",
      "Epoch [478/1000], Loss: 0.5239\n",
      "Epoch [479/1000], Loss: 0.5316\n",
      "Epoch [480/1000], Loss: 0.5300\n",
      "Epoch [481/1000], Loss: 0.5246\n",
      "Epoch [482/1000], Loss: 0.5316\n",
      "Epoch [483/1000], Loss: 0.5277\n",
      "Epoch [484/1000], Loss: 0.5300\n",
      "Epoch [485/1000], Loss: 0.5277\n",
      "Epoch [486/1000], Loss: 0.5285\n",
      "Epoch [487/1000], Loss: 0.5285\n",
      "Epoch [488/1000], Loss: 0.5277\n",
      "Epoch [489/1000], Loss: 0.5246\n",
      "Epoch [490/1000], Loss: 0.5277\n",
      "Epoch [491/1000], Loss: 0.5277\n",
      "Epoch [492/1000], Loss: 0.5231\n",
      "Epoch [493/1000], Loss: 0.5231\n",
      "Epoch [494/1000], Loss: 0.5339\n",
      "Epoch [495/1000], Loss: 0.5231\n",
      "Epoch [496/1000], Loss: 0.5293\n",
      "Epoch [497/1000], Loss: 0.5239\n",
      "Epoch [498/1000], Loss: 0.5339\n",
      "Epoch [499/1000], Loss: 0.5262\n",
      "Epoch [500/1000], Loss: 0.5285\n",
      "Epoch [501/1000], Loss: 0.5277\n",
      "Epoch [502/1000], Loss: 0.5293\n",
      "Epoch [503/1000], Loss: 0.5324\n",
      "Epoch [504/1000], Loss: 0.5254\n",
      "Epoch [505/1000], Loss: 0.5231\n",
      "Epoch [506/1000], Loss: 0.5246\n",
      "Epoch [507/1000], Loss: 0.5285\n",
      "Epoch [508/1000], Loss: 0.5254\n",
      "Epoch [509/1000], Loss: 0.5285\n",
      "Epoch [510/1000], Loss: 0.5324\n",
      "Epoch [511/1000], Loss: 0.5316\n",
      "Epoch [512/1000], Loss: 0.5277\n",
      "Epoch [513/1000], Loss: 0.5231\n",
      "Epoch [514/1000], Loss: 0.5231\n",
      "Epoch [515/1000], Loss: 0.5354\n",
      "Epoch [516/1000], Loss: 0.5308\n",
      "Epoch [517/1000], Loss: 0.5262\n",
      "Epoch [518/1000], Loss: 0.5308\n",
      "Epoch [519/1000], Loss: 0.5262\n",
      "Epoch [520/1000], Loss: 0.5254\n",
      "Epoch [521/1000], Loss: 0.5300\n",
      "Epoch [522/1000], Loss: 0.5300\n",
      "Epoch [523/1000], Loss: 0.5254\n",
      "Epoch [524/1000], Loss: 0.5231\n",
      "Epoch [525/1000], Loss: 0.5347\n",
      "Epoch [526/1000], Loss: 0.5293\n",
      "Epoch [527/1000], Loss: 0.5300\n",
      "Epoch [528/1000], Loss: 0.5300\n",
      "Epoch [529/1000], Loss: 0.5277\n",
      "Epoch [530/1000], Loss: 0.5308\n",
      "Epoch [531/1000], Loss: 0.5300\n",
      "Epoch [532/1000], Loss: 0.5293\n",
      "Epoch [533/1000], Loss: 0.5339\n",
      "Epoch [534/1000], Loss: 0.5254\n",
      "Epoch [535/1000], Loss: 0.5339\n",
      "Epoch [536/1000], Loss: 0.5285\n",
      "Epoch [537/1000], Loss: 0.5300\n",
      "Epoch [538/1000], Loss: 0.5246\n",
      "Epoch [539/1000], Loss: 0.5300\n",
      "Epoch [540/1000], Loss: 0.5331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [541/1000], Loss: 0.5308\n",
      "Epoch [542/1000], Loss: 0.5277\n",
      "Epoch [543/1000], Loss: 0.5293\n",
      "Epoch [544/1000], Loss: 0.5293\n",
      "Epoch [545/1000], Loss: 0.5293\n",
      "Epoch [546/1000], Loss: 0.5239\n",
      "Epoch [547/1000], Loss: 0.5316\n",
      "Epoch [548/1000], Loss: 0.5324\n",
      "Epoch [549/1000], Loss: 0.5270\n",
      "Epoch [550/1000], Loss: 0.5300\n",
      "Epoch [551/1000], Loss: 0.5293\n",
      "Epoch [552/1000], Loss: 0.5223\n",
      "Epoch [553/1000], Loss: 0.5331\n",
      "Epoch [554/1000], Loss: 0.5239\n",
      "Epoch [555/1000], Loss: 0.5308\n",
      "Epoch [556/1000], Loss: 0.5262\n",
      "Epoch [557/1000], Loss: 0.5270\n",
      "Epoch [558/1000], Loss: 0.5246\n",
      "Epoch [559/1000], Loss: 0.5300\n",
      "Epoch [560/1000], Loss: 0.5293\n",
      "Epoch [561/1000], Loss: 0.5262\n",
      "Epoch [562/1000], Loss: 0.5262\n",
      "Epoch [563/1000], Loss: 0.5293\n",
      "Epoch [564/1000], Loss: 0.5300\n",
      "Epoch [565/1000], Loss: 0.5347\n",
      "Epoch [566/1000], Loss: 0.5277\n",
      "Epoch [567/1000], Loss: 0.5239\n",
      "Epoch [568/1000], Loss: 0.5277\n",
      "Epoch [569/1000], Loss: 0.5293\n",
      "Epoch [570/1000], Loss: 0.5339\n",
      "Epoch [571/1000], Loss: 0.5324\n",
      "Epoch [572/1000], Loss: 0.5277\n",
      "Epoch [573/1000], Loss: 0.5270\n",
      "Epoch [574/1000], Loss: 0.5293\n",
      "Epoch [575/1000], Loss: 0.5300\n",
      "Epoch [576/1000], Loss: 0.5254\n",
      "Epoch [577/1000], Loss: 0.5370\n",
      "Epoch [578/1000], Loss: 0.5308\n",
      "Epoch [579/1000], Loss: 0.5316\n",
      "Epoch [580/1000], Loss: 0.5254\n",
      "Epoch [581/1000], Loss: 0.5239\n",
      "Epoch [582/1000], Loss: 0.5277\n",
      "Epoch [583/1000], Loss: 0.5285\n",
      "Epoch [584/1000], Loss: 0.5293\n",
      "Epoch [585/1000], Loss: 0.5254\n",
      "Epoch [586/1000], Loss: 0.5331\n",
      "Epoch [587/1000], Loss: 0.5347\n",
      "Epoch [588/1000], Loss: 0.5254\n",
      "Epoch [589/1000], Loss: 0.5239\n",
      "Epoch [590/1000], Loss: 0.5285\n",
      "Epoch [591/1000], Loss: 0.5270\n",
      "Epoch [592/1000], Loss: 0.5246\n",
      "Epoch [593/1000], Loss: 0.5239\n",
      "Epoch [594/1000], Loss: 0.5270\n",
      "Epoch [595/1000], Loss: 0.5316\n",
      "Epoch [596/1000], Loss: 0.5324\n",
      "Epoch [597/1000], Loss: 0.5354\n",
      "Epoch [598/1000], Loss: 0.5277\n",
      "Epoch [599/1000], Loss: 0.5293\n",
      "Epoch [600/1000], Loss: 0.5316\n",
      "Epoch [601/1000], Loss: 0.5324\n",
      "Epoch [602/1000], Loss: 0.5277\n",
      "Epoch [603/1000], Loss: 0.5285\n",
      "Epoch [604/1000], Loss: 0.5270\n",
      "Epoch [605/1000], Loss: 0.5300\n",
      "Epoch [606/1000], Loss: 0.5324\n",
      "Epoch [607/1000], Loss: 0.5277\n",
      "Epoch [608/1000], Loss: 0.5285\n",
      "Epoch [609/1000], Loss: 0.5277\n",
      "Epoch [610/1000], Loss: 0.5324\n",
      "Epoch [611/1000], Loss: 0.5285\n",
      "Epoch [612/1000], Loss: 0.5300\n",
      "Epoch [613/1000], Loss: 0.5300\n",
      "Epoch [614/1000], Loss: 0.5239\n",
      "Epoch [615/1000], Loss: 0.5254\n",
      "Epoch [616/1000], Loss: 0.5339\n",
      "Epoch [617/1000], Loss: 0.5239\n",
      "Epoch [618/1000], Loss: 0.5285\n",
      "Epoch [619/1000], Loss: 0.5239\n",
      "Epoch [620/1000], Loss: 0.5270\n",
      "Epoch [621/1000], Loss: 0.5331\n",
      "Epoch [622/1000], Loss: 0.5308\n",
      "Epoch [623/1000], Loss: 0.5324\n",
      "Epoch [624/1000], Loss: 0.5239\n",
      "Epoch [625/1000], Loss: 0.5246\n",
      "Epoch [626/1000], Loss: 0.5270\n",
      "Epoch [627/1000], Loss: 0.5262\n",
      "Epoch [628/1000], Loss: 0.5300\n",
      "Epoch [629/1000], Loss: 0.5331\n",
      "Epoch [630/1000], Loss: 0.5308\n",
      "Epoch [631/1000], Loss: 0.5285\n",
      "Epoch [632/1000], Loss: 0.5324\n",
      "Epoch [633/1000], Loss: 0.5246\n",
      "Epoch [634/1000], Loss: 0.5277\n",
      "Epoch [635/1000], Loss: 0.5308\n",
      "Epoch [636/1000], Loss: 0.5277\n",
      "Epoch [637/1000], Loss: 0.5339\n",
      "Epoch [638/1000], Loss: 0.5270\n",
      "Epoch [639/1000], Loss: 0.5308\n",
      "Epoch [640/1000], Loss: 0.5277\n",
      "Epoch [641/1000], Loss: 0.5246\n",
      "Epoch [642/1000], Loss: 0.5285\n",
      "Epoch [643/1000], Loss: 0.5300\n",
      "Epoch [644/1000], Loss: 0.5324\n",
      "Epoch [645/1000], Loss: 0.5246\n",
      "Epoch [646/1000], Loss: 0.5308\n",
      "Epoch [647/1000], Loss: 0.5293\n",
      "Epoch [648/1000], Loss: 0.5293\n",
      "Epoch [649/1000], Loss: 0.5246\n",
      "Epoch [650/1000], Loss: 0.5285\n",
      "Epoch [651/1000], Loss: 0.5277\n",
      "Epoch [652/1000], Loss: 0.5300\n",
      "Epoch [653/1000], Loss: 0.5300\n",
      "Epoch [654/1000], Loss: 0.5347\n",
      "Epoch [655/1000], Loss: 0.5331\n",
      "Epoch [656/1000], Loss: 0.5308\n",
      "Epoch [657/1000], Loss: 0.5331\n",
      "Epoch [658/1000], Loss: 0.5254\n",
      "Epoch [659/1000], Loss: 0.5262\n",
      "Epoch [660/1000], Loss: 0.5339\n",
      "Epoch [661/1000], Loss: 0.5246\n",
      "Epoch [662/1000], Loss: 0.5308\n",
      "Epoch [663/1000], Loss: 0.5316\n",
      "Epoch [664/1000], Loss: 0.5300\n",
      "Epoch [665/1000], Loss: 0.5331\n",
      "Epoch [666/1000], Loss: 0.5223\n",
      "Epoch [667/1000], Loss: 0.5254\n",
      "Epoch [668/1000], Loss: 0.5308\n",
      "Epoch [669/1000], Loss: 0.5354\n",
      "Epoch [670/1000], Loss: 0.5270\n",
      "Epoch [671/1000], Loss: 0.5270\n",
      "Epoch [672/1000], Loss: 0.5254\n",
      "Epoch [673/1000], Loss: 0.5293\n",
      "Epoch [674/1000], Loss: 0.5316\n",
      "Epoch [675/1000], Loss: 0.5308\n",
      "Epoch [676/1000], Loss: 0.5223\n",
      "Epoch [677/1000], Loss: 0.5270\n",
      "Epoch [678/1000], Loss: 0.5308\n",
      "Epoch [679/1000], Loss: 0.5223\n",
      "Epoch [680/1000], Loss: 0.5285\n",
      "Epoch [681/1000], Loss: 0.5300\n",
      "Epoch [682/1000], Loss: 0.5316\n",
      "Epoch [683/1000], Loss: 0.5293\n",
      "Epoch [684/1000], Loss: 0.5277\n",
      "Epoch [685/1000], Loss: 0.5193\n",
      "Epoch [686/1000], Loss: 0.5308\n",
      "Epoch [687/1000], Loss: 0.5277\n",
      "Epoch [688/1000], Loss: 0.5270\n",
      "Epoch [689/1000], Loss: 0.5285\n",
      "Epoch [690/1000], Loss: 0.5324\n",
      "Epoch [691/1000], Loss: 0.5246\n",
      "Epoch [692/1000], Loss: 0.5177\n",
      "Epoch [693/1000], Loss: 0.5262\n",
      "Epoch [694/1000], Loss: 0.5316\n",
      "Epoch [695/1000], Loss: 0.5285\n",
      "Epoch [696/1000], Loss: 0.5193\n",
      "Epoch [697/1000], Loss: 0.5277\n",
      "Epoch [698/1000], Loss: 0.5308\n",
      "Epoch [699/1000], Loss: 0.5270\n",
      "Epoch [700/1000], Loss: 0.5285\n",
      "Epoch [701/1000], Loss: 0.5331\n",
      "Epoch [702/1000], Loss: 0.5331\n",
      "Epoch [703/1000], Loss: 0.5293\n",
      "Epoch [704/1000], Loss: 0.5347\n",
      "Epoch [705/1000], Loss: 0.5331\n",
      "Epoch [706/1000], Loss: 0.5270\n",
      "Epoch [707/1000], Loss: 0.5270\n",
      "Epoch [708/1000], Loss: 0.5316\n",
      "Epoch [709/1000], Loss: 0.5285\n",
      "Epoch [710/1000], Loss: 0.5316\n",
      "Epoch [711/1000], Loss: 0.5316\n",
      "Epoch [712/1000], Loss: 0.5246\n",
      "Epoch [713/1000], Loss: 0.5308\n",
      "Epoch [714/1000], Loss: 0.5324\n",
      "Epoch [715/1000], Loss: 0.5254\n",
      "Epoch [716/1000], Loss: 0.5239\n",
      "Epoch [717/1000], Loss: 0.5254\n",
      "Epoch [718/1000], Loss: 0.5277\n",
      "Epoch [719/1000], Loss: 0.5254\n",
      "Epoch [720/1000], Loss: 0.5293\n",
      "Epoch [721/1000], Loss: 0.5254\n",
      "Epoch [722/1000], Loss: 0.5293\n",
      "Epoch [723/1000], Loss: 0.5262\n",
      "Epoch [724/1000], Loss: 0.5347\n",
      "Epoch [725/1000], Loss: 0.5277\n",
      "Epoch [726/1000], Loss: 0.5308\n",
      "Epoch [727/1000], Loss: 0.5300\n",
      "Epoch [728/1000], Loss: 0.5254\n",
      "Epoch [729/1000], Loss: 0.5262\n",
      "Epoch [730/1000], Loss: 0.5262\n",
      "Epoch [731/1000], Loss: 0.5270\n",
      "Epoch [732/1000], Loss: 0.5270\n",
      "Epoch [733/1000], Loss: 0.5254\n",
      "Epoch [734/1000], Loss: 0.5300\n",
      "Epoch [735/1000], Loss: 0.5285\n",
      "Epoch [736/1000], Loss: 0.5254\n",
      "Epoch [737/1000], Loss: 0.5239\n",
      "Epoch [738/1000], Loss: 0.5316\n",
      "Epoch [739/1000], Loss: 0.5293\n",
      "Epoch [740/1000], Loss: 0.5277\n",
      "Epoch [741/1000], Loss: 0.5231\n",
      "Epoch [742/1000], Loss: 0.5239\n",
      "Epoch [743/1000], Loss: 0.5285\n",
      "Epoch [744/1000], Loss: 0.5277\n",
      "Epoch [745/1000], Loss: 0.5324\n",
      "Epoch [746/1000], Loss: 0.5308\n",
      "Epoch [747/1000], Loss: 0.5339\n",
      "Epoch [748/1000], Loss: 0.5300\n",
      "Epoch [749/1000], Loss: 0.5293\n",
      "Epoch [750/1000], Loss: 0.5300\n",
      "Epoch [751/1000], Loss: 0.5246\n",
      "Epoch [752/1000], Loss: 0.5316\n",
      "Epoch [753/1000], Loss: 0.5239\n",
      "Epoch [754/1000], Loss: 0.5277\n",
      "Epoch [755/1000], Loss: 0.5316\n",
      "Epoch [756/1000], Loss: 0.5293\n",
      "Epoch [757/1000], Loss: 0.5270\n",
      "Epoch [758/1000], Loss: 0.5277\n",
      "Epoch [759/1000], Loss: 0.5316\n",
      "Epoch [760/1000], Loss: 0.5277\n",
      "Epoch [761/1000], Loss: 0.5246\n",
      "Epoch [762/1000], Loss: 0.5270\n",
      "Epoch [763/1000], Loss: 0.5293\n",
      "Epoch [764/1000], Loss: 0.5300\n",
      "Epoch [765/1000], Loss: 0.5339\n",
      "Epoch [766/1000], Loss: 0.5277\n",
      "Epoch [767/1000], Loss: 0.5300\n",
      "Epoch [768/1000], Loss: 0.5262\n",
      "Epoch [769/1000], Loss: 0.5277\n",
      "Epoch [770/1000], Loss: 0.5277\n",
      "Epoch [771/1000], Loss: 0.5347\n",
      "Epoch [772/1000], Loss: 0.5239\n",
      "Epoch [773/1000], Loss: 0.5270\n",
      "Epoch [774/1000], Loss: 0.5262\n",
      "Epoch [775/1000], Loss: 0.5308\n",
      "Epoch [776/1000], Loss: 0.5277\n",
      "Epoch [777/1000], Loss: 0.5316\n",
      "Epoch [778/1000], Loss: 0.5354\n",
      "Epoch [779/1000], Loss: 0.5246\n",
      "Epoch [780/1000], Loss: 0.5254\n",
      "Epoch [781/1000], Loss: 0.5270\n",
      "Epoch [782/1000], Loss: 0.5277\n",
      "Epoch [783/1000], Loss: 0.5354\n",
      "Epoch [784/1000], Loss: 0.5300\n",
      "Epoch [785/1000], Loss: 0.5331\n",
      "Epoch [786/1000], Loss: 0.5231\n",
      "Epoch [787/1000], Loss: 0.5270\n",
      "Epoch [788/1000], Loss: 0.5239\n",
      "Epoch [789/1000], Loss: 0.5270\n",
      "Epoch [790/1000], Loss: 0.5285\n",
      "Epoch [791/1000], Loss: 0.5339\n",
      "Epoch [792/1000], Loss: 0.5339\n",
      "Epoch [793/1000], Loss: 0.5324\n",
      "Epoch [794/1000], Loss: 0.5216\n",
      "Epoch [795/1000], Loss: 0.5316\n",
      "Epoch [796/1000], Loss: 0.5254\n",
      "Epoch [797/1000], Loss: 0.5308\n",
      "Epoch [798/1000], Loss: 0.5254\n",
      "Epoch [799/1000], Loss: 0.5270\n",
      "Epoch [800/1000], Loss: 0.5270\n",
      "Epoch [801/1000], Loss: 0.5262\n",
      "Epoch [802/1000], Loss: 0.5270\n",
      "Epoch [803/1000], Loss: 0.5285\n",
      "Epoch [804/1000], Loss: 0.5316\n",
      "Epoch [805/1000], Loss: 0.5254\n",
      "Epoch [806/1000], Loss: 0.5262\n",
      "Epoch [807/1000], Loss: 0.5262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [808/1000], Loss: 0.5285\n",
      "Epoch [809/1000], Loss: 0.5300\n",
      "Epoch [810/1000], Loss: 0.5254\n",
      "Epoch [811/1000], Loss: 0.5324\n",
      "Epoch [812/1000], Loss: 0.5277\n",
      "Epoch [813/1000], Loss: 0.5362\n",
      "Epoch [814/1000], Loss: 0.5277\n",
      "Epoch [815/1000], Loss: 0.5308\n",
      "Epoch [816/1000], Loss: 0.5254\n",
      "Epoch [817/1000], Loss: 0.5254\n",
      "Epoch [818/1000], Loss: 0.5285\n",
      "Epoch [819/1000], Loss: 0.5293\n",
      "Epoch [820/1000], Loss: 0.5277\n",
      "Epoch [821/1000], Loss: 0.5277\n",
      "Epoch [822/1000], Loss: 0.5316\n",
      "Epoch [823/1000], Loss: 0.5339\n",
      "Epoch [824/1000], Loss: 0.5285\n",
      "Epoch [825/1000], Loss: 0.5316\n",
      "Epoch [826/1000], Loss: 0.5300\n",
      "Epoch [827/1000], Loss: 0.5277\n",
      "Epoch [828/1000], Loss: 0.5277\n",
      "Epoch [829/1000], Loss: 0.5231\n",
      "Epoch [830/1000], Loss: 0.5339\n",
      "Epoch [831/1000], Loss: 0.5223\n",
      "Epoch [832/1000], Loss: 0.5277\n",
      "Epoch [833/1000], Loss: 0.5370\n",
      "Epoch [834/1000], Loss: 0.5231\n",
      "Epoch [835/1000], Loss: 0.5277\n",
      "Epoch [836/1000], Loss: 0.5239\n",
      "Epoch [837/1000], Loss: 0.5246\n",
      "Epoch [838/1000], Loss: 0.5293\n",
      "Epoch [839/1000], Loss: 0.5262\n",
      "Epoch [840/1000], Loss: 0.5293\n",
      "Epoch [841/1000], Loss: 0.5246\n",
      "Epoch [842/1000], Loss: 0.5270\n",
      "Epoch [843/1000], Loss: 0.5293\n",
      "Epoch [844/1000], Loss: 0.5308\n",
      "Epoch [845/1000], Loss: 0.5262\n",
      "Epoch [846/1000], Loss: 0.5262\n",
      "Epoch [847/1000], Loss: 0.5277\n",
      "Epoch [848/1000], Loss: 0.5277\n",
      "Epoch [849/1000], Loss: 0.5331\n",
      "Epoch [850/1000], Loss: 0.5316\n",
      "Epoch [851/1000], Loss: 0.5262\n",
      "Epoch [852/1000], Loss: 0.5270\n",
      "Epoch [853/1000], Loss: 0.5277\n",
      "Epoch [854/1000], Loss: 0.5300\n",
      "Epoch [855/1000], Loss: 0.5339\n",
      "Epoch [856/1000], Loss: 0.5308\n",
      "Epoch [857/1000], Loss: 0.5339\n",
      "Epoch [858/1000], Loss: 0.5262\n",
      "Epoch [859/1000], Loss: 0.5262\n",
      "Epoch [860/1000], Loss: 0.5262\n",
      "Epoch [861/1000], Loss: 0.5246\n",
      "Epoch [862/1000], Loss: 0.5223\n",
      "Epoch [863/1000], Loss: 0.5254\n",
      "Epoch [864/1000], Loss: 0.5300\n",
      "Epoch [865/1000], Loss: 0.5293\n",
      "Epoch [866/1000], Loss: 0.5308\n",
      "Epoch [867/1000], Loss: 0.5254\n",
      "Epoch [868/1000], Loss: 0.5246\n",
      "Epoch [869/1000], Loss: 0.5277\n",
      "Epoch [870/1000], Loss: 0.5270\n",
      "Epoch [871/1000], Loss: 0.5300\n",
      "Epoch [872/1000], Loss: 0.5300\n",
      "Epoch [873/1000], Loss: 0.5270\n",
      "Epoch [874/1000], Loss: 0.5208\n",
      "Epoch [875/1000], Loss: 0.5285\n",
      "Epoch [876/1000], Loss: 0.5293\n",
      "Epoch [877/1000], Loss: 0.5231\n",
      "Epoch [878/1000], Loss: 0.5316\n",
      "Epoch [879/1000], Loss: 0.5316\n",
      "Epoch [880/1000], Loss: 0.5293\n",
      "Epoch [881/1000], Loss: 0.5239\n",
      "Epoch [882/1000], Loss: 0.5316\n",
      "Epoch [883/1000], Loss: 0.5270\n",
      "Epoch [884/1000], Loss: 0.5262\n",
      "Epoch [885/1000], Loss: 0.5316\n",
      "Epoch [886/1000], Loss: 0.5308\n",
      "Epoch [887/1000], Loss: 0.5293\n",
      "Epoch [888/1000], Loss: 0.5300\n",
      "Epoch [889/1000], Loss: 0.5362\n",
      "Epoch [890/1000], Loss: 0.5300\n",
      "Epoch [891/1000], Loss: 0.5300\n",
      "Epoch [892/1000], Loss: 0.5362\n",
      "Epoch [893/1000], Loss: 0.5239\n",
      "Epoch [894/1000], Loss: 0.5216\n",
      "Epoch [895/1000], Loss: 0.5300\n",
      "Epoch [896/1000], Loss: 0.5254\n",
      "Epoch [897/1000], Loss: 0.5277\n",
      "Epoch [898/1000], Loss: 0.5285\n",
      "Epoch [899/1000], Loss: 0.5285\n",
      "Epoch [900/1000], Loss: 0.5308\n",
      "Epoch [901/1000], Loss: 0.5293\n",
      "Epoch [902/1000], Loss: 0.5246\n",
      "Epoch [903/1000], Loss: 0.5300\n",
      "Epoch [904/1000], Loss: 0.5339\n",
      "Epoch [905/1000], Loss: 0.5331\n",
      "Epoch [906/1000], Loss: 0.5293\n",
      "Epoch [907/1000], Loss: 0.5354\n",
      "Epoch [908/1000], Loss: 0.5331\n",
      "Epoch [909/1000], Loss: 0.5223\n",
      "Epoch [910/1000], Loss: 0.5300\n",
      "Epoch [911/1000], Loss: 0.5277\n",
      "Epoch [912/1000], Loss: 0.5223\n",
      "Epoch [913/1000], Loss: 0.5331\n",
      "Epoch [914/1000], Loss: 0.5300\n",
      "Epoch [915/1000], Loss: 0.5293\n",
      "Epoch [916/1000], Loss: 0.5285\n",
      "Epoch [917/1000], Loss: 0.5300\n",
      "Epoch [918/1000], Loss: 0.5285\n",
      "Epoch [919/1000], Loss: 0.5324\n",
      "Epoch [920/1000], Loss: 0.5316\n",
      "Epoch [921/1000], Loss: 0.5308\n",
      "Epoch [922/1000], Loss: 0.5300\n",
      "Epoch [923/1000], Loss: 0.5324\n",
      "Epoch [924/1000], Loss: 0.5277\n",
      "Epoch [925/1000], Loss: 0.5239\n",
      "Epoch [926/1000], Loss: 0.5293\n",
      "Epoch [927/1000], Loss: 0.5277\n",
      "Epoch [928/1000], Loss: 0.5316\n",
      "Epoch [929/1000], Loss: 0.5285\n",
      "Epoch [930/1000], Loss: 0.5285\n",
      "Epoch [931/1000], Loss: 0.5270\n",
      "Epoch [932/1000], Loss: 0.5270\n",
      "Epoch [933/1000], Loss: 0.5293\n",
      "Epoch [934/1000], Loss: 0.5231\n",
      "Epoch [935/1000], Loss: 0.5331\n",
      "Epoch [936/1000], Loss: 0.5270\n",
      "Epoch [937/1000], Loss: 0.5277\n",
      "Epoch [938/1000], Loss: 0.5262\n",
      "Epoch [939/1000], Loss: 0.5354\n",
      "Epoch [940/1000], Loss: 0.5216\n",
      "Epoch [941/1000], Loss: 0.5285\n",
      "Epoch [942/1000], Loss: 0.5354\n",
      "Epoch [943/1000], Loss: 0.5324\n",
      "Epoch [944/1000], Loss: 0.5370\n",
      "Epoch [945/1000], Loss: 0.5254\n",
      "Epoch [946/1000], Loss: 0.5300\n",
      "Epoch [947/1000], Loss: 0.5254\n",
      "Epoch [948/1000], Loss: 0.5308\n",
      "Epoch [949/1000], Loss: 0.5285\n",
      "Epoch [950/1000], Loss: 0.5277\n",
      "Epoch [951/1000], Loss: 0.5300\n",
      "Epoch [952/1000], Loss: 0.5300\n",
      "Epoch [953/1000], Loss: 0.5285\n",
      "Epoch [954/1000], Loss: 0.5324\n",
      "Epoch [955/1000], Loss: 0.5300\n",
      "Epoch [956/1000], Loss: 0.5270\n",
      "Epoch [957/1000], Loss: 0.5316\n",
      "Epoch [958/1000], Loss: 0.5277\n",
      "Epoch [959/1000], Loss: 0.5316\n",
      "Epoch [960/1000], Loss: 0.5277\n",
      "Epoch [961/1000], Loss: 0.5308\n",
      "Epoch [962/1000], Loss: 0.5262\n",
      "Epoch [963/1000], Loss: 0.5316\n",
      "Epoch [964/1000], Loss: 0.5262\n",
      "Epoch [965/1000], Loss: 0.5316\n",
      "Epoch [966/1000], Loss: 0.5347\n",
      "Epoch [967/1000], Loss: 0.5270\n",
      "Epoch [968/1000], Loss: 0.5239\n",
      "Epoch [969/1000], Loss: 0.5270\n",
      "Epoch [970/1000], Loss: 0.5254\n",
      "Epoch [971/1000], Loss: 0.5316\n",
      "Epoch [972/1000], Loss: 0.5231\n",
      "Epoch [973/1000], Loss: 0.5300\n",
      "Epoch [974/1000], Loss: 0.5216\n",
      "Epoch [975/1000], Loss: 0.5262\n",
      "Epoch [976/1000], Loss: 0.5277\n",
      "Epoch [977/1000], Loss: 0.5285\n",
      "Epoch [978/1000], Loss: 0.5262\n",
      "Epoch [979/1000], Loss: 0.5277\n",
      "Epoch [980/1000], Loss: 0.5293\n",
      "Epoch [981/1000], Loss: 0.5316\n",
      "Epoch [982/1000], Loss: 0.5331\n",
      "Epoch [983/1000], Loss: 0.5254\n",
      "Epoch [984/1000], Loss: 0.5293\n",
      "Epoch [985/1000], Loss: 0.5339\n",
      "Epoch [986/1000], Loss: 0.5339\n",
      "Epoch [987/1000], Loss: 0.5270\n",
      "Epoch [988/1000], Loss: 0.5285\n",
      "Epoch [989/1000], Loss: 0.5270\n",
      "Epoch [990/1000], Loss: 0.5300\n",
      "Epoch [991/1000], Loss: 0.5239\n",
      "Epoch [992/1000], Loss: 0.5339\n",
      "Epoch [993/1000], Loss: 0.5277\n",
      "Epoch [994/1000], Loss: 0.5254\n",
      "Epoch [995/1000], Loss: 0.5285\n",
      "Epoch [996/1000], Loss: 0.5316\n",
      "Epoch [997/1000], Loss: 0.5254\n",
      "Epoch [998/1000], Loss: 0.5254\n",
      "Epoch [999/1000], Loss: 0.5223\n",
      "Epoch [1000/1000], Loss: 0.5300\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 302, lr :1.0, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.5084\n",
      "Epoch [2/1000], Loss: 0.5308\n",
      "Epoch [3/1000], Loss: 0.5324\n",
      "Epoch [4/1000], Loss: 0.5277\n",
      "Epoch [5/1000], Loss: 0.5285\n",
      "Epoch [6/1000], Loss: 0.5331\n",
      "Epoch [7/1000], Loss: 0.5285\n",
      "Epoch [8/1000], Loss: 0.5277\n",
      "Epoch [9/1000], Loss: 0.5285\n",
      "Epoch [10/1000], Loss: 0.5285\n",
      "Epoch [11/1000], Loss: 0.5331\n",
      "Epoch [12/1000], Loss: 0.5285\n",
      "Epoch [13/1000], Loss: 0.5246\n",
      "Epoch [14/1000], Loss: 0.5216\n",
      "Epoch [15/1000], Loss: 0.5277\n",
      "Epoch [16/1000], Loss: 0.5293\n",
      "Epoch [17/1000], Loss: 0.5300\n",
      "Epoch [18/1000], Loss: 0.5285\n",
      "Epoch [19/1000], Loss: 0.5316\n",
      "Epoch [20/1000], Loss: 0.5308\n",
      "Epoch [21/1000], Loss: 0.5239\n",
      "Epoch [22/1000], Loss: 0.5293\n",
      "Epoch [23/1000], Loss: 0.5270\n",
      "Epoch [24/1000], Loss: 0.5300\n",
      "Epoch [25/1000], Loss: 0.5208\n",
      "Epoch [26/1000], Loss: 0.5300\n",
      "Epoch [27/1000], Loss: 0.5277\n",
      "Epoch [28/1000], Loss: 0.5293\n",
      "Epoch [29/1000], Loss: 0.5270\n",
      "Epoch [30/1000], Loss: 0.5308\n",
      "Epoch [31/1000], Loss: 0.5316\n",
      "Epoch [32/1000], Loss: 0.5324\n",
      "Epoch [33/1000], Loss: 0.5293\n",
      "Epoch [34/1000], Loss: 0.5347\n",
      "Epoch [35/1000], Loss: 0.5285\n",
      "Epoch [36/1000], Loss: 0.5270\n",
      "Epoch [37/1000], Loss: 0.5246\n",
      "Epoch [38/1000], Loss: 0.5300\n",
      "Epoch [39/1000], Loss: 0.5339\n",
      "Epoch [40/1000], Loss: 0.5254\n",
      "Epoch [41/1000], Loss: 0.5270\n",
      "Epoch [42/1000], Loss: 0.5324\n",
      "Epoch [43/1000], Loss: 0.5231\n",
      "Epoch [44/1000], Loss: 0.5300\n",
      "Epoch [45/1000], Loss: 0.5300\n",
      "Epoch [46/1000], Loss: 0.5300\n",
      "Epoch [47/1000], Loss: 0.5262\n",
      "Epoch [48/1000], Loss: 0.5277\n",
      "Epoch [49/1000], Loss: 0.5339\n",
      "Epoch [50/1000], Loss: 0.5293\n",
      "Epoch [51/1000], Loss: 0.5293\n",
      "Epoch [52/1000], Loss: 0.5331\n",
      "Epoch [53/1000], Loss: 0.5347\n",
      "Epoch [54/1000], Loss: 0.5285\n",
      "Epoch [55/1000], Loss: 0.5239\n",
      "Epoch [56/1000], Loss: 0.5293\n",
      "Epoch [57/1000], Loss: 0.5231\n",
      "Epoch [58/1000], Loss: 0.5308\n",
      "Epoch [59/1000], Loss: 0.5354\n",
      "Epoch [60/1000], Loss: 0.5270\n",
      "Epoch [61/1000], Loss: 0.5239\n",
      "Epoch [62/1000], Loss: 0.5300\n",
      "Epoch [63/1000], Loss: 0.5254\n",
      "Epoch [64/1000], Loss: 0.5331\n",
      "Epoch [65/1000], Loss: 0.5254\n",
      "Epoch [66/1000], Loss: 0.5339\n",
      "Epoch [67/1000], Loss: 0.5262\n",
      "Epoch [68/1000], Loss: 0.5270\n",
      "Epoch [69/1000], Loss: 0.5270\n",
      "Epoch [70/1000], Loss: 0.5246\n",
      "Epoch [71/1000], Loss: 0.5324\n",
      "Epoch [72/1000], Loss: 0.5277\n",
      "Epoch [73/1000], Loss: 0.5270\n",
      "Epoch [74/1000], Loss: 0.5262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/1000], Loss: 0.5285\n",
      "Epoch [76/1000], Loss: 0.5300\n",
      "Epoch [77/1000], Loss: 0.5277\n",
      "Epoch [78/1000], Loss: 0.5293\n",
      "Epoch [79/1000], Loss: 0.5246\n",
      "Epoch [80/1000], Loss: 0.5300\n",
      "Epoch [81/1000], Loss: 0.5239\n",
      "Epoch [82/1000], Loss: 0.5277\n",
      "Epoch [83/1000], Loss: 0.5316\n",
      "Epoch [84/1000], Loss: 0.5300\n",
      "Epoch [85/1000], Loss: 0.5324\n",
      "Epoch [86/1000], Loss: 0.5285\n",
      "Epoch [87/1000], Loss: 0.5300\n",
      "Epoch [88/1000], Loss: 0.5277\n",
      "Epoch [89/1000], Loss: 0.5339\n",
      "Epoch [90/1000], Loss: 0.5316\n",
      "Epoch [91/1000], Loss: 0.5300\n",
      "Epoch [92/1000], Loss: 0.5254\n",
      "Epoch [93/1000], Loss: 0.5331\n",
      "Epoch [94/1000], Loss: 0.5300\n",
      "Epoch [95/1000], Loss: 0.5324\n",
      "Epoch [96/1000], Loss: 0.5300\n",
      "Epoch [97/1000], Loss: 0.5339\n",
      "Epoch [98/1000], Loss: 0.5200\n",
      "Epoch [99/1000], Loss: 0.5270\n",
      "Epoch [100/1000], Loss: 0.5285\n",
      "Epoch [101/1000], Loss: 0.5270\n",
      "Epoch [102/1000], Loss: 0.5262\n",
      "Epoch [103/1000], Loss: 0.5270\n",
      "Epoch [104/1000], Loss: 0.5231\n",
      "Epoch [105/1000], Loss: 0.5293\n",
      "Epoch [106/1000], Loss: 0.5324\n",
      "Epoch [107/1000], Loss: 0.5339\n",
      "Epoch [108/1000], Loss: 0.5285\n",
      "Epoch [109/1000], Loss: 0.5293\n",
      "Epoch [110/1000], Loss: 0.5270\n",
      "Epoch [111/1000], Loss: 0.5308\n",
      "Epoch [112/1000], Loss: 0.5285\n",
      "Epoch [113/1000], Loss: 0.5293\n",
      "Epoch [114/1000], Loss: 0.5339\n",
      "Epoch [115/1000], Loss: 0.5246\n",
      "Epoch [116/1000], Loss: 0.5231\n",
      "Epoch [117/1000], Loss: 0.5277\n",
      "Epoch [118/1000], Loss: 0.5300\n",
      "Epoch [119/1000], Loss: 0.5316\n",
      "Epoch [120/1000], Loss: 0.5285\n",
      "Epoch [121/1000], Loss: 0.5324\n",
      "Epoch [122/1000], Loss: 0.5262\n",
      "Epoch [123/1000], Loss: 0.5316\n",
      "Epoch [124/1000], Loss: 0.5246\n",
      "Epoch [125/1000], Loss: 0.5246\n",
      "Epoch [126/1000], Loss: 0.5293\n",
      "Epoch [127/1000], Loss: 0.5239\n",
      "Epoch [128/1000], Loss: 0.5300\n",
      "Epoch [129/1000], Loss: 0.5262\n",
      "Epoch [130/1000], Loss: 0.5308\n",
      "Epoch [131/1000], Loss: 0.5324\n",
      "Epoch [132/1000], Loss: 0.5262\n",
      "Epoch [133/1000], Loss: 0.5262\n",
      "Epoch [134/1000], Loss: 0.5262\n",
      "Epoch [135/1000], Loss: 0.5270\n",
      "Epoch [136/1000], Loss: 0.5270\n",
      "Epoch [137/1000], Loss: 0.5293\n",
      "Epoch [138/1000], Loss: 0.5285\n",
      "Epoch [139/1000], Loss: 0.5308\n",
      "Epoch [140/1000], Loss: 0.5270\n",
      "Epoch [141/1000], Loss: 0.5254\n",
      "Epoch [142/1000], Loss: 0.5308\n",
      "Epoch [143/1000], Loss: 0.5293\n",
      "Epoch [144/1000], Loss: 0.5246\n",
      "Epoch [145/1000], Loss: 0.5246\n",
      "Epoch [146/1000], Loss: 0.5254\n",
      "Epoch [147/1000], Loss: 0.5300\n",
      "Epoch [148/1000], Loss: 0.5347\n",
      "Epoch [149/1000], Loss: 0.5277\n",
      "Epoch [150/1000], Loss: 0.5285\n",
      "Epoch [151/1000], Loss: 0.5293\n",
      "Epoch [152/1000], Loss: 0.5200\n",
      "Epoch [153/1000], Loss: 0.5331\n",
      "Epoch [154/1000], Loss: 0.5277\n",
      "Epoch [155/1000], Loss: 0.5246\n",
      "Epoch [156/1000], Loss: 0.5262\n",
      "Epoch [157/1000], Loss: 0.5308\n",
      "Epoch [158/1000], Loss: 0.5293\n",
      "Epoch [159/1000], Loss: 0.5300\n",
      "Epoch [160/1000], Loss: 0.5239\n",
      "Epoch [161/1000], Loss: 0.5331\n",
      "Epoch [162/1000], Loss: 0.5347\n",
      "Epoch [163/1000], Loss: 0.5231\n",
      "Epoch [164/1000], Loss: 0.5262\n",
      "Epoch [165/1000], Loss: 0.5293\n",
      "Epoch [166/1000], Loss: 0.5300\n",
      "Epoch [167/1000], Loss: 0.5277\n",
      "Epoch [168/1000], Loss: 0.5285\n",
      "Epoch [169/1000], Loss: 0.5270\n",
      "Epoch [170/1000], Loss: 0.5285\n",
      "Epoch [171/1000], Loss: 0.5293\n",
      "Epoch [172/1000], Loss: 0.5270\n",
      "Epoch [173/1000], Loss: 0.5270\n",
      "Epoch [174/1000], Loss: 0.5254\n",
      "Epoch [175/1000], Loss: 0.5300\n",
      "Epoch [176/1000], Loss: 0.5262\n",
      "Epoch [177/1000], Loss: 0.5300\n",
      "Epoch [178/1000], Loss: 0.5300\n",
      "Epoch [179/1000], Loss: 0.5246\n",
      "Epoch [180/1000], Loss: 0.5262\n",
      "Epoch [181/1000], Loss: 0.5300\n",
      "Epoch [182/1000], Loss: 0.5231\n",
      "Epoch [183/1000], Loss: 0.5270\n",
      "Epoch [184/1000], Loss: 0.5300\n",
      "Epoch [185/1000], Loss: 0.5285\n",
      "Epoch [186/1000], Loss: 0.5300\n",
      "Epoch [187/1000], Loss: 0.5262\n",
      "Epoch [188/1000], Loss: 0.5285\n",
      "Epoch [189/1000], Loss: 0.5270\n",
      "Epoch [190/1000], Loss: 0.5300\n",
      "Epoch [191/1000], Loss: 0.5270\n",
      "Epoch [192/1000], Loss: 0.5308\n",
      "Epoch [193/1000], Loss: 0.5270\n",
      "Epoch [194/1000], Loss: 0.5277\n",
      "Epoch [195/1000], Loss: 0.5293\n",
      "Epoch [196/1000], Loss: 0.5254\n",
      "Epoch [197/1000], Loss: 0.5331\n",
      "Epoch [198/1000], Loss: 0.5277\n",
      "Epoch [199/1000], Loss: 0.5308\n",
      "Epoch [200/1000], Loss: 0.5293\n",
      "Epoch [201/1000], Loss: 0.5270\n",
      "Epoch [202/1000], Loss: 0.5254\n",
      "Epoch [203/1000], Loss: 0.5293\n",
      "Epoch [204/1000], Loss: 0.5324\n",
      "Epoch [205/1000], Loss: 0.5293\n",
      "Epoch [206/1000], Loss: 0.5293\n",
      "Epoch [207/1000], Loss: 0.5246\n",
      "Epoch [208/1000], Loss: 0.5254\n",
      "Epoch [209/1000], Loss: 0.5262\n",
      "Epoch [210/1000], Loss: 0.5308\n",
      "Epoch [211/1000], Loss: 0.5270\n",
      "Epoch [212/1000], Loss: 0.5354\n",
      "Epoch [213/1000], Loss: 0.5308\n",
      "Epoch [214/1000], Loss: 0.5308\n",
      "Epoch [215/1000], Loss: 0.5270\n",
      "Epoch [216/1000], Loss: 0.5277\n",
      "Epoch [217/1000], Loss: 0.5362\n",
      "Epoch [218/1000], Loss: 0.5285\n",
      "Epoch [219/1000], Loss: 0.5316\n",
      "Epoch [220/1000], Loss: 0.5308\n",
      "Epoch [221/1000], Loss: 0.5300\n",
      "Epoch [222/1000], Loss: 0.5262\n",
      "Epoch [223/1000], Loss: 0.5270\n",
      "Epoch [224/1000], Loss: 0.5270\n",
      "Epoch [225/1000], Loss: 0.5277\n",
      "Epoch [226/1000], Loss: 0.5293\n",
      "Epoch [227/1000], Loss: 0.5339\n",
      "Epoch [228/1000], Loss: 0.5254\n",
      "Epoch [229/1000], Loss: 0.5324\n",
      "Epoch [230/1000], Loss: 0.5270\n",
      "Epoch [231/1000], Loss: 0.5285\n",
      "Epoch [232/1000], Loss: 0.5316\n",
      "Epoch [233/1000], Loss: 0.5270\n",
      "Epoch [234/1000], Loss: 0.5308\n",
      "Epoch [235/1000], Loss: 0.5285\n",
      "Epoch [236/1000], Loss: 0.5262\n",
      "Epoch [237/1000], Loss: 0.5300\n",
      "Epoch [238/1000], Loss: 0.5254\n",
      "Epoch [239/1000], Loss: 0.5308\n",
      "Epoch [240/1000], Loss: 0.5300\n",
      "Epoch [241/1000], Loss: 0.5324\n",
      "Epoch [242/1000], Loss: 0.5308\n",
      "Epoch [243/1000], Loss: 0.5246\n",
      "Epoch [244/1000], Loss: 0.5262\n",
      "Epoch [245/1000], Loss: 0.5254\n",
      "Epoch [246/1000], Loss: 0.5285\n",
      "Epoch [247/1000], Loss: 0.5223\n",
      "Epoch [248/1000], Loss: 0.5324\n",
      "Epoch [249/1000], Loss: 0.5308\n",
      "Epoch [250/1000], Loss: 0.5339\n",
      "Epoch [251/1000], Loss: 0.5293\n",
      "Epoch [252/1000], Loss: 0.5277\n",
      "Epoch [253/1000], Loss: 0.5254\n",
      "Epoch [254/1000], Loss: 0.5308\n",
      "Epoch [255/1000], Loss: 0.5331\n",
      "Epoch [256/1000], Loss: 0.5277\n",
      "Epoch [257/1000], Loss: 0.5285\n",
      "Epoch [258/1000], Loss: 0.5254\n",
      "Epoch [259/1000], Loss: 0.5254\n",
      "Epoch [260/1000], Loss: 0.5270\n",
      "Epoch [261/1000], Loss: 0.5223\n",
      "Epoch [262/1000], Loss: 0.5285\n",
      "Epoch [263/1000], Loss: 0.5316\n",
      "Epoch [264/1000], Loss: 0.5254\n",
      "Epoch [265/1000], Loss: 0.5239\n",
      "Epoch [266/1000], Loss: 0.5262\n",
      "Epoch [267/1000], Loss: 0.5316\n",
      "Epoch [268/1000], Loss: 0.5254\n",
      "Epoch [269/1000], Loss: 0.5316\n",
      "Epoch [270/1000], Loss: 0.5354\n",
      "Epoch [271/1000], Loss: 0.5254\n",
      "Epoch [272/1000], Loss: 0.5262\n",
      "Epoch [273/1000], Loss: 0.5262\n",
      "Epoch [274/1000], Loss: 0.5223\n",
      "Epoch [275/1000], Loss: 0.5324\n",
      "Epoch [276/1000], Loss: 0.5246\n",
      "Epoch [277/1000], Loss: 0.5316\n",
      "Epoch [278/1000], Loss: 0.5300\n",
      "Epoch [279/1000], Loss: 0.5270\n",
      "Epoch [280/1000], Loss: 0.5239\n",
      "Epoch [281/1000], Loss: 0.5300\n",
      "Epoch [282/1000], Loss: 0.5300\n",
      "Epoch [283/1000], Loss: 0.5270\n",
      "Epoch [284/1000], Loss: 0.5331\n",
      "Epoch [285/1000], Loss: 0.5300\n",
      "Epoch [286/1000], Loss: 0.5339\n",
      "Epoch [287/1000], Loss: 0.5300\n",
      "Epoch [288/1000], Loss: 0.5347\n",
      "Epoch [289/1000], Loss: 0.5270\n",
      "Epoch [290/1000], Loss: 0.5270\n",
      "Epoch [291/1000], Loss: 0.5262\n",
      "Epoch [292/1000], Loss: 0.5324\n",
      "Epoch [293/1000], Loss: 0.5270\n",
      "Epoch [294/1000], Loss: 0.5331\n",
      "Epoch [295/1000], Loss: 0.5285\n",
      "Epoch [296/1000], Loss: 0.5239\n",
      "Epoch [297/1000], Loss: 0.5277\n",
      "Epoch [298/1000], Loss: 0.5270\n",
      "Epoch [299/1000], Loss: 0.5316\n",
      "Epoch [300/1000], Loss: 0.5216\n",
      "Epoch [301/1000], Loss: 0.5277\n",
      "Epoch [302/1000], Loss: 0.5246\n",
      "Epoch [303/1000], Loss: 0.5300\n",
      "Epoch [304/1000], Loss: 0.5277\n",
      "Epoch [305/1000], Loss: 0.5239\n",
      "Epoch [306/1000], Loss: 0.5339\n",
      "Epoch [307/1000], Loss: 0.5285\n",
      "Epoch [308/1000], Loss: 0.5270\n",
      "Epoch [309/1000], Loss: 0.5285\n",
      "Epoch [310/1000], Loss: 0.5254\n",
      "Epoch [311/1000], Loss: 0.5254\n",
      "Epoch [312/1000], Loss: 0.5300\n",
      "Epoch [313/1000], Loss: 0.5331\n",
      "Epoch [314/1000], Loss: 0.5185\n",
      "Epoch [315/1000], Loss: 0.5324\n",
      "Epoch [316/1000], Loss: 0.5339\n",
      "Epoch [317/1000], Loss: 0.5331\n",
      "Epoch [318/1000], Loss: 0.5285\n",
      "Epoch [319/1000], Loss: 0.5254\n",
      "Epoch [320/1000], Loss: 0.5285\n",
      "Epoch [321/1000], Loss: 0.5308\n",
      "Epoch [322/1000], Loss: 0.5308\n",
      "Epoch [323/1000], Loss: 0.5293\n",
      "Epoch [324/1000], Loss: 0.5339\n",
      "Epoch [325/1000], Loss: 0.5270\n",
      "Epoch [326/1000], Loss: 0.5270\n",
      "Epoch [327/1000], Loss: 0.5239\n",
      "Epoch [328/1000], Loss: 0.5270\n",
      "Epoch [329/1000], Loss: 0.5277\n",
      "Epoch [330/1000], Loss: 0.5308\n",
      "Epoch [331/1000], Loss: 0.5285\n",
      "Epoch [332/1000], Loss: 0.5254\n",
      "Epoch [333/1000], Loss: 0.5270\n",
      "Epoch [334/1000], Loss: 0.5254\n",
      "Epoch [335/1000], Loss: 0.5270\n",
      "Epoch [336/1000], Loss: 0.5285\n",
      "Epoch [337/1000], Loss: 0.5300\n",
      "Epoch [338/1000], Loss: 0.5293\n",
      "Epoch [339/1000], Loss: 0.5246\n",
      "Epoch [340/1000], Loss: 0.5331\n",
      "Epoch [341/1000], Loss: 0.5239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [342/1000], Loss: 0.5277\n",
      "Epoch [343/1000], Loss: 0.5270\n",
      "Epoch [344/1000], Loss: 0.5331\n",
      "Epoch [345/1000], Loss: 0.5254\n",
      "Epoch [346/1000], Loss: 0.5246\n",
      "Epoch [347/1000], Loss: 0.5254\n",
      "Epoch [348/1000], Loss: 0.5316\n",
      "Epoch [349/1000], Loss: 0.5246\n",
      "Epoch [350/1000], Loss: 0.5254\n",
      "Epoch [351/1000], Loss: 0.5262\n",
      "Epoch [352/1000], Loss: 0.5339\n",
      "Epoch [353/1000], Loss: 0.5316\n",
      "Epoch [354/1000], Loss: 0.5300\n",
      "Epoch [355/1000], Loss: 0.5277\n",
      "Epoch [356/1000], Loss: 0.5293\n",
      "Epoch [357/1000], Loss: 0.5277\n",
      "Epoch [358/1000], Loss: 0.5324\n",
      "Epoch [359/1000], Loss: 0.5270\n",
      "Epoch [360/1000], Loss: 0.5216\n",
      "Epoch [361/1000], Loss: 0.5285\n",
      "Epoch [362/1000], Loss: 0.5277\n",
      "Epoch [363/1000], Loss: 0.5239\n",
      "Epoch [364/1000], Loss: 0.5285\n",
      "Epoch [365/1000], Loss: 0.5370\n",
      "Epoch [366/1000], Loss: 0.5324\n",
      "Epoch [367/1000], Loss: 0.5293\n",
      "Epoch [368/1000], Loss: 0.5231\n",
      "Epoch [369/1000], Loss: 0.5331\n",
      "Epoch [370/1000], Loss: 0.5285\n",
      "Epoch [371/1000], Loss: 0.5231\n",
      "Epoch [372/1000], Loss: 0.5254\n",
      "Epoch [373/1000], Loss: 0.5300\n",
      "Epoch [374/1000], Loss: 0.5339\n",
      "Epoch [375/1000], Loss: 0.5316\n",
      "Epoch [376/1000], Loss: 0.5300\n",
      "Epoch [377/1000], Loss: 0.5293\n",
      "Epoch [378/1000], Loss: 0.5293\n",
      "Epoch [379/1000], Loss: 0.5277\n",
      "Epoch [380/1000], Loss: 0.5262\n",
      "Epoch [381/1000], Loss: 0.5339\n",
      "Epoch [382/1000], Loss: 0.5308\n",
      "Epoch [383/1000], Loss: 0.5277\n",
      "Epoch [384/1000], Loss: 0.5277\n",
      "Epoch [385/1000], Loss: 0.5246\n",
      "Epoch [386/1000], Loss: 0.5316\n",
      "Epoch [387/1000], Loss: 0.5270\n",
      "Epoch [388/1000], Loss: 0.5262\n",
      "Epoch [389/1000], Loss: 0.5300\n",
      "Epoch [390/1000], Loss: 0.5277\n",
      "Epoch [391/1000], Loss: 0.5246\n",
      "Epoch [392/1000], Loss: 0.5262\n",
      "Epoch [393/1000], Loss: 0.5331\n",
      "Epoch [394/1000], Loss: 0.5277\n",
      "Epoch [395/1000], Loss: 0.5300\n",
      "Epoch [396/1000], Loss: 0.5277\n",
      "Epoch [397/1000], Loss: 0.5285\n",
      "Epoch [398/1000], Loss: 0.5262\n",
      "Epoch [399/1000], Loss: 0.5316\n",
      "Epoch [400/1000], Loss: 0.5324\n",
      "Epoch [401/1000], Loss: 0.5293\n",
      "Epoch [402/1000], Loss: 0.5277\n",
      "Epoch [403/1000], Loss: 0.5246\n",
      "Epoch [404/1000], Loss: 0.5285\n",
      "Epoch [405/1000], Loss: 0.5270\n",
      "Epoch [406/1000], Loss: 0.5262\n",
      "Epoch [407/1000], Loss: 0.5277\n",
      "Epoch [408/1000], Loss: 0.5362\n",
      "Epoch [409/1000], Loss: 0.5285\n",
      "Epoch [410/1000], Loss: 0.5300\n",
      "Epoch [411/1000], Loss: 0.5285\n",
      "Epoch [412/1000], Loss: 0.5277\n",
      "Epoch [413/1000], Loss: 0.5354\n",
      "Epoch [414/1000], Loss: 0.5246\n",
      "Epoch [415/1000], Loss: 0.5216\n",
      "Epoch [416/1000], Loss: 0.5270\n",
      "Epoch [417/1000], Loss: 0.5324\n",
      "Epoch [418/1000], Loss: 0.5293\n",
      "Epoch [419/1000], Loss: 0.5270\n",
      "Epoch [420/1000], Loss: 0.5285\n",
      "Epoch [421/1000], Loss: 0.5223\n",
      "Epoch [422/1000], Loss: 0.5300\n",
      "Epoch [423/1000], Loss: 0.5331\n",
      "Epoch [424/1000], Loss: 0.5270\n",
      "Epoch [425/1000], Loss: 0.5223\n",
      "Epoch [426/1000], Loss: 0.5254\n",
      "Epoch [427/1000], Loss: 0.5285\n",
      "Epoch [428/1000], Loss: 0.5270\n",
      "Epoch [429/1000], Loss: 0.5316\n",
      "Epoch [430/1000], Loss: 0.5316\n",
      "Epoch [431/1000], Loss: 0.5254\n",
      "Epoch [432/1000], Loss: 0.5285\n",
      "Epoch [433/1000], Loss: 0.5300\n",
      "Epoch [434/1000], Loss: 0.5324\n",
      "Epoch [435/1000], Loss: 0.5316\n",
      "Epoch [436/1000], Loss: 0.5246\n",
      "Epoch [437/1000], Loss: 0.5285\n",
      "Epoch [438/1000], Loss: 0.5324\n",
      "Epoch [439/1000], Loss: 0.5293\n",
      "Epoch [440/1000], Loss: 0.5254\n",
      "Epoch [441/1000], Loss: 0.5277\n",
      "Epoch [442/1000], Loss: 0.5270\n",
      "Epoch [443/1000], Loss: 0.5270\n",
      "Epoch [444/1000], Loss: 0.5246\n",
      "Epoch [445/1000], Loss: 0.5293\n",
      "Epoch [446/1000], Loss: 0.5246\n",
      "Epoch [447/1000], Loss: 0.5262\n",
      "Epoch [448/1000], Loss: 0.5270\n",
      "Epoch [449/1000], Loss: 0.5277\n",
      "Epoch [450/1000], Loss: 0.5293\n",
      "Epoch [451/1000], Loss: 0.5300\n",
      "Epoch [452/1000], Loss: 0.5308\n",
      "Epoch [453/1000], Loss: 0.5262\n",
      "Epoch [454/1000], Loss: 0.5316\n",
      "Epoch [455/1000], Loss: 0.5331\n",
      "Epoch [456/1000], Loss: 0.5316\n",
      "Epoch [457/1000], Loss: 0.5293\n",
      "Epoch [458/1000], Loss: 0.5316\n",
      "Epoch [459/1000], Loss: 0.5270\n",
      "Epoch [460/1000], Loss: 0.5239\n",
      "Epoch [461/1000], Loss: 0.5324\n",
      "Epoch [462/1000], Loss: 0.5277\n",
      "Epoch [463/1000], Loss: 0.5293\n",
      "Epoch [464/1000], Loss: 0.5308\n",
      "Epoch [465/1000], Loss: 0.5169\n",
      "Epoch [466/1000], Loss: 0.5239\n",
      "Epoch [467/1000], Loss: 0.5246\n",
      "Epoch [468/1000], Loss: 0.5324\n",
      "Epoch [469/1000], Loss: 0.5277\n",
      "Epoch [470/1000], Loss: 0.5316\n",
      "Epoch [471/1000], Loss: 0.5254\n",
      "Epoch [472/1000], Loss: 0.5277\n",
      "Epoch [473/1000], Loss: 0.5293\n",
      "Epoch [474/1000], Loss: 0.5285\n",
      "Epoch [475/1000], Loss: 0.5246\n",
      "Epoch [476/1000], Loss: 0.5347\n",
      "Epoch [477/1000], Loss: 0.5270\n",
      "Epoch [478/1000], Loss: 0.5277\n",
      "Epoch [479/1000], Loss: 0.5339\n",
      "Epoch [480/1000], Loss: 0.5300\n",
      "Epoch [481/1000], Loss: 0.5293\n",
      "Epoch [482/1000], Loss: 0.5293\n",
      "Epoch [483/1000], Loss: 0.5231\n",
      "Epoch [484/1000], Loss: 0.5308\n",
      "Epoch [485/1000], Loss: 0.5308\n",
      "Epoch [486/1000], Loss: 0.5200\n",
      "Epoch [487/1000], Loss: 0.5308\n",
      "Epoch [488/1000], Loss: 0.5254\n",
      "Epoch [489/1000], Loss: 0.5277\n",
      "Epoch [490/1000], Loss: 0.5254\n",
      "Epoch [491/1000], Loss: 0.5293\n",
      "Epoch [492/1000], Loss: 0.5270\n",
      "Epoch [493/1000], Loss: 0.5293\n",
      "Epoch [494/1000], Loss: 0.5285\n",
      "Epoch [495/1000], Loss: 0.5300\n",
      "Epoch [496/1000], Loss: 0.5285\n",
      "Epoch [497/1000], Loss: 0.5262\n",
      "Epoch [498/1000], Loss: 0.5293\n",
      "Epoch [499/1000], Loss: 0.5285\n",
      "Epoch [500/1000], Loss: 0.5293\n",
      "Epoch [501/1000], Loss: 0.5331\n",
      "Epoch [502/1000], Loss: 0.5285\n",
      "Epoch [503/1000], Loss: 0.5300\n",
      "Epoch [504/1000], Loss: 0.5293\n",
      "Epoch [505/1000], Loss: 0.5262\n",
      "Epoch [506/1000], Loss: 0.5300\n",
      "Epoch [507/1000], Loss: 0.5254\n",
      "Epoch [508/1000], Loss: 0.5231\n",
      "Epoch [509/1000], Loss: 0.5293\n",
      "Epoch [510/1000], Loss: 0.5300\n",
      "Epoch [511/1000], Loss: 0.5339\n",
      "Epoch [512/1000], Loss: 0.5293\n",
      "Epoch [513/1000], Loss: 0.5293\n",
      "Epoch [514/1000], Loss: 0.5285\n",
      "Epoch [515/1000], Loss: 0.5208\n",
      "Epoch [516/1000], Loss: 0.5300\n",
      "Epoch [517/1000], Loss: 0.5262\n",
      "Epoch [518/1000], Loss: 0.5308\n",
      "Epoch [519/1000], Loss: 0.5316\n",
      "Epoch [520/1000], Loss: 0.5270\n",
      "Epoch [521/1000], Loss: 0.5293\n",
      "Epoch [522/1000], Loss: 0.5324\n",
      "Epoch [523/1000], Loss: 0.5262\n",
      "Epoch [524/1000], Loss: 0.5324\n",
      "Epoch [525/1000], Loss: 0.5254\n",
      "Epoch [526/1000], Loss: 0.5277\n",
      "Epoch [527/1000], Loss: 0.5354\n",
      "Epoch [528/1000], Loss: 0.5316\n",
      "Epoch [529/1000], Loss: 0.5293\n",
      "Epoch [530/1000], Loss: 0.5300\n",
      "Epoch [531/1000], Loss: 0.5293\n",
      "Epoch [532/1000], Loss: 0.5293\n",
      "Epoch [533/1000], Loss: 0.5316\n",
      "Epoch [534/1000], Loss: 0.5277\n",
      "Epoch [535/1000], Loss: 0.5285\n",
      "Epoch [536/1000], Loss: 0.5308\n",
      "Epoch [537/1000], Loss: 0.5262\n",
      "Epoch [538/1000], Loss: 0.5216\n",
      "Epoch [539/1000], Loss: 0.5262\n",
      "Epoch [540/1000], Loss: 0.5208\n",
      "Epoch [541/1000], Loss: 0.5277\n",
      "Epoch [542/1000], Loss: 0.5285\n",
      "Epoch [543/1000], Loss: 0.5285\n",
      "Epoch [544/1000], Loss: 0.5277\n",
      "Epoch [545/1000], Loss: 0.5324\n",
      "Epoch [546/1000], Loss: 0.5262\n",
      "Epoch [547/1000], Loss: 0.5285\n",
      "Epoch [548/1000], Loss: 0.5339\n",
      "Epoch [549/1000], Loss: 0.5316\n",
      "Epoch [550/1000], Loss: 0.5270\n",
      "Epoch [551/1000], Loss: 0.5293\n",
      "Epoch [552/1000], Loss: 0.5308\n",
      "Epoch [553/1000], Loss: 0.5331\n",
      "Epoch [554/1000], Loss: 0.5277\n",
      "Epoch [555/1000], Loss: 0.5293\n",
      "Epoch [556/1000], Loss: 0.5246\n",
      "Epoch [557/1000], Loss: 0.5324\n",
      "Epoch [558/1000], Loss: 0.5285\n",
      "Epoch [559/1000], Loss: 0.5254\n",
      "Epoch [560/1000], Loss: 0.5300\n",
      "Epoch [561/1000], Loss: 0.5262\n",
      "Epoch [562/1000], Loss: 0.5285\n",
      "Epoch [563/1000], Loss: 0.5285\n",
      "Epoch [564/1000], Loss: 0.5262\n",
      "Epoch [565/1000], Loss: 0.5262\n",
      "Epoch [566/1000], Loss: 0.5300\n",
      "Epoch [567/1000], Loss: 0.5293\n",
      "Epoch [568/1000], Loss: 0.5285\n",
      "Epoch [569/1000], Loss: 0.5208\n",
      "Epoch [570/1000], Loss: 0.5316\n",
      "Epoch [571/1000], Loss: 0.5285\n",
      "Epoch [572/1000], Loss: 0.5331\n",
      "Epoch [573/1000], Loss: 0.5270\n",
      "Epoch [574/1000], Loss: 0.5316\n",
      "Epoch [575/1000], Loss: 0.5347\n",
      "Epoch [576/1000], Loss: 0.5316\n",
      "Epoch [577/1000], Loss: 0.5308\n",
      "Epoch [578/1000], Loss: 0.5331\n",
      "Epoch [579/1000], Loss: 0.5308\n",
      "Epoch [580/1000], Loss: 0.5223\n",
      "Epoch [581/1000], Loss: 0.5308\n",
      "Epoch [582/1000], Loss: 0.5277\n",
      "Epoch [583/1000], Loss: 0.5316\n",
      "Epoch [584/1000], Loss: 0.5277\n",
      "Epoch [585/1000], Loss: 0.5308\n",
      "Epoch [586/1000], Loss: 0.5270\n",
      "Epoch [587/1000], Loss: 0.5262\n",
      "Epoch [588/1000], Loss: 0.5293\n",
      "Epoch [589/1000], Loss: 0.5300\n",
      "Epoch [590/1000], Loss: 0.5324\n",
      "Epoch [591/1000], Loss: 0.5270\n",
      "Epoch [592/1000], Loss: 0.5239\n",
      "Epoch [593/1000], Loss: 0.5270\n",
      "Epoch [594/1000], Loss: 0.5300\n",
      "Epoch [595/1000], Loss: 0.5270\n",
      "Epoch [596/1000], Loss: 0.5246\n",
      "Epoch [597/1000], Loss: 0.5277\n",
      "Epoch [598/1000], Loss: 0.5277\n",
      "Epoch [599/1000], Loss: 0.5316\n",
      "Epoch [600/1000], Loss: 0.5270\n",
      "Epoch [601/1000], Loss: 0.5347\n",
      "Epoch [602/1000], Loss: 0.5331\n",
      "Epoch [603/1000], Loss: 0.5370\n",
      "Epoch [604/1000], Loss: 0.5285\n",
      "Epoch [605/1000], Loss: 0.5285\n",
      "Epoch [606/1000], Loss: 0.5331\n",
      "Epoch [607/1000], Loss: 0.5239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [608/1000], Loss: 0.5300\n",
      "Epoch [609/1000], Loss: 0.5370\n",
      "Epoch [610/1000], Loss: 0.5293\n",
      "Epoch [611/1000], Loss: 0.5270\n",
      "Epoch [612/1000], Loss: 0.5270\n",
      "Epoch [613/1000], Loss: 0.5277\n",
      "Epoch [614/1000], Loss: 0.5254\n",
      "Epoch [615/1000], Loss: 0.5277\n",
      "Epoch [616/1000], Loss: 0.5370\n",
      "Epoch [617/1000], Loss: 0.5270\n",
      "Epoch [618/1000], Loss: 0.5223\n",
      "Epoch [619/1000], Loss: 0.5270\n",
      "Epoch [620/1000], Loss: 0.5293\n",
      "Epoch [621/1000], Loss: 0.5316\n",
      "Epoch [622/1000], Loss: 0.5316\n",
      "Epoch [623/1000], Loss: 0.5331\n",
      "Epoch [624/1000], Loss: 0.5339\n",
      "Epoch [625/1000], Loss: 0.5262\n",
      "Epoch [626/1000], Loss: 0.5254\n",
      "Epoch [627/1000], Loss: 0.5262\n",
      "Epoch [628/1000], Loss: 0.5231\n",
      "Epoch [629/1000], Loss: 0.5223\n",
      "Epoch [630/1000], Loss: 0.5239\n",
      "Epoch [631/1000], Loss: 0.5262\n",
      "Epoch [632/1000], Loss: 0.5262\n",
      "Epoch [633/1000], Loss: 0.5285\n",
      "Epoch [634/1000], Loss: 0.5347\n",
      "Epoch [635/1000], Loss: 0.5239\n",
      "Epoch [636/1000], Loss: 0.5239\n",
      "Epoch [637/1000], Loss: 0.5324\n",
      "Epoch [638/1000], Loss: 0.5262\n",
      "Epoch [639/1000], Loss: 0.5308\n",
      "Epoch [640/1000], Loss: 0.5339\n",
      "Epoch [641/1000], Loss: 0.5231\n",
      "Epoch [642/1000], Loss: 0.5285\n",
      "Epoch [643/1000], Loss: 0.5246\n",
      "Epoch [644/1000], Loss: 0.5270\n",
      "Epoch [645/1000], Loss: 0.5300\n",
      "Epoch [646/1000], Loss: 0.5293\n",
      "Epoch [647/1000], Loss: 0.5293\n",
      "Epoch [648/1000], Loss: 0.5277\n",
      "Epoch [649/1000], Loss: 0.5262\n",
      "Epoch [650/1000], Loss: 0.5293\n",
      "Epoch [651/1000], Loss: 0.5270\n",
      "Epoch [652/1000], Loss: 0.5316\n",
      "Epoch [653/1000], Loss: 0.5254\n",
      "Epoch [654/1000], Loss: 0.5262\n",
      "Epoch [655/1000], Loss: 0.5285\n",
      "Epoch [656/1000], Loss: 0.5262\n",
      "Epoch [657/1000], Loss: 0.5262\n",
      "Epoch [658/1000], Loss: 0.5324\n",
      "Epoch [659/1000], Loss: 0.5285\n",
      "Epoch [660/1000], Loss: 0.5293\n",
      "Epoch [661/1000], Loss: 0.5239\n",
      "Epoch [662/1000], Loss: 0.5239\n",
      "Epoch [663/1000], Loss: 0.5270\n",
      "Epoch [664/1000], Loss: 0.5331\n",
      "Epoch [665/1000], Loss: 0.5231\n",
      "Epoch [666/1000], Loss: 0.5270\n",
      "Epoch [667/1000], Loss: 0.5293\n",
      "Epoch [668/1000], Loss: 0.5300\n",
      "Epoch [669/1000], Loss: 0.5200\n",
      "Epoch [670/1000], Loss: 0.5316\n",
      "Epoch [671/1000], Loss: 0.5262\n",
      "Epoch [672/1000], Loss: 0.5316\n",
      "Epoch [673/1000], Loss: 0.5293\n",
      "Epoch [674/1000], Loss: 0.5246\n",
      "Epoch [675/1000], Loss: 0.5285\n",
      "Epoch [676/1000], Loss: 0.5277\n",
      "Epoch [677/1000], Loss: 0.5354\n",
      "Epoch [678/1000], Loss: 0.5300\n",
      "Epoch [679/1000], Loss: 0.5316\n",
      "Epoch [680/1000], Loss: 0.5254\n",
      "Epoch [681/1000], Loss: 0.5324\n",
      "Epoch [682/1000], Loss: 0.5254\n",
      "Epoch [683/1000], Loss: 0.5254\n",
      "Epoch [684/1000], Loss: 0.5246\n",
      "Epoch [685/1000], Loss: 0.5246\n",
      "Epoch [686/1000], Loss: 0.5246\n",
      "Epoch [687/1000], Loss: 0.5324\n",
      "Epoch [688/1000], Loss: 0.5324\n",
      "Epoch [689/1000], Loss: 0.5254\n",
      "Epoch [690/1000], Loss: 0.5285\n",
      "Epoch [691/1000], Loss: 0.5277\n",
      "Epoch [692/1000], Loss: 0.5354\n",
      "Epoch [693/1000], Loss: 0.5246\n",
      "Epoch [694/1000], Loss: 0.5293\n",
      "Epoch [695/1000], Loss: 0.5254\n",
      "Epoch [696/1000], Loss: 0.5262\n",
      "Epoch [697/1000], Loss: 0.5262\n",
      "Epoch [698/1000], Loss: 0.5262\n",
      "Epoch [699/1000], Loss: 0.5262\n",
      "Epoch [700/1000], Loss: 0.5331\n",
      "Epoch [701/1000], Loss: 0.5300\n",
      "Epoch [702/1000], Loss: 0.5262\n",
      "Epoch [703/1000], Loss: 0.5324\n",
      "Epoch [704/1000], Loss: 0.5293\n",
      "Epoch [705/1000], Loss: 0.5223\n",
      "Epoch [706/1000], Loss: 0.5262\n",
      "Epoch [707/1000], Loss: 0.5262\n",
      "Epoch [708/1000], Loss: 0.5293\n",
      "Epoch [709/1000], Loss: 0.5270\n",
      "Epoch [710/1000], Loss: 0.5285\n",
      "Epoch [711/1000], Loss: 0.5331\n",
      "Epoch [712/1000], Loss: 0.5270\n",
      "Epoch [713/1000], Loss: 0.5285\n",
      "Epoch [714/1000], Loss: 0.5293\n",
      "Epoch [715/1000], Loss: 0.5308\n",
      "Epoch [716/1000], Loss: 0.5277\n",
      "Epoch [717/1000], Loss: 0.5254\n",
      "Epoch [718/1000], Loss: 0.5339\n",
      "Epoch [719/1000], Loss: 0.5270\n",
      "Epoch [720/1000], Loss: 0.5270\n",
      "Epoch [721/1000], Loss: 0.5262\n",
      "Epoch [722/1000], Loss: 0.5285\n",
      "Epoch [723/1000], Loss: 0.5316\n",
      "Epoch [724/1000], Loss: 0.5293\n",
      "Epoch [725/1000], Loss: 0.5316\n",
      "Epoch [726/1000], Loss: 0.5347\n",
      "Epoch [727/1000], Loss: 0.5285\n",
      "Epoch [728/1000], Loss: 0.5277\n",
      "Epoch [729/1000], Loss: 0.5331\n",
      "Epoch [730/1000], Loss: 0.5270\n",
      "Epoch [731/1000], Loss: 0.5231\n",
      "Epoch [732/1000], Loss: 0.5223\n",
      "Epoch [733/1000], Loss: 0.5254\n",
      "Epoch [734/1000], Loss: 0.5254\n",
      "Epoch [735/1000], Loss: 0.5308\n",
      "Epoch [736/1000], Loss: 0.5270\n",
      "Epoch [737/1000], Loss: 0.5308\n",
      "Epoch [738/1000], Loss: 0.5331\n",
      "Epoch [739/1000], Loss: 0.5293\n",
      "Epoch [740/1000], Loss: 0.5324\n",
      "Epoch [741/1000], Loss: 0.5246\n",
      "Epoch [742/1000], Loss: 0.5277\n",
      "Epoch [743/1000], Loss: 0.5339\n",
      "Epoch [744/1000], Loss: 0.5277\n",
      "Epoch [745/1000], Loss: 0.5293\n",
      "Epoch [746/1000], Loss: 0.5231\n",
      "Epoch [747/1000], Loss: 0.5262\n",
      "Epoch [748/1000], Loss: 0.5270\n",
      "Epoch [749/1000], Loss: 0.5231\n",
      "Epoch [750/1000], Loss: 0.5293\n",
      "Epoch [751/1000], Loss: 0.5270\n",
      "Epoch [752/1000], Loss: 0.5293\n",
      "Epoch [753/1000], Loss: 0.5316\n",
      "Epoch [754/1000], Loss: 0.5293\n",
      "Epoch [755/1000], Loss: 0.5354\n",
      "Epoch [756/1000], Loss: 0.5246\n",
      "Epoch [757/1000], Loss: 0.5254\n",
      "Epoch [758/1000], Loss: 0.5300\n",
      "Epoch [759/1000], Loss: 0.5293\n",
      "Epoch [760/1000], Loss: 0.5262\n",
      "Epoch [761/1000], Loss: 0.5270\n",
      "Epoch [762/1000], Loss: 0.5308\n",
      "Epoch [763/1000], Loss: 0.5300\n",
      "Epoch [764/1000], Loss: 0.5285\n",
      "Epoch [765/1000], Loss: 0.5262\n",
      "Epoch [766/1000], Loss: 0.5277\n",
      "Epoch [767/1000], Loss: 0.5285\n",
      "Epoch [768/1000], Loss: 0.5246\n",
      "Epoch [769/1000], Loss: 0.5246\n",
      "Epoch [770/1000], Loss: 0.5316\n",
      "Epoch [771/1000], Loss: 0.5254\n",
      "Epoch [772/1000], Loss: 0.5308\n",
      "Epoch [773/1000], Loss: 0.5293\n",
      "Epoch [774/1000], Loss: 0.5262\n",
      "Epoch [775/1000], Loss: 0.5262\n",
      "Epoch [776/1000], Loss: 0.5246\n",
      "Epoch [777/1000], Loss: 0.5285\n",
      "Epoch [778/1000], Loss: 0.5208\n",
      "Epoch [779/1000], Loss: 0.5339\n",
      "Epoch [780/1000], Loss: 0.5300\n",
      "Epoch [781/1000], Loss: 0.5331\n",
      "Epoch [782/1000], Loss: 0.5277\n",
      "Epoch [783/1000], Loss: 0.5270\n",
      "Epoch [784/1000], Loss: 0.5293\n",
      "Epoch [785/1000], Loss: 0.5339\n",
      "Epoch [786/1000], Loss: 0.5308\n",
      "Epoch [787/1000], Loss: 0.5324\n",
      "Epoch [788/1000], Loss: 0.5324\n",
      "Epoch [789/1000], Loss: 0.5246\n",
      "Epoch [790/1000], Loss: 0.5223\n",
      "Epoch [791/1000], Loss: 0.5293\n",
      "Epoch [792/1000], Loss: 0.5324\n",
      "Epoch [793/1000], Loss: 0.5324\n",
      "Epoch [794/1000], Loss: 0.5308\n",
      "Epoch [795/1000], Loss: 0.5285\n",
      "Epoch [796/1000], Loss: 0.5331\n",
      "Epoch [797/1000], Loss: 0.5324\n",
      "Epoch [798/1000], Loss: 0.5270\n",
      "Epoch [799/1000], Loss: 0.5300\n",
      "Epoch [800/1000], Loss: 0.5324\n",
      "Epoch [801/1000], Loss: 0.5277\n",
      "Epoch [802/1000], Loss: 0.5308\n",
      "Epoch [803/1000], Loss: 0.5293\n",
      "Epoch [804/1000], Loss: 0.5277\n",
      "Epoch [805/1000], Loss: 0.5239\n",
      "Epoch [806/1000], Loss: 0.5262\n",
      "Epoch [807/1000], Loss: 0.5347\n",
      "Epoch [808/1000], Loss: 0.5308\n",
      "Epoch [809/1000], Loss: 0.5293\n",
      "Epoch [810/1000], Loss: 0.5262\n",
      "Epoch [811/1000], Loss: 0.5231\n",
      "Epoch [812/1000], Loss: 0.5223\n",
      "Epoch [813/1000], Loss: 0.5270\n",
      "Epoch [814/1000], Loss: 0.5300\n",
      "Epoch [815/1000], Loss: 0.5239\n",
      "Epoch [816/1000], Loss: 0.5285\n",
      "Epoch [817/1000], Loss: 0.5277\n",
      "Epoch [818/1000], Loss: 0.5270\n",
      "Epoch [819/1000], Loss: 0.5339\n",
      "Epoch [820/1000], Loss: 0.5316\n",
      "Epoch [821/1000], Loss: 0.5262\n",
      "Epoch [822/1000], Loss: 0.5316\n",
      "Epoch [823/1000], Loss: 0.5277\n",
      "Epoch [824/1000], Loss: 0.5331\n",
      "Epoch [825/1000], Loss: 0.5254\n",
      "Epoch [826/1000], Loss: 0.5231\n",
      "Epoch [827/1000], Loss: 0.5285\n",
      "Epoch [828/1000], Loss: 0.5285\n",
      "Epoch [829/1000], Loss: 0.5270\n",
      "Epoch [830/1000], Loss: 0.5231\n",
      "Epoch [831/1000], Loss: 0.5231\n",
      "Epoch [832/1000], Loss: 0.5316\n",
      "Epoch [833/1000], Loss: 0.5208\n",
      "Epoch [834/1000], Loss: 0.5324\n",
      "Epoch [835/1000], Loss: 0.5316\n",
      "Epoch [836/1000], Loss: 0.5246\n",
      "Epoch [837/1000], Loss: 0.5300\n",
      "Epoch [838/1000], Loss: 0.5262\n",
      "Epoch [839/1000], Loss: 0.5300\n",
      "Epoch [840/1000], Loss: 0.5308\n",
      "Epoch [841/1000], Loss: 0.5270\n",
      "Epoch [842/1000], Loss: 0.5277\n",
      "Epoch [843/1000], Loss: 0.5308\n",
      "Epoch [844/1000], Loss: 0.5316\n",
      "Epoch [845/1000], Loss: 0.5324\n",
      "Epoch [846/1000], Loss: 0.5231\n",
      "Epoch [847/1000], Loss: 0.5316\n",
      "Epoch [848/1000], Loss: 0.5246\n",
      "Epoch [849/1000], Loss: 0.5300\n",
      "Epoch [850/1000], Loss: 0.5285\n",
      "Epoch [851/1000], Loss: 0.5262\n",
      "Epoch [852/1000], Loss: 0.5262\n",
      "Epoch [853/1000], Loss: 0.5270\n",
      "Epoch [854/1000], Loss: 0.5316\n",
      "Epoch [855/1000], Loss: 0.5285\n",
      "Epoch [856/1000], Loss: 0.5285\n",
      "Epoch [857/1000], Loss: 0.5231\n",
      "Epoch [858/1000], Loss: 0.5285\n",
      "Epoch [859/1000], Loss: 0.5300\n",
      "Epoch [860/1000], Loss: 0.5316\n",
      "Epoch [861/1000], Loss: 0.5277\n",
      "Epoch [862/1000], Loss: 0.5208\n",
      "Epoch [863/1000], Loss: 0.5216\n",
      "Epoch [864/1000], Loss: 0.5246\n",
      "Epoch [865/1000], Loss: 0.5308\n",
      "Epoch [866/1000], Loss: 0.5254\n",
      "Epoch [867/1000], Loss: 0.5262\n",
      "Epoch [868/1000], Loss: 0.5300\n",
      "Epoch [869/1000], Loss: 0.5239\n",
      "Epoch [870/1000], Loss: 0.5308\n",
      "Epoch [871/1000], Loss: 0.5324\n",
      "Epoch [872/1000], Loss: 0.5277\n",
      "Epoch [873/1000], Loss: 0.5216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [874/1000], Loss: 0.5216\n",
      "Epoch [875/1000], Loss: 0.5316\n",
      "Epoch [876/1000], Loss: 0.5331\n",
      "Epoch [877/1000], Loss: 0.5254\n",
      "Epoch [878/1000], Loss: 0.5254\n",
      "Epoch [879/1000], Loss: 0.5339\n",
      "Epoch [880/1000], Loss: 0.5300\n",
      "Epoch [881/1000], Loss: 0.5285\n",
      "Epoch [882/1000], Loss: 0.5293\n",
      "Epoch [883/1000], Loss: 0.5316\n",
      "Epoch [884/1000], Loss: 0.5285\n",
      "Epoch [885/1000], Loss: 0.5347\n",
      "Epoch [886/1000], Loss: 0.5231\n",
      "Epoch [887/1000], Loss: 0.5324\n",
      "Epoch [888/1000], Loss: 0.5316\n",
      "Epoch [889/1000], Loss: 0.5347\n",
      "Epoch [890/1000], Loss: 0.5316\n",
      "Epoch [891/1000], Loss: 0.5300\n",
      "Epoch [892/1000], Loss: 0.5300\n",
      "Epoch [893/1000], Loss: 0.5285\n",
      "Epoch [894/1000], Loss: 0.5254\n",
      "Epoch [895/1000], Loss: 0.5308\n",
      "Epoch [896/1000], Loss: 0.5285\n",
      "Epoch [897/1000], Loss: 0.5324\n",
      "Epoch [898/1000], Loss: 0.5277\n",
      "Epoch [899/1000], Loss: 0.5316\n",
      "Epoch [900/1000], Loss: 0.5270\n",
      "Epoch [901/1000], Loss: 0.5285\n",
      "Epoch [902/1000], Loss: 0.5293\n",
      "Epoch [903/1000], Loss: 0.5277\n",
      "Epoch [904/1000], Loss: 0.5293\n",
      "Epoch [905/1000], Loss: 0.5254\n",
      "Epoch [906/1000], Loss: 0.5308\n",
      "Epoch [907/1000], Loss: 0.5347\n",
      "Epoch [908/1000], Loss: 0.5277\n",
      "Epoch [909/1000], Loss: 0.5308\n",
      "Epoch [910/1000], Loss: 0.5324\n",
      "Epoch [911/1000], Loss: 0.5254\n",
      "Epoch [912/1000], Loss: 0.5262\n",
      "Epoch [913/1000], Loss: 0.5262\n",
      "Epoch [914/1000], Loss: 0.5239\n",
      "Epoch [915/1000], Loss: 0.5324\n",
      "Epoch [916/1000], Loss: 0.5308\n",
      "Epoch [917/1000], Loss: 0.5331\n",
      "Epoch [918/1000], Loss: 0.5316\n",
      "Epoch [919/1000], Loss: 0.5316\n",
      "Epoch [920/1000], Loss: 0.5239\n",
      "Epoch [921/1000], Loss: 0.5300\n",
      "Epoch [922/1000], Loss: 0.5277\n",
      "Epoch [923/1000], Loss: 0.5316\n",
      "Epoch [924/1000], Loss: 0.5277\n",
      "Epoch [925/1000], Loss: 0.5308\n",
      "Epoch [926/1000], Loss: 0.5277\n",
      "Epoch [927/1000], Loss: 0.5239\n",
      "Epoch [928/1000], Loss: 0.5324\n",
      "Epoch [929/1000], Loss: 0.5316\n",
      "Epoch [930/1000], Loss: 0.5277\n",
      "Epoch [931/1000], Loss: 0.5285\n",
      "Epoch [932/1000], Loss: 0.5308\n",
      "Epoch [933/1000], Loss: 0.5262\n",
      "Epoch [934/1000], Loss: 0.5300\n",
      "Epoch [935/1000], Loss: 0.5246\n",
      "Epoch [936/1000], Loss: 0.5293\n",
      "Epoch [937/1000], Loss: 0.5285\n",
      "Epoch [938/1000], Loss: 0.5324\n",
      "Epoch [939/1000], Loss: 0.5285\n",
      "Epoch [940/1000], Loss: 0.5285\n",
      "Epoch [941/1000], Loss: 0.5324\n",
      "Epoch [942/1000], Loss: 0.5254\n",
      "Epoch [943/1000], Loss: 0.5324\n",
      "Epoch [944/1000], Loss: 0.5393\n",
      "Epoch [945/1000], Loss: 0.5331\n",
      "Epoch [946/1000], Loss: 0.5285\n",
      "Epoch [947/1000], Loss: 0.5316\n",
      "Epoch [948/1000], Loss: 0.5331\n",
      "Epoch [949/1000], Loss: 0.5285\n",
      "Epoch [950/1000], Loss: 0.5277\n",
      "Epoch [951/1000], Loss: 0.5316\n",
      "Epoch [952/1000], Loss: 0.5316\n",
      "Epoch [953/1000], Loss: 0.5239\n",
      "Epoch [954/1000], Loss: 0.5308\n",
      "Epoch [955/1000], Loss: 0.5293\n",
      "Epoch [956/1000], Loss: 0.5324\n",
      "Epoch [957/1000], Loss: 0.5285\n",
      "Epoch [958/1000], Loss: 0.5293\n",
      "Epoch [959/1000], Loss: 0.5262\n",
      "Epoch [960/1000], Loss: 0.5239\n",
      "Epoch [961/1000], Loss: 0.5347\n",
      "Epoch [962/1000], Loss: 0.5285\n",
      "Epoch [963/1000], Loss: 0.5246\n",
      "Epoch [964/1000], Loss: 0.5254\n",
      "Epoch [965/1000], Loss: 0.5216\n",
      "Epoch [966/1000], Loss: 0.5293\n",
      "Epoch [967/1000], Loss: 0.5324\n",
      "Epoch [968/1000], Loss: 0.5316\n",
      "Epoch [969/1000], Loss: 0.5231\n",
      "Epoch [970/1000], Loss: 0.5339\n",
      "Epoch [971/1000], Loss: 0.5293\n",
      "Epoch [972/1000], Loss: 0.5293\n",
      "Epoch [973/1000], Loss: 0.5254\n",
      "Epoch [974/1000], Loss: 0.5246\n",
      "Epoch [975/1000], Loss: 0.5324\n",
      "Epoch [976/1000], Loss: 0.5285\n",
      "Epoch [977/1000], Loss: 0.5246\n",
      "Epoch [978/1000], Loss: 0.5246\n",
      "Epoch [979/1000], Loss: 0.5239\n",
      "Epoch [980/1000], Loss: 0.5277\n",
      "Epoch [981/1000], Loss: 0.5254\n",
      "Epoch [982/1000], Loss: 0.5277\n",
      "Epoch [983/1000], Loss: 0.5262\n",
      "Epoch [984/1000], Loss: 0.5324\n",
      "Epoch [985/1000], Loss: 0.5270\n",
      "Epoch [986/1000], Loss: 0.5293\n",
      "Epoch [987/1000], Loss: 0.5293\n",
      "Epoch [988/1000], Loss: 0.5254\n",
      "Epoch [989/1000], Loss: 0.5285\n",
      "Epoch [990/1000], Loss: 0.5308\n",
      "Epoch [991/1000], Loss: 0.5354\n",
      "Epoch [992/1000], Loss: 0.5270\n",
      "Epoch [993/1000], Loss: 0.5270\n",
      "Epoch [994/1000], Loss: 0.5262\n",
      "Epoch [995/1000], Loss: 0.5285\n",
      "Epoch [996/1000], Loss: 0.5262\n",
      "Epoch [997/1000], Loss: 0.5324\n",
      "Epoch [998/1000], Loss: 0.5293\n",
      "Epoch [999/1000], Loss: 0.5270\n",
      "Epoch [1000/1000], Loss: 0.5293\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 302, lr :1.0, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2553\n",
      "Epoch [2/1000], Loss: 0.2492\n",
      "Epoch [3/1000], Loss: 0.2500\n",
      "Epoch [4/1000], Loss: 0.2468\n",
      "Epoch [5/1000], Loss: 0.2477\n",
      "Epoch [6/1000], Loss: 0.2485\n",
      "Epoch [7/1000], Loss: 0.2477\n",
      "Epoch [8/1000], Loss: 0.2465\n",
      "Epoch [9/1000], Loss: 0.2480\n",
      "Epoch [10/1000], Loss: 0.2456\n",
      "Epoch [11/1000], Loss: 0.2475\n",
      "Epoch [12/1000], Loss: 0.2440\n",
      "Epoch [13/1000], Loss: 0.2419\n",
      "Epoch [14/1000], Loss: 0.2385\n",
      "Epoch [15/1000], Loss: 0.2354\n",
      "Epoch [16/1000], Loss: 0.2306\n",
      "Epoch [17/1000], Loss: 0.2267\n",
      "Epoch [18/1000], Loss: 0.2210\n",
      "Epoch [19/1000], Loss: 0.2132\n",
      "Epoch [20/1000], Loss: 0.2083\n",
      "Epoch [21/1000], Loss: 0.1979\n",
      "Epoch [22/1000], Loss: 0.1954\n",
      "Epoch [23/1000], Loss: 0.1924\n",
      "Epoch [24/1000], Loss: 0.1853\n",
      "Epoch [25/1000], Loss: 0.1758\n",
      "Epoch [26/1000], Loss: 0.1764\n",
      "Epoch [27/1000], Loss: 0.1741\n",
      "Epoch [28/1000], Loss: 0.1628\n",
      "Epoch [29/1000], Loss: 0.1710\n",
      "Epoch [30/1000], Loss: 0.1635\n",
      "Epoch [31/1000], Loss: 0.1491\n",
      "Epoch [32/1000], Loss: 0.1406\n",
      "Epoch [33/1000], Loss: 0.1624\n",
      "Epoch [34/1000], Loss: 0.1230\n",
      "Epoch [35/1000], Loss: 0.1489\n",
      "Epoch [36/1000], Loss: 0.1217\n",
      "Epoch [37/1000], Loss: 0.1137\n",
      "Epoch [38/1000], Loss: 0.1537\n",
      "Epoch [39/1000], Loss: 0.1196\n",
      "Epoch [40/1000], Loss: 0.1283\n",
      "Epoch [41/1000], Loss: 0.0883\n",
      "Epoch [42/1000], Loss: 0.1025\n",
      "Epoch [43/1000], Loss: 0.0916\n",
      "Epoch [44/1000], Loss: 0.0922\n",
      "Epoch [45/1000], Loss: 0.0986\n",
      "Epoch [46/1000], Loss: 0.0928\n",
      "Epoch [47/1000], Loss: 0.0707\n",
      "Epoch [48/1000], Loss: 0.0730\n",
      "Epoch [49/1000], Loss: 0.0926\n",
      "Epoch [50/1000], Loss: 0.0722\n",
      "Epoch [51/1000], Loss: 0.0783\n",
      "Epoch [52/1000], Loss: 0.0938\n",
      "Epoch [53/1000], Loss: 0.0889\n",
      "Epoch [54/1000], Loss: 0.0732\n",
      "Epoch [55/1000], Loss: 0.0501\n",
      "Epoch [56/1000], Loss: 0.0622\n",
      "Epoch [57/1000], Loss: 0.0645\n",
      "Epoch [58/1000], Loss: 0.0464\n",
      "Epoch [59/1000], Loss: 0.0357\n",
      "Epoch [60/1000], Loss: 0.0582\n",
      "Epoch [61/1000], Loss: 0.0445\n",
      "Epoch [62/1000], Loss: 0.0416\n",
      "Epoch [63/1000], Loss: 0.1053\n",
      "Epoch [64/1000], Loss: 0.0463\n",
      "Epoch [65/1000], Loss: 0.0409\n",
      "Epoch [66/1000], Loss: 0.0243\n",
      "Epoch [67/1000], Loss: 0.0530\n",
      "Epoch [68/1000], Loss: 0.0302\n",
      "Epoch [69/1000], Loss: 0.0253\n",
      "Epoch [70/1000], Loss: 0.0177\n",
      "Epoch [71/1000], Loss: 0.0113\n",
      "Epoch [72/1000], Loss: 0.0998\n",
      "Epoch [73/1000], Loss: 0.0486\n",
      "Epoch [74/1000], Loss: 0.0245\n",
      "Epoch [75/1000], Loss: 0.0090\n",
      "Epoch [76/1000], Loss: 0.0089\n",
      "Epoch [77/1000], Loss: 0.0045\n",
      "Epoch [78/1000], Loss: 0.0041\n",
      "Epoch [79/1000], Loss: 0.0036\n",
      "Epoch [80/1000], Loss: 0.0033\n",
      "Epoch [81/1000], Loss: 0.0032\n",
      "Epoch [82/1000], Loss: 0.0035\n",
      "Epoch [83/1000], Loss: 0.0207\n",
      "Epoch [84/1000], Loss: 0.0027\n",
      "Epoch [85/1000], Loss: 0.0023\n",
      "Epoch [86/1000], Loss: 0.0019\n",
      "Epoch [87/1000], Loss: 0.0017\n",
      "Epoch [88/1000], Loss: 0.0017\n",
      "Epoch [89/1000], Loss: 0.0015\n",
      "Epoch [90/1000], Loss: 0.0014\n",
      "Epoch [91/1000], Loss: 0.0013\n",
      "Epoch [92/1000], Loss: 0.0012\n",
      "Epoch [93/1000], Loss: 0.0013\n",
      "Epoch [94/1000], Loss: 0.0012\n",
      "Epoch [95/1000], Loss: 0.0013\n",
      "Epoch [96/1000], Loss: 0.0012\n",
      "Epoch [97/1000], Loss: 0.0012\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 302, lr :10.0, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.5174\n",
      "Epoch [2/1000], Loss: 0.5277\n",
      "Epoch [3/1000], Loss: 0.5200\n",
      "Epoch [4/1000], Loss: 0.5293\n",
      "Epoch [5/1000], Loss: 0.5239\n",
      "Epoch [6/1000], Loss: 0.5293\n",
      "Epoch [7/1000], Loss: 0.5339\n",
      "Epoch [8/1000], Loss: 0.5331\n",
      "Epoch [9/1000], Loss: 0.5239\n",
      "Epoch [10/1000], Loss: 0.5300\n",
      "Epoch [11/1000], Loss: 0.5393\n",
      "Epoch [12/1000], Loss: 0.5246\n",
      "Epoch [13/1000], Loss: 0.5277\n",
      "Epoch [14/1000], Loss: 0.5339\n",
      "Epoch [15/1000], Loss: 0.5262\n",
      "Epoch [16/1000], Loss: 0.5239\n",
      "Epoch [17/1000], Loss: 0.5300\n",
      "Epoch [18/1000], Loss: 0.5324\n",
      "Epoch [19/1000], Loss: 0.5362\n",
      "Epoch [20/1000], Loss: 0.5270\n",
      "Epoch [21/1000], Loss: 0.5308\n",
      "Epoch [22/1000], Loss: 0.5316\n",
      "Epoch [23/1000], Loss: 0.5277\n",
      "Epoch [24/1000], Loss: 0.5285\n",
      "Epoch [25/1000], Loss: 0.5231\n",
      "Epoch [26/1000], Loss: 0.5254\n",
      "Epoch [27/1000], Loss: 0.5354\n",
      "Epoch [28/1000], Loss: 0.5347\n",
      "Epoch [29/1000], Loss: 0.5293\n",
      "Epoch [30/1000], Loss: 0.5300\n",
      "Epoch [31/1000], Loss: 0.5331\n",
      "Epoch [32/1000], Loss: 0.5339\n",
      "Epoch [33/1000], Loss: 0.5347\n",
      "Epoch [34/1000], Loss: 0.5354\n",
      "Epoch [35/1000], Loss: 0.5254\n",
      "Epoch [36/1000], Loss: 0.5270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/1000], Loss: 0.5308\n",
      "Epoch [38/1000], Loss: 0.5270\n",
      "Epoch [39/1000], Loss: 0.5262\n",
      "Epoch [40/1000], Loss: 0.5277\n",
      "Epoch [41/1000], Loss: 0.5316\n",
      "Epoch [42/1000], Loss: 0.5277\n",
      "Epoch [43/1000], Loss: 0.5308\n",
      "Epoch [44/1000], Loss: 0.5316\n",
      "Epoch [45/1000], Loss: 0.5293\n",
      "Epoch [46/1000], Loss: 0.5285\n",
      "Epoch [47/1000], Loss: 0.5254\n",
      "Epoch [48/1000], Loss: 0.5285\n",
      "Epoch [49/1000], Loss: 0.5293\n",
      "Epoch [50/1000], Loss: 0.5339\n",
      "Epoch [51/1000], Loss: 0.5277\n",
      "Epoch [52/1000], Loss: 0.5254\n",
      "Epoch [53/1000], Loss: 0.5285\n",
      "Epoch [54/1000], Loss: 0.5308\n",
      "Epoch [55/1000], Loss: 0.5246\n",
      "Epoch [56/1000], Loss: 0.5262\n",
      "Epoch [57/1000], Loss: 0.5308\n",
      "Epoch [58/1000], Loss: 0.5254\n",
      "Epoch [59/1000], Loss: 0.5308\n",
      "Epoch [60/1000], Loss: 0.5308\n",
      "Epoch [61/1000], Loss: 0.5347\n",
      "Epoch [62/1000], Loss: 0.5239\n",
      "Epoch [63/1000], Loss: 0.5239\n",
      "Epoch [64/1000], Loss: 0.5277\n",
      "Epoch [65/1000], Loss: 0.5270\n",
      "Epoch [66/1000], Loss: 0.5293\n",
      "Epoch [67/1000], Loss: 0.5285\n",
      "Epoch [68/1000], Loss: 0.5316\n",
      "Epoch [69/1000], Loss: 0.5254\n",
      "Epoch [70/1000], Loss: 0.5293\n",
      "Epoch [71/1000], Loss: 0.5277\n",
      "Epoch [72/1000], Loss: 0.5193\n",
      "Epoch [73/1000], Loss: 0.5324\n",
      "Epoch [74/1000], Loss: 0.5262\n",
      "Epoch [75/1000], Loss: 0.5262\n",
      "Epoch [76/1000], Loss: 0.5308\n",
      "Epoch [77/1000], Loss: 0.5300\n",
      "Epoch [78/1000], Loss: 0.5277\n",
      "Epoch [79/1000], Loss: 0.5285\n",
      "Epoch [80/1000], Loss: 0.5254\n",
      "Epoch [81/1000], Loss: 0.5347\n",
      "Epoch [82/1000], Loss: 0.5254\n",
      "Epoch [83/1000], Loss: 0.5285\n",
      "Epoch [84/1000], Loss: 0.5216\n",
      "Epoch [85/1000], Loss: 0.5324\n",
      "Epoch [86/1000], Loss: 0.5246\n",
      "Epoch [87/1000], Loss: 0.5293\n",
      "Epoch [88/1000], Loss: 0.5293\n",
      "Epoch [89/1000], Loss: 0.5208\n",
      "Epoch [90/1000], Loss: 0.5324\n",
      "Epoch [91/1000], Loss: 0.5270\n",
      "Epoch [92/1000], Loss: 0.5231\n",
      "Epoch [93/1000], Loss: 0.5239\n",
      "Epoch [94/1000], Loss: 0.5285\n",
      "Epoch [95/1000], Loss: 0.5208\n",
      "Epoch [96/1000], Loss: 0.5308\n",
      "Epoch [97/1000], Loss: 0.5223\n",
      "Epoch [98/1000], Loss: 0.5246\n",
      "Epoch [99/1000], Loss: 0.5300\n",
      "Epoch [100/1000], Loss: 0.5270\n",
      "Epoch [101/1000], Loss: 0.5262\n",
      "Epoch [102/1000], Loss: 0.5324\n",
      "Epoch [103/1000], Loss: 0.5316\n",
      "Epoch [104/1000], Loss: 0.5339\n",
      "Epoch [105/1000], Loss: 0.5254\n",
      "Epoch [106/1000], Loss: 0.5231\n",
      "Epoch [107/1000], Loss: 0.5308\n",
      "Epoch [108/1000], Loss: 0.5277\n",
      "Epoch [109/1000], Loss: 0.5293\n",
      "Epoch [110/1000], Loss: 0.5277\n",
      "Epoch [111/1000], Loss: 0.5277\n",
      "Epoch [112/1000], Loss: 0.5254\n",
      "Epoch [113/1000], Loss: 0.5324\n",
      "Epoch [114/1000], Loss: 0.5262\n",
      "Epoch [115/1000], Loss: 0.5239\n",
      "Epoch [116/1000], Loss: 0.5308\n",
      "Epoch [117/1000], Loss: 0.5331\n",
      "Epoch [118/1000], Loss: 0.5293\n",
      "Epoch [119/1000], Loss: 0.5331\n",
      "Epoch [120/1000], Loss: 0.5308\n",
      "Epoch [121/1000], Loss: 0.5239\n",
      "Epoch [122/1000], Loss: 0.5246\n",
      "Epoch [123/1000], Loss: 0.5331\n",
      "Epoch [124/1000], Loss: 0.5246\n",
      "Epoch [125/1000], Loss: 0.5370\n",
      "Epoch [126/1000], Loss: 0.5277\n",
      "Epoch [127/1000], Loss: 0.5339\n",
      "Epoch [128/1000], Loss: 0.5293\n",
      "Epoch [129/1000], Loss: 0.5246\n",
      "Epoch [130/1000], Loss: 0.5316\n",
      "Epoch [131/1000], Loss: 0.5239\n",
      "Epoch [132/1000], Loss: 0.5300\n",
      "Epoch [133/1000], Loss: 0.5270\n",
      "Epoch [134/1000], Loss: 0.5262\n",
      "Epoch [135/1000], Loss: 0.5308\n",
      "Epoch [136/1000], Loss: 0.5254\n",
      "Epoch [137/1000], Loss: 0.5254\n",
      "Epoch [138/1000], Loss: 0.5246\n",
      "Epoch [139/1000], Loss: 0.5308\n",
      "Epoch [140/1000], Loss: 0.5293\n",
      "Epoch [141/1000], Loss: 0.5262\n",
      "Epoch [142/1000], Loss: 0.5324\n",
      "Epoch [143/1000], Loss: 0.5239\n",
      "Epoch [144/1000], Loss: 0.5285\n",
      "Epoch [145/1000], Loss: 0.5277\n",
      "Epoch [146/1000], Loss: 0.5308\n",
      "Epoch [147/1000], Loss: 0.5293\n",
      "Epoch [148/1000], Loss: 0.5293\n",
      "Epoch [149/1000], Loss: 0.5324\n",
      "Epoch [150/1000], Loss: 0.5293\n",
      "Epoch [151/1000], Loss: 0.5285\n",
      "Epoch [152/1000], Loss: 0.5285\n",
      "Epoch [153/1000], Loss: 0.5300\n",
      "Epoch [154/1000], Loss: 0.5277\n",
      "Epoch [155/1000], Loss: 0.5270\n",
      "Epoch [156/1000], Loss: 0.5316\n",
      "Epoch [157/1000], Loss: 0.5223\n",
      "Epoch [158/1000], Loss: 0.5285\n",
      "Epoch [159/1000], Loss: 0.5316\n",
      "Epoch [160/1000], Loss: 0.5239\n",
      "Epoch [161/1000], Loss: 0.5293\n",
      "Epoch [162/1000], Loss: 0.5254\n",
      "Epoch [163/1000], Loss: 0.5308\n",
      "Epoch [164/1000], Loss: 0.5316\n",
      "Epoch [165/1000], Loss: 0.5254\n",
      "Epoch [166/1000], Loss: 0.5270\n",
      "Epoch [167/1000], Loss: 0.5285\n",
      "Epoch [168/1000], Loss: 0.5293\n",
      "Epoch [169/1000], Loss: 0.5300\n",
      "Epoch [170/1000], Loss: 0.5347\n",
      "Epoch [171/1000], Loss: 0.5285\n",
      "Epoch [172/1000], Loss: 0.5254\n",
      "Epoch [173/1000], Loss: 0.5285\n",
      "Epoch [174/1000], Loss: 0.5239\n",
      "Epoch [175/1000], Loss: 0.5239\n",
      "Epoch [176/1000], Loss: 0.5339\n",
      "Epoch [177/1000], Loss: 0.5239\n",
      "Epoch [178/1000], Loss: 0.5285\n",
      "Epoch [179/1000], Loss: 0.5262\n",
      "Epoch [180/1000], Loss: 0.5300\n",
      "Epoch [181/1000], Loss: 0.5347\n",
      "Epoch [182/1000], Loss: 0.5277\n",
      "Epoch [183/1000], Loss: 0.5254\n",
      "Epoch [184/1000], Loss: 0.5324\n",
      "Epoch [185/1000], Loss: 0.5246\n",
      "Epoch [186/1000], Loss: 0.5270\n",
      "Epoch [187/1000], Loss: 0.5316\n",
      "Epoch [188/1000], Loss: 0.5285\n",
      "Epoch [189/1000], Loss: 0.5362\n",
      "Epoch [190/1000], Loss: 0.5285\n",
      "Epoch [191/1000], Loss: 0.5231\n",
      "Epoch [192/1000], Loss: 0.5254\n",
      "Epoch [193/1000], Loss: 0.5308\n",
      "Epoch [194/1000], Loss: 0.5300\n",
      "Epoch [195/1000], Loss: 0.5246\n",
      "Epoch [196/1000], Loss: 0.5293\n",
      "Epoch [197/1000], Loss: 0.5254\n",
      "Epoch [198/1000], Loss: 0.5293\n",
      "Epoch [199/1000], Loss: 0.5254\n",
      "Epoch [200/1000], Loss: 0.5270\n",
      "Epoch [201/1000], Loss: 0.5239\n",
      "Epoch [202/1000], Loss: 0.5285\n",
      "Epoch [203/1000], Loss: 0.5316\n",
      "Epoch [204/1000], Loss: 0.5354\n",
      "Epoch [205/1000], Loss: 0.5246\n",
      "Epoch [206/1000], Loss: 0.5300\n",
      "Epoch [207/1000], Loss: 0.5285\n",
      "Epoch [208/1000], Loss: 0.5300\n",
      "Epoch [209/1000], Loss: 0.5270\n",
      "Epoch [210/1000], Loss: 0.5270\n",
      "Epoch [211/1000], Loss: 0.5270\n",
      "Epoch [212/1000], Loss: 0.5300\n",
      "Epoch [213/1000], Loss: 0.5285\n",
      "Epoch [214/1000], Loss: 0.5339\n",
      "Epoch [215/1000], Loss: 0.5246\n",
      "Epoch [216/1000], Loss: 0.5254\n",
      "Epoch [217/1000], Loss: 0.5293\n",
      "Epoch [218/1000], Loss: 0.5285\n",
      "Epoch [219/1000], Loss: 0.5231\n",
      "Epoch [220/1000], Loss: 0.5254\n",
      "Epoch [221/1000], Loss: 0.5293\n",
      "Epoch [222/1000], Loss: 0.5300\n",
      "Epoch [223/1000], Loss: 0.5239\n",
      "Epoch [224/1000], Loss: 0.5270\n",
      "Epoch [225/1000], Loss: 0.5270\n",
      "Epoch [226/1000], Loss: 0.5270\n",
      "Epoch [227/1000], Loss: 0.5316\n",
      "Epoch [228/1000], Loss: 0.5285\n",
      "Epoch [229/1000], Loss: 0.5293\n",
      "Epoch [230/1000], Loss: 0.5293\n",
      "Epoch [231/1000], Loss: 0.5239\n",
      "Epoch [232/1000], Loss: 0.5270\n",
      "Epoch [233/1000], Loss: 0.5270\n",
      "Epoch [234/1000], Loss: 0.5254\n",
      "Epoch [235/1000], Loss: 0.5308\n",
      "Epoch [236/1000], Loss: 0.5316\n",
      "Epoch [237/1000], Loss: 0.5246\n",
      "Epoch [238/1000], Loss: 0.5216\n",
      "Epoch [239/1000], Loss: 0.5316\n",
      "Epoch [240/1000], Loss: 0.5277\n",
      "Epoch [241/1000], Loss: 0.5262\n",
      "Epoch [242/1000], Loss: 0.5293\n",
      "Epoch [243/1000], Loss: 0.5285\n",
      "Epoch [244/1000], Loss: 0.5324\n",
      "Epoch [245/1000], Loss: 0.5324\n",
      "Epoch [246/1000], Loss: 0.5300\n",
      "Epoch [247/1000], Loss: 0.5339\n",
      "Epoch [248/1000], Loss: 0.5316\n",
      "Epoch [249/1000], Loss: 0.5285\n",
      "Epoch [250/1000], Loss: 0.5277\n",
      "Epoch [251/1000], Loss: 0.5285\n",
      "Epoch [252/1000], Loss: 0.5324\n",
      "Epoch [253/1000], Loss: 0.5285\n",
      "Epoch [254/1000], Loss: 0.5277\n",
      "Epoch [255/1000], Loss: 0.5293\n",
      "Epoch [256/1000], Loss: 0.5231\n",
      "Epoch [257/1000], Loss: 0.5254\n",
      "Epoch [258/1000], Loss: 0.5293\n",
      "Epoch [259/1000], Loss: 0.5285\n",
      "Epoch [260/1000], Loss: 0.5354\n",
      "Epoch [261/1000], Loss: 0.5293\n",
      "Epoch [262/1000], Loss: 0.5216\n",
      "Epoch [263/1000], Loss: 0.5285\n",
      "Epoch [264/1000], Loss: 0.5354\n",
      "Epoch [265/1000], Loss: 0.5331\n",
      "Epoch [266/1000], Loss: 0.5293\n",
      "Epoch [267/1000], Loss: 0.5293\n",
      "Epoch [268/1000], Loss: 0.5285\n",
      "Epoch [269/1000], Loss: 0.5316\n",
      "Epoch [270/1000], Loss: 0.5293\n",
      "Epoch [271/1000], Loss: 0.5324\n",
      "Epoch [272/1000], Loss: 0.5262\n",
      "Epoch [273/1000], Loss: 0.5308\n",
      "Epoch [274/1000], Loss: 0.5231\n",
      "Epoch [275/1000], Loss: 0.5285\n",
      "Epoch [276/1000], Loss: 0.5293\n",
      "Epoch [277/1000], Loss: 0.5293\n",
      "Epoch [278/1000], Loss: 0.5293\n",
      "Epoch [279/1000], Loss: 0.5293\n",
      "Epoch [280/1000], Loss: 0.5300\n",
      "Epoch [281/1000], Loss: 0.5293\n",
      "Epoch [282/1000], Loss: 0.5239\n",
      "Epoch [283/1000], Loss: 0.5316\n",
      "Epoch [284/1000], Loss: 0.5277\n",
      "Epoch [285/1000], Loss: 0.5347\n",
      "Epoch [286/1000], Loss: 0.5300\n",
      "Epoch [287/1000], Loss: 0.5293\n",
      "Epoch [288/1000], Loss: 0.5300\n",
      "Epoch [289/1000], Loss: 0.5262\n",
      "Epoch [290/1000], Loss: 0.5285\n",
      "Epoch [291/1000], Loss: 0.5231\n",
      "Epoch [292/1000], Loss: 0.5324\n",
      "Epoch [293/1000], Loss: 0.5331\n",
      "Epoch [294/1000], Loss: 0.5262\n",
      "Epoch [295/1000], Loss: 0.5316\n",
      "Epoch [296/1000], Loss: 0.5277\n",
      "Epoch [297/1000], Loss: 0.5177\n",
      "Epoch [298/1000], Loss: 0.5293\n",
      "Epoch [299/1000], Loss: 0.5308\n",
      "Epoch [300/1000], Loss: 0.5339\n",
      "Epoch [301/1000], Loss: 0.5293\n",
      "Epoch [302/1000], Loss: 0.5331\n",
      "Epoch [303/1000], Loss: 0.5277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [304/1000], Loss: 0.5285\n",
      "Epoch [305/1000], Loss: 0.5347\n",
      "Epoch [306/1000], Loss: 0.5285\n",
      "Epoch [307/1000], Loss: 0.5262\n",
      "Epoch [308/1000], Loss: 0.5231\n",
      "Epoch [309/1000], Loss: 0.5270\n",
      "Epoch [310/1000], Loss: 0.5285\n",
      "Epoch [311/1000], Loss: 0.5285\n",
      "Epoch [312/1000], Loss: 0.5300\n",
      "Epoch [313/1000], Loss: 0.5324\n",
      "Epoch [314/1000], Loss: 0.5316\n",
      "Epoch [315/1000], Loss: 0.5316\n",
      "Epoch [316/1000], Loss: 0.5316\n",
      "Epoch [317/1000], Loss: 0.5254\n",
      "Epoch [318/1000], Loss: 0.5300\n",
      "Epoch [319/1000], Loss: 0.5300\n",
      "Epoch [320/1000], Loss: 0.5277\n",
      "Epoch [321/1000], Loss: 0.5277\n",
      "Epoch [322/1000], Loss: 0.5231\n",
      "Epoch [323/1000], Loss: 0.5339\n",
      "Epoch [324/1000], Loss: 0.5231\n",
      "Epoch [325/1000], Loss: 0.5324\n",
      "Epoch [326/1000], Loss: 0.5324\n",
      "Epoch [327/1000], Loss: 0.5308\n",
      "Epoch [328/1000], Loss: 0.5339\n",
      "Epoch [329/1000], Loss: 0.5277\n",
      "Epoch [330/1000], Loss: 0.5285\n",
      "Epoch [331/1000], Loss: 0.5308\n",
      "Epoch [332/1000], Loss: 0.5277\n",
      "Epoch [333/1000], Loss: 0.5277\n",
      "Epoch [334/1000], Loss: 0.5277\n",
      "Epoch [335/1000], Loss: 0.5331\n",
      "Epoch [336/1000], Loss: 0.5254\n",
      "Epoch [337/1000], Loss: 0.5223\n",
      "Epoch [338/1000], Loss: 0.5285\n",
      "Epoch [339/1000], Loss: 0.5239\n",
      "Epoch [340/1000], Loss: 0.5300\n",
      "Epoch [341/1000], Loss: 0.5308\n",
      "Epoch [342/1000], Loss: 0.5300\n",
      "Epoch [343/1000], Loss: 0.5300\n",
      "Epoch [344/1000], Loss: 0.5200\n",
      "Epoch [345/1000], Loss: 0.5254\n",
      "Epoch [346/1000], Loss: 0.5300\n",
      "Epoch [347/1000], Loss: 0.5300\n",
      "Epoch [348/1000], Loss: 0.5254\n",
      "Epoch [349/1000], Loss: 0.5270\n",
      "Epoch [350/1000], Loss: 0.5277\n",
      "Epoch [351/1000], Loss: 0.5262\n",
      "Epoch [352/1000], Loss: 0.5223\n",
      "Epoch [353/1000], Loss: 0.5300\n",
      "Epoch [354/1000], Loss: 0.5300\n",
      "Epoch [355/1000], Loss: 0.5293\n",
      "Epoch [356/1000], Loss: 0.5293\n",
      "Epoch [357/1000], Loss: 0.5262\n",
      "Epoch [358/1000], Loss: 0.5239\n",
      "Epoch [359/1000], Loss: 0.5293\n",
      "Epoch [360/1000], Loss: 0.5300\n",
      "Epoch [361/1000], Loss: 0.5324\n",
      "Epoch [362/1000], Loss: 0.5231\n",
      "Epoch [363/1000], Loss: 0.5262\n",
      "Epoch [364/1000], Loss: 0.5239\n",
      "Epoch [365/1000], Loss: 0.5300\n",
      "Epoch [366/1000], Loss: 0.5308\n",
      "Epoch [367/1000], Loss: 0.5277\n",
      "Epoch [368/1000], Loss: 0.5300\n",
      "Epoch [369/1000], Loss: 0.5316\n",
      "Epoch [370/1000], Loss: 0.5277\n",
      "Epoch [371/1000], Loss: 0.5293\n",
      "Epoch [372/1000], Loss: 0.5300\n",
      "Epoch [373/1000], Loss: 0.5162\n",
      "Epoch [374/1000], Loss: 0.5254\n",
      "Epoch [375/1000], Loss: 0.5254\n",
      "Epoch [376/1000], Loss: 0.5239\n",
      "Epoch [377/1000], Loss: 0.5285\n",
      "Epoch [378/1000], Loss: 0.5300\n",
      "Epoch [379/1000], Loss: 0.5277\n",
      "Epoch [380/1000], Loss: 0.5293\n",
      "Epoch [381/1000], Loss: 0.5277\n",
      "Epoch [382/1000], Loss: 0.5270\n",
      "Epoch [383/1000], Loss: 0.5285\n",
      "Epoch [384/1000], Loss: 0.5300\n",
      "Epoch [385/1000], Loss: 0.5285\n",
      "Epoch [386/1000], Loss: 0.5277\n",
      "Epoch [387/1000], Loss: 0.5331\n",
      "Epoch [388/1000], Loss: 0.5285\n",
      "Epoch [389/1000], Loss: 0.5285\n",
      "Epoch [390/1000], Loss: 0.5339\n",
      "Epoch [391/1000], Loss: 0.5277\n",
      "Epoch [392/1000], Loss: 0.5246\n",
      "Epoch [393/1000], Loss: 0.5246\n",
      "Epoch [394/1000], Loss: 0.5270\n",
      "Epoch [395/1000], Loss: 0.5223\n",
      "Epoch [396/1000], Loss: 0.5246\n",
      "Epoch [397/1000], Loss: 0.5231\n",
      "Epoch [398/1000], Loss: 0.5277\n",
      "Epoch [399/1000], Loss: 0.5316\n",
      "Epoch [400/1000], Loss: 0.5262\n",
      "Epoch [401/1000], Loss: 0.5293\n",
      "Epoch [402/1000], Loss: 0.5223\n",
      "Epoch [403/1000], Loss: 0.5270\n",
      "Epoch [404/1000], Loss: 0.5316\n",
      "Epoch [405/1000], Loss: 0.5331\n",
      "Epoch [406/1000], Loss: 0.5223\n",
      "Epoch [407/1000], Loss: 0.5285\n",
      "Epoch [408/1000], Loss: 0.5354\n",
      "Epoch [409/1000], Loss: 0.5293\n",
      "Epoch [410/1000], Loss: 0.5254\n",
      "Epoch [411/1000], Loss: 0.5308\n",
      "Epoch [412/1000], Loss: 0.5270\n",
      "Epoch [413/1000], Loss: 0.5293\n",
      "Epoch [414/1000], Loss: 0.5331\n",
      "Epoch [415/1000], Loss: 0.5293\n",
      "Epoch [416/1000], Loss: 0.5308\n",
      "Epoch [417/1000], Loss: 0.5308\n",
      "Epoch [418/1000], Loss: 0.5277\n",
      "Epoch [419/1000], Loss: 0.5308\n",
      "Epoch [420/1000], Loss: 0.5293\n",
      "Epoch [421/1000], Loss: 0.5277\n",
      "Epoch [422/1000], Loss: 0.5308\n",
      "Epoch [423/1000], Loss: 0.5324\n",
      "Epoch [424/1000], Loss: 0.5316\n",
      "Epoch [425/1000], Loss: 0.5270\n",
      "Epoch [426/1000], Loss: 0.5324\n",
      "Epoch [427/1000], Loss: 0.5354\n",
      "Epoch [428/1000], Loss: 0.5293\n",
      "Epoch [429/1000], Loss: 0.5285\n",
      "Epoch [430/1000], Loss: 0.5308\n",
      "Epoch [431/1000], Loss: 0.5277\n",
      "Epoch [432/1000], Loss: 0.5324\n",
      "Epoch [433/1000], Loss: 0.5285\n",
      "Epoch [434/1000], Loss: 0.5308\n",
      "Epoch [435/1000], Loss: 0.5270\n",
      "Epoch [436/1000], Loss: 0.5285\n",
      "Epoch [437/1000], Loss: 0.5277\n",
      "Epoch [438/1000], Loss: 0.5316\n",
      "Epoch [439/1000], Loss: 0.5239\n",
      "Epoch [440/1000], Loss: 0.5254\n",
      "Epoch [441/1000], Loss: 0.5300\n",
      "Epoch [442/1000], Loss: 0.5293\n",
      "Epoch [443/1000], Loss: 0.5246\n",
      "Epoch [444/1000], Loss: 0.5300\n",
      "Epoch [445/1000], Loss: 0.5308\n",
      "Epoch [446/1000], Loss: 0.5293\n",
      "Epoch [447/1000], Loss: 0.5308\n",
      "Epoch [448/1000], Loss: 0.5347\n",
      "Epoch [449/1000], Loss: 0.5223\n",
      "Epoch [450/1000], Loss: 0.5285\n",
      "Epoch [451/1000], Loss: 0.5277\n",
      "Epoch [452/1000], Loss: 0.5262\n",
      "Epoch [453/1000], Loss: 0.5285\n",
      "Epoch [454/1000], Loss: 0.5285\n",
      "Epoch [455/1000], Loss: 0.5293\n",
      "Epoch [456/1000], Loss: 0.5254\n",
      "Epoch [457/1000], Loss: 0.5254\n",
      "Epoch [458/1000], Loss: 0.5370\n",
      "Epoch [459/1000], Loss: 0.5216\n",
      "Epoch [460/1000], Loss: 0.5277\n",
      "Epoch [461/1000], Loss: 0.5331\n",
      "Epoch [462/1000], Loss: 0.5239\n",
      "Epoch [463/1000], Loss: 0.5270\n",
      "Epoch [464/1000], Loss: 0.5277\n",
      "Epoch [465/1000], Loss: 0.5324\n",
      "Epoch [466/1000], Loss: 0.5293\n",
      "Epoch [467/1000], Loss: 0.5239\n",
      "Epoch [468/1000], Loss: 0.5254\n",
      "Epoch [469/1000], Loss: 0.5285\n",
      "Epoch [470/1000], Loss: 0.5316\n",
      "Epoch [471/1000], Loss: 0.5277\n",
      "Epoch [472/1000], Loss: 0.5316\n",
      "Epoch [473/1000], Loss: 0.5270\n",
      "Epoch [474/1000], Loss: 0.5300\n",
      "Epoch [475/1000], Loss: 0.5339\n",
      "Epoch [476/1000], Loss: 0.5231\n",
      "Epoch [477/1000], Loss: 0.5293\n",
      "Epoch [478/1000], Loss: 0.5254\n",
      "Epoch [479/1000], Loss: 0.5293\n",
      "Epoch [480/1000], Loss: 0.5270\n",
      "Epoch [481/1000], Loss: 0.5277\n",
      "Epoch [482/1000], Loss: 0.5300\n",
      "Epoch [483/1000], Loss: 0.5277\n",
      "Epoch [484/1000], Loss: 0.5331\n",
      "Epoch [485/1000], Loss: 0.5300\n",
      "Epoch [486/1000], Loss: 0.5293\n",
      "Epoch [487/1000], Loss: 0.5324\n",
      "Epoch [488/1000], Loss: 0.5270\n",
      "Epoch [489/1000], Loss: 0.5277\n",
      "Epoch [490/1000], Loss: 0.5270\n",
      "Epoch [491/1000], Loss: 0.5293\n",
      "Epoch [492/1000], Loss: 0.5262\n",
      "Epoch [493/1000], Loss: 0.5300\n",
      "Epoch [494/1000], Loss: 0.5285\n",
      "Epoch [495/1000], Loss: 0.5316\n",
      "Epoch [496/1000], Loss: 0.5285\n",
      "Epoch [497/1000], Loss: 0.5293\n",
      "Epoch [498/1000], Loss: 0.5300\n",
      "Epoch [499/1000], Loss: 0.5277\n",
      "Epoch [500/1000], Loss: 0.5277\n",
      "Epoch [501/1000], Loss: 0.5277\n",
      "Epoch [502/1000], Loss: 0.5324\n",
      "Epoch [503/1000], Loss: 0.5331\n",
      "Epoch [504/1000], Loss: 0.5308\n",
      "Epoch [505/1000], Loss: 0.5254\n",
      "Epoch [506/1000], Loss: 0.5270\n",
      "Epoch [507/1000], Loss: 0.5277\n",
      "Epoch [508/1000], Loss: 0.5316\n",
      "Epoch [509/1000], Loss: 0.5308\n",
      "Epoch [510/1000], Loss: 0.5262\n",
      "Epoch [511/1000], Loss: 0.5293\n",
      "Epoch [512/1000], Loss: 0.5300\n",
      "Epoch [513/1000], Loss: 0.5316\n",
      "Epoch [514/1000], Loss: 0.5354\n",
      "Epoch [515/1000], Loss: 0.5277\n",
      "Epoch [516/1000], Loss: 0.5308\n",
      "Epoch [517/1000], Loss: 0.5223\n",
      "Epoch [518/1000], Loss: 0.5270\n",
      "Epoch [519/1000], Loss: 0.5324\n",
      "Epoch [520/1000], Loss: 0.5308\n",
      "Epoch [521/1000], Loss: 0.5324\n",
      "Epoch [522/1000], Loss: 0.5270\n",
      "Epoch [523/1000], Loss: 0.5331\n",
      "Epoch [524/1000], Loss: 0.5293\n",
      "Epoch [525/1000], Loss: 0.5262\n",
      "Epoch [526/1000], Loss: 0.5316\n",
      "Epoch [527/1000], Loss: 0.5262\n",
      "Epoch [528/1000], Loss: 0.5316\n",
      "Epoch [529/1000], Loss: 0.5300\n",
      "Epoch [530/1000], Loss: 0.5270\n",
      "Epoch [531/1000], Loss: 0.5293\n",
      "Epoch [532/1000], Loss: 0.5300\n",
      "Epoch [533/1000], Loss: 0.5270\n",
      "Epoch [534/1000], Loss: 0.5300\n",
      "Epoch [535/1000], Loss: 0.5277\n",
      "Epoch [536/1000], Loss: 0.5293\n",
      "Epoch [537/1000], Loss: 0.5223\n",
      "Epoch [538/1000], Loss: 0.5231\n",
      "Epoch [539/1000], Loss: 0.5300\n",
      "Epoch [540/1000], Loss: 0.5308\n",
      "Epoch [541/1000], Loss: 0.5285\n",
      "Epoch [542/1000], Loss: 0.5270\n",
      "Epoch [543/1000], Loss: 0.5293\n",
      "Epoch [544/1000], Loss: 0.5277\n",
      "Epoch [545/1000], Loss: 0.5308\n",
      "Epoch [546/1000], Loss: 0.5300\n",
      "Epoch [547/1000], Loss: 0.5277\n",
      "Epoch [548/1000], Loss: 0.5293\n",
      "Epoch [549/1000], Loss: 0.5331\n",
      "Epoch [550/1000], Loss: 0.5339\n",
      "Epoch [551/1000], Loss: 0.5231\n",
      "Epoch [552/1000], Loss: 0.5300\n",
      "Epoch [553/1000], Loss: 0.5324\n",
      "Epoch [554/1000], Loss: 0.5324\n",
      "Epoch [555/1000], Loss: 0.5270\n",
      "Epoch [556/1000], Loss: 0.5223\n",
      "Epoch [557/1000], Loss: 0.5262\n",
      "Epoch [558/1000], Loss: 0.5285\n",
      "Epoch [559/1000], Loss: 0.5231\n",
      "Epoch [560/1000], Loss: 0.5277\n",
      "Epoch [561/1000], Loss: 0.5277\n",
      "Epoch [562/1000], Loss: 0.5339\n",
      "Epoch [563/1000], Loss: 0.5293\n",
      "Epoch [564/1000], Loss: 0.5308\n",
      "Epoch [565/1000], Loss: 0.5285\n",
      "Epoch [566/1000], Loss: 0.5223\n",
      "Epoch [567/1000], Loss: 0.5277\n",
      "Epoch [568/1000], Loss: 0.5300\n",
      "Epoch [569/1000], Loss: 0.5270\n",
      "Epoch [570/1000], Loss: 0.5339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [571/1000], Loss: 0.5262\n",
      "Epoch [572/1000], Loss: 0.5285\n",
      "Epoch [573/1000], Loss: 0.5270\n",
      "Epoch [574/1000], Loss: 0.5293\n",
      "Epoch [575/1000], Loss: 0.5239\n",
      "Epoch [576/1000], Loss: 0.5316\n",
      "Epoch [577/1000], Loss: 0.5285\n",
      "Epoch [578/1000], Loss: 0.5270\n",
      "Epoch [579/1000], Loss: 0.5331\n",
      "Epoch [580/1000], Loss: 0.5239\n",
      "Epoch [581/1000], Loss: 0.5277\n",
      "Epoch [582/1000], Loss: 0.5300\n",
      "Epoch [583/1000], Loss: 0.5270\n",
      "Epoch [584/1000], Loss: 0.5270\n",
      "Epoch [585/1000], Loss: 0.5262\n",
      "Epoch [586/1000], Loss: 0.5223\n",
      "Epoch [587/1000], Loss: 0.5239\n",
      "Epoch [588/1000], Loss: 0.5262\n",
      "Epoch [589/1000], Loss: 0.5316\n",
      "Epoch [590/1000], Loss: 0.5293\n",
      "Epoch [591/1000], Loss: 0.5262\n",
      "Epoch [592/1000], Loss: 0.5285\n",
      "Epoch [593/1000], Loss: 0.5308\n",
      "Epoch [594/1000], Loss: 0.5231\n",
      "Epoch [595/1000], Loss: 0.5285\n",
      "Epoch [596/1000], Loss: 0.5324\n",
      "Epoch [597/1000], Loss: 0.5277\n",
      "Epoch [598/1000], Loss: 0.5285\n",
      "Epoch [599/1000], Loss: 0.5262\n",
      "Epoch [600/1000], Loss: 0.5293\n",
      "Epoch [601/1000], Loss: 0.5239\n",
      "Epoch [602/1000], Loss: 0.5308\n",
      "Epoch [603/1000], Loss: 0.5324\n",
      "Epoch [604/1000], Loss: 0.5285\n",
      "Epoch [605/1000], Loss: 0.5370\n",
      "Epoch [606/1000], Loss: 0.5293\n",
      "Epoch [607/1000], Loss: 0.5300\n",
      "Epoch [608/1000], Loss: 0.5331\n",
      "Epoch [609/1000], Loss: 0.5316\n",
      "Epoch [610/1000], Loss: 0.5293\n",
      "Epoch [611/1000], Loss: 0.5262\n",
      "Epoch [612/1000], Loss: 0.5293\n",
      "Epoch [613/1000], Loss: 0.5285\n",
      "Epoch [614/1000], Loss: 0.5293\n",
      "Epoch [615/1000], Loss: 0.5293\n",
      "Epoch [616/1000], Loss: 0.5262\n",
      "Epoch [617/1000], Loss: 0.5270\n",
      "Epoch [618/1000], Loss: 0.5293\n",
      "Epoch [619/1000], Loss: 0.5246\n",
      "Epoch [620/1000], Loss: 0.5316\n",
      "Epoch [621/1000], Loss: 0.5223\n",
      "Epoch [622/1000], Loss: 0.5239\n",
      "Epoch [623/1000], Loss: 0.5270\n",
      "Epoch [624/1000], Loss: 0.5270\n",
      "Epoch [625/1000], Loss: 0.5270\n",
      "Epoch [626/1000], Loss: 0.5331\n",
      "Epoch [627/1000], Loss: 0.5339\n",
      "Epoch [628/1000], Loss: 0.5254\n",
      "Epoch [629/1000], Loss: 0.5239\n",
      "Epoch [630/1000], Loss: 0.5277\n",
      "Epoch [631/1000], Loss: 0.5324\n",
      "Epoch [632/1000], Loss: 0.5339\n",
      "Epoch [633/1000], Loss: 0.5270\n",
      "Epoch [634/1000], Loss: 0.5285\n",
      "Epoch [635/1000], Loss: 0.5308\n",
      "Epoch [636/1000], Loss: 0.5347\n",
      "Epoch [637/1000], Loss: 0.5246\n",
      "Epoch [638/1000], Loss: 0.5300\n",
      "Epoch [639/1000], Loss: 0.5270\n",
      "Epoch [640/1000], Loss: 0.5293\n",
      "Epoch [641/1000], Loss: 0.5331\n",
      "Epoch [642/1000], Loss: 0.5246\n",
      "Epoch [643/1000], Loss: 0.5270\n",
      "Epoch [644/1000], Loss: 0.5262\n",
      "Epoch [645/1000], Loss: 0.5293\n",
      "Epoch [646/1000], Loss: 0.5308\n",
      "Epoch [647/1000], Loss: 0.5277\n",
      "Epoch [648/1000], Loss: 0.5293\n",
      "Epoch [649/1000], Loss: 0.5254\n",
      "Epoch [650/1000], Loss: 0.5270\n",
      "Epoch [651/1000], Loss: 0.5285\n",
      "Epoch [652/1000], Loss: 0.5300\n",
      "Epoch [653/1000], Loss: 0.5270\n",
      "Epoch [654/1000], Loss: 0.5316\n",
      "Epoch [655/1000], Loss: 0.5262\n",
      "Epoch [656/1000], Loss: 0.5246\n",
      "Epoch [657/1000], Loss: 0.5293\n",
      "Epoch [658/1000], Loss: 0.5308\n",
      "Epoch [659/1000], Loss: 0.5316\n",
      "Epoch [660/1000], Loss: 0.5285\n",
      "Epoch [661/1000], Loss: 0.5316\n",
      "Epoch [662/1000], Loss: 0.5277\n",
      "Epoch [663/1000], Loss: 0.5316\n",
      "Epoch [664/1000], Loss: 0.5300\n",
      "Epoch [665/1000], Loss: 0.5239\n",
      "Epoch [666/1000], Loss: 0.5293\n",
      "Epoch [667/1000], Loss: 0.5285\n",
      "Epoch [668/1000], Loss: 0.5285\n",
      "Epoch [669/1000], Loss: 0.5285\n",
      "Epoch [670/1000], Loss: 0.5277\n",
      "Epoch [671/1000], Loss: 0.5300\n",
      "Epoch [672/1000], Loss: 0.5293\n",
      "Epoch [673/1000], Loss: 0.5270\n",
      "Epoch [674/1000], Loss: 0.5254\n",
      "Epoch [675/1000], Loss: 0.5223\n",
      "Epoch [676/1000], Loss: 0.5285\n",
      "Epoch [677/1000], Loss: 0.5262\n",
      "Epoch [678/1000], Loss: 0.5316\n",
      "Epoch [679/1000], Loss: 0.5277\n",
      "Epoch [680/1000], Loss: 0.5254\n",
      "Epoch [681/1000], Loss: 0.5300\n",
      "Epoch [682/1000], Loss: 0.5324\n",
      "Epoch [683/1000], Loss: 0.5277\n",
      "Epoch [684/1000], Loss: 0.5231\n",
      "Epoch [685/1000], Loss: 0.5254\n",
      "Epoch [686/1000], Loss: 0.5277\n",
      "Epoch [687/1000], Loss: 0.5331\n",
      "Epoch [688/1000], Loss: 0.5347\n",
      "Epoch [689/1000], Loss: 0.5316\n",
      "Epoch [690/1000], Loss: 0.5231\n",
      "Epoch [691/1000], Loss: 0.5331\n",
      "Epoch [692/1000], Loss: 0.5285\n",
      "Epoch [693/1000], Loss: 0.5270\n",
      "Epoch [694/1000], Loss: 0.5354\n",
      "Epoch [695/1000], Loss: 0.5308\n",
      "Epoch [696/1000], Loss: 0.5262\n",
      "Epoch [697/1000], Loss: 0.5239\n",
      "Epoch [698/1000], Loss: 0.5277\n",
      "Epoch [699/1000], Loss: 0.5277\n",
      "Epoch [700/1000], Loss: 0.5300\n",
      "Epoch [701/1000], Loss: 0.5285\n",
      "Epoch [702/1000], Loss: 0.5300\n",
      "Epoch [703/1000], Loss: 0.5285\n",
      "Epoch [704/1000], Loss: 0.5324\n",
      "Epoch [705/1000], Loss: 0.5300\n",
      "Epoch [706/1000], Loss: 0.5316\n",
      "Epoch [707/1000], Loss: 0.5277\n",
      "Epoch [708/1000], Loss: 0.5316\n",
      "Epoch [709/1000], Loss: 0.5308\n",
      "Epoch [710/1000], Loss: 0.5293\n",
      "Epoch [711/1000], Loss: 0.5270\n",
      "Epoch [712/1000], Loss: 0.5347\n",
      "Epoch [713/1000], Loss: 0.5324\n",
      "Epoch [714/1000], Loss: 0.5285\n",
      "Epoch [715/1000], Loss: 0.5285\n",
      "Epoch [716/1000], Loss: 0.5231\n",
      "Epoch [717/1000], Loss: 0.5270\n",
      "Epoch [718/1000], Loss: 0.5270\n",
      "Epoch [719/1000], Loss: 0.5293\n",
      "Epoch [720/1000], Loss: 0.5300\n",
      "Epoch [721/1000], Loss: 0.5300\n",
      "Epoch [722/1000], Loss: 0.5208\n",
      "Epoch [723/1000], Loss: 0.5285\n",
      "Epoch [724/1000], Loss: 0.5324\n",
      "Epoch [725/1000], Loss: 0.5308\n",
      "Epoch [726/1000], Loss: 0.5300\n",
      "Epoch [727/1000], Loss: 0.5270\n",
      "Epoch [728/1000], Loss: 0.5308\n",
      "Epoch [729/1000], Loss: 0.5239\n",
      "Epoch [730/1000], Loss: 0.5270\n",
      "Epoch [731/1000], Loss: 0.5270\n",
      "Epoch [732/1000], Loss: 0.5262\n",
      "Epoch [733/1000], Loss: 0.5339\n",
      "Epoch [734/1000], Loss: 0.5300\n",
      "Epoch [735/1000], Loss: 0.5316\n",
      "Epoch [736/1000], Loss: 0.5293\n",
      "Epoch [737/1000], Loss: 0.5324\n",
      "Epoch [738/1000], Loss: 0.5231\n",
      "Epoch [739/1000], Loss: 0.5246\n",
      "Epoch [740/1000], Loss: 0.5216\n",
      "Epoch [741/1000], Loss: 0.5270\n",
      "Epoch [742/1000], Loss: 0.5293\n",
      "Epoch [743/1000], Loss: 0.5270\n",
      "Epoch [744/1000], Loss: 0.5308\n",
      "Epoch [745/1000], Loss: 0.5262\n",
      "Epoch [746/1000], Loss: 0.5316\n",
      "Epoch [747/1000], Loss: 0.5285\n",
      "Epoch [748/1000], Loss: 0.5254\n",
      "Epoch [749/1000], Loss: 0.5331\n",
      "Epoch [750/1000], Loss: 0.5270\n",
      "Epoch [751/1000], Loss: 0.5208\n",
      "Epoch [752/1000], Loss: 0.5331\n",
      "Epoch [753/1000], Loss: 0.5246\n",
      "Epoch [754/1000], Loss: 0.5324\n",
      "Epoch [755/1000], Loss: 0.5270\n",
      "Epoch [756/1000], Loss: 0.5223\n",
      "Epoch [757/1000], Loss: 0.5293\n",
      "Epoch [758/1000], Loss: 0.5270\n",
      "Epoch [759/1000], Loss: 0.5216\n",
      "Epoch [760/1000], Loss: 0.5254\n",
      "Epoch [761/1000], Loss: 0.5285\n",
      "Epoch [762/1000], Loss: 0.5308\n",
      "Epoch [763/1000], Loss: 0.5293\n",
      "Epoch [764/1000], Loss: 0.5324\n",
      "Epoch [765/1000], Loss: 0.5293\n",
      "Epoch [766/1000], Loss: 0.5254\n",
      "Epoch [767/1000], Loss: 0.5270\n",
      "Epoch [768/1000], Loss: 0.5300\n",
      "Epoch [769/1000], Loss: 0.5223\n",
      "Epoch [770/1000], Loss: 0.5246\n",
      "Epoch [771/1000], Loss: 0.5270\n",
      "Epoch [772/1000], Loss: 0.5231\n",
      "Epoch [773/1000], Loss: 0.5262\n",
      "Epoch [774/1000], Loss: 0.5293\n",
      "Epoch [775/1000], Loss: 0.5331\n",
      "Epoch [776/1000], Loss: 0.5300\n",
      "Epoch [777/1000], Loss: 0.5285\n",
      "Epoch [778/1000], Loss: 0.5246\n",
      "Epoch [779/1000], Loss: 0.5262\n",
      "Epoch [780/1000], Loss: 0.5300\n",
      "Epoch [781/1000], Loss: 0.5285\n",
      "Epoch [782/1000], Loss: 0.5300\n",
      "Epoch [783/1000], Loss: 0.5285\n",
      "Epoch [784/1000], Loss: 0.5300\n",
      "Epoch [785/1000], Loss: 0.5324\n",
      "Epoch [786/1000], Loss: 0.5277\n",
      "Epoch [787/1000], Loss: 0.5308\n",
      "Epoch [788/1000], Loss: 0.5231\n",
      "Epoch [789/1000], Loss: 0.5339\n",
      "Epoch [790/1000], Loss: 0.5216\n",
      "Epoch [791/1000], Loss: 0.5262\n",
      "Epoch [792/1000], Loss: 0.5254\n",
      "Epoch [793/1000], Loss: 0.5246\n",
      "Epoch [794/1000], Loss: 0.5239\n",
      "Epoch [795/1000], Loss: 0.5239\n",
      "Epoch [796/1000], Loss: 0.5347\n",
      "Epoch [797/1000], Loss: 0.5316\n",
      "Epoch [798/1000], Loss: 0.5308\n",
      "Epoch [799/1000], Loss: 0.5277\n",
      "Epoch [800/1000], Loss: 0.5293\n",
      "Epoch [801/1000], Loss: 0.5285\n",
      "Epoch [802/1000], Loss: 0.5293\n",
      "Epoch [803/1000], Loss: 0.5308\n",
      "Epoch [804/1000], Loss: 0.5324\n",
      "Epoch [805/1000], Loss: 0.5324\n",
      "Epoch [806/1000], Loss: 0.5254\n",
      "Epoch [807/1000], Loss: 0.5308\n",
      "Epoch [808/1000], Loss: 0.5324\n",
      "Epoch [809/1000], Loss: 0.5262\n",
      "Epoch [810/1000], Loss: 0.5270\n",
      "Epoch [811/1000], Loss: 0.5231\n",
      "Epoch [812/1000], Loss: 0.5324\n",
      "Epoch [813/1000], Loss: 0.5262\n",
      "Epoch [814/1000], Loss: 0.5270\n",
      "Epoch [815/1000], Loss: 0.5262\n",
      "Epoch [816/1000], Loss: 0.5223\n",
      "Epoch [817/1000], Loss: 0.5277\n",
      "Epoch [818/1000], Loss: 0.5300\n",
      "Epoch [819/1000], Loss: 0.5347\n",
      "Epoch [820/1000], Loss: 0.5223\n",
      "Epoch [821/1000], Loss: 0.5316\n",
      "Epoch [822/1000], Loss: 0.5239\n",
      "Epoch [823/1000], Loss: 0.5223\n",
      "Epoch [824/1000], Loss: 0.5270\n",
      "Epoch [825/1000], Loss: 0.5223\n",
      "Epoch [826/1000], Loss: 0.5246\n",
      "Epoch [827/1000], Loss: 0.5246\n",
      "Epoch [828/1000], Loss: 0.5293\n",
      "Epoch [829/1000], Loss: 0.5262\n",
      "Epoch [830/1000], Loss: 0.5293\n",
      "Epoch [831/1000], Loss: 0.5254\n",
      "Epoch [832/1000], Loss: 0.5277\n",
      "Epoch [833/1000], Loss: 0.5331\n",
      "Epoch [834/1000], Loss: 0.5285\n",
      "Epoch [835/1000], Loss: 0.5270\n",
      "Epoch [836/1000], Loss: 0.5324\n",
      "Epoch [837/1000], Loss: 0.5285\n",
      "Epoch [838/1000], Loss: 0.5324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [839/1000], Loss: 0.5285\n",
      "Epoch [840/1000], Loss: 0.5270\n",
      "Epoch [841/1000], Loss: 0.5331\n",
      "Epoch [842/1000], Loss: 0.5254\n",
      "Epoch [843/1000], Loss: 0.5254\n",
      "Epoch [844/1000], Loss: 0.5300\n",
      "Epoch [845/1000], Loss: 0.5246\n",
      "Epoch [846/1000], Loss: 0.5300\n",
      "Epoch [847/1000], Loss: 0.5262\n",
      "Epoch [848/1000], Loss: 0.5254\n",
      "Epoch [849/1000], Loss: 0.5277\n",
      "Epoch [850/1000], Loss: 0.5270\n",
      "Epoch [851/1000], Loss: 0.5270\n",
      "Epoch [852/1000], Loss: 0.5339\n",
      "Epoch [853/1000], Loss: 0.5285\n",
      "Epoch [854/1000], Loss: 0.5262\n",
      "Epoch [855/1000], Loss: 0.5331\n",
      "Epoch [856/1000], Loss: 0.5285\n",
      "Epoch [857/1000], Loss: 0.5339\n",
      "Epoch [858/1000], Loss: 0.5285\n",
      "Epoch [859/1000], Loss: 0.5293\n",
      "Epoch [860/1000], Loss: 0.5331\n",
      "Epoch [861/1000], Loss: 0.5262\n",
      "Epoch [862/1000], Loss: 0.5262\n",
      "Epoch [863/1000], Loss: 0.5262\n",
      "Epoch [864/1000], Loss: 0.5293\n",
      "Epoch [865/1000], Loss: 0.5300\n",
      "Epoch [866/1000], Loss: 0.5216\n",
      "Epoch [867/1000], Loss: 0.5316\n",
      "Epoch [868/1000], Loss: 0.5300\n",
      "Epoch [869/1000], Loss: 0.5270\n",
      "Epoch [870/1000], Loss: 0.5277\n",
      "Epoch [871/1000], Loss: 0.5324\n",
      "Epoch [872/1000], Loss: 0.5316\n",
      "Epoch [873/1000], Loss: 0.5300\n",
      "Epoch [874/1000], Loss: 0.5362\n",
      "Epoch [875/1000], Loss: 0.5223\n",
      "Epoch [876/1000], Loss: 0.5254\n",
      "Epoch [877/1000], Loss: 0.5277\n",
      "Epoch [878/1000], Loss: 0.5231\n",
      "Epoch [879/1000], Loss: 0.5254\n",
      "Epoch [880/1000], Loss: 0.5339\n",
      "Epoch [881/1000], Loss: 0.5277\n",
      "Epoch [882/1000], Loss: 0.5277\n",
      "Epoch [883/1000], Loss: 0.5300\n",
      "Epoch [884/1000], Loss: 0.5239\n",
      "Epoch [885/1000], Loss: 0.5254\n",
      "Epoch [886/1000], Loss: 0.5316\n",
      "Epoch [887/1000], Loss: 0.5293\n",
      "Epoch [888/1000], Loss: 0.5308\n",
      "Epoch [889/1000], Loss: 0.5293\n",
      "Epoch [890/1000], Loss: 0.5362\n",
      "Epoch [891/1000], Loss: 0.5277\n",
      "Epoch [892/1000], Loss: 0.5277\n",
      "Epoch [893/1000], Loss: 0.5254\n",
      "Epoch [894/1000], Loss: 0.5324\n",
      "Epoch [895/1000], Loss: 0.5285\n",
      "Epoch [896/1000], Loss: 0.5239\n",
      "Epoch [897/1000], Loss: 0.5339\n",
      "Epoch [898/1000], Loss: 0.5262\n",
      "Epoch [899/1000], Loss: 0.5300\n",
      "Epoch [900/1000], Loss: 0.5308\n",
      "Epoch [901/1000], Loss: 0.5262\n",
      "Epoch [902/1000], Loss: 0.5254\n",
      "Epoch [903/1000], Loss: 0.5293\n",
      "Epoch [904/1000], Loss: 0.5293\n",
      "Epoch [905/1000], Loss: 0.5324\n",
      "Epoch [906/1000], Loss: 0.5285\n",
      "Epoch [907/1000], Loss: 0.5285\n",
      "Epoch [908/1000], Loss: 0.5293\n",
      "Epoch [909/1000], Loss: 0.5285\n",
      "Epoch [910/1000], Loss: 0.5208\n",
      "Epoch [911/1000], Loss: 0.5316\n",
      "Epoch [912/1000], Loss: 0.5300\n",
      "Epoch [913/1000], Loss: 0.5262\n",
      "Epoch [914/1000], Loss: 0.5254\n",
      "Epoch [915/1000], Loss: 0.5300\n",
      "Epoch [916/1000], Loss: 0.5293\n",
      "Epoch [917/1000], Loss: 0.5316\n",
      "Epoch [918/1000], Loss: 0.5239\n",
      "Epoch [919/1000], Loss: 0.5300\n",
      "Epoch [920/1000], Loss: 0.5331\n",
      "Epoch [921/1000], Loss: 0.5308\n",
      "Epoch [922/1000], Loss: 0.5339\n",
      "Epoch [923/1000], Loss: 0.5308\n",
      "Epoch [924/1000], Loss: 0.5308\n",
      "Epoch [925/1000], Loss: 0.5277\n",
      "Epoch [926/1000], Loss: 0.5308\n",
      "Epoch [927/1000], Loss: 0.5293\n",
      "Epoch [928/1000], Loss: 0.5285\n",
      "Epoch [929/1000], Loss: 0.5262\n",
      "Epoch [930/1000], Loss: 0.5362\n",
      "Epoch [931/1000], Loss: 0.5277\n",
      "Epoch [932/1000], Loss: 0.5300\n",
      "Epoch [933/1000], Loss: 0.5246\n",
      "Epoch [934/1000], Loss: 0.5285\n",
      "Epoch [935/1000], Loss: 0.5285\n",
      "Epoch [936/1000], Loss: 0.5331\n",
      "Epoch [937/1000], Loss: 0.5254\n",
      "Epoch [938/1000], Loss: 0.5316\n",
      "Epoch [939/1000], Loss: 0.5277\n",
      "Epoch [940/1000], Loss: 0.5246\n",
      "Epoch [941/1000], Loss: 0.5316\n",
      "Epoch [942/1000], Loss: 0.5262\n",
      "Epoch [943/1000], Loss: 0.5331\n",
      "Epoch [944/1000], Loss: 0.5285\n",
      "Epoch [945/1000], Loss: 0.5254\n",
      "Epoch [946/1000], Loss: 0.5354\n",
      "Epoch [947/1000], Loss: 0.5347\n",
      "Epoch [948/1000], Loss: 0.5293\n",
      "Epoch [949/1000], Loss: 0.5331\n",
      "Epoch [950/1000], Loss: 0.5254\n",
      "Epoch [951/1000], Loss: 0.5293\n",
      "Epoch [952/1000], Loss: 0.5277\n",
      "Epoch [953/1000], Loss: 0.5308\n",
      "Epoch [954/1000], Loss: 0.5308\n",
      "Epoch [955/1000], Loss: 0.5331\n",
      "Epoch [956/1000], Loss: 0.5293\n",
      "Epoch [957/1000], Loss: 0.5239\n",
      "Epoch [958/1000], Loss: 0.5362\n",
      "Epoch [959/1000], Loss: 0.5270\n",
      "Epoch [960/1000], Loss: 0.5262\n",
      "Epoch [961/1000], Loss: 0.5254\n",
      "Epoch [962/1000], Loss: 0.5254\n",
      "Epoch [963/1000], Loss: 0.5285\n",
      "Epoch [964/1000], Loss: 0.5270\n",
      "Epoch [965/1000], Loss: 0.5270\n",
      "Epoch [966/1000], Loss: 0.5362\n",
      "Epoch [967/1000], Loss: 0.5285\n",
      "Epoch [968/1000], Loss: 0.5270\n",
      "Epoch [969/1000], Loss: 0.5285\n",
      "Epoch [970/1000], Loss: 0.5262\n",
      "Epoch [971/1000], Loss: 0.5270\n",
      "Epoch [972/1000], Loss: 0.5300\n",
      "Epoch [973/1000], Loss: 0.5300\n",
      "Epoch [974/1000], Loss: 0.5285\n",
      "Epoch [975/1000], Loss: 0.5239\n",
      "Epoch [976/1000], Loss: 0.5331\n",
      "Epoch [977/1000], Loss: 0.5293\n",
      "Epoch [978/1000], Loss: 0.5270\n",
      "Epoch [979/1000], Loss: 0.5308\n",
      "Epoch [980/1000], Loss: 0.5270\n",
      "Epoch [981/1000], Loss: 0.5223\n",
      "Epoch [982/1000], Loss: 0.5270\n",
      "Epoch [983/1000], Loss: 0.5308\n",
      "Epoch [984/1000], Loss: 0.5324\n",
      "Epoch [985/1000], Loss: 0.5277\n",
      "Epoch [986/1000], Loss: 0.5354\n",
      "Epoch [987/1000], Loss: 0.5262\n",
      "Epoch [988/1000], Loss: 0.5331\n",
      "Epoch [989/1000], Loss: 0.5347\n",
      "Epoch [990/1000], Loss: 0.5270\n",
      "Epoch [991/1000], Loss: 0.5254\n",
      "Epoch [992/1000], Loss: 0.5277\n",
      "Epoch [993/1000], Loss: 0.5347\n",
      "Epoch [994/1000], Loss: 0.5270\n",
      "Epoch [995/1000], Loss: 0.5300\n",
      "Epoch [996/1000], Loss: 0.5216\n",
      "Epoch [997/1000], Loss: 0.5254\n",
      "Epoch [998/1000], Loss: 0.5285\n",
      "Epoch [999/1000], Loss: 0.5270\n",
      "Epoch [1000/1000], Loss: 0.5262\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 302, lr :10.0, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.5087\n",
      "Epoch [2/1000], Loss: 0.5285\n",
      "Epoch [3/1000], Loss: 0.5300\n",
      "Epoch [4/1000], Loss: 0.5377\n",
      "Epoch [5/1000], Loss: 0.5285\n",
      "Epoch [6/1000], Loss: 0.5254\n",
      "Epoch [7/1000], Loss: 0.5300\n",
      "Epoch [8/1000], Loss: 0.5200\n",
      "Epoch [9/1000], Loss: 0.5231\n",
      "Epoch [10/1000], Loss: 0.5277\n",
      "Epoch [11/1000], Loss: 0.5277\n",
      "Epoch [12/1000], Loss: 0.5254\n",
      "Epoch [13/1000], Loss: 0.5277\n",
      "Epoch [14/1000], Loss: 0.5293\n",
      "Epoch [15/1000], Loss: 0.5285\n",
      "Epoch [16/1000], Loss: 0.5223\n",
      "Epoch [17/1000], Loss: 0.5285\n",
      "Epoch [18/1000], Loss: 0.5316\n",
      "Epoch [19/1000], Loss: 0.5308\n",
      "Epoch [20/1000], Loss: 0.5262\n",
      "Epoch [21/1000], Loss: 0.5324\n",
      "Epoch [22/1000], Loss: 0.5254\n",
      "Epoch [23/1000], Loss: 0.5262\n",
      "Epoch [24/1000], Loss: 0.5254\n",
      "Epoch [25/1000], Loss: 0.5254\n",
      "Epoch [26/1000], Loss: 0.5285\n",
      "Epoch [27/1000], Loss: 0.5285\n",
      "Epoch [28/1000], Loss: 0.5254\n",
      "Epoch [29/1000], Loss: 0.5270\n",
      "Epoch [30/1000], Loss: 0.5293\n",
      "Epoch [31/1000], Loss: 0.5293\n",
      "Epoch [32/1000], Loss: 0.5293\n",
      "Epoch [33/1000], Loss: 0.5324\n",
      "Epoch [34/1000], Loss: 0.5270\n",
      "Epoch [35/1000], Loss: 0.5331\n",
      "Epoch [36/1000], Loss: 0.5239\n",
      "Epoch [37/1000], Loss: 0.5300\n",
      "Epoch [38/1000], Loss: 0.5308\n",
      "Epoch [39/1000], Loss: 0.5254\n",
      "Epoch [40/1000], Loss: 0.5293\n",
      "Epoch [41/1000], Loss: 0.5300\n",
      "Epoch [42/1000], Loss: 0.5300\n",
      "Epoch [43/1000], Loss: 0.5277\n",
      "Epoch [44/1000], Loss: 0.5293\n",
      "Epoch [45/1000], Loss: 0.5270\n",
      "Epoch [46/1000], Loss: 0.5316\n",
      "Epoch [47/1000], Loss: 0.5254\n",
      "Epoch [48/1000], Loss: 0.5308\n",
      "Epoch [49/1000], Loss: 0.5277\n",
      "Epoch [50/1000], Loss: 0.5285\n",
      "Epoch [51/1000], Loss: 0.5254\n",
      "Epoch [52/1000], Loss: 0.5270\n",
      "Epoch [53/1000], Loss: 0.5239\n",
      "Epoch [54/1000], Loss: 0.5270\n",
      "Epoch [55/1000], Loss: 0.5308\n",
      "Epoch [56/1000], Loss: 0.5270\n",
      "Epoch [57/1000], Loss: 0.5270\n",
      "Epoch [58/1000], Loss: 0.5324\n",
      "Epoch [59/1000], Loss: 0.5254\n",
      "Epoch [60/1000], Loss: 0.5300\n",
      "Epoch [61/1000], Loss: 0.5277\n",
      "Epoch [62/1000], Loss: 0.5277\n",
      "Epoch [63/1000], Loss: 0.5300\n",
      "Epoch [64/1000], Loss: 0.5324\n",
      "Epoch [65/1000], Loss: 0.5285\n",
      "Epoch [66/1000], Loss: 0.5347\n",
      "Epoch [67/1000], Loss: 0.5277\n",
      "Epoch [68/1000], Loss: 0.5223\n",
      "Epoch [69/1000], Loss: 0.5308\n",
      "Epoch [70/1000], Loss: 0.5300\n",
      "Epoch [71/1000], Loss: 0.5300\n",
      "Epoch [72/1000], Loss: 0.5239\n",
      "Epoch [73/1000], Loss: 0.5293\n",
      "Epoch [74/1000], Loss: 0.5324\n",
      "Epoch [75/1000], Loss: 0.5246\n",
      "Epoch [76/1000], Loss: 0.5293\n",
      "Epoch [77/1000], Loss: 0.5285\n",
      "Epoch [78/1000], Loss: 0.5300\n",
      "Epoch [79/1000], Loss: 0.5316\n",
      "Epoch [80/1000], Loss: 0.5277\n",
      "Epoch [81/1000], Loss: 0.5293\n",
      "Epoch [82/1000], Loss: 0.5285\n",
      "Epoch [83/1000], Loss: 0.5293\n",
      "Epoch [84/1000], Loss: 0.5246\n",
      "Epoch [85/1000], Loss: 0.5293\n",
      "Epoch [86/1000], Loss: 0.5293\n",
      "Epoch [87/1000], Loss: 0.5293\n",
      "Epoch [88/1000], Loss: 0.5239\n",
      "Epoch [89/1000], Loss: 0.5239\n",
      "Epoch [90/1000], Loss: 0.5285\n",
      "Epoch [91/1000], Loss: 0.5316\n",
      "Epoch [92/1000], Loss: 0.5324\n",
      "Epoch [93/1000], Loss: 0.5308\n",
      "Epoch [94/1000], Loss: 0.5300\n",
      "Epoch [95/1000], Loss: 0.5324\n",
      "Epoch [96/1000], Loss: 0.5339\n",
      "Epoch [97/1000], Loss: 0.5300\n",
      "Epoch [98/1000], Loss: 0.5285\n",
      "Epoch [99/1000], Loss: 0.5246\n",
      "Epoch [100/1000], Loss: 0.5285\n",
      "Epoch [101/1000], Loss: 0.5277\n",
      "Epoch [102/1000], Loss: 0.5300\n",
      "Epoch [103/1000], Loss: 0.5277\n",
      "Epoch [104/1000], Loss: 0.5277\n",
      "Epoch [105/1000], Loss: 0.5231\n",
      "Epoch [106/1000], Loss: 0.5285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [107/1000], Loss: 0.5262\n",
      "Epoch [108/1000], Loss: 0.5293\n",
      "Epoch [109/1000], Loss: 0.5200\n",
      "Epoch [110/1000], Loss: 0.5324\n",
      "Epoch [111/1000], Loss: 0.5193\n",
      "Epoch [112/1000], Loss: 0.5277\n",
      "Epoch [113/1000], Loss: 0.5254\n",
      "Epoch [114/1000], Loss: 0.5231\n",
      "Epoch [115/1000], Loss: 0.5300\n",
      "Epoch [116/1000], Loss: 0.5293\n",
      "Epoch [117/1000], Loss: 0.5316\n",
      "Epoch [118/1000], Loss: 0.5270\n",
      "Epoch [119/1000], Loss: 0.5316\n",
      "Epoch [120/1000], Loss: 0.5262\n",
      "Epoch [121/1000], Loss: 0.5277\n",
      "Epoch [122/1000], Loss: 0.5231\n",
      "Epoch [123/1000], Loss: 0.5285\n",
      "Epoch [124/1000], Loss: 0.5254\n",
      "Epoch [125/1000], Loss: 0.5262\n",
      "Epoch [126/1000], Loss: 0.5324\n",
      "Epoch [127/1000], Loss: 0.5339\n",
      "Epoch [128/1000], Loss: 0.5293\n",
      "Epoch [129/1000], Loss: 0.5246\n",
      "Epoch [130/1000], Loss: 0.5300\n",
      "Epoch [131/1000], Loss: 0.5254\n",
      "Epoch [132/1000], Loss: 0.5293\n",
      "Epoch [133/1000], Loss: 0.5293\n",
      "Epoch [134/1000], Loss: 0.5316\n",
      "Epoch [135/1000], Loss: 0.5316\n",
      "Epoch [136/1000], Loss: 0.5262\n",
      "Epoch [137/1000], Loss: 0.5324\n",
      "Epoch [138/1000], Loss: 0.5308\n",
      "Epoch [139/1000], Loss: 0.5347\n",
      "Epoch [140/1000], Loss: 0.5285\n",
      "Epoch [141/1000], Loss: 0.5277\n",
      "Epoch [142/1000], Loss: 0.5339\n",
      "Epoch [143/1000], Loss: 0.5293\n",
      "Epoch [144/1000], Loss: 0.5262\n",
      "Epoch [145/1000], Loss: 0.5293\n",
      "Epoch [146/1000], Loss: 0.5246\n",
      "Epoch [147/1000], Loss: 0.5285\n",
      "Epoch [148/1000], Loss: 0.5300\n",
      "Epoch [149/1000], Loss: 0.5354\n",
      "Epoch [150/1000], Loss: 0.5254\n",
      "Epoch [151/1000], Loss: 0.5277\n",
      "Epoch [152/1000], Loss: 0.5277\n",
      "Epoch [153/1000], Loss: 0.5277\n",
      "Epoch [154/1000], Loss: 0.5231\n",
      "Epoch [155/1000], Loss: 0.5331\n",
      "Epoch [156/1000], Loss: 0.5293\n",
      "Epoch [157/1000], Loss: 0.5308\n",
      "Epoch [158/1000], Loss: 0.5231\n",
      "Epoch [159/1000], Loss: 0.5308\n",
      "Epoch [160/1000], Loss: 0.5316\n",
      "Epoch [161/1000], Loss: 0.5300\n",
      "Epoch [162/1000], Loss: 0.5246\n",
      "Epoch [163/1000], Loss: 0.5285\n",
      "Epoch [164/1000], Loss: 0.5231\n",
      "Epoch [165/1000], Loss: 0.5293\n",
      "Epoch [166/1000], Loss: 0.5316\n",
      "Epoch [167/1000], Loss: 0.5293\n",
      "Epoch [168/1000], Loss: 0.5331\n",
      "Epoch [169/1000], Loss: 0.5300\n",
      "Epoch [170/1000], Loss: 0.5277\n",
      "Epoch [171/1000], Loss: 0.5293\n",
      "Epoch [172/1000], Loss: 0.5285\n",
      "Epoch [173/1000], Loss: 0.5277\n",
      "Epoch [174/1000], Loss: 0.5331\n",
      "Epoch [175/1000], Loss: 0.5246\n",
      "Epoch [176/1000], Loss: 0.5270\n",
      "Epoch [177/1000], Loss: 0.5246\n",
      "Epoch [178/1000], Loss: 0.5254\n",
      "Epoch [179/1000], Loss: 0.5262\n",
      "Epoch [180/1000], Loss: 0.5270\n",
      "Epoch [181/1000], Loss: 0.5362\n",
      "Epoch [182/1000], Loss: 0.5316\n",
      "Epoch [183/1000], Loss: 0.5300\n",
      "Epoch [184/1000], Loss: 0.5316\n",
      "Epoch [185/1000], Loss: 0.5300\n",
      "Epoch [186/1000], Loss: 0.5316\n",
      "Epoch [187/1000], Loss: 0.5331\n",
      "Epoch [188/1000], Loss: 0.5285\n",
      "Epoch [189/1000], Loss: 0.5308\n",
      "Epoch [190/1000], Loss: 0.5246\n",
      "Epoch [191/1000], Loss: 0.5254\n",
      "Epoch [192/1000], Loss: 0.5270\n",
      "Epoch [193/1000], Loss: 0.5223\n",
      "Epoch [194/1000], Loss: 0.5300\n",
      "Epoch [195/1000], Loss: 0.5300\n",
      "Epoch [196/1000], Loss: 0.5324\n",
      "Epoch [197/1000], Loss: 0.5246\n",
      "Epoch [198/1000], Loss: 0.5293\n",
      "Epoch [199/1000], Loss: 0.5262\n",
      "Epoch [200/1000], Loss: 0.5293\n",
      "Epoch [201/1000], Loss: 0.5370\n",
      "Epoch [202/1000], Loss: 0.5254\n",
      "Epoch [203/1000], Loss: 0.5293\n",
      "Epoch [204/1000], Loss: 0.5308\n",
      "Epoch [205/1000], Loss: 0.5285\n",
      "Epoch [206/1000], Loss: 0.5324\n",
      "Epoch [207/1000], Loss: 0.5270\n",
      "Epoch [208/1000], Loss: 0.5347\n",
      "Epoch [209/1000], Loss: 0.5239\n",
      "Epoch [210/1000], Loss: 0.5285\n",
      "Epoch [211/1000], Loss: 0.5339\n",
      "Epoch [212/1000], Loss: 0.5231\n",
      "Epoch [213/1000], Loss: 0.5308\n",
      "Epoch [214/1000], Loss: 0.5300\n",
      "Epoch [215/1000], Loss: 0.5246\n",
      "Epoch [216/1000], Loss: 0.5285\n",
      "Epoch [217/1000], Loss: 0.5293\n",
      "Epoch [218/1000], Loss: 0.5262\n",
      "Epoch [219/1000], Loss: 0.5316\n",
      "Epoch [220/1000], Loss: 0.5285\n",
      "Epoch [221/1000], Loss: 0.5246\n",
      "Epoch [222/1000], Loss: 0.5254\n",
      "Epoch [223/1000], Loss: 0.5277\n",
      "Epoch [224/1000], Loss: 0.5324\n",
      "Epoch [225/1000], Loss: 0.5300\n",
      "Epoch [226/1000], Loss: 0.5324\n",
      "Epoch [227/1000], Loss: 0.5223\n",
      "Epoch [228/1000], Loss: 0.5254\n",
      "Epoch [229/1000], Loss: 0.5239\n",
      "Epoch [230/1000], Loss: 0.5316\n",
      "Epoch [231/1000], Loss: 0.5246\n",
      "Epoch [232/1000], Loss: 0.5246\n",
      "Epoch [233/1000], Loss: 0.5223\n",
      "Epoch [234/1000], Loss: 0.5254\n",
      "Epoch [235/1000], Loss: 0.5293\n",
      "Epoch [236/1000], Loss: 0.5370\n",
      "Epoch [237/1000], Loss: 0.5254\n",
      "Epoch [238/1000], Loss: 0.5277\n",
      "Epoch [239/1000], Loss: 0.5254\n",
      "Epoch [240/1000], Loss: 0.5316\n",
      "Epoch [241/1000], Loss: 0.5277\n",
      "Epoch [242/1000], Loss: 0.5308\n",
      "Epoch [243/1000], Loss: 0.5277\n",
      "Epoch [244/1000], Loss: 0.5300\n",
      "Epoch [245/1000], Loss: 0.5285\n",
      "Epoch [246/1000], Loss: 0.5293\n",
      "Epoch [247/1000], Loss: 0.5347\n",
      "Epoch [248/1000], Loss: 0.5262\n",
      "Epoch [249/1000], Loss: 0.5293\n",
      "Epoch [250/1000], Loss: 0.5324\n",
      "Epoch [251/1000], Loss: 0.5300\n",
      "Epoch [252/1000], Loss: 0.5208\n",
      "Epoch [253/1000], Loss: 0.5308\n",
      "Epoch [254/1000], Loss: 0.5308\n",
      "Epoch [255/1000], Loss: 0.5308\n",
      "Epoch [256/1000], Loss: 0.5308\n",
      "Epoch [257/1000], Loss: 0.5316\n",
      "Epoch [258/1000], Loss: 0.5246\n",
      "Epoch [259/1000], Loss: 0.5308\n",
      "Epoch [260/1000], Loss: 0.5308\n",
      "Epoch [261/1000], Loss: 0.5285\n",
      "Epoch [262/1000], Loss: 0.5293\n",
      "Epoch [263/1000], Loss: 0.5285\n",
      "Epoch [264/1000], Loss: 0.5308\n",
      "Epoch [265/1000], Loss: 0.5285\n",
      "Epoch [266/1000], Loss: 0.5270\n",
      "Epoch [267/1000], Loss: 0.5246\n",
      "Epoch [268/1000], Loss: 0.5331\n",
      "Epoch [269/1000], Loss: 0.5285\n",
      "Epoch [270/1000], Loss: 0.5223\n",
      "Epoch [271/1000], Loss: 0.5316\n",
      "Epoch [272/1000], Loss: 0.5331\n",
      "Epoch [273/1000], Loss: 0.5331\n",
      "Epoch [274/1000], Loss: 0.5300\n",
      "Epoch [275/1000], Loss: 0.5293\n",
      "Epoch [276/1000], Loss: 0.5308\n",
      "Epoch [277/1000], Loss: 0.5316\n",
      "Epoch [278/1000], Loss: 0.5246\n",
      "Epoch [279/1000], Loss: 0.5293\n",
      "Epoch [280/1000], Loss: 0.5270\n",
      "Epoch [281/1000], Loss: 0.5231\n",
      "Epoch [282/1000], Loss: 0.5254\n",
      "Epoch [283/1000], Loss: 0.5246\n",
      "Epoch [284/1000], Loss: 0.5246\n",
      "Epoch [285/1000], Loss: 0.5293\n",
      "Epoch [286/1000], Loss: 0.5262\n",
      "Epoch [287/1000], Loss: 0.5254\n",
      "Epoch [288/1000], Loss: 0.5308\n",
      "Epoch [289/1000], Loss: 0.5262\n",
      "Epoch [290/1000], Loss: 0.5316\n",
      "Epoch [291/1000], Loss: 0.5300\n",
      "Epoch [292/1000], Loss: 0.5262\n",
      "Epoch [293/1000], Loss: 0.5300\n",
      "Epoch [294/1000], Loss: 0.5277\n",
      "Epoch [295/1000], Loss: 0.5262\n",
      "Epoch [296/1000], Loss: 0.5300\n",
      "Epoch [297/1000], Loss: 0.5293\n",
      "Epoch [298/1000], Loss: 0.5377\n",
      "Epoch [299/1000], Loss: 0.5308\n",
      "Epoch [300/1000], Loss: 0.5285\n",
      "Epoch [301/1000], Loss: 0.5270\n",
      "Epoch [302/1000], Loss: 0.5293\n",
      "Epoch [303/1000], Loss: 0.5277\n",
      "Epoch [304/1000], Loss: 0.5293\n",
      "Epoch [305/1000], Loss: 0.5270\n",
      "Epoch [306/1000], Loss: 0.5285\n",
      "Epoch [307/1000], Loss: 0.5277\n",
      "Epoch [308/1000], Loss: 0.5293\n",
      "Epoch [309/1000], Loss: 0.5293\n",
      "Epoch [310/1000], Loss: 0.5362\n",
      "Epoch [311/1000], Loss: 0.5277\n",
      "Epoch [312/1000], Loss: 0.5254\n",
      "Epoch [313/1000], Loss: 0.5316\n",
      "Epoch [314/1000], Loss: 0.5324\n",
      "Epoch [315/1000], Loss: 0.5239\n",
      "Epoch [316/1000], Loss: 0.5262\n",
      "Epoch [317/1000], Loss: 0.5270\n",
      "Epoch [318/1000], Loss: 0.5339\n",
      "Epoch [319/1000], Loss: 0.5262\n",
      "Epoch [320/1000], Loss: 0.5216\n",
      "Epoch [321/1000], Loss: 0.5223\n",
      "Epoch [322/1000], Loss: 0.5246\n",
      "Epoch [323/1000], Loss: 0.5300\n",
      "Epoch [324/1000], Loss: 0.5300\n",
      "Epoch [325/1000], Loss: 0.5277\n",
      "Epoch [326/1000], Loss: 0.5308\n",
      "Epoch [327/1000], Loss: 0.5293\n",
      "Epoch [328/1000], Loss: 0.5254\n",
      "Epoch [329/1000], Loss: 0.5285\n",
      "Epoch [330/1000], Loss: 0.5231\n",
      "Epoch [331/1000], Loss: 0.5331\n",
      "Epoch [332/1000], Loss: 0.5208\n",
      "Epoch [333/1000], Loss: 0.5223\n",
      "Epoch [334/1000], Loss: 0.5262\n",
      "Epoch [335/1000], Loss: 0.5246\n",
      "Epoch [336/1000], Loss: 0.5308\n",
      "Epoch [337/1000], Loss: 0.5277\n",
      "Epoch [338/1000], Loss: 0.5254\n",
      "Epoch [339/1000], Loss: 0.5239\n",
      "Epoch [340/1000], Loss: 0.5216\n",
      "Epoch [341/1000], Loss: 0.5277\n",
      "Epoch [342/1000], Loss: 0.5293\n",
      "Epoch [343/1000], Loss: 0.5270\n",
      "Epoch [344/1000], Loss: 0.5308\n",
      "Epoch [345/1000], Loss: 0.5285\n",
      "Epoch [346/1000], Loss: 0.5300\n",
      "Epoch [347/1000], Loss: 0.5324\n",
      "Epoch [348/1000], Loss: 0.5354\n",
      "Epoch [349/1000], Loss: 0.5308\n",
      "Epoch [350/1000], Loss: 0.5339\n",
      "Epoch [351/1000], Loss: 0.5193\n",
      "Epoch [352/1000], Loss: 0.5277\n",
      "Epoch [353/1000], Loss: 0.5246\n",
      "Epoch [354/1000], Loss: 0.5277\n",
      "Epoch [355/1000], Loss: 0.5293\n",
      "Epoch [356/1000], Loss: 0.5270\n",
      "Epoch [357/1000], Loss: 0.5270\n",
      "Epoch [358/1000], Loss: 0.5254\n",
      "Epoch [359/1000], Loss: 0.5300\n",
      "Epoch [360/1000], Loss: 0.5285\n",
      "Epoch [361/1000], Loss: 0.5216\n",
      "Epoch [362/1000], Loss: 0.5277\n",
      "Epoch [363/1000], Loss: 0.5331\n",
      "Epoch [364/1000], Loss: 0.5262\n",
      "Epoch [365/1000], Loss: 0.5277\n",
      "Epoch [366/1000], Loss: 0.5324\n",
      "Epoch [367/1000], Loss: 0.5285\n",
      "Epoch [368/1000], Loss: 0.5262\n",
      "Epoch [369/1000], Loss: 0.5285\n",
      "Epoch [370/1000], Loss: 0.5324\n",
      "Epoch [371/1000], Loss: 0.5262\n",
      "Epoch [372/1000], Loss: 0.5262\n",
      "Epoch [373/1000], Loss: 0.5300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [374/1000], Loss: 0.5285\n",
      "Epoch [375/1000], Loss: 0.5270\n",
      "Epoch [376/1000], Loss: 0.5308\n",
      "Epoch [377/1000], Loss: 0.5300\n",
      "Epoch [378/1000], Loss: 0.5339\n",
      "Epoch [379/1000], Loss: 0.5254\n",
      "Epoch [380/1000], Loss: 0.5262\n",
      "Epoch [381/1000], Loss: 0.5270\n",
      "Epoch [382/1000], Loss: 0.5300\n",
      "Epoch [383/1000], Loss: 0.5277\n",
      "Epoch [384/1000], Loss: 0.5270\n",
      "Epoch [385/1000], Loss: 0.5262\n",
      "Epoch [386/1000], Loss: 0.5331\n",
      "Epoch [387/1000], Loss: 0.5308\n",
      "Epoch [388/1000], Loss: 0.5223\n",
      "Epoch [389/1000], Loss: 0.5300\n",
      "Epoch [390/1000], Loss: 0.5270\n",
      "Epoch [391/1000], Loss: 0.5293\n",
      "Epoch [392/1000], Loss: 0.5246\n",
      "Epoch [393/1000], Loss: 0.5347\n",
      "Epoch [394/1000], Loss: 0.5362\n",
      "Epoch [395/1000], Loss: 0.5300\n",
      "Epoch [396/1000], Loss: 0.5316\n",
      "Epoch [397/1000], Loss: 0.5308\n",
      "Epoch [398/1000], Loss: 0.5270\n",
      "Epoch [399/1000], Loss: 0.5270\n",
      "Epoch [400/1000], Loss: 0.5254\n",
      "Epoch [401/1000], Loss: 0.5254\n",
      "Epoch [402/1000], Loss: 0.5277\n",
      "Epoch [403/1000], Loss: 0.5285\n",
      "Epoch [404/1000], Loss: 0.5308\n",
      "Epoch [405/1000], Loss: 0.5277\n",
      "Epoch [406/1000], Loss: 0.5254\n",
      "Epoch [407/1000], Loss: 0.5331\n",
      "Epoch [408/1000], Loss: 0.5246\n",
      "Epoch [409/1000], Loss: 0.5270\n",
      "Epoch [410/1000], Loss: 0.5262\n",
      "Epoch [411/1000], Loss: 0.5331\n",
      "Epoch [412/1000], Loss: 0.5216\n",
      "Epoch [413/1000], Loss: 0.5316\n",
      "Epoch [414/1000], Loss: 0.5316\n",
      "Epoch [415/1000], Loss: 0.5246\n",
      "Epoch [416/1000], Loss: 0.5277\n",
      "Epoch [417/1000], Loss: 0.5285\n",
      "Epoch [418/1000], Loss: 0.5262\n",
      "Epoch [419/1000], Loss: 0.5277\n",
      "Epoch [420/1000], Loss: 0.5254\n",
      "Epoch [421/1000], Loss: 0.5300\n",
      "Epoch [422/1000], Loss: 0.5293\n",
      "Epoch [423/1000], Loss: 0.5308\n",
      "Epoch [424/1000], Loss: 0.5285\n",
      "Epoch [425/1000], Loss: 0.5316\n",
      "Epoch [426/1000], Loss: 0.5316\n",
      "Epoch [427/1000], Loss: 0.5285\n",
      "Epoch [428/1000], Loss: 0.5262\n",
      "Epoch [429/1000], Loss: 0.5347\n",
      "Epoch [430/1000], Loss: 0.5270\n",
      "Epoch [431/1000], Loss: 0.5262\n",
      "Epoch [432/1000], Loss: 0.5254\n",
      "Epoch [433/1000], Loss: 0.5239\n",
      "Epoch [434/1000], Loss: 0.5293\n",
      "Epoch [435/1000], Loss: 0.5293\n",
      "Epoch [436/1000], Loss: 0.5270\n",
      "Epoch [437/1000], Loss: 0.5293\n",
      "Epoch [438/1000], Loss: 0.5270\n",
      "Epoch [439/1000], Loss: 0.5239\n",
      "Epoch [440/1000], Loss: 0.5354\n",
      "Epoch [441/1000], Loss: 0.5324\n",
      "Epoch [442/1000], Loss: 0.5293\n",
      "Epoch [443/1000], Loss: 0.5270\n",
      "Epoch [444/1000], Loss: 0.5270\n",
      "Epoch [445/1000], Loss: 0.5285\n",
      "Epoch [446/1000], Loss: 0.5277\n",
      "Epoch [447/1000], Loss: 0.5293\n",
      "Epoch [448/1000], Loss: 0.5223\n",
      "Epoch [449/1000], Loss: 0.5277\n",
      "Epoch [450/1000], Loss: 0.5239\n",
      "Epoch [451/1000], Loss: 0.5223\n",
      "Epoch [452/1000], Loss: 0.5277\n",
      "Epoch [453/1000], Loss: 0.5270\n",
      "Epoch [454/1000], Loss: 0.5285\n",
      "Epoch [455/1000], Loss: 0.5277\n",
      "Epoch [456/1000], Loss: 0.5262\n",
      "Epoch [457/1000], Loss: 0.5331\n",
      "Epoch [458/1000], Loss: 0.5277\n",
      "Epoch [459/1000], Loss: 0.5316\n",
      "Epoch [460/1000], Loss: 0.5339\n",
      "Epoch [461/1000], Loss: 0.5254\n",
      "Epoch [462/1000], Loss: 0.5277\n",
      "Epoch [463/1000], Loss: 0.5293\n",
      "Epoch [464/1000], Loss: 0.5293\n",
      "Epoch [465/1000], Loss: 0.5293\n",
      "Epoch [466/1000], Loss: 0.5285\n",
      "Epoch [467/1000], Loss: 0.5316\n",
      "Epoch [468/1000], Loss: 0.5277\n",
      "Epoch [469/1000], Loss: 0.5285\n",
      "Epoch [470/1000], Loss: 0.5285\n",
      "Epoch [471/1000], Loss: 0.5285\n",
      "Epoch [472/1000], Loss: 0.5254\n",
      "Epoch [473/1000], Loss: 0.5270\n",
      "Epoch [474/1000], Loss: 0.5277\n",
      "Epoch [475/1000], Loss: 0.5270\n",
      "Epoch [476/1000], Loss: 0.5300\n",
      "Epoch [477/1000], Loss: 0.5262\n",
      "Epoch [478/1000], Loss: 0.5254\n",
      "Epoch [479/1000], Loss: 0.5331\n",
      "Epoch [480/1000], Loss: 0.5285\n",
      "Epoch [481/1000], Loss: 0.5277\n",
      "Epoch [482/1000], Loss: 0.5254\n",
      "Epoch [483/1000], Loss: 0.5285\n",
      "Epoch [484/1000], Loss: 0.5308\n",
      "Epoch [485/1000], Loss: 0.5331\n",
      "Epoch [486/1000], Loss: 0.5277\n",
      "Epoch [487/1000], Loss: 0.5300\n",
      "Epoch [488/1000], Loss: 0.5324\n",
      "Epoch [489/1000], Loss: 0.5270\n",
      "Epoch [490/1000], Loss: 0.5293\n",
      "Epoch [491/1000], Loss: 0.5308\n",
      "Epoch [492/1000], Loss: 0.5293\n",
      "Epoch [493/1000], Loss: 0.5246\n",
      "Epoch [494/1000], Loss: 0.5270\n",
      "Epoch [495/1000], Loss: 0.5277\n",
      "Epoch [496/1000], Loss: 0.5300\n",
      "Epoch [497/1000], Loss: 0.5270\n",
      "Epoch [498/1000], Loss: 0.5254\n",
      "Epoch [499/1000], Loss: 0.5293\n",
      "Epoch [500/1000], Loss: 0.5316\n",
      "Epoch [501/1000], Loss: 0.5324\n",
      "Epoch [502/1000], Loss: 0.5308\n",
      "Epoch [503/1000], Loss: 0.5293\n",
      "Epoch [504/1000], Loss: 0.5270\n",
      "Epoch [505/1000], Loss: 0.5270\n",
      "Epoch [506/1000], Loss: 0.5339\n",
      "Epoch [507/1000], Loss: 0.5308\n",
      "Epoch [508/1000], Loss: 0.5300\n",
      "Epoch [509/1000], Loss: 0.5308\n",
      "Epoch [510/1000], Loss: 0.5246\n",
      "Epoch [511/1000], Loss: 0.5254\n",
      "Epoch [512/1000], Loss: 0.5285\n",
      "Epoch [513/1000], Loss: 0.5262\n",
      "Epoch [514/1000], Loss: 0.5324\n",
      "Epoch [515/1000], Loss: 0.5277\n",
      "Epoch [516/1000], Loss: 0.5239\n",
      "Epoch [517/1000], Loss: 0.5254\n",
      "Epoch [518/1000], Loss: 0.5277\n",
      "Epoch [519/1000], Loss: 0.5254\n",
      "Epoch [520/1000], Loss: 0.5277\n",
      "Epoch [521/1000], Loss: 0.5293\n",
      "Epoch [522/1000], Loss: 0.5277\n",
      "Epoch [523/1000], Loss: 0.5300\n",
      "Epoch [524/1000], Loss: 0.5246\n",
      "Epoch [525/1000], Loss: 0.5262\n",
      "Epoch [526/1000], Loss: 0.5246\n",
      "Epoch [527/1000], Loss: 0.5239\n",
      "Epoch [528/1000], Loss: 0.5246\n",
      "Epoch [529/1000], Loss: 0.5300\n",
      "Epoch [530/1000], Loss: 0.5347\n",
      "Epoch [531/1000], Loss: 0.5270\n",
      "Epoch [532/1000], Loss: 0.5300\n",
      "Epoch [533/1000], Loss: 0.5239\n",
      "Epoch [534/1000], Loss: 0.5246\n",
      "Epoch [535/1000], Loss: 0.5277\n",
      "Epoch [536/1000], Loss: 0.5293\n",
      "Epoch [537/1000], Loss: 0.5277\n",
      "Epoch [538/1000], Loss: 0.5254\n",
      "Epoch [539/1000], Loss: 0.5324\n",
      "Epoch [540/1000], Loss: 0.5285\n",
      "Epoch [541/1000], Loss: 0.5285\n",
      "Epoch [542/1000], Loss: 0.5262\n",
      "Epoch [543/1000], Loss: 0.5324\n",
      "Epoch [544/1000], Loss: 0.5300\n",
      "Epoch [545/1000], Loss: 0.5254\n",
      "Epoch [546/1000], Loss: 0.5308\n",
      "Epoch [547/1000], Loss: 0.5277\n",
      "Epoch [548/1000], Loss: 0.5270\n",
      "Epoch [549/1000], Loss: 0.5324\n",
      "Epoch [550/1000], Loss: 0.5285\n",
      "Epoch [551/1000], Loss: 0.5262\n",
      "Epoch [552/1000], Loss: 0.5308\n",
      "Epoch [553/1000], Loss: 0.5239\n",
      "Epoch [554/1000], Loss: 0.5324\n",
      "Epoch [555/1000], Loss: 0.5339\n",
      "Epoch [556/1000], Loss: 0.5293\n",
      "Epoch [557/1000], Loss: 0.5339\n",
      "Epoch [558/1000], Loss: 0.5316\n",
      "Epoch [559/1000], Loss: 0.5262\n",
      "Epoch [560/1000], Loss: 0.5216\n",
      "Epoch [561/1000], Loss: 0.5208\n",
      "Epoch [562/1000], Loss: 0.5331\n",
      "Epoch [563/1000], Loss: 0.5277\n",
      "Epoch [564/1000], Loss: 0.5262\n",
      "Epoch [565/1000], Loss: 0.5300\n",
      "Epoch [566/1000], Loss: 0.5270\n",
      "Epoch [567/1000], Loss: 0.5293\n",
      "Epoch [568/1000], Loss: 0.5347\n",
      "Epoch [569/1000], Loss: 0.5223\n",
      "Epoch [570/1000], Loss: 0.5285\n",
      "Epoch [571/1000], Loss: 0.5308\n",
      "Epoch [572/1000], Loss: 0.5324\n",
      "Epoch [573/1000], Loss: 0.5254\n",
      "Epoch [574/1000], Loss: 0.5262\n",
      "Epoch [575/1000], Loss: 0.5285\n",
      "Epoch [576/1000], Loss: 0.5293\n",
      "Epoch [577/1000], Loss: 0.5262\n",
      "Epoch [578/1000], Loss: 0.5231\n",
      "Epoch [579/1000], Loss: 0.5354\n",
      "Epoch [580/1000], Loss: 0.5300\n",
      "Epoch [581/1000], Loss: 0.5308\n",
      "Epoch [582/1000], Loss: 0.5239\n",
      "Epoch [583/1000], Loss: 0.5339\n",
      "Epoch [584/1000], Loss: 0.5277\n",
      "Epoch [585/1000], Loss: 0.5300\n",
      "Epoch [586/1000], Loss: 0.5293\n",
      "Epoch [587/1000], Loss: 0.5285\n",
      "Epoch [588/1000], Loss: 0.5277\n",
      "Epoch [589/1000], Loss: 0.5239\n",
      "Epoch [590/1000], Loss: 0.5270\n",
      "Epoch [591/1000], Loss: 0.5316\n",
      "Epoch [592/1000], Loss: 0.5339\n",
      "Epoch [593/1000], Loss: 0.5300\n",
      "Epoch [594/1000], Loss: 0.5285\n",
      "Epoch [595/1000], Loss: 0.5316\n",
      "Epoch [596/1000], Loss: 0.5347\n",
      "Epoch [597/1000], Loss: 0.5324\n",
      "Epoch [598/1000], Loss: 0.5277\n",
      "Epoch [599/1000], Loss: 0.5300\n",
      "Epoch [600/1000], Loss: 0.5308\n",
      "Epoch [601/1000], Loss: 0.5316\n",
      "Epoch [602/1000], Loss: 0.5239\n",
      "Epoch [603/1000], Loss: 0.5262\n",
      "Epoch [604/1000], Loss: 0.5308\n",
      "Epoch [605/1000], Loss: 0.5316\n",
      "Epoch [606/1000], Loss: 0.5347\n",
      "Epoch [607/1000], Loss: 0.5246\n",
      "Epoch [608/1000], Loss: 0.5262\n",
      "Epoch [609/1000], Loss: 0.5270\n",
      "Epoch [610/1000], Loss: 0.5277\n",
      "Epoch [611/1000], Loss: 0.5285\n",
      "Epoch [612/1000], Loss: 0.5262\n",
      "Epoch [613/1000], Loss: 0.5285\n",
      "Epoch [614/1000], Loss: 0.5354\n",
      "Epoch [615/1000], Loss: 0.5300\n",
      "Epoch [616/1000], Loss: 0.5277\n",
      "Epoch [617/1000], Loss: 0.5293\n",
      "Epoch [618/1000], Loss: 0.5270\n",
      "Epoch [619/1000], Loss: 0.5270\n",
      "Epoch [620/1000], Loss: 0.5231\n",
      "Epoch [621/1000], Loss: 0.5324\n",
      "Epoch [622/1000], Loss: 0.5223\n",
      "Epoch [623/1000], Loss: 0.5216\n",
      "Epoch [624/1000], Loss: 0.5308\n",
      "Epoch [625/1000], Loss: 0.5231\n",
      "Epoch [626/1000], Loss: 0.5270\n",
      "Epoch [627/1000], Loss: 0.5285\n",
      "Epoch [628/1000], Loss: 0.5354\n",
      "Epoch [629/1000], Loss: 0.5262\n",
      "Epoch [630/1000], Loss: 0.5246\n",
      "Epoch [631/1000], Loss: 0.5285\n",
      "Epoch [632/1000], Loss: 0.5316\n",
      "Epoch [633/1000], Loss: 0.5285\n",
      "Epoch [634/1000], Loss: 0.5285\n",
      "Epoch [635/1000], Loss: 0.5254\n",
      "Epoch [636/1000], Loss: 0.5293\n",
      "Epoch [637/1000], Loss: 0.5262\n",
      "Epoch [638/1000], Loss: 0.5270\n",
      "Epoch [639/1000], Loss: 0.5254\n",
      "Epoch [640/1000], Loss: 0.5246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [641/1000], Loss: 0.5308\n",
      "Epoch [642/1000], Loss: 0.5231\n",
      "Epoch [643/1000], Loss: 0.5316\n",
      "Epoch [644/1000], Loss: 0.5262\n",
      "Epoch [645/1000], Loss: 0.5308\n",
      "Epoch [646/1000], Loss: 0.5308\n",
      "Epoch [647/1000], Loss: 0.5285\n",
      "Epoch [648/1000], Loss: 0.5262\n",
      "Epoch [649/1000], Loss: 0.5316\n",
      "Epoch [650/1000], Loss: 0.5300\n",
      "Epoch [651/1000], Loss: 0.5285\n",
      "Epoch [652/1000], Loss: 0.5270\n",
      "Epoch [653/1000], Loss: 0.5262\n",
      "Epoch [654/1000], Loss: 0.5254\n",
      "Epoch [655/1000], Loss: 0.5324\n",
      "Epoch [656/1000], Loss: 0.5262\n",
      "Epoch [657/1000], Loss: 0.5262\n",
      "Epoch [658/1000], Loss: 0.5246\n",
      "Epoch [659/1000], Loss: 0.5316\n",
      "Epoch [660/1000], Loss: 0.5300\n",
      "Epoch [661/1000], Loss: 0.5231\n",
      "Epoch [662/1000], Loss: 0.5262\n",
      "Epoch [663/1000], Loss: 0.5324\n",
      "Epoch [664/1000], Loss: 0.5277\n",
      "Epoch [665/1000], Loss: 0.5285\n",
      "Epoch [666/1000], Loss: 0.5293\n",
      "Epoch [667/1000], Loss: 0.5277\n",
      "Epoch [668/1000], Loss: 0.5293\n",
      "Epoch [669/1000], Loss: 0.5300\n",
      "Epoch [670/1000], Loss: 0.5293\n",
      "Epoch [671/1000], Loss: 0.5308\n",
      "Epoch [672/1000], Loss: 0.5316\n",
      "Epoch [673/1000], Loss: 0.5254\n",
      "Epoch [674/1000], Loss: 0.5331\n",
      "Epoch [675/1000], Loss: 0.5308\n",
      "Epoch [676/1000], Loss: 0.5300\n",
      "Epoch [677/1000], Loss: 0.5285\n",
      "Epoch [678/1000], Loss: 0.5331\n",
      "Epoch [679/1000], Loss: 0.5293\n",
      "Epoch [680/1000], Loss: 0.5216\n",
      "Epoch [681/1000], Loss: 0.5308\n",
      "Epoch [682/1000], Loss: 0.5331\n",
      "Epoch [683/1000], Loss: 0.5316\n",
      "Epoch [684/1000], Loss: 0.5277\n",
      "Epoch [685/1000], Loss: 0.5331\n",
      "Epoch [686/1000], Loss: 0.5254\n",
      "Epoch [687/1000], Loss: 0.5262\n",
      "Epoch [688/1000], Loss: 0.5324\n",
      "Epoch [689/1000], Loss: 0.5324\n",
      "Epoch [690/1000], Loss: 0.5239\n",
      "Epoch [691/1000], Loss: 0.5308\n",
      "Epoch [692/1000], Loss: 0.5246\n",
      "Epoch [693/1000], Loss: 0.5231\n",
      "Epoch [694/1000], Loss: 0.5231\n",
      "Epoch [695/1000], Loss: 0.5270\n",
      "Epoch [696/1000], Loss: 0.5377\n",
      "Epoch [697/1000], Loss: 0.5254\n",
      "Epoch [698/1000], Loss: 0.5324\n",
      "Epoch [699/1000], Loss: 0.5285\n",
      "Epoch [700/1000], Loss: 0.5354\n",
      "Epoch [701/1000], Loss: 0.5300\n",
      "Epoch [702/1000], Loss: 0.5331\n",
      "Epoch [703/1000], Loss: 0.5308\n",
      "Epoch [704/1000], Loss: 0.5254\n",
      "Epoch [705/1000], Loss: 0.5231\n",
      "Epoch [706/1000], Loss: 0.5293\n",
      "Epoch [707/1000], Loss: 0.5293\n",
      "Epoch [708/1000], Loss: 0.5254\n",
      "Epoch [709/1000], Loss: 0.5277\n",
      "Epoch [710/1000], Loss: 0.5354\n",
      "Epoch [711/1000], Loss: 0.5316\n",
      "Epoch [712/1000], Loss: 0.5300\n",
      "Epoch [713/1000], Loss: 0.5231\n",
      "Epoch [714/1000], Loss: 0.5285\n",
      "Epoch [715/1000], Loss: 0.5254\n",
      "Epoch [716/1000], Loss: 0.5262\n",
      "Epoch [717/1000], Loss: 0.5331\n",
      "Epoch [718/1000], Loss: 0.5339\n",
      "Epoch [719/1000], Loss: 0.5324\n",
      "Epoch [720/1000], Loss: 0.5277\n",
      "Epoch [721/1000], Loss: 0.5285\n",
      "Epoch [722/1000], Loss: 0.5262\n",
      "Epoch [723/1000], Loss: 0.5339\n",
      "Epoch [724/1000], Loss: 0.5270\n",
      "Epoch [725/1000], Loss: 0.5285\n",
      "Epoch [726/1000], Loss: 0.5300\n",
      "Epoch [727/1000], Loss: 0.5354\n",
      "Epoch [728/1000], Loss: 0.5324\n",
      "Epoch [729/1000], Loss: 0.5324\n",
      "Epoch [730/1000], Loss: 0.5277\n",
      "Epoch [731/1000], Loss: 0.5285\n",
      "Epoch [732/1000], Loss: 0.5270\n",
      "Epoch [733/1000], Loss: 0.5239\n",
      "Epoch [734/1000], Loss: 0.5308\n",
      "Epoch [735/1000], Loss: 0.5316\n",
      "Epoch [736/1000], Loss: 0.5316\n",
      "Epoch [737/1000], Loss: 0.5308\n",
      "Epoch [738/1000], Loss: 0.5293\n",
      "Epoch [739/1000], Loss: 0.5277\n",
      "Epoch [740/1000], Loss: 0.5300\n",
      "Epoch [741/1000], Loss: 0.5354\n",
      "Epoch [742/1000], Loss: 0.5308\n",
      "Epoch [743/1000], Loss: 0.5362\n",
      "Epoch [744/1000], Loss: 0.5300\n",
      "Epoch [745/1000], Loss: 0.5277\n",
      "Epoch [746/1000], Loss: 0.5316\n",
      "Epoch [747/1000], Loss: 0.5347\n",
      "Epoch [748/1000], Loss: 0.5254\n",
      "Epoch [749/1000], Loss: 0.5262\n",
      "Epoch [750/1000], Loss: 0.5316\n",
      "Epoch [751/1000], Loss: 0.5254\n",
      "Epoch [752/1000], Loss: 0.5308\n",
      "Epoch [753/1000], Loss: 0.5331\n",
      "Epoch [754/1000], Loss: 0.5331\n",
      "Epoch [755/1000], Loss: 0.5277\n",
      "Epoch [756/1000], Loss: 0.5254\n",
      "Epoch [757/1000], Loss: 0.5300\n",
      "Epoch [758/1000], Loss: 0.5293\n",
      "Epoch [759/1000], Loss: 0.5277\n",
      "Epoch [760/1000], Loss: 0.5324\n",
      "Epoch [761/1000], Loss: 0.5324\n",
      "Epoch [762/1000], Loss: 0.5223\n",
      "Epoch [763/1000], Loss: 0.5246\n",
      "Epoch [764/1000], Loss: 0.5285\n",
      "Epoch [765/1000], Loss: 0.5270\n",
      "Epoch [766/1000], Loss: 0.5254\n",
      "Epoch [767/1000], Loss: 0.5200\n",
      "Epoch [768/1000], Loss: 0.5324\n",
      "Epoch [769/1000], Loss: 0.5324\n",
      "Epoch [770/1000], Loss: 0.5324\n",
      "Epoch [771/1000], Loss: 0.5270\n",
      "Epoch [772/1000], Loss: 0.5246\n",
      "Epoch [773/1000], Loss: 0.5254\n",
      "Epoch [774/1000], Loss: 0.5254\n",
      "Epoch [775/1000], Loss: 0.5246\n",
      "Epoch [776/1000], Loss: 0.5270\n",
      "Epoch [777/1000], Loss: 0.5300\n",
      "Epoch [778/1000], Loss: 0.5285\n",
      "Epoch [779/1000], Loss: 0.5285\n",
      "Epoch [780/1000], Loss: 0.5339\n",
      "Epoch [781/1000], Loss: 0.5277\n",
      "Epoch [782/1000], Loss: 0.5270\n",
      "Epoch [783/1000], Loss: 0.5293\n",
      "Epoch [784/1000], Loss: 0.5377\n",
      "Epoch [785/1000], Loss: 0.5277\n",
      "Epoch [786/1000], Loss: 0.5285\n",
      "Epoch [787/1000], Loss: 0.5293\n",
      "Epoch [788/1000], Loss: 0.5300\n",
      "Epoch [789/1000], Loss: 0.5324\n",
      "Epoch [790/1000], Loss: 0.5262\n",
      "Epoch [791/1000], Loss: 0.5300\n",
      "Epoch [792/1000], Loss: 0.5285\n",
      "Epoch [793/1000], Loss: 0.5339\n",
      "Epoch [794/1000], Loss: 0.5308\n",
      "Epoch [795/1000], Loss: 0.5277\n",
      "Epoch [796/1000], Loss: 0.5339\n",
      "Epoch [797/1000], Loss: 0.5300\n",
      "Epoch [798/1000], Loss: 0.5316\n",
      "Epoch [799/1000], Loss: 0.5285\n",
      "Epoch [800/1000], Loss: 0.5262\n",
      "Epoch [801/1000], Loss: 0.5308\n",
      "Epoch [802/1000], Loss: 0.5300\n",
      "Epoch [803/1000], Loss: 0.5254\n",
      "Epoch [804/1000], Loss: 0.5362\n",
      "Epoch [805/1000], Loss: 0.5270\n",
      "Epoch [806/1000], Loss: 0.5239\n",
      "Epoch [807/1000], Loss: 0.5324\n",
      "Epoch [808/1000], Loss: 0.5254\n",
      "Epoch [809/1000], Loss: 0.5262\n",
      "Epoch [810/1000], Loss: 0.5339\n",
      "Epoch [811/1000], Loss: 0.5262\n",
      "Epoch [812/1000], Loss: 0.5246\n",
      "Epoch [813/1000], Loss: 0.5231\n",
      "Epoch [814/1000], Loss: 0.5270\n",
      "Epoch [815/1000], Loss: 0.5239\n",
      "Epoch [816/1000], Loss: 0.5293\n",
      "Epoch [817/1000], Loss: 0.5285\n",
      "Epoch [818/1000], Loss: 0.5316\n",
      "Epoch [819/1000], Loss: 0.5262\n",
      "Epoch [820/1000], Loss: 0.5308\n",
      "Epoch [821/1000], Loss: 0.5293\n",
      "Epoch [822/1000], Loss: 0.5316\n",
      "Epoch [823/1000], Loss: 0.5185\n",
      "Epoch [824/1000], Loss: 0.5339\n",
      "Epoch [825/1000], Loss: 0.5285\n",
      "Epoch [826/1000], Loss: 0.5293\n",
      "Epoch [827/1000], Loss: 0.5277\n",
      "Epoch [828/1000], Loss: 0.5308\n",
      "Epoch [829/1000], Loss: 0.5262\n",
      "Epoch [830/1000], Loss: 0.5254\n",
      "Epoch [831/1000], Loss: 0.5339\n",
      "Epoch [832/1000], Loss: 0.5316\n",
      "Epoch [833/1000], Loss: 0.5285\n",
      "Epoch [834/1000], Loss: 0.5285\n",
      "Epoch [835/1000], Loss: 0.5308\n",
      "Epoch [836/1000], Loss: 0.5262\n",
      "Epoch [837/1000], Loss: 0.5262\n",
      "Epoch [838/1000], Loss: 0.5293\n",
      "Epoch [839/1000], Loss: 0.5324\n",
      "Epoch [840/1000], Loss: 0.5285\n",
      "Epoch [841/1000], Loss: 0.5285\n",
      "Epoch [842/1000], Loss: 0.5300\n",
      "Epoch [843/1000], Loss: 0.5347\n",
      "Epoch [844/1000], Loss: 0.5316\n",
      "Epoch [845/1000], Loss: 0.5270\n",
      "Epoch [846/1000], Loss: 0.5246\n",
      "Epoch [847/1000], Loss: 0.5308\n",
      "Epoch [848/1000], Loss: 0.5300\n",
      "Epoch [849/1000], Loss: 0.5277\n",
      "Epoch [850/1000], Loss: 0.5324\n",
      "Epoch [851/1000], Loss: 0.5277\n",
      "Epoch [852/1000], Loss: 0.5308\n",
      "Epoch [853/1000], Loss: 0.5293\n",
      "Epoch [854/1000], Loss: 0.5239\n",
      "Epoch [855/1000], Loss: 0.5270\n",
      "Epoch [856/1000], Loss: 0.5270\n",
      "Epoch [857/1000], Loss: 0.5300\n",
      "Epoch [858/1000], Loss: 0.5308\n",
      "Epoch [859/1000], Loss: 0.5293\n",
      "Epoch [860/1000], Loss: 0.5293\n",
      "Epoch [861/1000], Loss: 0.5339\n",
      "Epoch [862/1000], Loss: 0.5270\n",
      "Epoch [863/1000], Loss: 0.5316\n",
      "Epoch [864/1000], Loss: 0.5308\n",
      "Epoch [865/1000], Loss: 0.5231\n",
      "Epoch [866/1000], Loss: 0.5354\n",
      "Epoch [867/1000], Loss: 0.5277\n",
      "Epoch [868/1000], Loss: 0.5293\n",
      "Epoch [869/1000], Loss: 0.5331\n",
      "Epoch [870/1000], Loss: 0.5231\n",
      "Epoch [871/1000], Loss: 0.5347\n",
      "Epoch [872/1000], Loss: 0.5347\n",
      "Epoch [873/1000], Loss: 0.5270\n",
      "Epoch [874/1000], Loss: 0.5185\n",
      "Epoch [875/1000], Loss: 0.5270\n",
      "Epoch [876/1000], Loss: 0.5277\n",
      "Epoch [877/1000], Loss: 0.5324\n",
      "Epoch [878/1000], Loss: 0.5246\n",
      "Epoch [879/1000], Loss: 0.5277\n",
      "Epoch [880/1000], Loss: 0.5308\n",
      "Epoch [881/1000], Loss: 0.5347\n",
      "Epoch [882/1000], Loss: 0.5324\n",
      "Epoch [883/1000], Loss: 0.5277\n",
      "Epoch [884/1000], Loss: 0.5316\n",
      "Epoch [885/1000], Loss: 0.5293\n",
      "Epoch [886/1000], Loss: 0.5316\n",
      "Epoch [887/1000], Loss: 0.5316\n",
      "Epoch [888/1000], Loss: 0.5262\n",
      "Epoch [889/1000], Loss: 0.5254\n",
      "Epoch [890/1000], Loss: 0.5293\n",
      "Epoch [891/1000], Loss: 0.5285\n",
      "Epoch [892/1000], Loss: 0.5216\n",
      "Epoch [893/1000], Loss: 0.5285\n",
      "Epoch [894/1000], Loss: 0.5324\n",
      "Epoch [895/1000], Loss: 0.5354\n",
      "Epoch [896/1000], Loss: 0.5331\n",
      "Epoch [897/1000], Loss: 0.5331\n",
      "Epoch [898/1000], Loss: 0.5308\n",
      "Epoch [899/1000], Loss: 0.5277\n",
      "Epoch [900/1000], Loss: 0.5270\n",
      "Epoch [901/1000], Loss: 0.5370\n",
      "Epoch [902/1000], Loss: 0.5277\n",
      "Epoch [903/1000], Loss: 0.5308\n",
      "Epoch [904/1000], Loss: 0.5316\n",
      "Epoch [905/1000], Loss: 0.5354\n",
      "Epoch [906/1000], Loss: 0.5293\n",
      "Epoch [907/1000], Loss: 0.5270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [908/1000], Loss: 0.5262\n",
      "Epoch [909/1000], Loss: 0.5262\n",
      "Epoch [910/1000], Loss: 0.5300\n",
      "Epoch [911/1000], Loss: 0.5300\n",
      "Epoch [912/1000], Loss: 0.5277\n",
      "Epoch [913/1000], Loss: 0.5339\n",
      "Epoch [914/1000], Loss: 0.5331\n",
      "Epoch [915/1000], Loss: 0.5354\n",
      "Epoch [916/1000], Loss: 0.5285\n",
      "Epoch [917/1000], Loss: 0.5270\n",
      "Epoch [918/1000], Loss: 0.5300\n",
      "Epoch [919/1000], Loss: 0.5270\n",
      "Epoch [920/1000], Loss: 0.5231\n",
      "Epoch [921/1000], Loss: 0.5354\n",
      "Epoch [922/1000], Loss: 0.5254\n",
      "Epoch [923/1000], Loss: 0.5300\n",
      "Epoch [924/1000], Loss: 0.5262\n",
      "Epoch [925/1000], Loss: 0.5223\n",
      "Epoch [926/1000], Loss: 0.5254\n",
      "Epoch [927/1000], Loss: 0.5270\n",
      "Epoch [928/1000], Loss: 0.5300\n",
      "Epoch [929/1000], Loss: 0.5277\n",
      "Epoch [930/1000], Loss: 0.5270\n",
      "Epoch [931/1000], Loss: 0.5239\n",
      "Epoch [932/1000], Loss: 0.5300\n",
      "Epoch [933/1000], Loss: 0.5277\n",
      "Epoch [934/1000], Loss: 0.5324\n",
      "Epoch [935/1000], Loss: 0.5300\n",
      "Epoch [936/1000], Loss: 0.5254\n",
      "Epoch [937/1000], Loss: 0.5308\n",
      "Epoch [938/1000], Loss: 0.5285\n",
      "Epoch [939/1000], Loss: 0.5277\n",
      "Epoch [940/1000], Loss: 0.5254\n",
      "Epoch [941/1000], Loss: 0.5231\n",
      "Epoch [942/1000], Loss: 0.5285\n",
      "Epoch [943/1000], Loss: 0.5246\n",
      "Epoch [944/1000], Loss: 0.5293\n",
      "Epoch [945/1000], Loss: 0.5285\n",
      "Epoch [946/1000], Loss: 0.5285\n",
      "Epoch [947/1000], Loss: 0.5293\n",
      "Epoch [948/1000], Loss: 0.5347\n",
      "Epoch [949/1000], Loss: 0.5316\n",
      "Epoch [950/1000], Loss: 0.5293\n",
      "Epoch [951/1000], Loss: 0.5300\n",
      "Epoch [952/1000], Loss: 0.5285\n",
      "Epoch [953/1000], Loss: 0.5231\n",
      "Epoch [954/1000], Loss: 0.5270\n",
      "Epoch [955/1000], Loss: 0.5162\n",
      "Epoch [956/1000], Loss: 0.5324\n",
      "Epoch [957/1000], Loss: 0.5262\n",
      "Epoch [958/1000], Loss: 0.5277\n",
      "Epoch [959/1000], Loss: 0.5285\n",
      "Epoch [960/1000], Loss: 0.5254\n",
      "Epoch [961/1000], Loss: 0.5254\n",
      "Epoch [962/1000], Loss: 0.5308\n",
      "Epoch [963/1000], Loss: 0.5277\n",
      "Epoch [964/1000], Loss: 0.5308\n",
      "Epoch [965/1000], Loss: 0.5308\n",
      "Epoch [966/1000], Loss: 0.5308\n",
      "Epoch [967/1000], Loss: 0.5246\n",
      "Epoch [968/1000], Loss: 0.5293\n",
      "Epoch [969/1000], Loss: 0.5277\n",
      "Epoch [970/1000], Loss: 0.5262\n",
      "Epoch [971/1000], Loss: 0.5277\n",
      "Epoch [972/1000], Loss: 0.5246\n",
      "Epoch [973/1000], Loss: 0.5239\n",
      "Epoch [974/1000], Loss: 0.5339\n",
      "Epoch [975/1000], Loss: 0.5262\n",
      "Epoch [976/1000], Loss: 0.5308\n",
      "Epoch [977/1000], Loss: 0.5300\n",
      "Epoch [978/1000], Loss: 0.5331\n",
      "Epoch [979/1000], Loss: 0.5293\n",
      "Epoch [980/1000], Loss: 0.5300\n",
      "Epoch [981/1000], Loss: 0.5254\n",
      "Epoch [982/1000], Loss: 0.5347\n",
      "Epoch [983/1000], Loss: 0.5239\n",
      "Epoch [984/1000], Loss: 0.5324\n",
      "Epoch [985/1000], Loss: 0.5246\n",
      "Epoch [986/1000], Loss: 0.5316\n",
      "Epoch [987/1000], Loss: 0.5262\n",
      "Epoch [988/1000], Loss: 0.5347\n",
      "Epoch [989/1000], Loss: 0.5277\n",
      "Epoch [990/1000], Loss: 0.5270\n",
      "Epoch [991/1000], Loss: 0.5324\n",
      "Epoch [992/1000], Loss: 0.5308\n",
      "Epoch [993/1000], Loss: 0.5254\n",
      "Epoch [994/1000], Loss: 0.5308\n",
      "Epoch [995/1000], Loss: 0.5262\n",
      "Epoch [996/1000], Loss: 0.5270\n",
      "Epoch [997/1000], Loss: 0.5300\n",
      "Epoch [998/1000], Loss: 0.5262\n",
      "Epoch [999/1000], Loss: 0.5300\n",
      "Epoch [1000/1000], Loss: 0.5293\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 302, lr :10.0, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.5762\n",
      "Epoch [2/1000], Loss: 0.5999\n",
      "Epoch [3/1000], Loss: 0.6006\n",
      "Epoch [4/1000], Loss: 0.6014\n",
      "Epoch [5/1000], Loss: 0.5922\n",
      "Epoch [6/1000], Loss: 0.6060\n",
      "Epoch [7/1000], Loss: 0.5991\n",
      "Epoch [8/1000], Loss: 0.5937\n",
      "Epoch [9/1000], Loss: 0.5991\n",
      "Epoch [10/1000], Loss: 0.5999\n",
      "Epoch [11/1000], Loss: 0.5991\n",
      "Epoch [12/1000], Loss: 0.5983\n",
      "Epoch [13/1000], Loss: 0.5976\n",
      "Epoch [14/1000], Loss: 0.5937\n",
      "Epoch [15/1000], Loss: 0.5983\n",
      "Epoch [16/1000], Loss: 0.6045\n",
      "Epoch [17/1000], Loss: 0.5914\n",
      "Epoch [18/1000], Loss: 0.5968\n",
      "Epoch [19/1000], Loss: 0.6022\n",
      "Epoch [20/1000], Loss: 0.5999\n",
      "Epoch [21/1000], Loss: 0.5991\n",
      "Epoch [22/1000], Loss: 0.6006\n",
      "Epoch [23/1000], Loss: 0.6037\n",
      "Epoch [24/1000], Loss: 0.5929\n",
      "Epoch [25/1000], Loss: 0.6006\n",
      "Epoch [26/1000], Loss: 0.6006\n",
      "Epoch [27/1000], Loss: 0.6014\n",
      "Epoch [28/1000], Loss: 0.5968\n",
      "Epoch [29/1000], Loss: 0.6014\n",
      "Epoch [30/1000], Loss: 0.5945\n",
      "Epoch [31/1000], Loss: 0.6014\n",
      "Epoch [32/1000], Loss: 0.6022\n",
      "Epoch [33/1000], Loss: 0.5991\n",
      "Epoch [34/1000], Loss: 0.5968\n",
      "Epoch [35/1000], Loss: 0.5976\n",
      "Epoch [36/1000], Loss: 0.6022\n",
      "Epoch [37/1000], Loss: 0.5991\n",
      "Epoch [38/1000], Loss: 0.5999\n",
      "Epoch [39/1000], Loss: 0.5929\n",
      "Epoch [40/1000], Loss: 0.5945\n",
      "Epoch [41/1000], Loss: 0.5976\n",
      "Epoch [42/1000], Loss: 0.5976\n",
      "Epoch [43/1000], Loss: 0.5983\n",
      "Epoch [44/1000], Loss: 0.5976\n",
      "Epoch [45/1000], Loss: 0.5991\n",
      "Epoch [46/1000], Loss: 0.5999\n",
      "Epoch [47/1000], Loss: 0.5991\n",
      "Epoch [48/1000], Loss: 0.6006\n",
      "Epoch [49/1000], Loss: 0.5991\n",
      "Epoch [50/1000], Loss: 0.5999\n",
      "Epoch [51/1000], Loss: 0.5983\n",
      "Epoch [52/1000], Loss: 0.6022\n",
      "Epoch [53/1000], Loss: 0.6014\n",
      "Epoch [54/1000], Loss: 0.5899\n",
      "Epoch [55/1000], Loss: 0.6014\n",
      "Epoch [56/1000], Loss: 0.6045\n",
      "Epoch [57/1000], Loss: 0.6014\n",
      "Epoch [58/1000], Loss: 0.5991\n",
      "Epoch [59/1000], Loss: 0.5983\n",
      "Epoch [60/1000], Loss: 0.6022\n",
      "Epoch [61/1000], Loss: 0.5929\n",
      "Epoch [62/1000], Loss: 0.5968\n",
      "Epoch [63/1000], Loss: 0.6022\n",
      "Epoch [64/1000], Loss: 0.5968\n",
      "Epoch [65/1000], Loss: 0.6014\n",
      "Epoch [66/1000], Loss: 0.5999\n",
      "Epoch [67/1000], Loss: 0.6037\n",
      "Epoch [68/1000], Loss: 0.5999\n",
      "Epoch [69/1000], Loss: 0.5991\n",
      "Epoch [70/1000], Loss: 0.6068\n",
      "Epoch [71/1000], Loss: 0.5991\n",
      "Epoch [72/1000], Loss: 0.5945\n",
      "Epoch [73/1000], Loss: 0.6022\n",
      "Epoch [74/1000], Loss: 0.5983\n",
      "Epoch [75/1000], Loss: 0.6037\n",
      "Epoch [76/1000], Loss: 0.5991\n",
      "Epoch [77/1000], Loss: 0.6053\n",
      "Epoch [78/1000], Loss: 0.5999\n",
      "Epoch [79/1000], Loss: 0.5991\n",
      "Epoch [80/1000], Loss: 0.5960\n",
      "Epoch [81/1000], Loss: 0.6030\n",
      "Epoch [82/1000], Loss: 0.6014\n",
      "Epoch [83/1000], Loss: 0.5968\n",
      "Epoch [84/1000], Loss: 0.5991\n",
      "Epoch [85/1000], Loss: 0.5945\n",
      "Epoch [86/1000], Loss: 0.5991\n",
      "Epoch [87/1000], Loss: 0.6053\n",
      "Epoch [88/1000], Loss: 0.5922\n",
      "Epoch [89/1000], Loss: 0.6053\n",
      "Epoch [90/1000], Loss: 0.6030\n",
      "Epoch [91/1000], Loss: 0.6014\n",
      "Epoch [92/1000], Loss: 0.5937\n",
      "Epoch [93/1000], Loss: 0.5999\n",
      "Epoch [94/1000], Loss: 0.5968\n",
      "Epoch [95/1000], Loss: 0.5991\n",
      "Epoch [96/1000], Loss: 0.6022\n",
      "Epoch [97/1000], Loss: 0.5999\n",
      "Epoch [98/1000], Loss: 0.6053\n",
      "Epoch [99/1000], Loss: 0.5929\n",
      "Epoch [100/1000], Loss: 0.5983\n",
      "Epoch [101/1000], Loss: 0.5953\n",
      "Epoch [102/1000], Loss: 0.6014\n",
      "Epoch [103/1000], Loss: 0.6006\n",
      "Epoch [104/1000], Loss: 0.5929\n",
      "Epoch [105/1000], Loss: 0.5999\n",
      "Epoch [106/1000], Loss: 0.5937\n",
      "Epoch [107/1000], Loss: 0.5968\n",
      "Epoch [108/1000], Loss: 0.5968\n",
      "Epoch [109/1000], Loss: 0.5929\n",
      "Epoch [110/1000], Loss: 0.5983\n",
      "Epoch [111/1000], Loss: 0.5976\n",
      "Epoch [112/1000], Loss: 0.5983\n",
      "Epoch [113/1000], Loss: 0.5999\n",
      "Epoch [114/1000], Loss: 0.6006\n",
      "Epoch [115/1000], Loss: 0.5976\n",
      "Epoch [116/1000], Loss: 0.6068\n",
      "Epoch [117/1000], Loss: 0.5999\n",
      "Epoch [118/1000], Loss: 0.5991\n",
      "Epoch [119/1000], Loss: 0.5968\n",
      "Epoch [120/1000], Loss: 0.6053\n",
      "Epoch [121/1000], Loss: 0.5960\n",
      "Epoch [122/1000], Loss: 0.5999\n",
      "Epoch [123/1000], Loss: 0.5999\n",
      "Epoch [124/1000], Loss: 0.6030\n",
      "Epoch [125/1000], Loss: 0.5991\n",
      "Epoch [126/1000], Loss: 0.6014\n",
      "Epoch [127/1000], Loss: 0.5952\n",
      "Epoch [128/1000], Loss: 0.5929\n",
      "Epoch [129/1000], Loss: 0.5999\n",
      "Epoch [130/1000], Loss: 0.5976\n",
      "Epoch [131/1000], Loss: 0.5991\n",
      "Epoch [132/1000], Loss: 0.6037\n",
      "Epoch [133/1000], Loss: 0.5991\n",
      "Epoch [134/1000], Loss: 0.5999\n",
      "Epoch [135/1000], Loss: 0.5999\n",
      "Epoch [136/1000], Loss: 0.5991\n",
      "Epoch [137/1000], Loss: 0.6045\n",
      "Epoch [138/1000], Loss: 0.5999\n",
      "Epoch [139/1000], Loss: 0.5906\n",
      "Epoch [140/1000], Loss: 0.5991\n",
      "Epoch [141/1000], Loss: 0.6006\n",
      "Epoch [142/1000], Loss: 0.5991\n",
      "Epoch [143/1000], Loss: 0.6030\n",
      "Epoch [144/1000], Loss: 0.6006\n",
      "Epoch [145/1000], Loss: 0.5953\n",
      "Epoch [146/1000], Loss: 0.6030\n",
      "Epoch [147/1000], Loss: 0.5968\n",
      "Epoch [148/1000], Loss: 0.6022\n",
      "Epoch [149/1000], Loss: 0.5883\n",
      "Epoch [150/1000], Loss: 0.5953\n",
      "Epoch [151/1000], Loss: 0.6006\n",
      "Epoch [152/1000], Loss: 0.5952\n",
      "Epoch [153/1000], Loss: 0.5999\n",
      "Epoch [154/1000], Loss: 0.6053\n",
      "Epoch [155/1000], Loss: 0.5976\n",
      "Epoch [156/1000], Loss: 0.5968\n",
      "Epoch [157/1000], Loss: 0.5937\n",
      "Epoch [158/1000], Loss: 0.6030\n",
      "Epoch [159/1000], Loss: 0.5953\n",
      "Epoch [160/1000], Loss: 0.6053\n",
      "Epoch [161/1000], Loss: 0.6022\n",
      "Epoch [162/1000], Loss: 0.6014\n",
      "Epoch [163/1000], Loss: 0.6006\n",
      "Epoch [164/1000], Loss: 0.6037\n",
      "Epoch [165/1000], Loss: 0.5968\n",
      "Epoch [166/1000], Loss: 0.5960\n",
      "Epoch [167/1000], Loss: 0.5960\n",
      "Epoch [168/1000], Loss: 0.5914\n",
      "Epoch [169/1000], Loss: 0.5937\n",
      "Epoch [170/1000], Loss: 0.5991\n",
      "Epoch [171/1000], Loss: 0.5929\n",
      "Epoch [172/1000], Loss: 0.6006\n",
      "Epoch [173/1000], Loss: 0.6022\n",
      "Epoch [174/1000], Loss: 0.5960\n",
      "Epoch [175/1000], Loss: 0.5960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [176/1000], Loss: 0.5999\n",
      "Epoch [177/1000], Loss: 0.5968\n",
      "Epoch [178/1000], Loss: 0.6037\n",
      "Epoch [179/1000], Loss: 0.5883\n",
      "Epoch [180/1000], Loss: 0.6045\n",
      "Epoch [181/1000], Loss: 0.5968\n",
      "Epoch [182/1000], Loss: 0.5991\n",
      "Epoch [183/1000], Loss: 0.5960\n",
      "Epoch [184/1000], Loss: 0.6014\n",
      "Epoch [185/1000], Loss: 0.6014\n",
      "Epoch [186/1000], Loss: 0.5945\n",
      "Epoch [187/1000], Loss: 0.5945\n",
      "Epoch [188/1000], Loss: 0.5945\n",
      "Epoch [189/1000], Loss: 0.6006\n",
      "Epoch [190/1000], Loss: 0.6014\n",
      "Epoch [191/1000], Loss: 0.5976\n",
      "Epoch [192/1000], Loss: 0.6053\n",
      "Epoch [193/1000], Loss: 0.6022\n",
      "Epoch [194/1000], Loss: 0.5960\n",
      "Epoch [195/1000], Loss: 0.5983\n",
      "Epoch [196/1000], Loss: 0.5952\n",
      "Epoch [197/1000], Loss: 0.5945\n",
      "Epoch [198/1000], Loss: 0.5991\n",
      "Epoch [199/1000], Loss: 0.5999\n",
      "Epoch [200/1000], Loss: 0.6022\n",
      "Epoch [201/1000], Loss: 0.5991\n",
      "Epoch [202/1000], Loss: 0.5976\n",
      "Epoch [203/1000], Loss: 0.5976\n",
      "Epoch [204/1000], Loss: 0.5983\n",
      "Epoch [205/1000], Loss: 0.5960\n",
      "Epoch [206/1000], Loss: 0.6014\n",
      "Epoch [207/1000], Loss: 0.6006\n",
      "Epoch [208/1000], Loss: 0.5983\n",
      "Epoch [209/1000], Loss: 0.5983\n",
      "Epoch [210/1000], Loss: 0.5960\n",
      "Epoch [211/1000], Loss: 0.5991\n",
      "Epoch [212/1000], Loss: 0.6022\n",
      "Epoch [213/1000], Loss: 0.6037\n",
      "Epoch [214/1000], Loss: 0.5968\n",
      "Epoch [215/1000], Loss: 0.5960\n",
      "Epoch [216/1000], Loss: 0.5991\n",
      "Epoch [217/1000], Loss: 0.5999\n",
      "Epoch [218/1000], Loss: 0.5914\n",
      "Epoch [219/1000], Loss: 0.5983\n",
      "Epoch [220/1000], Loss: 0.5968\n",
      "Epoch [221/1000], Loss: 0.5976\n",
      "Epoch [222/1000], Loss: 0.5929\n",
      "Epoch [223/1000], Loss: 0.5968\n",
      "Epoch [224/1000], Loss: 0.5953\n",
      "Epoch [225/1000], Loss: 0.5976\n",
      "Epoch [226/1000], Loss: 0.5960\n",
      "Epoch [227/1000], Loss: 0.5983\n",
      "Epoch [228/1000], Loss: 0.5968\n",
      "Epoch [229/1000], Loss: 0.6006\n",
      "Epoch [230/1000], Loss: 0.5991\n",
      "Epoch [231/1000], Loss: 0.5906\n",
      "Epoch [232/1000], Loss: 0.6014\n",
      "Epoch [233/1000], Loss: 0.6006\n",
      "Epoch [234/1000], Loss: 0.5952\n",
      "Epoch [235/1000], Loss: 0.5953\n",
      "Epoch [236/1000], Loss: 0.5983\n",
      "Epoch [237/1000], Loss: 0.6045\n",
      "Epoch [238/1000], Loss: 0.5960\n",
      "Epoch [239/1000], Loss: 0.5976\n",
      "Epoch [240/1000], Loss: 0.5960\n",
      "Epoch [241/1000], Loss: 0.5922\n",
      "Epoch [242/1000], Loss: 0.6037\n",
      "Epoch [243/1000], Loss: 0.6014\n",
      "Epoch [244/1000], Loss: 0.5968\n",
      "Epoch [245/1000], Loss: 0.5945\n",
      "Epoch [246/1000], Loss: 0.5960\n",
      "Epoch [247/1000], Loss: 0.5968\n",
      "Epoch [248/1000], Loss: 0.5983\n",
      "Epoch [249/1000], Loss: 0.5999\n",
      "Epoch [250/1000], Loss: 0.6006\n",
      "Epoch [251/1000], Loss: 0.5914\n",
      "Epoch [252/1000], Loss: 0.6014\n",
      "Epoch [253/1000], Loss: 0.5991\n",
      "Epoch [254/1000], Loss: 0.5991\n",
      "Epoch [255/1000], Loss: 0.6006\n",
      "Epoch [256/1000], Loss: 0.5999\n",
      "Epoch [257/1000], Loss: 0.5922\n",
      "Epoch [258/1000], Loss: 0.6030\n",
      "Epoch [259/1000], Loss: 0.6006\n",
      "Epoch [260/1000], Loss: 0.6006\n",
      "Epoch [261/1000], Loss: 0.6022\n",
      "Epoch [262/1000], Loss: 0.5991\n",
      "Epoch [263/1000], Loss: 0.6006\n",
      "Epoch [264/1000], Loss: 0.5960\n",
      "Epoch [265/1000], Loss: 0.5960\n",
      "Epoch [266/1000], Loss: 0.5983\n",
      "Epoch [267/1000], Loss: 0.5960\n",
      "Epoch [268/1000], Loss: 0.5991\n",
      "Epoch [269/1000], Loss: 0.5991\n",
      "Epoch [270/1000], Loss: 0.6037\n",
      "Epoch [271/1000], Loss: 0.5960\n",
      "Epoch [272/1000], Loss: 0.5968\n",
      "Epoch [273/1000], Loss: 0.6022\n",
      "Epoch [274/1000], Loss: 0.5976\n",
      "Epoch [275/1000], Loss: 0.6014\n",
      "Epoch [276/1000], Loss: 0.5968\n",
      "Epoch [277/1000], Loss: 0.5983\n",
      "Epoch [278/1000], Loss: 0.5968\n",
      "Epoch [279/1000], Loss: 0.6053\n",
      "Epoch [280/1000], Loss: 0.5983\n",
      "Epoch [281/1000], Loss: 0.5991\n",
      "Epoch [282/1000], Loss: 0.5953\n",
      "Epoch [283/1000], Loss: 0.5922\n",
      "Epoch [284/1000], Loss: 0.5968\n",
      "Epoch [285/1000], Loss: 0.5991\n",
      "Epoch [286/1000], Loss: 0.6014\n",
      "Epoch [287/1000], Loss: 0.6045\n",
      "Epoch [288/1000], Loss: 0.5960\n",
      "Epoch [289/1000], Loss: 0.5991\n",
      "Epoch [290/1000], Loss: 0.5999\n",
      "Epoch [291/1000], Loss: 0.6045\n",
      "Epoch [292/1000], Loss: 0.6037\n",
      "Epoch [293/1000], Loss: 0.5945\n",
      "Epoch [294/1000], Loss: 0.5953\n",
      "Epoch [295/1000], Loss: 0.6037\n",
      "Epoch [296/1000], Loss: 0.6022\n",
      "Epoch [297/1000], Loss: 0.6045\n",
      "Epoch [298/1000], Loss: 0.5953\n",
      "Epoch [299/1000], Loss: 0.5991\n",
      "Epoch [300/1000], Loss: 0.5983\n",
      "Epoch [301/1000], Loss: 0.5991\n",
      "Epoch [302/1000], Loss: 0.5968\n",
      "Epoch [303/1000], Loss: 0.6053\n",
      "Epoch [304/1000], Loss: 0.5937\n",
      "Epoch [305/1000], Loss: 0.6045\n",
      "Epoch [306/1000], Loss: 0.5983\n",
      "Epoch [307/1000], Loss: 0.6014\n",
      "Epoch [308/1000], Loss: 0.5999\n",
      "Epoch [309/1000], Loss: 0.5922\n",
      "Epoch [310/1000], Loss: 0.6014\n",
      "Epoch [311/1000], Loss: 0.6076\n",
      "Epoch [312/1000], Loss: 0.6068\n",
      "Epoch [313/1000], Loss: 0.5999\n",
      "Epoch [314/1000], Loss: 0.6006\n",
      "Epoch [315/1000], Loss: 0.5976\n",
      "Epoch [316/1000], Loss: 0.5983\n",
      "Epoch [317/1000], Loss: 0.5968\n",
      "Epoch [318/1000], Loss: 0.6030\n",
      "Epoch [319/1000], Loss: 0.6045\n",
      "Epoch [320/1000], Loss: 0.5983\n",
      "Epoch [321/1000], Loss: 0.6014\n",
      "Epoch [322/1000], Loss: 0.6037\n",
      "Epoch [323/1000], Loss: 0.5953\n",
      "Epoch [324/1000], Loss: 0.5953\n",
      "Epoch [325/1000], Loss: 0.5968\n",
      "Epoch [326/1000], Loss: 0.5991\n",
      "Epoch [327/1000], Loss: 0.6022\n",
      "Epoch [328/1000], Loss: 0.5960\n",
      "Epoch [329/1000], Loss: 0.5991\n",
      "Epoch [330/1000], Loss: 0.5991\n",
      "Epoch [331/1000], Loss: 0.5999\n",
      "Epoch [332/1000], Loss: 0.5976\n",
      "Epoch [333/1000], Loss: 0.5991\n",
      "Epoch [334/1000], Loss: 0.5991\n",
      "Epoch [335/1000], Loss: 0.5983\n",
      "Epoch [336/1000], Loss: 0.5952\n",
      "Epoch [337/1000], Loss: 0.6006\n",
      "Epoch [338/1000], Loss: 0.5937\n",
      "Epoch [339/1000], Loss: 0.6006\n",
      "Epoch [340/1000], Loss: 0.5976\n",
      "Epoch [341/1000], Loss: 0.5991\n",
      "Epoch [342/1000], Loss: 0.6030\n",
      "Epoch [343/1000], Loss: 0.5999\n",
      "Epoch [344/1000], Loss: 0.5976\n",
      "Epoch [345/1000], Loss: 0.5999\n",
      "Epoch [346/1000], Loss: 0.6014\n",
      "Epoch [347/1000], Loss: 0.5960\n",
      "Epoch [348/1000], Loss: 0.5999\n",
      "Epoch [349/1000], Loss: 0.6006\n",
      "Epoch [350/1000], Loss: 0.5968\n",
      "Epoch [351/1000], Loss: 0.5952\n",
      "Epoch [352/1000], Loss: 0.6014\n",
      "Epoch [353/1000], Loss: 0.5999\n",
      "Epoch [354/1000], Loss: 0.6030\n",
      "Epoch [355/1000], Loss: 0.5960\n",
      "Epoch [356/1000], Loss: 0.5991\n",
      "Epoch [357/1000], Loss: 0.5929\n",
      "Epoch [358/1000], Loss: 0.6022\n",
      "Epoch [359/1000], Loss: 0.6022\n",
      "Epoch [360/1000], Loss: 0.6006\n",
      "Epoch [361/1000], Loss: 0.5976\n",
      "Epoch [362/1000], Loss: 0.5999\n",
      "Epoch [363/1000], Loss: 0.5991\n",
      "Epoch [364/1000], Loss: 0.6006\n",
      "Epoch [365/1000], Loss: 0.5983\n",
      "Epoch [366/1000], Loss: 0.6045\n",
      "Epoch [367/1000], Loss: 0.5929\n",
      "Epoch [368/1000], Loss: 0.5960\n",
      "Epoch [369/1000], Loss: 0.5968\n",
      "Epoch [370/1000], Loss: 0.6006\n",
      "Epoch [371/1000], Loss: 0.6006\n",
      "Epoch [372/1000], Loss: 0.5983\n",
      "Epoch [373/1000], Loss: 0.5953\n",
      "Epoch [374/1000], Loss: 0.5991\n",
      "Epoch [375/1000], Loss: 0.5991\n",
      "Epoch [376/1000], Loss: 0.6006\n",
      "Epoch [377/1000], Loss: 0.5960\n",
      "Epoch [378/1000], Loss: 0.5999\n",
      "Epoch [379/1000], Loss: 0.5945\n",
      "Epoch [380/1000], Loss: 0.5968\n",
      "Epoch [381/1000], Loss: 0.6076\n",
      "Epoch [382/1000], Loss: 0.6037\n",
      "Epoch [383/1000], Loss: 0.6014\n",
      "Epoch [384/1000], Loss: 0.6014\n",
      "Epoch [385/1000], Loss: 0.6068\n",
      "Epoch [386/1000], Loss: 0.5952\n",
      "Epoch [387/1000], Loss: 0.5976\n",
      "Epoch [388/1000], Loss: 0.5960\n",
      "Epoch [389/1000], Loss: 0.5968\n",
      "Epoch [390/1000], Loss: 0.6006\n",
      "Epoch [391/1000], Loss: 0.5983\n",
      "Epoch [392/1000], Loss: 0.5983\n",
      "Epoch [393/1000], Loss: 0.6014\n",
      "Epoch [394/1000], Loss: 0.5991\n",
      "Epoch [395/1000], Loss: 0.6045\n",
      "Epoch [396/1000], Loss: 0.6022\n",
      "Epoch [397/1000], Loss: 0.6060\n",
      "Epoch [398/1000], Loss: 0.6014\n",
      "Epoch [399/1000], Loss: 0.5976\n",
      "Epoch [400/1000], Loss: 0.6006\n",
      "Epoch [401/1000], Loss: 0.5999\n",
      "Epoch [402/1000], Loss: 0.6053\n",
      "Epoch [403/1000], Loss: 0.5999\n",
      "Epoch [404/1000], Loss: 0.5991\n",
      "Epoch [405/1000], Loss: 0.5968\n",
      "Epoch [406/1000], Loss: 0.5999\n",
      "Epoch [407/1000], Loss: 0.6014\n",
      "Epoch [408/1000], Loss: 0.5983\n",
      "Epoch [409/1000], Loss: 0.6014\n",
      "Epoch [410/1000], Loss: 0.5952\n",
      "Epoch [411/1000], Loss: 0.6022\n",
      "Epoch [412/1000], Loss: 0.6030\n",
      "Epoch [413/1000], Loss: 0.6045\n",
      "Epoch [414/1000], Loss: 0.5968\n",
      "Epoch [415/1000], Loss: 0.5983\n",
      "Epoch [416/1000], Loss: 0.5999\n",
      "Epoch [417/1000], Loss: 0.6053\n",
      "Epoch [418/1000], Loss: 0.5968\n",
      "Epoch [419/1000], Loss: 0.6030\n",
      "Epoch [420/1000], Loss: 0.5983\n",
      "Epoch [421/1000], Loss: 0.6006\n",
      "Epoch [422/1000], Loss: 0.5968\n",
      "Epoch [423/1000], Loss: 0.5953\n",
      "Epoch [424/1000], Loss: 0.6006\n",
      "Epoch [425/1000], Loss: 0.6006\n",
      "Epoch [426/1000], Loss: 0.6045\n",
      "Epoch [427/1000], Loss: 0.5976\n",
      "Epoch [428/1000], Loss: 0.5999\n",
      "Epoch [429/1000], Loss: 0.5976\n",
      "Epoch [430/1000], Loss: 0.5929\n",
      "Epoch [431/1000], Loss: 0.5999\n",
      "Epoch [432/1000], Loss: 0.5991\n",
      "Epoch [433/1000], Loss: 0.5960\n",
      "Epoch [434/1000], Loss: 0.6006\n",
      "Epoch [435/1000], Loss: 0.5968\n",
      "Epoch [436/1000], Loss: 0.6006\n",
      "Epoch [437/1000], Loss: 0.6045\n",
      "Epoch [438/1000], Loss: 0.6037\n",
      "Epoch [439/1000], Loss: 0.5991\n",
      "Epoch [440/1000], Loss: 0.5929\n",
      "Epoch [441/1000], Loss: 0.5983\n",
      "Epoch [442/1000], Loss: 0.5999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [443/1000], Loss: 0.5983\n",
      "Epoch [444/1000], Loss: 0.5968\n",
      "Epoch [445/1000], Loss: 0.5952\n",
      "Epoch [446/1000], Loss: 0.5945\n",
      "Epoch [447/1000], Loss: 0.5983\n",
      "Epoch [448/1000], Loss: 0.6014\n",
      "Epoch [449/1000], Loss: 0.6068\n",
      "Epoch [450/1000], Loss: 0.5999\n",
      "Epoch [451/1000], Loss: 0.5953\n",
      "Epoch [452/1000], Loss: 0.5991\n",
      "Epoch [453/1000], Loss: 0.6022\n",
      "Epoch [454/1000], Loss: 0.5983\n",
      "Epoch [455/1000], Loss: 0.5953\n",
      "Epoch [456/1000], Loss: 0.5960\n",
      "Epoch [457/1000], Loss: 0.5983\n",
      "Epoch [458/1000], Loss: 0.5991\n",
      "Epoch [459/1000], Loss: 0.5976\n",
      "Epoch [460/1000], Loss: 0.6014\n",
      "Epoch [461/1000], Loss: 0.5945\n",
      "Epoch [462/1000], Loss: 0.5991\n",
      "Epoch [463/1000], Loss: 0.5983\n",
      "Epoch [464/1000], Loss: 0.5968\n",
      "Epoch [465/1000], Loss: 0.5976\n",
      "Epoch [466/1000], Loss: 0.6014\n",
      "Epoch [467/1000], Loss: 0.5968\n",
      "Epoch [468/1000], Loss: 0.5960\n",
      "Epoch [469/1000], Loss: 0.5960\n",
      "Epoch [470/1000], Loss: 0.5991\n",
      "Epoch [471/1000], Loss: 0.5983\n",
      "Epoch [472/1000], Loss: 0.6014\n",
      "Epoch [473/1000], Loss: 0.5976\n",
      "Epoch [474/1000], Loss: 0.5968\n",
      "Epoch [475/1000], Loss: 0.5960\n",
      "Epoch [476/1000], Loss: 0.6060\n",
      "Epoch [477/1000], Loss: 0.5952\n",
      "Epoch [478/1000], Loss: 0.6006\n",
      "Epoch [479/1000], Loss: 0.6045\n",
      "Epoch [480/1000], Loss: 0.6030\n",
      "Epoch [481/1000], Loss: 0.6014\n",
      "Epoch [482/1000], Loss: 0.6060\n",
      "Epoch [483/1000], Loss: 0.5937\n",
      "Epoch [484/1000], Loss: 0.6014\n",
      "Epoch [485/1000], Loss: 0.5983\n",
      "Epoch [486/1000], Loss: 0.5976\n",
      "Epoch [487/1000], Loss: 0.5960\n",
      "Epoch [488/1000], Loss: 0.6037\n",
      "Epoch [489/1000], Loss: 0.6083\n",
      "Epoch [490/1000], Loss: 0.6037\n",
      "Epoch [491/1000], Loss: 0.5968\n",
      "Epoch [492/1000], Loss: 0.6006\n",
      "Epoch [493/1000], Loss: 0.5968\n",
      "Epoch [494/1000], Loss: 0.6006\n",
      "Epoch [495/1000], Loss: 0.5999\n",
      "Epoch [496/1000], Loss: 0.5999\n",
      "Epoch [497/1000], Loss: 0.5929\n",
      "Epoch [498/1000], Loss: 0.5991\n",
      "Epoch [499/1000], Loss: 0.6030\n",
      "Epoch [500/1000], Loss: 0.5922\n",
      "Epoch [501/1000], Loss: 0.5953\n",
      "Epoch [502/1000], Loss: 0.6006\n",
      "Epoch [503/1000], Loss: 0.6053\n",
      "Epoch [504/1000], Loss: 0.5960\n",
      "Epoch [505/1000], Loss: 0.5960\n",
      "Epoch [506/1000], Loss: 0.6006\n",
      "Epoch [507/1000], Loss: 0.5960\n",
      "Epoch [508/1000], Loss: 0.6053\n",
      "Epoch [509/1000], Loss: 0.6030\n",
      "Epoch [510/1000], Loss: 0.5991\n",
      "Epoch [511/1000], Loss: 0.5945\n",
      "Epoch [512/1000], Loss: 0.5953\n",
      "Epoch [513/1000], Loss: 0.6022\n",
      "Epoch [514/1000], Loss: 0.6006\n",
      "Epoch [515/1000], Loss: 0.5991\n",
      "Epoch [516/1000], Loss: 0.5968\n",
      "Epoch [517/1000], Loss: 0.6006\n",
      "Epoch [518/1000], Loss: 0.6045\n",
      "Epoch [519/1000], Loss: 0.6037\n",
      "Epoch [520/1000], Loss: 0.6014\n",
      "Epoch [521/1000], Loss: 0.5960\n",
      "Epoch [522/1000], Loss: 0.6045\n",
      "Epoch [523/1000], Loss: 0.5976\n",
      "Epoch [524/1000], Loss: 0.5999\n",
      "Epoch [525/1000], Loss: 0.5953\n",
      "Epoch [526/1000], Loss: 0.5983\n",
      "Epoch [527/1000], Loss: 0.5960\n",
      "Epoch [528/1000], Loss: 0.5953\n",
      "Epoch [529/1000], Loss: 0.5991\n",
      "Epoch [530/1000], Loss: 0.5976\n",
      "Epoch [531/1000], Loss: 0.5991\n",
      "Epoch [532/1000], Loss: 0.5983\n",
      "Epoch [533/1000], Loss: 0.6006\n",
      "Epoch [534/1000], Loss: 0.5960\n",
      "Epoch [535/1000], Loss: 0.5999\n",
      "Epoch [536/1000], Loss: 0.6037\n",
      "Epoch [537/1000], Loss: 0.5945\n",
      "Epoch [538/1000], Loss: 0.6037\n",
      "Epoch [539/1000], Loss: 0.5976\n",
      "Epoch [540/1000], Loss: 0.6030\n",
      "Epoch [541/1000], Loss: 0.6045\n",
      "Epoch [542/1000], Loss: 0.6006\n",
      "Epoch [543/1000], Loss: 0.5945\n",
      "Epoch [544/1000], Loss: 0.5960\n",
      "Epoch [545/1000], Loss: 0.5945\n",
      "Epoch [546/1000], Loss: 0.5922\n",
      "Epoch [547/1000], Loss: 0.6060\n",
      "Epoch [548/1000], Loss: 0.6030\n",
      "Epoch [549/1000], Loss: 0.6060\n",
      "Epoch [550/1000], Loss: 0.6014\n",
      "Epoch [551/1000], Loss: 0.6014\n",
      "Epoch [552/1000], Loss: 0.5929\n",
      "Epoch [553/1000], Loss: 0.5929\n",
      "Epoch [554/1000], Loss: 0.6014\n",
      "Epoch [555/1000], Loss: 0.6037\n",
      "Epoch [556/1000], Loss: 0.6006\n",
      "Epoch [557/1000], Loss: 0.5983\n",
      "Epoch [558/1000], Loss: 0.5914\n",
      "Epoch [559/1000], Loss: 0.6030\n",
      "Epoch [560/1000], Loss: 0.6006\n",
      "Epoch [561/1000], Loss: 0.5960\n",
      "Epoch [562/1000], Loss: 0.5983\n",
      "Epoch [563/1000], Loss: 0.6014\n",
      "Epoch [564/1000], Loss: 0.6006\n",
      "Epoch [565/1000], Loss: 0.5999\n",
      "Epoch [566/1000], Loss: 0.6037\n",
      "Epoch [567/1000], Loss: 0.6030\n",
      "Epoch [568/1000], Loss: 0.5945\n",
      "Epoch [569/1000], Loss: 0.5983\n",
      "Epoch [570/1000], Loss: 0.5983\n",
      "Epoch [571/1000], Loss: 0.6053\n",
      "Epoch [572/1000], Loss: 0.5976\n",
      "Epoch [573/1000], Loss: 0.5983\n",
      "Epoch [574/1000], Loss: 0.6014\n",
      "Epoch [575/1000], Loss: 0.6014\n",
      "Epoch [576/1000], Loss: 0.6006\n",
      "Epoch [577/1000], Loss: 0.5922\n",
      "Epoch [578/1000], Loss: 0.5983\n",
      "Epoch [579/1000], Loss: 0.5976\n",
      "Epoch [580/1000], Loss: 0.5952\n",
      "Epoch [581/1000], Loss: 0.5960\n",
      "Epoch [582/1000], Loss: 0.6037\n",
      "Epoch [583/1000], Loss: 0.5953\n",
      "Epoch [584/1000], Loss: 0.6030\n",
      "Epoch [585/1000], Loss: 0.5914\n",
      "Epoch [586/1000], Loss: 0.5983\n",
      "Epoch [587/1000], Loss: 0.5999\n",
      "Epoch [588/1000], Loss: 0.5937\n",
      "Epoch [589/1000], Loss: 0.6014\n",
      "Epoch [590/1000], Loss: 0.5983\n",
      "Epoch [591/1000], Loss: 0.5976\n",
      "Epoch [592/1000], Loss: 0.6014\n",
      "Epoch [593/1000], Loss: 0.6022\n",
      "Epoch [594/1000], Loss: 0.6045\n",
      "Epoch [595/1000], Loss: 0.6030\n",
      "Epoch [596/1000], Loss: 0.5976\n",
      "Epoch [597/1000], Loss: 0.6068\n",
      "Epoch [598/1000], Loss: 0.6014\n",
      "Epoch [599/1000], Loss: 0.6006\n",
      "Epoch [600/1000], Loss: 0.5953\n",
      "Epoch [601/1000], Loss: 0.5968\n",
      "Epoch [602/1000], Loss: 0.6037\n",
      "Epoch [603/1000], Loss: 0.5999\n",
      "Epoch [604/1000], Loss: 0.6014\n",
      "Epoch [605/1000], Loss: 0.5976\n",
      "Epoch [606/1000], Loss: 0.5991\n",
      "Epoch [607/1000], Loss: 0.6022\n",
      "Epoch [608/1000], Loss: 0.5976\n",
      "Epoch [609/1000], Loss: 0.5968\n",
      "Epoch [610/1000], Loss: 0.5922\n",
      "Epoch [611/1000], Loss: 0.6022\n",
      "Epoch [612/1000], Loss: 0.6037\n",
      "Epoch [613/1000], Loss: 0.6006\n",
      "Epoch [614/1000], Loss: 0.5914\n",
      "Epoch [615/1000], Loss: 0.5976\n",
      "Epoch [616/1000], Loss: 0.5983\n",
      "Epoch [617/1000], Loss: 0.5937\n",
      "Epoch [618/1000], Loss: 0.5983\n",
      "Epoch [619/1000], Loss: 0.6014\n",
      "Epoch [620/1000], Loss: 0.5953\n",
      "Epoch [621/1000], Loss: 0.6083\n",
      "Epoch [622/1000], Loss: 0.5983\n",
      "Epoch [623/1000], Loss: 0.6076\n",
      "Epoch [624/1000], Loss: 0.5991\n",
      "Epoch [625/1000], Loss: 0.5937\n",
      "Epoch [626/1000], Loss: 0.5960\n",
      "Epoch [627/1000], Loss: 0.5983\n",
      "Epoch [628/1000], Loss: 0.5976\n",
      "Epoch [629/1000], Loss: 0.5968\n",
      "Epoch [630/1000], Loss: 0.6053\n",
      "Epoch [631/1000], Loss: 0.5952\n",
      "Epoch [632/1000], Loss: 0.6037\n",
      "Epoch [633/1000], Loss: 0.6030\n",
      "Epoch [634/1000], Loss: 0.5991\n",
      "Epoch [635/1000], Loss: 0.5968\n",
      "Epoch [636/1000], Loss: 0.6030\n",
      "Epoch [637/1000], Loss: 0.5991\n",
      "Epoch [638/1000], Loss: 0.6014\n",
      "Epoch [639/1000], Loss: 0.5983\n",
      "Epoch [640/1000], Loss: 0.5960\n",
      "Epoch [641/1000], Loss: 0.6006\n",
      "Epoch [642/1000], Loss: 0.5976\n",
      "Epoch [643/1000], Loss: 0.5953\n",
      "Epoch [644/1000], Loss: 0.6076\n",
      "Epoch [645/1000], Loss: 0.5983\n",
      "Epoch [646/1000], Loss: 0.5983\n",
      "Epoch [647/1000], Loss: 0.5968\n",
      "Epoch [648/1000], Loss: 0.6006\n",
      "Epoch [649/1000], Loss: 0.6014\n",
      "Epoch [650/1000], Loss: 0.6022\n",
      "Epoch [651/1000], Loss: 0.5991\n",
      "Epoch [652/1000], Loss: 0.5960\n",
      "Epoch [653/1000], Loss: 0.5968\n",
      "Epoch [654/1000], Loss: 0.6022\n",
      "Epoch [655/1000], Loss: 0.5945\n",
      "Epoch [656/1000], Loss: 0.5945\n",
      "Epoch [657/1000], Loss: 0.5999\n",
      "Epoch [658/1000], Loss: 0.5914\n",
      "Epoch [659/1000], Loss: 0.6045\n",
      "Epoch [660/1000], Loss: 0.6037\n",
      "Epoch [661/1000], Loss: 0.5968\n",
      "Epoch [662/1000], Loss: 0.6006\n",
      "Epoch [663/1000], Loss: 0.5929\n",
      "Epoch [664/1000], Loss: 0.5960\n",
      "Epoch [665/1000], Loss: 0.5937\n",
      "Epoch [666/1000], Loss: 0.6014\n",
      "Epoch [667/1000], Loss: 0.5953\n",
      "Epoch [668/1000], Loss: 0.5937\n",
      "Epoch [669/1000], Loss: 0.5968\n",
      "Epoch [670/1000], Loss: 0.5976\n",
      "Epoch [671/1000], Loss: 0.5953\n",
      "Epoch [672/1000], Loss: 0.5991\n",
      "Epoch [673/1000], Loss: 0.5945\n",
      "Epoch [674/1000], Loss: 0.5991\n",
      "Epoch [675/1000], Loss: 0.6022\n",
      "Epoch [676/1000], Loss: 0.5999\n",
      "Epoch [677/1000], Loss: 0.5953\n",
      "Epoch [678/1000], Loss: 0.5999\n",
      "Epoch [679/1000], Loss: 0.6022\n",
      "Epoch [680/1000], Loss: 0.6030\n",
      "Epoch [681/1000], Loss: 0.5999\n",
      "Epoch [682/1000], Loss: 0.6030\n",
      "Epoch [683/1000], Loss: 0.5953\n",
      "Epoch [684/1000], Loss: 0.5960\n",
      "Epoch [685/1000], Loss: 0.6014\n",
      "Epoch [686/1000], Loss: 0.6045\n",
      "Epoch [687/1000], Loss: 0.5991\n",
      "Epoch [688/1000], Loss: 0.5999\n",
      "Epoch [689/1000], Loss: 0.5991\n",
      "Epoch [690/1000], Loss: 0.6006\n",
      "Epoch [691/1000], Loss: 0.6006\n",
      "Epoch [692/1000], Loss: 0.6045\n",
      "Epoch [693/1000], Loss: 0.5976\n",
      "Epoch [694/1000], Loss: 0.5968\n",
      "Epoch [695/1000], Loss: 0.5991\n",
      "Epoch [696/1000], Loss: 0.5991\n",
      "Epoch [697/1000], Loss: 0.6053\n",
      "Epoch [698/1000], Loss: 0.6037\n",
      "Epoch [699/1000], Loss: 0.5968\n",
      "Epoch [700/1000], Loss: 0.6006\n",
      "Epoch [701/1000], Loss: 0.5999\n",
      "Epoch [702/1000], Loss: 0.5976\n",
      "Epoch [703/1000], Loss: 0.5999\n",
      "Epoch [704/1000], Loss: 0.5999\n",
      "Epoch [705/1000], Loss: 0.5999\n",
      "Epoch [706/1000], Loss: 0.5968\n",
      "Epoch [707/1000], Loss: 0.5999\n",
      "Epoch [708/1000], Loss: 0.5991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [709/1000], Loss: 0.5968\n",
      "Epoch [710/1000], Loss: 0.6006\n",
      "Epoch [711/1000], Loss: 0.5976\n",
      "Epoch [712/1000], Loss: 0.5968\n",
      "Epoch [713/1000], Loss: 0.5968\n",
      "Epoch [714/1000], Loss: 0.5983\n",
      "Epoch [715/1000], Loss: 0.5983\n",
      "Epoch [716/1000], Loss: 0.6022\n",
      "Epoch [717/1000], Loss: 0.6022\n",
      "Epoch [718/1000], Loss: 0.6037\n",
      "Epoch [719/1000], Loss: 0.5991\n",
      "Epoch [720/1000], Loss: 0.5983\n",
      "Epoch [721/1000], Loss: 0.5945\n",
      "Epoch [722/1000], Loss: 0.6006\n",
      "Epoch [723/1000], Loss: 0.5929\n",
      "Epoch [724/1000], Loss: 0.6006\n",
      "Epoch [725/1000], Loss: 0.5968\n",
      "Epoch [726/1000], Loss: 0.5983\n",
      "Epoch [727/1000], Loss: 0.6006\n",
      "Epoch [728/1000], Loss: 0.6053\n",
      "Epoch [729/1000], Loss: 0.5906\n",
      "Epoch [730/1000], Loss: 0.6045\n",
      "Epoch [731/1000], Loss: 0.5991\n",
      "Epoch [732/1000], Loss: 0.5953\n",
      "Epoch [733/1000], Loss: 0.5983\n",
      "Epoch [734/1000], Loss: 0.5922\n",
      "Epoch [735/1000], Loss: 0.5952\n",
      "Epoch [736/1000], Loss: 0.5983\n",
      "Epoch [737/1000], Loss: 0.6037\n",
      "Epoch [738/1000], Loss: 0.6083\n",
      "Epoch [739/1000], Loss: 0.6014\n",
      "Epoch [740/1000], Loss: 0.5968\n",
      "Epoch [741/1000], Loss: 0.5960\n",
      "Epoch [742/1000], Loss: 0.5976\n",
      "Epoch [743/1000], Loss: 0.5968\n",
      "Epoch [744/1000], Loss: 0.5999\n",
      "Epoch [745/1000], Loss: 0.5976\n",
      "Epoch [746/1000], Loss: 0.5983\n",
      "Epoch [747/1000], Loss: 0.5976\n",
      "Epoch [748/1000], Loss: 0.5937\n",
      "Epoch [749/1000], Loss: 0.5945\n",
      "Epoch [750/1000], Loss: 0.6030\n",
      "Epoch [751/1000], Loss: 0.5999\n",
      "Epoch [752/1000], Loss: 0.5999\n",
      "Epoch [753/1000], Loss: 0.5999\n",
      "Epoch [754/1000], Loss: 0.6053\n",
      "Epoch [755/1000], Loss: 0.5991\n",
      "Epoch [756/1000], Loss: 0.5937\n",
      "Epoch [757/1000], Loss: 0.6022\n",
      "Epoch [758/1000], Loss: 0.6022\n",
      "Epoch [759/1000], Loss: 0.6053\n",
      "Epoch [760/1000], Loss: 0.5952\n",
      "Epoch [761/1000], Loss: 0.6053\n",
      "Epoch [762/1000], Loss: 0.6014\n",
      "Epoch [763/1000], Loss: 0.5968\n",
      "Epoch [764/1000], Loss: 0.6037\n",
      "Epoch [765/1000], Loss: 0.5922\n",
      "Epoch [766/1000], Loss: 0.6022\n",
      "Epoch [767/1000], Loss: 0.5983\n",
      "Epoch [768/1000], Loss: 0.5976\n",
      "Epoch [769/1000], Loss: 0.5922\n",
      "Epoch [770/1000], Loss: 0.6037\n",
      "Epoch [771/1000], Loss: 0.6022\n",
      "Epoch [772/1000], Loss: 0.5968\n",
      "Epoch [773/1000], Loss: 0.5991\n",
      "Epoch [774/1000], Loss: 0.5960\n",
      "Epoch [775/1000], Loss: 0.5960\n",
      "Epoch [776/1000], Loss: 0.5952\n",
      "Epoch [777/1000], Loss: 0.6014\n",
      "Epoch [778/1000], Loss: 0.5968\n",
      "Epoch [779/1000], Loss: 0.6045\n",
      "Epoch [780/1000], Loss: 0.5999\n",
      "Epoch [781/1000], Loss: 0.5983\n",
      "Epoch [782/1000], Loss: 0.6037\n",
      "Epoch [783/1000], Loss: 0.5983\n",
      "Epoch [784/1000], Loss: 0.6045\n",
      "Epoch [785/1000], Loss: 0.5960\n",
      "Epoch [786/1000], Loss: 0.5983\n",
      "Epoch [787/1000], Loss: 0.5991\n",
      "Epoch [788/1000], Loss: 0.6014\n",
      "Epoch [789/1000], Loss: 0.5976\n",
      "Epoch [790/1000], Loss: 0.6006\n",
      "Epoch [791/1000], Loss: 0.5983\n",
      "Epoch [792/1000], Loss: 0.5983\n",
      "Epoch [793/1000], Loss: 0.6014\n",
      "Epoch [794/1000], Loss: 0.6014\n",
      "Epoch [795/1000], Loss: 0.5983\n",
      "Epoch [796/1000], Loss: 0.6068\n",
      "Epoch [797/1000], Loss: 0.5991\n",
      "Epoch [798/1000], Loss: 0.5991\n",
      "Epoch [799/1000], Loss: 0.5976\n",
      "Epoch [800/1000], Loss: 0.6022\n",
      "Epoch [801/1000], Loss: 0.6022\n",
      "Epoch [802/1000], Loss: 0.5953\n",
      "Epoch [803/1000], Loss: 0.6006\n",
      "Epoch [804/1000], Loss: 0.5976\n",
      "Epoch [805/1000], Loss: 0.6022\n",
      "Epoch [806/1000], Loss: 0.6014\n",
      "Epoch [807/1000], Loss: 0.5952\n",
      "Epoch [808/1000], Loss: 0.6053\n",
      "Epoch [809/1000], Loss: 0.5999\n",
      "Epoch [810/1000], Loss: 0.5929\n",
      "Epoch [811/1000], Loss: 0.6006\n",
      "Epoch [812/1000], Loss: 0.6006\n",
      "Epoch [813/1000], Loss: 0.6006\n",
      "Epoch [814/1000], Loss: 0.5968\n",
      "Epoch [815/1000], Loss: 0.5968\n",
      "Epoch [816/1000], Loss: 0.5929\n",
      "Epoch [817/1000], Loss: 0.6014\n",
      "Epoch [818/1000], Loss: 0.5960\n",
      "Epoch [819/1000], Loss: 0.5937\n",
      "Epoch [820/1000], Loss: 0.5999\n",
      "Epoch [821/1000], Loss: 0.5960\n",
      "Epoch [822/1000], Loss: 0.5976\n",
      "Epoch [823/1000], Loss: 0.5976\n",
      "Epoch [824/1000], Loss: 0.6014\n",
      "Epoch [825/1000], Loss: 0.5991\n",
      "Epoch [826/1000], Loss: 0.5991\n",
      "Epoch [827/1000], Loss: 0.6014\n",
      "Epoch [828/1000], Loss: 0.6022\n",
      "Epoch [829/1000], Loss: 0.6037\n",
      "Epoch [830/1000], Loss: 0.5991\n",
      "Epoch [831/1000], Loss: 0.5945\n",
      "Epoch [832/1000], Loss: 0.5983\n",
      "Epoch [833/1000], Loss: 0.5991\n",
      "Epoch [834/1000], Loss: 0.6022\n",
      "Epoch [835/1000], Loss: 0.5960\n",
      "Epoch [836/1000], Loss: 0.5960\n",
      "Epoch [837/1000], Loss: 0.6006\n",
      "Epoch [838/1000], Loss: 0.5991\n",
      "Epoch [839/1000], Loss: 0.5991\n",
      "Epoch [840/1000], Loss: 0.6014\n",
      "Epoch [841/1000], Loss: 0.6022\n",
      "Epoch [842/1000], Loss: 0.5945\n",
      "Epoch [843/1000], Loss: 0.6022\n",
      "Epoch [844/1000], Loss: 0.5976\n",
      "Epoch [845/1000], Loss: 0.5983\n",
      "Epoch [846/1000], Loss: 0.6045\n",
      "Epoch [847/1000], Loss: 0.5960\n",
      "Epoch [848/1000], Loss: 0.5983\n",
      "Epoch [849/1000], Loss: 0.6053\n",
      "Epoch [850/1000], Loss: 0.5968\n",
      "Epoch [851/1000], Loss: 0.6053\n",
      "Epoch [852/1000], Loss: 0.5976\n",
      "Epoch [853/1000], Loss: 0.5983\n",
      "Epoch [854/1000], Loss: 0.5937\n",
      "Epoch [855/1000], Loss: 0.5937\n",
      "Epoch [856/1000], Loss: 0.6037\n",
      "Epoch [857/1000], Loss: 0.6022\n",
      "Epoch [858/1000], Loss: 0.6045\n",
      "Epoch [859/1000], Loss: 0.5945\n",
      "Epoch [860/1000], Loss: 0.5991\n",
      "Epoch [861/1000], Loss: 0.5945\n",
      "Epoch [862/1000], Loss: 0.5976\n",
      "Epoch [863/1000], Loss: 0.5983\n",
      "Epoch [864/1000], Loss: 0.5999\n",
      "Epoch [865/1000], Loss: 0.5968\n",
      "Epoch [866/1000], Loss: 0.5983\n",
      "Epoch [867/1000], Loss: 0.6030\n",
      "Epoch [868/1000], Loss: 0.5983\n",
      "Epoch [869/1000], Loss: 0.5976\n",
      "Epoch [870/1000], Loss: 0.5968\n",
      "Epoch [871/1000], Loss: 0.5960\n",
      "Epoch [872/1000], Loss: 0.5991\n",
      "Epoch [873/1000], Loss: 0.5952\n",
      "Epoch [874/1000], Loss: 0.5999\n",
      "Epoch [875/1000], Loss: 0.6014\n",
      "Epoch [876/1000], Loss: 0.5953\n",
      "Epoch [877/1000], Loss: 0.6006\n",
      "Epoch [878/1000], Loss: 0.6068\n",
      "Epoch [879/1000], Loss: 0.5991\n",
      "Epoch [880/1000], Loss: 0.6006\n",
      "Epoch [881/1000], Loss: 0.6037\n",
      "Epoch [882/1000], Loss: 0.5983\n",
      "Epoch [883/1000], Loss: 0.5991\n",
      "Epoch [884/1000], Loss: 0.5991\n",
      "Epoch [885/1000], Loss: 0.5945\n",
      "Epoch [886/1000], Loss: 0.5976\n",
      "Epoch [887/1000], Loss: 0.5991\n",
      "Epoch [888/1000], Loss: 0.5983\n",
      "Epoch [889/1000], Loss: 0.5945\n",
      "Epoch [890/1000], Loss: 0.5960\n",
      "Epoch [891/1000], Loss: 0.6045\n",
      "Epoch [892/1000], Loss: 0.6060\n",
      "Epoch [893/1000], Loss: 0.5999\n",
      "Epoch [894/1000], Loss: 0.5945\n",
      "Epoch [895/1000], Loss: 0.5983\n",
      "Epoch [896/1000], Loss: 0.5976\n",
      "Epoch [897/1000], Loss: 0.5891\n",
      "Epoch [898/1000], Loss: 0.6076\n",
      "Epoch [899/1000], Loss: 0.5952\n",
      "Epoch [900/1000], Loss: 0.5968\n",
      "Epoch [901/1000], Loss: 0.6030\n",
      "Epoch [902/1000], Loss: 0.6006\n",
      "Epoch [903/1000], Loss: 0.5937\n",
      "Epoch [904/1000], Loss: 0.6037\n",
      "Epoch [905/1000], Loss: 0.5983\n",
      "Epoch [906/1000], Loss: 0.5991\n",
      "Epoch [907/1000], Loss: 0.5991\n",
      "Epoch [908/1000], Loss: 0.5929\n",
      "Epoch [909/1000], Loss: 0.5983\n",
      "Epoch [910/1000], Loss: 0.5945\n",
      "Epoch [911/1000], Loss: 0.5952\n",
      "Epoch [912/1000], Loss: 0.6022\n",
      "Epoch [913/1000], Loss: 0.6006\n",
      "Epoch [914/1000], Loss: 0.5991\n",
      "Epoch [915/1000], Loss: 0.5945\n",
      "Epoch [916/1000], Loss: 0.6022\n",
      "Epoch [917/1000], Loss: 0.5991\n",
      "Epoch [918/1000], Loss: 0.5999\n",
      "Epoch [919/1000], Loss: 0.5999\n",
      "Epoch [920/1000], Loss: 0.5991\n",
      "Epoch [921/1000], Loss: 0.5945\n",
      "Epoch [922/1000], Loss: 0.6022\n",
      "Epoch [923/1000], Loss: 0.6014\n",
      "Epoch [924/1000], Loss: 0.6014\n",
      "Epoch [925/1000], Loss: 0.6030\n",
      "Epoch [926/1000], Loss: 0.6022\n",
      "Epoch [927/1000], Loss: 0.6037\n",
      "Epoch [928/1000], Loss: 0.6053\n",
      "Epoch [929/1000], Loss: 0.5983\n",
      "Epoch [930/1000], Loss: 0.5960\n",
      "Epoch [931/1000], Loss: 0.5991\n",
      "Epoch [932/1000], Loss: 0.5999\n",
      "Epoch [933/1000], Loss: 0.5968\n",
      "Epoch [934/1000], Loss: 0.5953\n",
      "Epoch [935/1000], Loss: 0.5968\n",
      "Epoch [936/1000], Loss: 0.5999\n",
      "Epoch [937/1000], Loss: 0.5983\n",
      "Epoch [938/1000], Loss: 0.6022\n",
      "Epoch [939/1000], Loss: 0.6030\n",
      "Epoch [940/1000], Loss: 0.6022\n",
      "Epoch [941/1000], Loss: 0.6045\n",
      "Epoch [942/1000], Loss: 0.5983\n",
      "Epoch [943/1000], Loss: 0.6014\n",
      "Epoch [944/1000], Loss: 0.6053\n",
      "Epoch [945/1000], Loss: 0.5983\n",
      "Epoch [946/1000], Loss: 0.6060\n",
      "Epoch [947/1000], Loss: 0.6006\n",
      "Epoch [948/1000], Loss: 0.5976\n",
      "Epoch [949/1000], Loss: 0.5976\n",
      "Epoch [950/1000], Loss: 0.5999\n",
      "Epoch [951/1000], Loss: 0.6045\n",
      "Epoch [952/1000], Loss: 0.6006\n",
      "Epoch [953/1000], Loss: 0.6014\n",
      "Epoch [954/1000], Loss: 0.5983\n",
      "Epoch [955/1000], Loss: 0.6030\n",
      "Epoch [956/1000], Loss: 0.6006\n",
      "Epoch [957/1000], Loss: 0.6045\n",
      "Epoch [958/1000], Loss: 0.5968\n",
      "Epoch [959/1000], Loss: 0.5983\n",
      "Epoch [960/1000], Loss: 0.5999\n",
      "Epoch [961/1000], Loss: 0.5976\n",
      "Epoch [962/1000], Loss: 0.6006\n",
      "Epoch [963/1000], Loss: 0.5983\n",
      "Epoch [964/1000], Loss: 0.5999\n",
      "Epoch [965/1000], Loss: 0.5991\n",
      "Epoch [966/1000], Loss: 0.5983\n",
      "Epoch [967/1000], Loss: 0.5960\n",
      "Epoch [968/1000], Loss: 0.5960\n",
      "Epoch [969/1000], Loss: 0.5976\n",
      "Epoch [970/1000], Loss: 0.5960\n",
      "Epoch [971/1000], Loss: 0.5968\n",
      "Epoch [972/1000], Loss: 0.5953\n",
      "Epoch [973/1000], Loss: 0.5976\n",
      "Epoch [974/1000], Loss: 0.6014\n",
      "Epoch [975/1000], Loss: 0.5991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [976/1000], Loss: 0.5976\n",
      "Epoch [977/1000], Loss: 0.5976\n",
      "Epoch [978/1000], Loss: 0.6091\n",
      "Epoch [979/1000], Loss: 0.5922\n",
      "Epoch [980/1000], Loss: 0.5999\n",
      "Epoch [981/1000], Loss: 0.5991\n",
      "Epoch [982/1000], Loss: 0.6006\n",
      "Epoch [983/1000], Loss: 0.5976\n",
      "Epoch [984/1000], Loss: 0.6014\n",
      "Epoch [985/1000], Loss: 0.5991\n",
      "Epoch [986/1000], Loss: 0.5991\n",
      "Epoch [987/1000], Loss: 0.5976\n",
      "Epoch [988/1000], Loss: 0.5968\n",
      "Epoch [989/1000], Loss: 0.5976\n",
      "Epoch [990/1000], Loss: 0.5999\n",
      "Epoch [991/1000], Loss: 0.6045\n",
      "Epoch [992/1000], Loss: 0.6045\n",
      "Epoch [993/1000], Loss: 0.5976\n",
      "Epoch [994/1000], Loss: 0.5945\n",
      "Epoch [995/1000], Loss: 0.5983\n",
      "Epoch [996/1000], Loss: 0.5999\n",
      "Epoch [997/1000], Loss: 0.5976\n",
      "Epoch [998/1000], Loss: 0.5968\n",
      "Epoch [999/1000], Loss: 0.5991\n",
      "Epoch [1000/1000], Loss: 0.6006\n",
      "Accuracy of the network on the 1000 validation data: 42.10 %\n",
      "Training model with batch_size: 302, lr :10.0, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2748\n",
      "Epoch [2/1000], Loss: 0.2600\n",
      "Epoch [3/1000], Loss: 0.2538\n",
      "Epoch [4/1000], Loss: 0.2385\n",
      "Epoch [5/1000], Loss: 0.2301\n",
      "Epoch [6/1000], Loss: 0.2400\n",
      "Epoch [7/1000], Loss: 0.2544\n",
      "Epoch [8/1000], Loss: 0.2398\n",
      "Epoch [9/1000], Loss: 0.2320\n",
      "Epoch [10/1000], Loss: 0.2324\n",
      "Epoch [11/1000], Loss: 0.2297\n",
      "Epoch [12/1000], Loss: 0.2276\n",
      "Epoch [13/1000], Loss: 0.2272\n",
      "Epoch [14/1000], Loss: 0.2266\n",
      "Epoch [15/1000], Loss: 0.2271\n",
      "Epoch [16/1000], Loss: 0.2241\n",
      "Epoch [17/1000], Loss: 0.2262\n",
      "Epoch [18/1000], Loss: 0.2256\n",
      "Epoch [19/1000], Loss: 0.2290\n",
      "Epoch [20/1000], Loss: 0.2264\n",
      "Epoch [21/1000], Loss: 0.2258\n",
      "Epoch [22/1000], Loss: 0.2268\n",
      "Epoch [23/1000], Loss: 0.2270\n",
      "Epoch [24/1000], Loss: 0.2249\n",
      "Epoch [25/1000], Loss: 0.2305\n",
      "Epoch [26/1000], Loss: 0.2285\n",
      "Epoch [27/1000], Loss: 0.2381\n",
      "Epoch [28/1000], Loss: 0.2264\n",
      "Epoch [29/1000], Loss: 0.2270\n",
      "Epoch [30/1000], Loss: 0.2240\n",
      "Epoch [31/1000], Loss: 0.2298\n",
      "Epoch [32/1000], Loss: 0.2267\n",
      "Epoch [33/1000], Loss: 0.2270\n",
      "Epoch [34/1000], Loss: 0.2269\n",
      "Epoch [35/1000], Loss: 0.2281\n",
      "Epoch [36/1000], Loss: 0.2268\n",
      "Epoch [37/1000], Loss: 0.2257\n",
      "Epoch [38/1000], Loss: 0.2267\n",
      "Epoch [39/1000], Loss: 0.2249\n",
      "Epoch [40/1000], Loss: 0.2250\n",
      "Epoch [41/1000], Loss: 0.2252\n",
      "Epoch [42/1000], Loss: 0.2240\n",
      "Epoch [43/1000], Loss: 0.2324\n",
      "Epoch [44/1000], Loss: 0.2348\n",
      "Epoch [45/1000], Loss: 0.2287\n",
      "Epoch [46/1000], Loss: 0.2248\n",
      "Epoch [47/1000], Loss: 0.2259\n",
      "Epoch [48/1000], Loss: 0.2267\n",
      "Epoch [49/1000], Loss: 0.2285\n",
      "Epoch [50/1000], Loss: 0.2195\n",
      "Epoch [51/1000], Loss: 0.2276\n",
      "Epoch [52/1000], Loss: 0.2291\n",
      "Epoch [53/1000], Loss: 0.2270\n",
      "Epoch [54/1000], Loss: 0.2260\n",
      "Epoch [55/1000], Loss: 0.2714\n",
      "Epoch [56/1000], Loss: 0.2474\n",
      "Epoch [57/1000], Loss: 0.2307\n",
      "Epoch [58/1000], Loss: 0.2300\n",
      "Epoch [59/1000], Loss: 0.2197\n",
      "Epoch [60/1000], Loss: 0.2144\n",
      "Epoch [61/1000], Loss: 0.2568\n",
      "Epoch [62/1000], Loss: 0.2272\n",
      "Epoch [63/1000], Loss: 0.2215\n",
      "Epoch [64/1000], Loss: 0.2236\n",
      "Epoch [65/1000], Loss: 0.2332\n",
      "Epoch [66/1000], Loss: 0.2199\n",
      "Epoch [67/1000], Loss: 0.2221\n",
      "Epoch [68/1000], Loss: 0.2160\n",
      "Epoch [69/1000], Loss: 0.2105\n",
      "Epoch [70/1000], Loss: 0.2242\n",
      "Epoch [71/1000], Loss: 0.2198\n",
      "Epoch [72/1000], Loss: 0.2050\n",
      "Epoch [73/1000], Loss: 0.2137\n",
      "Epoch [74/1000], Loss: 0.2135\n",
      "Epoch [75/1000], Loss: 0.2006\n",
      "Epoch [76/1000], Loss: 0.2196\n",
      "Epoch [77/1000], Loss: 0.2078\n",
      "Epoch [78/1000], Loss: 0.1992\n",
      "Epoch [79/1000], Loss: 0.2156\n",
      "Epoch [80/1000], Loss: 0.2060\n",
      "Epoch [81/1000], Loss: 0.1983\n",
      "Epoch [82/1000], Loss: 0.1941\n",
      "Epoch [83/1000], Loss: 0.2090\n",
      "Epoch [84/1000], Loss: 0.1858\n",
      "Epoch [85/1000], Loss: 0.2087\n",
      "Epoch [86/1000], Loss: 0.2013\n",
      "Epoch [87/1000], Loss: 0.2070\n",
      "Epoch [88/1000], Loss: 0.2260\n",
      "Epoch [89/1000], Loss: 0.2125\n",
      "Epoch [90/1000], Loss: 0.2096\n",
      "Epoch [91/1000], Loss: 0.2083\n",
      "Epoch [92/1000], Loss: 0.2061\n",
      "Epoch [93/1000], Loss: 0.2062\n",
      "Epoch [94/1000], Loss: 0.2001\n",
      "Epoch [95/1000], Loss: 0.2051\n",
      "Epoch [96/1000], Loss: 0.2057\n",
      "Epoch [97/1000], Loss: 0.2049\n",
      "Epoch [98/1000], Loss: 0.2051\n",
      "Epoch [99/1000], Loss: 0.2036\n",
      "Epoch [100/1000], Loss: 0.2009\n",
      "Epoch [101/1000], Loss: 0.1872\n",
      "Epoch [102/1000], Loss: 0.1902\n",
      "Epoch [103/1000], Loss: 0.1865\n",
      "Epoch [104/1000], Loss: 0.1816\n",
      "Epoch [105/1000], Loss: 0.1839\n",
      "Epoch [106/1000], Loss: 0.1961\n",
      "Epoch [107/1000], Loss: 0.2134\n",
      "Epoch [108/1000], Loss: 0.2030\n",
      "Epoch [109/1000], Loss: 0.1861\n",
      "Epoch [110/1000], Loss: 0.1897\n",
      "Epoch [111/1000], Loss: 0.2296\n",
      "Epoch [112/1000], Loss: 0.2170\n",
      "Epoch [113/1000], Loss: 0.2107\n",
      "Epoch [114/1000], Loss: 0.2036\n",
      "Epoch [115/1000], Loss: 0.2123\n",
      "Epoch [116/1000], Loss: 0.2268\n",
      "Epoch [117/1000], Loss: 0.2339\n",
      "Epoch [118/1000], Loss: 0.2151\n",
      "Epoch [119/1000], Loss: 0.2129\n",
      "Epoch [120/1000], Loss: 0.2126\n",
      "Epoch [121/1000], Loss: 0.2049\n",
      "Epoch [122/1000], Loss: 0.2051\n",
      "Epoch [123/1000], Loss: 0.2010\n",
      "Epoch [124/1000], Loss: 0.2039\n",
      "Epoch [125/1000], Loss: 0.2122\n",
      "Epoch [126/1000], Loss: 0.2067\n",
      "Epoch [127/1000], Loss: 0.2053\n",
      "Epoch [128/1000], Loss: 0.2077\n",
      "Epoch [129/1000], Loss: 0.1978\n",
      "Epoch [130/1000], Loss: 0.1931\n",
      "Epoch [131/1000], Loss: 0.2010\n",
      "Epoch [132/1000], Loss: 0.1956\n",
      "Epoch [133/1000], Loss: 0.1929\n",
      "Epoch [134/1000], Loss: 0.1939\n",
      "Epoch [135/1000], Loss: 0.1933\n",
      "Epoch [136/1000], Loss: 0.1893\n",
      "Epoch [137/1000], Loss: 0.1883\n",
      "Epoch [138/1000], Loss: 0.1899\n",
      "Epoch [139/1000], Loss: 0.1854\n",
      "Epoch [140/1000], Loss: 0.1898\n",
      "Epoch [141/1000], Loss: 0.1878\n",
      "Epoch [142/1000], Loss: 0.1815\n",
      "Epoch [143/1000], Loss: 0.1847\n",
      "Epoch [144/1000], Loss: 0.1897\n",
      "Epoch [145/1000], Loss: 0.1796\n",
      "Epoch [146/1000], Loss: 0.1755\n",
      "Epoch [147/1000], Loss: 0.1736\n",
      "Epoch [148/1000], Loss: 0.1685\n",
      "Epoch [149/1000], Loss: 0.1691\n",
      "Epoch [150/1000], Loss: 0.1869\n",
      "Epoch [151/1000], Loss: 0.1744\n",
      "Epoch [152/1000], Loss: 0.1689\n",
      "Epoch [153/1000], Loss: 0.2091\n",
      "Epoch [154/1000], Loss: 0.1953\n",
      "Epoch [155/1000], Loss: 0.1696\n",
      "Epoch [156/1000], Loss: 0.2183\n",
      "Epoch [157/1000], Loss: 0.2234\n",
      "Epoch [158/1000], Loss: 0.1998\n",
      "Epoch [159/1000], Loss: 0.1998\n",
      "Epoch [160/1000], Loss: 0.1887\n",
      "Epoch [161/1000], Loss: 0.2217\n",
      "Epoch [162/1000], Loss: 0.2076\n",
      "Epoch [163/1000], Loss: 0.2032\n",
      "Epoch [164/1000], Loss: 0.1902\n",
      "Epoch [165/1000], Loss: 0.1775\n",
      "Epoch [166/1000], Loss: 0.2045\n",
      "Epoch [167/1000], Loss: 0.2068\n",
      "Epoch [168/1000], Loss: 0.2040\n",
      "Epoch [169/1000], Loss: 0.2064\n",
      "Epoch [170/1000], Loss: 0.1992\n",
      "Epoch [171/1000], Loss: 0.2700\n",
      "Epoch [172/1000], Loss: 0.2402\n",
      "Epoch [173/1000], Loss: 0.2260\n",
      "Epoch [174/1000], Loss: 0.2290\n",
      "Epoch [175/1000], Loss: 0.2287\n",
      "Epoch [176/1000], Loss: 0.2359\n",
      "Epoch [177/1000], Loss: 0.2230\n",
      "Epoch [178/1000], Loss: 0.2272\n",
      "Epoch [179/1000], Loss: 0.2185\n",
      "Epoch [180/1000], Loss: 0.2132\n",
      "Epoch [181/1000], Loss: 0.2129\n",
      "Epoch [182/1000], Loss: 0.1956\n",
      "Epoch [183/1000], Loss: 0.1735\n",
      "Epoch [184/1000], Loss: 0.2344\n",
      "Epoch [185/1000], Loss: 0.1925\n",
      "Epoch [186/1000], Loss: 0.1906\n",
      "Epoch [187/1000], Loss: 0.1820\n",
      "Epoch [188/1000], Loss: 0.1677\n",
      "Epoch [189/1000], Loss: 0.1915\n",
      "Epoch [190/1000], Loss: 0.1988\n",
      "Epoch [191/1000], Loss: 0.1905\n",
      "Epoch [192/1000], Loss: 0.2004\n",
      "Epoch [193/1000], Loss: 0.1982\n",
      "Epoch [194/1000], Loss: 0.1992\n",
      "Epoch [195/1000], Loss: 0.1914\n",
      "Epoch [196/1000], Loss: 0.1740\n",
      "Epoch [197/1000], Loss: 0.1665\n",
      "Epoch [198/1000], Loss: 0.1656\n",
      "Epoch [199/1000], Loss: 0.1657\n",
      "Epoch [200/1000], Loss: 0.1651\n",
      "Epoch [201/1000], Loss: 0.1624\n",
      "Epoch [202/1000], Loss: 0.1712\n",
      "Epoch [203/1000], Loss: 0.1716\n",
      "Epoch [204/1000], Loss: 0.1795\n",
      "Epoch [205/1000], Loss: 0.1930\n",
      "Epoch [206/1000], Loss: 0.1907\n",
      "Epoch [207/1000], Loss: 0.1864\n",
      "Epoch [208/1000], Loss: 0.1792\n",
      "Epoch [209/1000], Loss: 0.1747\n",
      "Epoch [210/1000], Loss: 0.1737\n",
      "Epoch [211/1000], Loss: 0.1755\n",
      "Epoch [212/1000], Loss: 0.1881\n",
      "Epoch [213/1000], Loss: 0.1989\n",
      "Epoch [214/1000], Loss: 0.2001\n",
      "Epoch [215/1000], Loss: 0.1799\n",
      "Epoch [216/1000], Loss: 0.1918\n",
      "Epoch [217/1000], Loss: 0.1825\n",
      "Epoch [218/1000], Loss: 0.1674\n",
      "Epoch [219/1000], Loss: 0.1672\n",
      "Epoch [220/1000], Loss: 0.1652\n",
      "Epoch [221/1000], Loss: 0.1663\n",
      "Epoch [222/1000], Loss: 0.1628\n",
      "Epoch [223/1000], Loss: 0.1612\n",
      "Epoch [224/1000], Loss: 0.1839\n",
      "Epoch [225/1000], Loss: 0.1933\n",
      "Epoch [226/1000], Loss: 0.1731\n",
      "Epoch [227/1000], Loss: 0.1954\n",
      "Epoch [228/1000], Loss: 0.1936\n",
      "Epoch [229/1000], Loss: 0.1718\n",
      "Epoch [230/1000], Loss: 0.1657\n",
      "Epoch [231/1000], Loss: 0.1634\n",
      "Epoch [232/1000], Loss: 0.1686\n",
      "Epoch [233/1000], Loss: 0.1645\n",
      "Epoch [234/1000], Loss: 0.1617\n",
      "Epoch [235/1000], Loss: 0.1667\n",
      "Epoch [236/1000], Loss: 0.1613\n",
      "Epoch [237/1000], Loss: 0.1624\n",
      "Epoch [238/1000], Loss: 0.1721\n",
      "Epoch [239/1000], Loss: 0.1721\n",
      "Epoch [240/1000], Loss: 0.1783\n",
      "Epoch [241/1000], Loss: 0.1609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [242/1000], Loss: 0.1603\n",
      "Epoch [243/1000], Loss: 0.1592\n",
      "Epoch [244/1000], Loss: 0.1589\n",
      "Epoch [245/1000], Loss: 0.1611\n",
      "Epoch [246/1000], Loss: 0.1858\n",
      "Epoch [247/1000], Loss: 0.1990\n",
      "Epoch [248/1000], Loss: 0.2031\n",
      "Epoch [249/1000], Loss: 0.1951\n",
      "Epoch [250/1000], Loss: 0.1913\n",
      "Epoch [251/1000], Loss: 0.2832\n",
      "Epoch [252/1000], Loss: 0.1959\n",
      "Epoch [253/1000], Loss: 0.1831\n",
      "Epoch [254/1000], Loss: 0.1850\n",
      "Epoch [255/1000], Loss: 0.1796\n",
      "Epoch [256/1000], Loss: 0.1691\n",
      "Epoch [257/1000], Loss: 0.1641\n",
      "Epoch [258/1000], Loss: 0.1627\n",
      "Epoch [259/1000], Loss: 0.1734\n",
      "Epoch [260/1000], Loss: 0.1569\n",
      "Epoch [261/1000], Loss: 0.1566\n",
      "Epoch [262/1000], Loss: 0.1604\n",
      "Epoch [263/1000], Loss: 0.1547\n",
      "Epoch [264/1000], Loss: 0.1554\n",
      "Epoch [265/1000], Loss: 0.1814\n",
      "Epoch [266/1000], Loss: 0.1690\n",
      "Epoch [267/1000], Loss: 0.1589\n",
      "Epoch [268/1000], Loss: 0.1572\n",
      "Epoch [269/1000], Loss: 0.1646\n",
      "Epoch [270/1000], Loss: 0.2007\n",
      "Epoch [271/1000], Loss: 0.1877\n",
      "Epoch [272/1000], Loss: 0.1841\n",
      "Epoch [273/1000], Loss: 0.1765\n",
      "Epoch [274/1000], Loss: 0.2057\n",
      "Epoch [275/1000], Loss: 0.1869\n",
      "Epoch [276/1000], Loss: 0.1554\n",
      "Epoch [277/1000], Loss: 0.1599\n",
      "Epoch [278/1000], Loss: 0.1569\n",
      "Epoch [279/1000], Loss: 0.1562\n",
      "Epoch [280/1000], Loss: 0.1533\n",
      "Epoch [281/1000], Loss: 0.1540\n",
      "Epoch [282/1000], Loss: 0.1514\n",
      "Epoch [283/1000], Loss: 0.1765\n",
      "Epoch [284/1000], Loss: 0.2080\n",
      "Epoch [285/1000], Loss: 0.1884\n",
      "Epoch [286/1000], Loss: 0.2017\n",
      "Epoch [287/1000], Loss: 0.1653\n",
      "Epoch [288/1000], Loss: 0.1600\n",
      "Epoch [289/1000], Loss: 0.1582\n",
      "Epoch [290/1000], Loss: 0.1576\n",
      "Epoch [291/1000], Loss: 0.1806\n",
      "Epoch [292/1000], Loss: 0.1775\n",
      "Epoch [293/1000], Loss: 0.1730\n",
      "Epoch [294/1000], Loss: 0.1587\n",
      "Epoch [295/1000], Loss: 0.1587\n",
      "Epoch [296/1000], Loss: 0.1602\n",
      "Epoch [297/1000], Loss: 0.1603\n",
      "Epoch [298/1000], Loss: 0.1582\n",
      "Epoch [299/1000], Loss: 0.1570\n",
      "Epoch [300/1000], Loss: 0.1593\n",
      "Epoch [301/1000], Loss: 0.1586\n",
      "Epoch [302/1000], Loss: 0.1586\n",
      "Epoch [303/1000], Loss: 0.1578\n",
      "Epoch [304/1000], Loss: 0.1574\n",
      "Epoch [305/1000], Loss: 0.1569\n",
      "Epoch [306/1000], Loss: 0.1571\n",
      "Epoch [307/1000], Loss: 0.1560\n",
      "Epoch [308/1000], Loss: 0.1571\n",
      "Epoch [309/1000], Loss: 0.1564\n",
      "Epoch [310/1000], Loss: 0.1556\n",
      "Epoch [311/1000], Loss: 0.1568\n",
      "Epoch [312/1000], Loss: 0.1563\n",
      "Epoch [313/1000], Loss: 0.1559\n",
      "Epoch [314/1000], Loss: 0.1558\n",
      "Epoch [315/1000], Loss: 0.1571\n",
      "Epoch [316/1000], Loss: 0.1561\n",
      "Epoch [317/1000], Loss: 0.1563\n",
      "Epoch [318/1000], Loss: 0.1575\n",
      "Epoch [319/1000], Loss: 0.1570\n",
      "Epoch [320/1000], Loss: 0.1569\n",
      "Epoch [321/1000], Loss: 0.1565\n",
      "Epoch [322/1000], Loss: 0.1563\n",
      "Epoch [323/1000], Loss: 0.1574\n",
      "Epoch [324/1000], Loss: 0.1558\n",
      "Epoch [325/1000], Loss: 0.1550\n",
      "Epoch [326/1000], Loss: 0.1557\n",
      "Epoch [327/1000], Loss: 0.1554\n",
      "Epoch [328/1000], Loss: 0.1566\n",
      "Epoch [329/1000], Loss: 0.1544\n",
      "Epoch [330/1000], Loss: 0.1554\n",
      "Epoch [331/1000], Loss: 0.1575\n",
      "Epoch [332/1000], Loss: 0.1575\n",
      "Epoch [333/1000], Loss: 0.1552\n",
      "Epoch [334/1000], Loss: 0.1568\n",
      "Epoch [335/1000], Loss: 0.1548\n",
      "Epoch [336/1000], Loss: 0.1578\n",
      "Epoch [337/1000], Loss: 0.1558\n",
      "Epoch [338/1000], Loss: 0.1562\n",
      "Epoch [339/1000], Loss: 0.1563\n",
      "Epoch [340/1000], Loss: 0.1581\n",
      "Epoch [341/1000], Loss: 0.1570\n",
      "Epoch [342/1000], Loss: 0.1561\n",
      "Epoch [343/1000], Loss: 0.1577\n",
      "Epoch [344/1000], Loss: 0.1572\n",
      "Epoch [345/1000], Loss: 0.1566\n",
      "Epoch [346/1000], Loss: 0.1547\n",
      "Epoch [347/1000], Loss: 0.1562\n",
      "Epoch [348/1000], Loss: 0.1559\n",
      "Epoch [349/1000], Loss: 0.1582\n",
      "Epoch [350/1000], Loss: 0.1581\n",
      "Epoch [351/1000], Loss: 0.1583\n",
      "Epoch [352/1000], Loss: 0.1554\n",
      "Epoch [353/1000], Loss: 0.1552\n",
      "Epoch [354/1000], Loss: 0.1546\n",
      "Epoch [355/1000], Loss: 0.1560\n",
      "Epoch [356/1000], Loss: 0.1558\n",
      "Epoch [357/1000], Loss: 0.1560\n",
      "Epoch [358/1000], Loss: 0.1547\n",
      "Epoch [359/1000], Loss: 0.1563\n",
      "Epoch [360/1000], Loss: 0.1573\n",
      "Epoch [361/1000], Loss: 0.1561\n",
      "Epoch [362/1000], Loss: 0.1540\n",
      "Epoch [363/1000], Loss: 0.1537\n",
      "Epoch [364/1000], Loss: 0.1556\n",
      "Epoch [365/1000], Loss: 0.1560\n",
      "Epoch [366/1000], Loss: 0.1560\n",
      "Epoch [367/1000], Loss: 0.1567\n",
      "Epoch [368/1000], Loss: 0.1544\n",
      "Epoch [369/1000], Loss: 0.1569\n",
      "Epoch [370/1000], Loss: 0.1560\n",
      "Epoch [371/1000], Loss: 0.1564\n",
      "Epoch [372/1000], Loss: 0.1548\n",
      "Epoch [373/1000], Loss: 0.1578\n",
      "Epoch [374/1000], Loss: 0.1551\n",
      "Epoch [375/1000], Loss: 0.1563\n",
      "Epoch [376/1000], Loss: 0.1546\n",
      "Epoch [377/1000], Loss: 0.1568\n",
      "Epoch [378/1000], Loss: 0.1556\n",
      "Epoch [379/1000], Loss: 0.1555\n",
      "Epoch [380/1000], Loss: 0.1561\n",
      "Epoch [381/1000], Loss: 0.1557\n",
      "Epoch [382/1000], Loss: 0.1566\n",
      "Epoch [383/1000], Loss: 0.1574\n",
      "Epoch [384/1000], Loss: 0.1542\n",
      "Epoch [385/1000], Loss: 0.1552\n",
      "Epoch [386/1000], Loss: 0.1565\n",
      "Epoch [387/1000], Loss: 0.1566\n",
      "Epoch [388/1000], Loss: 0.1564\n",
      "Epoch [389/1000], Loss: 0.1554\n",
      "Epoch [390/1000], Loss: 0.1562\n",
      "Epoch [391/1000], Loss: 0.1556\n",
      "Epoch [392/1000], Loss: 0.1542\n",
      "Epoch [393/1000], Loss: 0.1554\n",
      "Epoch [394/1000], Loss: 0.1544\n",
      "Epoch [395/1000], Loss: 0.1563\n",
      "Epoch [396/1000], Loss: 0.1556\n",
      "Epoch [397/1000], Loss: 0.1548\n",
      "Epoch [398/1000], Loss: 0.1540\n",
      "Epoch [399/1000], Loss: 0.1543\n",
      "Epoch [400/1000], Loss: 0.1562\n",
      "Epoch [401/1000], Loss: 0.1547\n",
      "Epoch [402/1000], Loss: 0.1564\n",
      "Epoch [403/1000], Loss: 0.1567\n",
      "Epoch [404/1000], Loss: 0.1570\n",
      "Epoch [405/1000], Loss: 0.1532\n",
      "Epoch [406/1000], Loss: 0.1560\n",
      "Epoch [407/1000], Loss: 0.1555\n",
      "Epoch [408/1000], Loss: 0.1564\n",
      "Epoch [409/1000], Loss: 0.1558\n",
      "Epoch [410/1000], Loss: 0.1547\n",
      "Epoch [411/1000], Loss: 0.1550\n",
      "Epoch [412/1000], Loss: 0.1560\n",
      "Epoch [413/1000], Loss: 0.1553\n",
      "Epoch [414/1000], Loss: 0.1566\n",
      "Epoch [415/1000], Loss: 0.1566\n",
      "Epoch [416/1000], Loss: 0.1562\n",
      "Epoch [417/1000], Loss: 0.1559\n",
      "Epoch [418/1000], Loss: 0.1540\n",
      "Epoch [419/1000], Loss: 0.1565\n",
      "Epoch [420/1000], Loss: 0.1552\n",
      "Epoch [421/1000], Loss: 0.1567\n",
      "Epoch [422/1000], Loss: 0.1545\n",
      "Epoch [423/1000], Loss: 0.1562\n",
      "Epoch [424/1000], Loss: 0.1552\n",
      "Epoch [425/1000], Loss: 0.1551\n",
      "Epoch [426/1000], Loss: 0.1557\n",
      "Epoch [427/1000], Loss: 0.1561\n",
      "Epoch [428/1000], Loss: 0.1561\n",
      "Epoch [429/1000], Loss: 0.1586\n",
      "Epoch [430/1000], Loss: 0.1580\n",
      "Epoch [431/1000], Loss: 0.1570\n",
      "Epoch [432/1000], Loss: 0.1570\n",
      "Epoch [433/1000], Loss: 0.1567\n",
      "Epoch [434/1000], Loss: 0.1562\n",
      "Epoch [435/1000], Loss: 0.1568\n",
      "Epoch [436/1000], Loss: 0.1576\n",
      "Epoch [437/1000], Loss: 0.1574\n",
      "Epoch [438/1000], Loss: 0.1562\n",
      "Epoch [439/1000], Loss: 0.1567\n",
      "Epoch [440/1000], Loss: 0.1565\n",
      "Epoch [441/1000], Loss: 0.1557\n",
      "Epoch [442/1000], Loss: 0.1555\n",
      "Epoch [443/1000], Loss: 0.1558\n",
      "Epoch [444/1000], Loss: 0.1548\n",
      "Epoch [445/1000], Loss: 0.1550\n",
      "Epoch [446/1000], Loss: 0.1553\n",
      "Epoch [447/1000], Loss: 0.1577\n",
      "Epoch [448/1000], Loss: 0.1571\n",
      "Epoch [449/1000], Loss: 0.1558\n",
      "Epoch [450/1000], Loss: 0.1552\n",
      "Epoch [451/1000], Loss: 0.1560\n",
      "Epoch [452/1000], Loss: 0.1556\n",
      "Epoch [453/1000], Loss: 0.1571\n",
      "Epoch [454/1000], Loss: 0.1541\n",
      "Epoch [455/1000], Loss: 0.1556\n",
      "Epoch [456/1000], Loss: 0.1568\n",
      "Epoch [457/1000], Loss: 0.1562\n",
      "Epoch [458/1000], Loss: 0.1560\n",
      "Epoch [459/1000], Loss: 0.1565\n",
      "Epoch [460/1000], Loss: 0.1545\n",
      "Epoch [461/1000], Loss: 0.1566\n",
      "Epoch [462/1000], Loss: 0.1562\n",
      "Epoch [463/1000], Loss: 0.1552\n",
      "Epoch [464/1000], Loss: 0.1549\n",
      "Epoch [465/1000], Loss: 0.1556\n",
      "Epoch [466/1000], Loss: 0.1575\n",
      "Epoch [467/1000], Loss: 0.1569\n",
      "Epoch [468/1000], Loss: 0.1580\n",
      "Epoch [469/1000], Loss: 0.1553\n",
      "Epoch [470/1000], Loss: 0.1563\n",
      "Epoch [471/1000], Loss: 0.1566\n",
      "Epoch [472/1000], Loss: 0.1561\n",
      "Epoch [473/1000], Loss: 0.1565\n",
      "Epoch [474/1000], Loss: 0.1549\n",
      "Epoch [475/1000], Loss: 0.1578\n",
      "Epoch [476/1000], Loss: 0.1553\n",
      "Epoch [477/1000], Loss: 0.1558\n",
      "Epoch [478/1000], Loss: 0.1550\n",
      "Epoch [479/1000], Loss: 0.1551\n",
      "Epoch [480/1000], Loss: 0.1537\n",
      "Epoch [481/1000], Loss: 0.1539\n",
      "Epoch [482/1000], Loss: 0.1559\n",
      "Epoch [483/1000], Loss: 0.1543\n",
      "Epoch [484/1000], Loss: 0.1584\n",
      "Epoch [485/1000], Loss: 0.1558\n",
      "Epoch [486/1000], Loss: 0.1549\n",
      "Epoch [487/1000], Loss: 0.1561\n",
      "Epoch [488/1000], Loss: 0.1552\n",
      "Epoch [489/1000], Loss: 0.1555\n",
      "Epoch [490/1000], Loss: 0.1548\n",
      "Epoch [491/1000], Loss: 0.1570\n",
      "Epoch [492/1000], Loss: 0.1567\n",
      "Epoch [493/1000], Loss: 0.1540\n",
      "Epoch [494/1000], Loss: 0.1539\n",
      "Epoch [495/1000], Loss: 0.1576\n",
      "Epoch [496/1000], Loss: 0.1537\n",
      "Epoch [497/1000], Loss: 0.1557\n",
      "Epoch [498/1000], Loss: 0.1546\n",
      "Epoch [499/1000], Loss: 0.1559\n",
      "Epoch [500/1000], Loss: 0.1572\n",
      "Epoch [501/1000], Loss: 0.1558\n",
      "Epoch [502/1000], Loss: 0.1541\n",
      "Epoch [503/1000], Loss: 0.1568\n",
      "Epoch [504/1000], Loss: 0.1552\n",
      "Epoch [505/1000], Loss: 0.1560\n",
      "Epoch [506/1000], Loss: 0.1545\n",
      "Epoch [507/1000], Loss: 0.1569\n",
      "Epoch [508/1000], Loss: 0.1557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [509/1000], Loss: 0.1566\n",
      "Epoch [510/1000], Loss: 0.1579\n",
      "Epoch [511/1000], Loss: 0.1573\n",
      "Epoch [512/1000], Loss: 0.1527\n",
      "Epoch [513/1000], Loss: 0.1564\n",
      "Epoch [514/1000], Loss: 0.1562\n",
      "Epoch [515/1000], Loss: 0.1569\n",
      "Epoch [516/1000], Loss: 0.1555\n",
      "Epoch [517/1000], Loss: 0.1558\n",
      "Epoch [518/1000], Loss: 0.1559\n",
      "Epoch [519/1000], Loss: 0.1555\n",
      "Epoch [520/1000], Loss: 0.1568\n",
      "Epoch [521/1000], Loss: 0.1560\n",
      "Epoch [522/1000], Loss: 0.1549\n",
      "Epoch [523/1000], Loss: 0.1562\n",
      "Epoch [524/1000], Loss: 0.1555\n",
      "Epoch [525/1000], Loss: 0.1558\n",
      "Epoch [526/1000], Loss: 0.1572\n",
      "Epoch [527/1000], Loss: 0.1563\n",
      "Epoch [528/1000], Loss: 0.1576\n",
      "Epoch [529/1000], Loss: 0.1561\n",
      "Epoch [530/1000], Loss: 0.1548\n",
      "Epoch [531/1000], Loss: 0.1578\n",
      "Epoch [532/1000], Loss: 0.1571\n",
      "Epoch [533/1000], Loss: 0.1568\n",
      "Epoch [534/1000], Loss: 0.1560\n",
      "Epoch [535/1000], Loss: 0.1560\n",
      "Epoch [536/1000], Loss: 0.1552\n",
      "Epoch [537/1000], Loss: 0.1542\n",
      "Epoch [538/1000], Loss: 0.1579\n",
      "Epoch [539/1000], Loss: 0.1577\n",
      "Epoch [540/1000], Loss: 0.1569\n",
      "Epoch [541/1000], Loss: 0.1564\n",
      "Epoch [542/1000], Loss: 0.1540\n",
      "Epoch [543/1000], Loss: 0.1547\n",
      "Epoch [544/1000], Loss: 0.1554\n",
      "Epoch [545/1000], Loss: 0.1569\n",
      "Epoch [546/1000], Loss: 0.1566\n",
      "Epoch [547/1000], Loss: 0.1566\n",
      "Epoch [548/1000], Loss: 0.1555\n",
      "Epoch [549/1000], Loss: 0.1579\n",
      "Epoch [550/1000], Loss: 0.1549\n",
      "Epoch [551/1000], Loss: 0.1548\n",
      "Epoch [552/1000], Loss: 0.1558\n",
      "Epoch [553/1000], Loss: 0.1560\n",
      "Epoch [554/1000], Loss: 0.1552\n",
      "Epoch [555/1000], Loss: 0.1558\n",
      "Epoch [556/1000], Loss: 0.1552\n",
      "Epoch [557/1000], Loss: 0.1554\n",
      "Epoch [558/1000], Loss: 0.1558\n",
      "Epoch [559/1000], Loss: 0.1557\n",
      "Epoch [560/1000], Loss: 0.1559\n",
      "Epoch [561/1000], Loss: 0.1567\n",
      "Epoch [562/1000], Loss: 0.1570\n",
      "Epoch [563/1000], Loss: 0.1560\n",
      "Epoch [564/1000], Loss: 0.1579\n",
      "Epoch [565/1000], Loss: 0.1558\n",
      "Epoch [566/1000], Loss: 0.1556\n",
      "Epoch [567/1000], Loss: 0.1565\n",
      "Epoch [568/1000], Loss: 0.1560\n",
      "Epoch [569/1000], Loss: 0.1556\n",
      "Epoch [570/1000], Loss: 0.1556\n",
      "Epoch [571/1000], Loss: 0.1532\n",
      "Epoch [572/1000], Loss: 0.1560\n",
      "Epoch [573/1000], Loss: 0.1551\n",
      "Epoch [574/1000], Loss: 0.1564\n",
      "Epoch [575/1000], Loss: 0.1569\n",
      "Epoch [576/1000], Loss: 0.1566\n",
      "Epoch [577/1000], Loss: 0.1547\n",
      "Epoch [578/1000], Loss: 0.1566\n",
      "Epoch [579/1000], Loss: 0.1542\n",
      "Epoch [580/1000], Loss: 0.1560\n",
      "Epoch [581/1000], Loss: 0.1561\n",
      "Epoch [582/1000], Loss: 0.1560\n",
      "Epoch [583/1000], Loss: 0.1565\n",
      "Epoch [584/1000], Loss: 0.1552\n",
      "Epoch [585/1000], Loss: 0.1547\n",
      "Epoch [586/1000], Loss: 0.1555\n",
      "Epoch [587/1000], Loss: 0.1555\n",
      "Epoch [588/1000], Loss: 0.1554\n",
      "Epoch [589/1000], Loss: 0.1550\n",
      "Epoch [590/1000], Loss: 0.1552\n",
      "Epoch [591/1000], Loss: 0.1566\n",
      "Epoch [592/1000], Loss: 0.1557\n",
      "Epoch [593/1000], Loss: 0.1551\n",
      "Epoch [594/1000], Loss: 0.1569\n",
      "Epoch [595/1000], Loss: 0.1570\n",
      "Epoch [596/1000], Loss: 0.1565\n",
      "Epoch [597/1000], Loss: 0.1560\n",
      "Epoch [598/1000], Loss: 0.1550\n",
      "Epoch [599/1000], Loss: 0.1561\n",
      "Epoch [600/1000], Loss: 0.1581\n",
      "Epoch [601/1000], Loss: 0.1569\n",
      "Epoch [602/1000], Loss: 0.1544\n",
      "Epoch [603/1000], Loss: 0.1544\n",
      "Epoch [604/1000], Loss: 0.1562\n",
      "Epoch [605/1000], Loss: 0.1582\n",
      "Epoch [606/1000], Loss: 0.1661\n",
      "Epoch [607/1000], Loss: 0.1499\n",
      "Epoch [608/1000], Loss: 0.1513\n",
      "Epoch [609/1000], Loss: 0.1516\n",
      "Epoch [610/1000], Loss: 0.1590\n",
      "Epoch [611/1000], Loss: 0.1528\n",
      "Epoch [612/1000], Loss: 0.1546\n",
      "Epoch [613/1000], Loss: 0.1616\n",
      "Epoch [614/1000], Loss: 0.3623\n",
      "Epoch [615/1000], Loss: 0.3440\n",
      "Epoch [616/1000], Loss: 0.3451\n",
      "Epoch [617/1000], Loss: 0.3441\n",
      "Epoch [618/1000], Loss: 0.3398\n",
      "Epoch [619/1000], Loss: 0.3373\n",
      "Epoch [620/1000], Loss: 0.3403\n",
      "Epoch [621/1000], Loss: 0.3374\n",
      "Epoch [622/1000], Loss: 0.3380\n",
      "Epoch [623/1000], Loss: 0.3373\n",
      "Epoch [624/1000], Loss: 0.3373\n",
      "Epoch [625/1000], Loss: 0.3640\n",
      "Epoch [626/1000], Loss: 0.3741\n",
      "Epoch [627/1000], Loss: 0.3648\n",
      "Epoch [628/1000], Loss: 0.3638\n",
      "Epoch [629/1000], Loss: 0.3589\n",
      "Epoch [630/1000], Loss: 0.3615\n",
      "Epoch [631/1000], Loss: 0.3596\n",
      "Epoch [632/1000], Loss: 0.3592\n",
      "Epoch [633/1000], Loss: 0.3664\n",
      "Epoch [634/1000], Loss: 0.3614\n",
      "Epoch [635/1000], Loss: 0.3617\n",
      "Epoch [636/1000], Loss: 0.3639\n",
      "Epoch [637/1000], Loss: 0.3596\n",
      "Epoch [638/1000], Loss: 0.3633\n",
      "Epoch [639/1000], Loss: 0.3586\n",
      "Epoch [640/1000], Loss: 0.3575\n",
      "Epoch [641/1000], Loss: 0.3529\n",
      "Epoch [642/1000], Loss: 0.3442\n",
      "Epoch [643/1000], Loss: 0.3449\n",
      "Epoch [644/1000], Loss: 0.3495\n",
      "Epoch [645/1000], Loss: 0.3474\n",
      "Epoch [646/1000], Loss: 0.3550\n",
      "Epoch [647/1000], Loss: 0.3440\n",
      "Epoch [648/1000], Loss: 0.3463\n",
      "Epoch [649/1000], Loss: 0.3517\n",
      "Epoch [650/1000], Loss: 0.3527\n",
      "Epoch [651/1000], Loss: 0.3522\n",
      "Epoch [652/1000], Loss: 0.3513\n",
      "Epoch [653/1000], Loss: 0.3516\n",
      "Epoch [654/1000], Loss: 0.3503\n",
      "Epoch [655/1000], Loss: 0.3523\n",
      "Epoch [656/1000], Loss: 0.3519\n",
      "Epoch [657/1000], Loss: 0.3497\n",
      "Epoch [658/1000], Loss: 0.3486\n",
      "Epoch [659/1000], Loss: 0.3513\n",
      "Epoch [660/1000], Loss: 0.3463\n",
      "Epoch [661/1000], Loss: 0.3496\n",
      "Epoch [662/1000], Loss: 0.3472\n",
      "Epoch [663/1000], Loss: 0.3469\n",
      "Epoch [664/1000], Loss: 0.3498\n",
      "Epoch [665/1000], Loss: 0.3539\n",
      "Epoch [666/1000], Loss: 0.3500\n",
      "Epoch [667/1000], Loss: 0.3537\n",
      "Epoch [668/1000], Loss: 0.3468\n",
      "Epoch [669/1000], Loss: 0.3497\n",
      "Epoch [670/1000], Loss: 0.3525\n",
      "Epoch [671/1000], Loss: 0.3503\n",
      "Epoch [672/1000], Loss: 0.3520\n",
      "Epoch [673/1000], Loss: 0.3513\n",
      "Epoch [674/1000], Loss: 0.3542\n",
      "Epoch [675/1000], Loss: 0.3528\n",
      "Epoch [676/1000], Loss: 0.3571\n",
      "Epoch [677/1000], Loss: 0.3528\n",
      "Epoch [678/1000], Loss: 0.3566\n",
      "Epoch [679/1000], Loss: 0.3506\n",
      "Epoch [680/1000], Loss: 0.3575\n",
      "Epoch [681/1000], Loss: 0.3543\n",
      "Epoch [682/1000], Loss: 0.3539\n",
      "Epoch [683/1000], Loss: 0.3527\n",
      "Epoch [684/1000], Loss: 0.3510\n",
      "Epoch [685/1000], Loss: 0.3548\n",
      "Epoch [686/1000], Loss: 0.3521\n",
      "Epoch [687/1000], Loss: 0.3570\n",
      "Epoch [688/1000], Loss: 0.3548\n",
      "Epoch [689/1000], Loss: 0.3540\n",
      "Epoch [690/1000], Loss: 0.3570\n",
      "Epoch [691/1000], Loss: 0.3528\n",
      "Epoch [692/1000], Loss: 0.3514\n",
      "Epoch [693/1000], Loss: 0.3522\n",
      "Epoch [694/1000], Loss: 0.3518\n",
      "Epoch [695/1000], Loss: 0.3560\n",
      "Epoch [696/1000], Loss: 0.3542\n",
      "Epoch [697/1000], Loss: 0.3510\n",
      "Epoch [698/1000], Loss: 0.3533\n",
      "Epoch [699/1000], Loss: 0.3527\n",
      "Epoch [700/1000], Loss: 0.3517\n",
      "Epoch [701/1000], Loss: 0.3583\n",
      "Epoch [702/1000], Loss: 0.3541\n",
      "Epoch [703/1000], Loss: 0.3579\n",
      "Epoch [704/1000], Loss: 0.3510\n",
      "Epoch [705/1000], Loss: 0.3494\n",
      "Epoch [706/1000], Loss: 0.3511\n",
      "Epoch [707/1000], Loss: 0.3570\n",
      "Epoch [708/1000], Loss: 0.3553\n",
      "Epoch [709/1000], Loss: 0.3549\n",
      "Epoch [710/1000], Loss: 0.3502\n",
      "Epoch [711/1000], Loss: 0.3534\n",
      "Epoch [712/1000], Loss: 0.3547\n",
      "Epoch [713/1000], Loss: 0.3529\n",
      "Epoch [714/1000], Loss: 0.3543\n",
      "Epoch [715/1000], Loss: 0.3486\n",
      "Epoch [716/1000], Loss: 0.3538\n",
      "Epoch [717/1000], Loss: 0.3555\n",
      "Epoch [718/1000], Loss: 0.3511\n",
      "Epoch [719/1000], Loss: 0.3575\n",
      "Epoch [720/1000], Loss: 0.3516\n",
      "Epoch [721/1000], Loss: 0.3628\n",
      "Epoch [722/1000], Loss: 0.3557\n",
      "Epoch [723/1000], Loss: 0.3543\n",
      "Epoch [724/1000], Loss: 0.3553\n",
      "Epoch [725/1000], Loss: 0.3537\n",
      "Epoch [726/1000], Loss: 0.3572\n",
      "Epoch [727/1000], Loss: 0.3514\n",
      "Epoch [728/1000], Loss: 0.3510\n",
      "Epoch [729/1000], Loss: 0.3541\n",
      "Epoch [730/1000], Loss: 0.3578\n",
      "Epoch [731/1000], Loss: 0.3495\n",
      "Epoch [732/1000], Loss: 0.3576\n",
      "Epoch [733/1000], Loss: 0.3535\n",
      "Epoch [734/1000], Loss: 0.3574\n",
      "Epoch [735/1000], Loss: 0.3560\n",
      "Epoch [736/1000], Loss: 0.3544\n",
      "Epoch [737/1000], Loss: 0.3515\n",
      "Epoch [738/1000], Loss: 0.3481\n",
      "Epoch [739/1000], Loss: 0.3545\n",
      "Epoch [740/1000], Loss: 0.3530\n",
      "Epoch [741/1000], Loss: 0.3553\n",
      "Epoch [742/1000], Loss: 0.3520\n",
      "Epoch [743/1000], Loss: 0.3524\n",
      "Epoch [744/1000], Loss: 0.3536\n",
      "Epoch [745/1000], Loss: 0.3491\n",
      "Epoch [746/1000], Loss: 0.3545\n",
      "Epoch [747/1000], Loss: 0.3564\n",
      "Epoch [748/1000], Loss: 0.3539\n",
      "Epoch [749/1000], Loss: 0.3567\n",
      "Epoch [750/1000], Loss: 0.3510\n",
      "Epoch [751/1000], Loss: 0.3593\n",
      "Epoch [752/1000], Loss: 0.3562\n",
      "Epoch [753/1000], Loss: 0.3572\n",
      "Epoch [754/1000], Loss: 0.3529\n",
      "Epoch [755/1000], Loss: 0.3547\n",
      "Epoch [756/1000], Loss: 0.3519\n",
      "Epoch [757/1000], Loss: 0.3525\n",
      "Epoch [758/1000], Loss: 0.3586\n",
      "Epoch [759/1000], Loss: 0.3509\n",
      "Epoch [760/1000], Loss: 0.3506\n",
      "Epoch [761/1000], Loss: 0.3566\n",
      "Epoch [762/1000], Loss: 0.3524\n",
      "Epoch [763/1000], Loss: 0.3584\n",
      "Epoch [764/1000], Loss: 0.3540\n",
      "Epoch [765/1000], Loss: 0.3541\n",
      "Epoch [766/1000], Loss: 0.3548\n",
      "Epoch [767/1000], Loss: 0.3576\n",
      "Epoch [768/1000], Loss: 0.3583\n",
      "Epoch [769/1000], Loss: 0.3551\n",
      "Epoch [770/1000], Loss: 0.3532\n",
      "Epoch [771/1000], Loss: 0.3532\n",
      "Epoch [772/1000], Loss: 0.3535\n",
      "Epoch [773/1000], Loss: 0.3533\n",
      "Epoch [774/1000], Loss: 0.3514\n",
      "Epoch [775/1000], Loss: 0.3556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [776/1000], Loss: 0.3526\n",
      "Epoch [777/1000], Loss: 0.3510\n",
      "Epoch [778/1000], Loss: 0.3520\n",
      "Epoch [779/1000], Loss: 0.3508\n",
      "Epoch [780/1000], Loss: 0.3551\n",
      "Epoch [781/1000], Loss: 0.3520\n",
      "Epoch [782/1000], Loss: 0.3494\n",
      "Epoch [783/1000], Loss: 0.3524\n",
      "Epoch [784/1000], Loss: 0.3559\n",
      "Epoch [785/1000], Loss: 0.3514\n",
      "Epoch [786/1000], Loss: 0.3515\n",
      "Epoch [787/1000], Loss: 0.3574\n",
      "Epoch [788/1000], Loss: 0.3551\n",
      "Epoch [789/1000], Loss: 0.3546\n",
      "Epoch [790/1000], Loss: 0.3555\n",
      "Epoch [791/1000], Loss: 0.3576\n",
      "Epoch [792/1000], Loss: 0.3528\n",
      "Epoch [793/1000], Loss: 0.3515\n",
      "Epoch [794/1000], Loss: 0.3527\n",
      "Epoch [795/1000], Loss: 0.3528\n",
      "Epoch [796/1000], Loss: 0.3535\n",
      "Epoch [797/1000], Loss: 0.3522\n",
      "Epoch [798/1000], Loss: 0.3514\n",
      "Epoch [799/1000], Loss: 0.3529\n",
      "Epoch [800/1000], Loss: 0.3537\n",
      "Epoch [801/1000], Loss: 0.3566\n",
      "Epoch [802/1000], Loss: 0.3553\n",
      "Epoch [803/1000], Loss: 0.3533\n",
      "Epoch [804/1000], Loss: 0.3518\n",
      "Epoch [805/1000], Loss: 0.3540\n",
      "Epoch [806/1000], Loss: 0.3531\n",
      "Epoch [807/1000], Loss: 0.3538\n",
      "Epoch [808/1000], Loss: 0.3568\n",
      "Epoch [809/1000], Loss: 0.3590\n",
      "Epoch [810/1000], Loss: 0.3593\n",
      "Epoch [811/1000], Loss: 0.3542\n",
      "Epoch [812/1000], Loss: 0.3554\n",
      "Epoch [813/1000], Loss: 0.3558\n",
      "Epoch [814/1000], Loss: 0.3528\n",
      "Epoch [815/1000], Loss: 0.3512\n",
      "Epoch [816/1000], Loss: 0.3536\n",
      "Epoch [817/1000], Loss: 0.3541\n",
      "Epoch [818/1000], Loss: 0.3565\n",
      "Epoch [819/1000], Loss: 0.3540\n",
      "Epoch [820/1000], Loss: 0.3504\n",
      "Epoch [821/1000], Loss: 0.3523\n",
      "Epoch [822/1000], Loss: 0.3541\n",
      "Epoch [823/1000], Loss: 0.3529\n",
      "Epoch [824/1000], Loss: 0.3517\n",
      "Epoch [825/1000], Loss: 0.3586\n",
      "Epoch [826/1000], Loss: 0.3498\n",
      "Epoch [827/1000], Loss: 0.3564\n",
      "Epoch [828/1000], Loss: 0.3559\n",
      "Epoch [829/1000], Loss: 0.3620\n",
      "Epoch [830/1000], Loss: 0.3539\n",
      "Epoch [831/1000], Loss: 0.3553\n",
      "Epoch [832/1000], Loss: 0.3543\n",
      "Epoch [833/1000], Loss: 0.3529\n",
      "Epoch [834/1000], Loss: 0.3533\n",
      "Epoch [835/1000], Loss: 0.3551\n",
      "Epoch [836/1000], Loss: 0.3542\n",
      "Epoch [837/1000], Loss: 0.3540\n",
      "Epoch [838/1000], Loss: 0.3556\n",
      "Epoch [839/1000], Loss: 0.3552\n",
      "Epoch [840/1000], Loss: 0.3554\n",
      "Epoch [841/1000], Loss: 0.3577\n",
      "Epoch [842/1000], Loss: 0.3576\n",
      "Epoch [843/1000], Loss: 0.3579\n",
      "Epoch [844/1000], Loss: 0.3550\n",
      "Epoch [845/1000], Loss: 0.3542\n",
      "Epoch [846/1000], Loss: 0.3546\n",
      "Epoch [847/1000], Loss: 0.3524\n",
      "Epoch [848/1000], Loss: 0.3541\n",
      "Epoch [849/1000], Loss: 0.3558\n",
      "Epoch [850/1000], Loss: 0.3561\n",
      "Epoch [851/1000], Loss: 0.3464\n",
      "Epoch [852/1000], Loss: 0.3568\n",
      "Epoch [853/1000], Loss: 0.3563\n",
      "Epoch [854/1000], Loss: 0.3576\n",
      "Epoch [855/1000], Loss: 0.3519\n",
      "Epoch [856/1000], Loss: 0.3533\n",
      "Epoch [857/1000], Loss: 0.3568\n",
      "Epoch [858/1000], Loss: 0.3541\n",
      "Epoch [859/1000], Loss: 0.3540\n",
      "Epoch [860/1000], Loss: 0.3548\n",
      "Epoch [861/1000], Loss: 0.3535\n",
      "Epoch [862/1000], Loss: 0.3530\n",
      "Epoch [863/1000], Loss: 0.3524\n",
      "Epoch [864/1000], Loss: 0.3574\n",
      "Epoch [865/1000], Loss: 0.3577\n",
      "Epoch [866/1000], Loss: 0.3524\n",
      "Epoch [867/1000], Loss: 0.3533\n",
      "Epoch [868/1000], Loss: 0.3557\n",
      "Epoch [869/1000], Loss: 0.3534\n",
      "Epoch [870/1000], Loss: 0.3567\n",
      "Epoch [871/1000], Loss: 0.3575\n",
      "Epoch [872/1000], Loss: 0.3572\n",
      "Epoch [873/1000], Loss: 0.3579\n",
      "Epoch [874/1000], Loss: 0.3540\n",
      "Epoch [875/1000], Loss: 0.3586\n",
      "Epoch [876/1000], Loss: 0.3506\n",
      "Epoch [877/1000], Loss: 0.3589\n",
      "Epoch [878/1000], Loss: 0.3588\n",
      "Epoch [879/1000], Loss: 0.3551\n",
      "Epoch [880/1000], Loss: 0.3553\n",
      "Epoch [881/1000], Loss: 0.3532\n",
      "Epoch [882/1000], Loss: 0.3515\n",
      "Epoch [883/1000], Loss: 0.3516\n",
      "Epoch [884/1000], Loss: 0.3526\n",
      "Epoch [885/1000], Loss: 0.3523\n",
      "Epoch [886/1000], Loss: 0.3554\n",
      "Epoch [887/1000], Loss: 0.3526\n",
      "Epoch [888/1000], Loss: 0.3486\n",
      "Epoch [889/1000], Loss: 0.3575\n",
      "Epoch [890/1000], Loss: 0.3547\n",
      "Epoch [891/1000], Loss: 0.3580\n",
      "Epoch [892/1000], Loss: 0.3546\n",
      "Epoch [893/1000], Loss: 0.3561\n",
      "Epoch [894/1000], Loss: 0.3561\n",
      "Epoch [895/1000], Loss: 0.3545\n",
      "Epoch [896/1000], Loss: 0.3529\n",
      "Epoch [897/1000], Loss: 0.3558\n",
      "Epoch [898/1000], Loss: 0.3507\n",
      "Epoch [899/1000], Loss: 0.3543\n",
      "Epoch [900/1000], Loss: 0.3529\n",
      "Epoch [901/1000], Loss: 0.3548\n",
      "Epoch [902/1000], Loss: 0.3503\n",
      "Epoch [903/1000], Loss: 0.3584\n",
      "Epoch [904/1000], Loss: 0.3556\n",
      "Epoch [905/1000], Loss: 0.3543\n",
      "Epoch [906/1000], Loss: 0.3515\n",
      "Epoch [907/1000], Loss: 0.3515\n",
      "Epoch [908/1000], Loss: 0.3551\n",
      "Epoch [909/1000], Loss: 0.3536\n",
      "Epoch [910/1000], Loss: 0.3510\n",
      "Epoch [911/1000], Loss: 0.3521\n",
      "Epoch [912/1000], Loss: 0.3553\n",
      "Epoch [913/1000], Loss: 0.3557\n",
      "Epoch [914/1000], Loss: 0.3541\n",
      "Epoch [915/1000], Loss: 0.3557\n",
      "Epoch [916/1000], Loss: 0.3555\n",
      "Epoch [917/1000], Loss: 0.3541\n",
      "Epoch [918/1000], Loss: 0.3560\n",
      "Epoch [919/1000], Loss: 0.3524\n",
      "Epoch [920/1000], Loss: 0.3571\n",
      "Epoch [921/1000], Loss: 0.3562\n",
      "Epoch [922/1000], Loss: 0.3509\n",
      "Epoch [923/1000], Loss: 0.3571\n",
      "Epoch [924/1000], Loss: 0.3521\n",
      "Epoch [925/1000], Loss: 0.3552\n",
      "Epoch [926/1000], Loss: 0.3560\n",
      "Epoch [927/1000], Loss: 0.3494\n",
      "Epoch [928/1000], Loss: 0.3533\n",
      "Epoch [929/1000], Loss: 0.3576\n",
      "Epoch [930/1000], Loss: 0.3542\n",
      "Epoch [931/1000], Loss: 0.3580\n",
      "Epoch [932/1000], Loss: 0.3549\n",
      "Epoch [933/1000], Loss: 0.3551\n",
      "Epoch [934/1000], Loss: 0.3535\n",
      "Epoch [935/1000], Loss: 0.3537\n",
      "Epoch [936/1000], Loss: 0.3545\n",
      "Epoch [937/1000], Loss: 0.3544\n",
      "Epoch [938/1000], Loss: 0.3573\n",
      "Epoch [939/1000], Loss: 0.3509\n",
      "Epoch [940/1000], Loss: 0.3471\n",
      "Epoch [941/1000], Loss: 0.3526\n",
      "Epoch [942/1000], Loss: 0.3532\n",
      "Epoch [943/1000], Loss: 0.3480\n",
      "Epoch [944/1000], Loss: 0.3543\n",
      "Epoch [945/1000], Loss: 0.3572\n",
      "Epoch [946/1000], Loss: 0.3524\n",
      "Epoch [947/1000], Loss: 0.3540\n",
      "Epoch [948/1000], Loss: 0.3568\n",
      "Epoch [949/1000], Loss: 0.3529\n",
      "Epoch [950/1000], Loss: 0.3507\n",
      "Epoch [951/1000], Loss: 0.3550\n",
      "Epoch [952/1000], Loss: 0.3530\n",
      "Epoch [953/1000], Loss: 0.3511\n",
      "Epoch [954/1000], Loss: 0.3496\n",
      "Epoch [955/1000], Loss: 0.3589\n",
      "Epoch [956/1000], Loss: 0.3538\n",
      "Epoch [957/1000], Loss: 0.3499\n",
      "Epoch [958/1000], Loss: 0.3549\n",
      "Epoch [959/1000], Loss: 0.3559\n",
      "Epoch [960/1000], Loss: 0.3541\n",
      "Epoch [961/1000], Loss: 0.3526\n",
      "Epoch [962/1000], Loss: 0.3553\n",
      "Epoch [963/1000], Loss: 0.3565\n",
      "Epoch [964/1000], Loss: 0.3545\n",
      "Epoch [965/1000], Loss: 0.3539\n",
      "Epoch [966/1000], Loss: 0.3593\n",
      "Epoch [967/1000], Loss: 0.3541\n",
      "Epoch [968/1000], Loss: 0.3516\n",
      "Epoch [969/1000], Loss: 0.3502\n",
      "Epoch [970/1000], Loss: 0.3531\n",
      "Epoch [971/1000], Loss: 0.3554\n",
      "Epoch [972/1000], Loss: 0.3546\n",
      "Epoch [973/1000], Loss: 0.3529\n",
      "Epoch [974/1000], Loss: 0.3546\n",
      "Epoch [975/1000], Loss: 0.3497\n",
      "Epoch [976/1000], Loss: 0.3544\n",
      "Epoch [977/1000], Loss: 0.3554\n",
      "Epoch [978/1000], Loss: 0.3534\n",
      "Epoch [979/1000], Loss: 0.3522\n",
      "Epoch [980/1000], Loss: 0.3588\n",
      "Epoch [981/1000], Loss: 0.3523\n",
      "Epoch [982/1000], Loss: 0.3544\n",
      "Epoch [983/1000], Loss: 0.3521\n",
      "Epoch [984/1000], Loss: 0.3565\n",
      "Epoch [985/1000], Loss: 0.3522\n",
      "Epoch [986/1000], Loss: 0.3521\n",
      "Epoch [987/1000], Loss: 0.3546\n",
      "Epoch [988/1000], Loss: 0.3539\n",
      "Epoch [989/1000], Loss: 0.3577\n",
      "Epoch [990/1000], Loss: 0.3524\n",
      "Epoch [991/1000], Loss: 0.3518\n",
      "Epoch [992/1000], Loss: 0.3526\n",
      "Epoch [993/1000], Loss: 0.3555\n",
      "Epoch [994/1000], Loss: 0.3568\n",
      "Epoch [995/1000], Loss: 0.3553\n",
      "Epoch [996/1000], Loss: 0.3531\n",
      "Epoch [997/1000], Loss: 0.3521\n",
      "Epoch [998/1000], Loss: 0.3573\n",
      "Epoch [999/1000], Loss: 0.3577\n",
      "Epoch [1000/1000], Loss: 0.3550\n",
      "Accuracy of the network on the 1000 validation data: 60.70 %\n",
      "Training model with batch_size: 400, lr :0.001, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.2472\n",
      "Epoch [2/1000], Loss: 0.2446\n",
      "Epoch [3/1000], Loss: 0.2434\n",
      "Epoch [4/1000], Loss: 0.2425\n",
      "Epoch [5/1000], Loss: 0.2418\n",
      "Epoch [6/1000], Loss: 0.2413\n",
      "Epoch [7/1000], Loss: 0.2409\n",
      "Epoch [8/1000], Loss: 0.2405\n",
      "Epoch [9/1000], Loss: 0.2402\n",
      "Epoch [10/1000], Loss: 0.2399\n",
      "Epoch [11/1000], Loss: 0.2396\n",
      "Epoch [12/1000], Loss: 0.2394\n",
      "Epoch [13/1000], Loss: 0.2392\n",
      "Epoch [14/1000], Loss: 0.2390\n",
      "Epoch [15/1000], Loss: 0.2389\n",
      "Epoch [16/1000], Loss: 0.2387\n",
      "Epoch [17/1000], Loss: 0.2386\n",
      "Epoch [18/1000], Loss: 0.2384\n",
      "Epoch [19/1000], Loss: 0.2383\n",
      "Epoch [20/1000], Loss: 0.2382\n",
      "Epoch [21/1000], Loss: 0.2381\n",
      "Epoch [22/1000], Loss: 0.2380\n",
      "Epoch [23/1000], Loss: 0.2379\n",
      "Epoch [24/1000], Loss: 0.2378\n",
      "Epoch [25/1000], Loss: 0.2377\n",
      "Epoch [26/1000], Loss: 0.2376\n",
      "Epoch [27/1000], Loss: 0.2375\n",
      "Epoch [28/1000], Loss: 0.2374\n",
      "Epoch [29/1000], Loss: 0.2374\n",
      "Epoch [30/1000], Loss: 0.2373\n",
      "Epoch [31/1000], Loss: 0.2372\n",
      "Epoch [32/1000], Loss: 0.2371\n",
      "Epoch [33/1000], Loss: 0.2371\n",
      "Epoch [34/1000], Loss: 0.2370\n",
      "Epoch [35/1000], Loss: 0.2370\n",
      "Epoch [36/1000], Loss: 0.2369\n",
      "Epoch [37/1000], Loss: 0.2369\n",
      "Epoch [38/1000], Loss: 0.2368\n",
      "Epoch [39/1000], Loss: 0.2368\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 59.00 %\n",
      "Training model with batch_size: 400, lr :0.001, optimizer : Adam\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 0.2656\n",
      "Epoch [2/1000], Loss: 0.2532\n",
      "Epoch [3/1000], Loss: 0.2465\n",
      "Epoch [4/1000], Loss: 0.2417\n",
      "Epoch [5/1000], Loss: 0.2382\n",
      "Epoch [6/1000], Loss: 0.2358\n",
      "Epoch [7/1000], Loss: 0.2343\n",
      "Epoch [8/1000], Loss: 0.2333\n",
      "Epoch [9/1000], Loss: 0.2323\n",
      "Epoch [10/1000], Loss: 0.2315\n",
      "Epoch [11/1000], Loss: 0.2308\n",
      "Epoch [12/1000], Loss: 0.2299\n",
      "Epoch [13/1000], Loss: 0.2289\n",
      "Epoch [14/1000], Loss: 0.2278\n",
      "Epoch [15/1000], Loss: 0.2265\n",
      "Epoch [16/1000], Loss: 0.2255\n",
      "Epoch [17/1000], Loss: 0.2242\n",
      "Epoch [18/1000], Loss: 0.2232\n",
      "Epoch [19/1000], Loss: 0.2218\n",
      "Epoch [20/1000], Loss: 0.2206\n",
      "Epoch [21/1000], Loss: 0.2191\n",
      "Epoch [22/1000], Loss: 0.2176\n",
      "Epoch [23/1000], Loss: 0.2160\n",
      "Epoch [24/1000], Loss: 0.2143\n",
      "Epoch [25/1000], Loss: 0.2125\n",
      "Epoch [26/1000], Loss: 0.2107\n",
      "Epoch [27/1000], Loss: 0.2087\n",
      "Epoch [28/1000], Loss: 0.2068\n",
      "Epoch [29/1000], Loss: 0.2046\n",
      "Epoch [30/1000], Loss: 0.2026\n",
      "Epoch [31/1000], Loss: 0.2005\n",
      "Epoch [32/1000], Loss: 0.1985\n",
      "Epoch [33/1000], Loss: 0.1965\n",
      "Epoch [34/1000], Loss: 0.1943\n",
      "Epoch [35/1000], Loss: 0.1921\n",
      "Epoch [36/1000], Loss: 0.1901\n",
      "Epoch [37/1000], Loss: 0.1884\n",
      "Epoch [38/1000], Loss: 0.1859\n",
      "Epoch [39/1000], Loss: 0.1839\n",
      "Epoch [40/1000], Loss: 0.1819\n",
      "Epoch [41/1000], Loss: 0.1800\n",
      "Epoch [42/1000], Loss: 0.1781\n",
      "Epoch [43/1000], Loss: 0.1762\n",
      "Epoch [44/1000], Loss: 0.1747\n",
      "Epoch [45/1000], Loss: 0.1726\n",
      "Epoch [46/1000], Loss: 0.1708\n",
      "Epoch [47/1000], Loss: 0.1690\n",
      "Epoch [48/1000], Loss: 0.1672\n",
      "Epoch [49/1000], Loss: 0.1656\n",
      "Epoch [50/1000], Loss: 0.1638\n",
      "Epoch [51/1000], Loss: 0.1618\n",
      "Epoch [52/1000], Loss: 0.1601\n",
      "Epoch [53/1000], Loss: 0.1583\n",
      "Epoch [54/1000], Loss: 0.1566\n",
      "Epoch [55/1000], Loss: 0.1548\n",
      "Epoch [56/1000], Loss: 0.1531\n",
      "Epoch [57/1000], Loss: 0.1512\n",
      "Epoch [58/1000], Loss: 0.1492\n",
      "Epoch [59/1000], Loss: 0.1474\n",
      "Epoch [60/1000], Loss: 0.1455\n",
      "Epoch [61/1000], Loss: 0.1435\n",
      "Epoch [62/1000], Loss: 0.1410\n",
      "Epoch [63/1000], Loss: 0.1388\n",
      "Epoch [64/1000], Loss: 0.1365\n",
      "Epoch [65/1000], Loss: 0.1343\n",
      "Epoch [66/1000], Loss: 0.1318\n",
      "Epoch [67/1000], Loss: 0.1295\n",
      "Epoch [68/1000], Loss: 0.1271\n",
      "Epoch [69/1000], Loss: 0.1245\n",
      "Epoch [70/1000], Loss: 0.1219\n",
      "Epoch [71/1000], Loss: 0.1193\n",
      "Epoch [72/1000], Loss: 0.1169\n",
      "Epoch [73/1000], Loss: 0.1140\n",
      "Epoch [74/1000], Loss: 0.1111\n",
      "Epoch [75/1000], Loss: 0.1086\n",
      "Epoch [76/1000], Loss: 0.1062\n",
      "Epoch [77/1000], Loss: 0.1035\n",
      "Epoch [78/1000], Loss: 0.1006\n",
      "Epoch [79/1000], Loss: 0.0977\n",
      "Epoch [80/1000], Loss: 0.0949\n",
      "Epoch [81/1000], Loss: 0.0921\n",
      "Epoch [82/1000], Loss: 0.0894\n",
      "Epoch [83/1000], Loss: 0.0867\n",
      "Epoch [84/1000], Loss: 0.0836\n",
      "Epoch [85/1000], Loss: 0.0810\n",
      "Epoch [86/1000], Loss: 0.0783\n",
      "Epoch [87/1000], Loss: 0.0756\n",
      "Epoch [88/1000], Loss: 0.0727\n",
      "Epoch [89/1000], Loss: 0.0703\n",
      "Epoch [90/1000], Loss: 0.0675\n",
      "Epoch [91/1000], Loss: 0.0648\n",
      "Epoch [92/1000], Loss: 0.0616\n",
      "Epoch [93/1000], Loss: 0.0590\n",
      "Epoch [94/1000], Loss: 0.0563\n",
      "Epoch [95/1000], Loss: 0.0541\n",
      "Epoch [96/1000], Loss: 0.0521\n",
      "Epoch [97/1000], Loss: 0.0502\n",
      "Epoch [98/1000], Loss: 0.0483\n",
      "Epoch [99/1000], Loss: 0.0467\n",
      "Epoch [100/1000], Loss: 0.0450\n",
      "Epoch [101/1000], Loss: 0.0431\n",
      "Epoch [102/1000], Loss: 0.0415\n",
      "Epoch [103/1000], Loss: 0.0403\n",
      "Epoch [104/1000], Loss: 0.0388\n",
      "Epoch [105/1000], Loss: 0.0375\n",
      "Epoch [106/1000], Loss: 0.0363\n",
      "Epoch [107/1000], Loss: 0.0348\n",
      "Epoch [108/1000], Loss: 0.0333\n",
      "Epoch [109/1000], Loss: 0.0321\n",
      "Epoch [110/1000], Loss: 0.0311\n",
      "Epoch [111/1000], Loss: 0.0299\n",
      "Epoch [112/1000], Loss: 0.0289\n",
      "Epoch [113/1000], Loss: 0.0279\n",
      "Epoch [114/1000], Loss: 0.0267\n",
      "Epoch [115/1000], Loss: 0.0258\n",
      "Epoch [116/1000], Loss: 0.0249\n",
      "Epoch [117/1000], Loss: 0.0241\n",
      "Epoch [118/1000], Loss: 0.0234\n",
      "Epoch [119/1000], Loss: 0.0223\n",
      "Epoch [120/1000], Loss: 0.0216\n",
      "Epoch [121/1000], Loss: 0.0208\n",
      "Epoch [122/1000], Loss: 0.0201\n",
      "Epoch [123/1000], Loss: 0.0194\n",
      "Epoch [124/1000], Loss: 0.0187\n",
      "Epoch [125/1000], Loss: 0.0181\n",
      "Epoch [126/1000], Loss: 0.0176\n",
      "Epoch [127/1000], Loss: 0.0170\n",
      "Epoch [128/1000], Loss: 0.0163\n",
      "Epoch [129/1000], Loss: 0.0158\n",
      "Epoch [130/1000], Loss: 0.0152\n",
      "Epoch [131/1000], Loss: 0.0147\n",
      "Epoch [132/1000], Loss: 0.0142\n",
      "Epoch [133/1000], Loss: 0.0138\n",
      "Epoch [134/1000], Loss: 0.0135\n",
      "Epoch [135/1000], Loss: 0.0130\n",
      "Epoch [136/1000], Loss: 0.0127\n",
      "Epoch [137/1000], Loss: 0.0122\n",
      "Epoch [138/1000], Loss: 0.0118\n",
      "Epoch [139/1000], Loss: 0.0114\n",
      "Epoch [140/1000], Loss: 0.0111\n",
      "Epoch [141/1000], Loss: 0.0108\n",
      "Epoch [142/1000], Loss: 0.0105\n",
      "Epoch [143/1000], Loss: 0.0102\n",
      "Epoch [144/1000], Loss: 0.0099\n",
      "Epoch [145/1000], Loss: 0.0096\n",
      "Epoch [146/1000], Loss: 0.0093\n",
      "Epoch [147/1000], Loss: 0.0091\n",
      "Epoch [148/1000], Loss: 0.0087\n",
      "Epoch [149/1000], Loss: 0.0085\n",
      "Epoch [150/1000], Loss: 0.0083\n",
      "Epoch [151/1000], Loss: 0.0081\n",
      "Epoch [152/1000], Loss: 0.0078\n",
      "Epoch [153/1000], Loss: 0.0076\n",
      "Epoch [154/1000], Loss: 0.0074\n",
      "Epoch [155/1000], Loss: 0.0072\n",
      "Epoch [156/1000], Loss: 0.0070\n",
      "Epoch [157/1000], Loss: 0.0068\n",
      "Epoch [158/1000], Loss: 0.0067\n",
      "Epoch [159/1000], Loss: 0.0066\n",
      "Epoch [160/1000], Loss: 0.0064\n",
      "Epoch [161/1000], Loss: 0.0063\n",
      "Epoch [162/1000], Loss: 0.0061\n",
      "Epoch [163/1000], Loss: 0.0060\n",
      "Epoch [164/1000], Loss: 0.0058\n",
      "Epoch [165/1000], Loss: 0.0057\n",
      "Epoch [166/1000], Loss: 0.0056\n",
      "Epoch [167/1000], Loss: 0.0054\n",
      "Epoch [168/1000], Loss: 0.0053\n",
      "Epoch [169/1000], Loss: 0.0052\n",
      "Epoch [170/1000], Loss: 0.0051\n",
      "Epoch [171/1000], Loss: 0.0050\n",
      "Epoch [172/1000], Loss: 0.0050\n",
      "Epoch [173/1000], Loss: 0.0049\n",
      "Epoch [174/1000], Loss: 0.0048\n",
      "Epoch [175/1000], Loss: 0.0047\n",
      "Epoch [176/1000], Loss: 0.0046\n",
      "Epoch [177/1000], Loss: 0.0045\n",
      "Epoch [178/1000], Loss: 0.0044\n",
      "Epoch [179/1000], Loss: 0.0043\n",
      "Epoch [180/1000], Loss: 0.0042\n",
      "Epoch [181/1000], Loss: 0.0041\n",
      "Epoch [182/1000], Loss: 0.0041\n",
      "Epoch [183/1000], Loss: 0.0040\n",
      "Epoch [184/1000], Loss: 0.0039\n",
      "Epoch [185/1000], Loss: 0.0039\n",
      "Epoch [186/1000], Loss: 0.0038\n",
      "Epoch [187/1000], Loss: 0.0038\n",
      "Epoch [188/1000], Loss: 0.0037\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 400, lr :0.001, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.2521\n",
      "Epoch [2/1000], Loss: 0.2360\n",
      "Epoch [3/1000], Loss: 0.2343\n",
      "Epoch [4/1000], Loss: 0.2334\n",
      "Epoch [5/1000], Loss: 0.2329\n",
      "Epoch [6/1000], Loss: 0.2321\n",
      "Epoch [7/1000], Loss: 0.2315\n",
      "Epoch [8/1000], Loss: 0.2308\n",
      "Epoch [9/1000], Loss: 0.2298\n",
      "Epoch [10/1000], Loss: 0.2290\n",
      "Epoch [11/1000], Loss: 0.2280\n",
      "Epoch [12/1000], Loss: 0.2273\n",
      "Epoch [13/1000], Loss: 0.2264\n",
      "Epoch [14/1000], Loss: 0.2255\n",
      "Epoch [15/1000], Loss: 0.2248\n",
      "Epoch [16/1000], Loss: 0.2240\n",
      "Epoch [17/1000], Loss: 0.2233\n",
      "Epoch [18/1000], Loss: 0.2218\n",
      "Epoch [19/1000], Loss: 0.2210\n",
      "Epoch [20/1000], Loss: 0.2202\n",
      "Epoch [21/1000], Loss: 0.2192\n",
      "Epoch [22/1000], Loss: 0.2183\n",
      "Epoch [23/1000], Loss: 0.2166\n",
      "Epoch [24/1000], Loss: 0.2162\n",
      "Epoch [25/1000], Loss: 0.2148\n",
      "Epoch [26/1000], Loss: 0.2133\n",
      "Epoch [27/1000], Loss: 0.2121\n",
      "Epoch [28/1000], Loss: 0.2108\n",
      "Epoch [29/1000], Loss: 0.2098\n",
      "Epoch [30/1000], Loss: 0.2084\n",
      "Epoch [31/1000], Loss: 0.2072\n",
      "Epoch [32/1000], Loss: 0.2057\n",
      "Epoch [33/1000], Loss: 0.2044\n",
      "Epoch [34/1000], Loss: 0.2033\n",
      "Epoch [35/1000], Loss: 0.2016\n",
      "Epoch [36/1000], Loss: 0.2002\n",
      "Epoch [37/1000], Loss: 0.1988\n",
      "Epoch [38/1000], Loss: 0.1973\n",
      "Epoch [39/1000], Loss: 0.1957\n",
      "Epoch [40/1000], Loss: 0.1943\n",
      "Epoch [41/1000], Loss: 0.1928\n",
      "Epoch [42/1000], Loss: 0.1910\n",
      "Epoch [43/1000], Loss: 0.1893\n",
      "Epoch [44/1000], Loss: 0.1884\n",
      "Epoch [45/1000], Loss: 0.1864\n",
      "Epoch [46/1000], Loss: 0.1845\n",
      "Epoch [47/1000], Loss: 0.1833\n",
      "Epoch [48/1000], Loss: 0.1812\n",
      "Epoch [49/1000], Loss: 0.1793\n",
      "Epoch [50/1000], Loss: 0.1777\n",
      "Epoch [51/1000], Loss: 0.1758\n",
      "Epoch [52/1000], Loss: 0.1737\n",
      "Epoch [53/1000], Loss: 0.1717\n",
      "Epoch [54/1000], Loss: 0.1697\n",
      "Epoch [55/1000], Loss: 0.1671\n",
      "Epoch [56/1000], Loss: 0.1648\n",
      "Epoch [57/1000], Loss: 0.1631\n",
      "Epoch [58/1000], Loss: 0.1610\n",
      "Epoch [59/1000], Loss: 0.1590\n",
      "Epoch [60/1000], Loss: 0.1569\n",
      "Epoch [61/1000], Loss: 0.1552\n",
      "Epoch [62/1000], Loss: 0.1529\n",
      "Epoch [63/1000], Loss: 0.1513\n",
      "Epoch [64/1000], Loss: 0.1490\n",
      "Epoch [65/1000], Loss: 0.1477\n",
      "Epoch [66/1000], Loss: 0.1449\n",
      "Epoch [67/1000], Loss: 0.1427\n",
      "Epoch [68/1000], Loss: 0.1411\n",
      "Epoch [69/1000], Loss: 0.1386\n",
      "Epoch [70/1000], Loss: 0.1372\n",
      "Epoch [71/1000], Loss: 0.1349\n",
      "Epoch [72/1000], Loss: 0.1325\n",
      "Epoch [73/1000], Loss: 0.1306\n",
      "Epoch [74/1000], Loss: 0.1288\n",
      "Epoch [75/1000], Loss: 0.1266\n",
      "Epoch [76/1000], Loss: 0.1243\n",
      "Epoch [77/1000], Loss: 0.1221\n",
      "Epoch [78/1000], Loss: 0.1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/1000], Loss: 0.1180\n",
      "Epoch [80/1000], Loss: 0.1162\n",
      "Epoch [81/1000], Loss: 0.1135\n",
      "Epoch [82/1000], Loss: 0.1117\n",
      "Epoch [83/1000], Loss: 0.1096\n",
      "Epoch [84/1000], Loss: 0.1075\n",
      "Epoch [85/1000], Loss: 0.1048\n",
      "Epoch [86/1000], Loss: 0.1029\n",
      "Epoch [87/1000], Loss: 0.1006\n",
      "Epoch [88/1000], Loss: 0.0987\n",
      "Epoch [89/1000], Loss: 0.0965\n",
      "Epoch [90/1000], Loss: 0.0941\n",
      "Epoch [91/1000], Loss: 0.0923\n",
      "Epoch [92/1000], Loss: 0.0903\n",
      "Epoch [93/1000], Loss: 0.0882\n",
      "Epoch [94/1000], Loss: 0.0862\n",
      "Epoch [95/1000], Loss: 0.0842\n",
      "Epoch [96/1000], Loss: 0.0823\n",
      "Epoch [97/1000], Loss: 0.0802\n",
      "Epoch [98/1000], Loss: 0.0792\n",
      "Epoch [99/1000], Loss: 0.0772\n",
      "Epoch [100/1000], Loss: 0.0758\n",
      "Epoch [101/1000], Loss: 0.0734\n",
      "Epoch [102/1000], Loss: 0.0718\n",
      "Epoch [103/1000], Loss: 0.0699\n",
      "Epoch [104/1000], Loss: 0.0682\n",
      "Epoch [105/1000], Loss: 0.0666\n",
      "Epoch [106/1000], Loss: 0.0650\n",
      "Epoch [107/1000], Loss: 0.0636\n",
      "Epoch [108/1000], Loss: 0.0622\n",
      "Epoch [109/1000], Loss: 0.0609\n",
      "Epoch [110/1000], Loss: 0.0594\n",
      "Epoch [111/1000], Loss: 0.0576\n",
      "Epoch [112/1000], Loss: 0.0565\n",
      "Epoch [113/1000], Loss: 0.0547\n",
      "Epoch [114/1000], Loss: 0.0537\n",
      "Epoch [115/1000], Loss: 0.0526\n",
      "Epoch [116/1000], Loss: 0.0508\n",
      "Epoch [117/1000], Loss: 0.0493\n",
      "Epoch [118/1000], Loss: 0.0481\n",
      "Epoch [119/1000], Loss: 0.0469\n",
      "Epoch [120/1000], Loss: 0.0457\n",
      "Epoch [121/1000], Loss: 0.0445\n",
      "Epoch [122/1000], Loss: 0.0437\n",
      "Epoch [123/1000], Loss: 0.0422\n",
      "Epoch [124/1000], Loss: 0.0417\n",
      "Epoch [125/1000], Loss: 0.0401\n",
      "Epoch [126/1000], Loss: 0.0397\n",
      "Epoch [127/1000], Loss: 0.0383\n",
      "Epoch [128/1000], Loss: 0.0375\n",
      "Epoch [129/1000], Loss: 0.0360\n",
      "Epoch [130/1000], Loss: 0.0352\n",
      "Epoch [131/1000], Loss: 0.0345\n",
      "Epoch [132/1000], Loss: 0.0334\n",
      "Epoch [133/1000], Loss: 0.0332\n",
      "Epoch [134/1000], Loss: 0.0319\n",
      "Epoch [135/1000], Loss: 0.0307\n",
      "Epoch [136/1000], Loss: 0.0299\n",
      "Epoch [137/1000], Loss: 0.0291\n",
      "Epoch [138/1000], Loss: 0.0286\n",
      "Epoch [139/1000], Loss: 0.0283\n",
      "Epoch [140/1000], Loss: 0.0268\n",
      "Epoch [141/1000], Loss: 0.0259\n",
      "Epoch [142/1000], Loss: 0.0252\n",
      "Epoch [143/1000], Loss: 0.0251\n",
      "Epoch [144/1000], Loss: 0.0239\n",
      "Epoch [145/1000], Loss: 0.0238\n",
      "Epoch [146/1000], Loss: 0.0226\n",
      "Epoch [147/1000], Loss: 0.0220\n",
      "Epoch [148/1000], Loss: 0.0214\n",
      "Epoch [149/1000], Loss: 0.0210\n",
      "Epoch [150/1000], Loss: 0.0203\n",
      "Epoch [151/1000], Loss: 0.0204\n",
      "Epoch [152/1000], Loss: 0.0194\n",
      "Epoch [153/1000], Loss: 0.0189\n",
      "Epoch [154/1000], Loss: 0.0188\n",
      "Epoch [155/1000], Loss: 0.0183\n",
      "Epoch [156/1000], Loss: 0.0174\n",
      "Epoch [157/1000], Loss: 0.0171\n",
      "Epoch [158/1000], Loss: 0.0164\n",
      "Epoch [159/1000], Loss: 0.0159\n",
      "Epoch [160/1000], Loss: 0.0159\n",
      "Epoch [161/1000], Loss: 0.0153\n",
      "Epoch [162/1000], Loss: 0.0145\n",
      "Epoch [163/1000], Loss: 0.0147\n",
      "Epoch [164/1000], Loss: 0.0144\n",
      "Epoch [165/1000], Loss: 0.0135\n",
      "Epoch [166/1000], Loss: 0.0132\n",
      "Epoch [167/1000], Loss: 0.0136\n",
      "Epoch [168/1000], Loss: 0.0124\n",
      "Epoch [169/1000], Loss: 0.0122\n",
      "Epoch [170/1000], Loss: 0.0117\n",
      "Epoch [171/1000], Loss: 0.0125\n",
      "Epoch [172/1000], Loss: 0.0114\n",
      "Epoch [173/1000], Loss: 0.0110\n",
      "Epoch [174/1000], Loss: 0.0106\n",
      "Epoch [175/1000], Loss: 0.0102\n",
      "Epoch [176/1000], Loss: 0.0102\n",
      "Epoch [177/1000], Loss: 0.0098\n",
      "Epoch [178/1000], Loss: 0.0096\n",
      "Epoch [179/1000], Loss: 0.0093\n",
      "Epoch [180/1000], Loss: 0.0090\n",
      "Epoch [181/1000], Loss: 0.0087\n",
      "Epoch [182/1000], Loss: 0.0087\n",
      "Epoch [183/1000], Loss: 0.0083\n",
      "Epoch [184/1000], Loss: 0.0082\n",
      "Epoch [185/1000], Loss: 0.0078\n",
      "Epoch [186/1000], Loss: 0.0078\n",
      "Epoch [187/1000], Loss: 0.0074\n",
      "Epoch [188/1000], Loss: 0.0071\n",
      "Epoch [189/1000], Loss: 0.0070\n",
      "Epoch [190/1000], Loss: 0.0071\n",
      "Epoch [191/1000], Loss: 0.0067\n",
      "Epoch [192/1000], Loss: 0.0067\n",
      "Epoch [193/1000], Loss: 0.0062\n",
      "Epoch [194/1000], Loss: 0.0065\n",
      "Epoch [195/1000], Loss: 0.0059\n",
      "Epoch [196/1000], Loss: 0.0058\n",
      "Epoch [197/1000], Loss: 0.0058\n",
      "Epoch [198/1000], Loss: 0.0054\n",
      "Epoch [199/1000], Loss: 0.0053\n",
      "Epoch [200/1000], Loss: 0.0052\n",
      "Epoch [201/1000], Loss: 0.0051\n",
      "Epoch [202/1000], Loss: 0.0050\n",
      "Epoch [203/1000], Loss: 0.0048\n",
      "Epoch [204/1000], Loss: 0.0047\n",
      "Epoch [205/1000], Loss: 0.0044\n",
      "Epoch [206/1000], Loss: 0.0044\n",
      "Epoch [207/1000], Loss: 0.0044\n",
      "Epoch [208/1000], Loss: 0.0042\n",
      "Epoch [209/1000], Loss: 0.0041\n",
      "Epoch [210/1000], Loss: 0.0039\n",
      "Epoch [211/1000], Loss: 0.0038\n",
      "Epoch [212/1000], Loss: 0.0037\n",
      "Epoch [213/1000], Loss: 0.0037\n",
      "Epoch [214/1000], Loss: 0.0036\n",
      "Epoch [215/1000], Loss: 0.0038\n",
      "Epoch [216/1000], Loss: 0.0033\n",
      "Epoch [217/1000], Loss: 0.0032\n",
      "Epoch [218/1000], Loss: 0.0033\n",
      "Epoch [219/1000], Loss: 0.0031\n",
      "Epoch [220/1000], Loss: 0.0030\n",
      "Epoch [221/1000], Loss: 0.0029\n",
      "Epoch [222/1000], Loss: 0.0028\n",
      "Epoch [223/1000], Loss: 0.0028\n",
      "Epoch [224/1000], Loss: 0.0026\n",
      "Epoch [225/1000], Loss: 0.0026\n",
      "Epoch [226/1000], Loss: 0.0025\n",
      "Epoch [227/1000], Loss: 0.0025\n",
      "Epoch [228/1000], Loss: 0.0025\n",
      "Epoch [229/1000], Loss: 0.0023\n",
      "Epoch [230/1000], Loss: 0.0022\n",
      "Epoch [231/1000], Loss: 0.0021\n",
      "Epoch [232/1000], Loss: 0.0022\n",
      "Epoch [233/1000], Loss: 0.0021\n",
      "Epoch [234/1000], Loss: 0.0020\n",
      "Epoch [235/1000], Loss: 0.0019\n",
      "Epoch [236/1000], Loss: 0.0021\n",
      "Epoch [237/1000], Loss: 0.0017\n",
      "Epoch [238/1000], Loss: 0.0017\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 400, lr :0.001, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2706\n",
      "Epoch [2/1000], Loss: 0.2701\n",
      "Epoch [3/1000], Loss: 0.2697\n",
      "Epoch [4/1000], Loss: 0.2692\n",
      "Epoch [5/1000], Loss: 0.2687\n",
      "Epoch [6/1000], Loss: 0.2683\n",
      "Epoch [7/1000], Loss: 0.2678\n",
      "Epoch [8/1000], Loss: 0.2673\n",
      "Epoch [9/1000], Loss: 0.2669\n",
      "Epoch [10/1000], Loss: 0.2664\n",
      "Epoch [11/1000], Loss: 0.2660\n",
      "Epoch [12/1000], Loss: 0.2655\n",
      "Epoch [13/1000], Loss: 0.2651\n",
      "Epoch [14/1000], Loss: 0.2646\n",
      "Epoch [15/1000], Loss: 0.2642\n",
      "Epoch [16/1000], Loss: 0.2638\n",
      "Epoch [17/1000], Loss: 0.2633\n",
      "Epoch [18/1000], Loss: 0.2629\n",
      "Epoch [19/1000], Loss: 0.2625\n",
      "Epoch [20/1000], Loss: 0.2621\n",
      "Epoch [21/1000], Loss: 0.2617\n",
      "Epoch [22/1000], Loss: 0.2613\n",
      "Epoch [23/1000], Loss: 0.2609\n",
      "Epoch [24/1000], Loss: 0.2605\n",
      "Epoch [25/1000], Loss: 0.2601\n",
      "Epoch [26/1000], Loss: 0.2597\n",
      "Epoch [27/1000], Loss: 0.2593\n",
      "Epoch [28/1000], Loss: 0.2590\n",
      "Epoch [29/1000], Loss: 0.2586\n",
      "Epoch [30/1000], Loss: 0.2582\n",
      "Epoch [31/1000], Loss: 0.2579\n",
      "Epoch [32/1000], Loss: 0.2575\n",
      "Epoch [33/1000], Loss: 0.2572\n",
      "Epoch [34/1000], Loss: 0.2568\n",
      "Epoch [35/1000], Loss: 0.2565\n",
      "Epoch [36/1000], Loss: 0.2561\n",
      "Epoch [37/1000], Loss: 0.2558\n",
      "Epoch [38/1000], Loss: 0.2555\n",
      "Epoch [39/1000], Loss: 0.2552\n",
      "Epoch [40/1000], Loss: 0.2549\n",
      "Epoch [41/1000], Loss: 0.2545\n",
      "Epoch [42/1000], Loss: 0.2542\n",
      "Epoch [43/1000], Loss: 0.2539\n",
      "Epoch [44/1000], Loss: 0.2536\n",
      "Epoch [45/1000], Loss: 0.2533\n",
      "Epoch [46/1000], Loss: 0.2531\n",
      "Epoch [47/1000], Loss: 0.2528\n",
      "Epoch [48/1000], Loss: 0.2525\n",
      "Epoch [49/1000], Loss: 0.2522\n",
      "Epoch [50/1000], Loss: 0.2520\n",
      "Epoch [51/1000], Loss: 0.2517\n",
      "Epoch [52/1000], Loss: 0.2515\n",
      "Epoch [53/1000], Loss: 0.2512\n",
      "Epoch [54/1000], Loss: 0.2510\n",
      "Epoch [55/1000], Loss: 0.2508\n",
      "Epoch [56/1000], Loss: 0.2506\n",
      "Epoch [57/1000], Loss: 0.2503\n",
      "Epoch [58/1000], Loss: 0.2501\n",
      "Epoch [59/1000], Loss: 0.2499\n",
      "Epoch [60/1000], Loss: 0.2497\n",
      "Epoch [61/1000], Loss: 0.2495\n",
      "Epoch [62/1000], Loss: 0.2493\n",
      "Epoch [63/1000], Loss: 0.2491\n",
      "Epoch [64/1000], Loss: 0.2489\n",
      "Epoch [65/1000], Loss: 0.2487\n",
      "Epoch [66/1000], Loss: 0.2486\n",
      "Epoch [67/1000], Loss: 0.2484\n",
      "Epoch [68/1000], Loss: 0.2482\n",
      "Epoch [69/1000], Loss: 0.2481\n",
      "Epoch [70/1000], Loss: 0.2479\n",
      "Epoch [71/1000], Loss: 0.2477\n",
      "Epoch [72/1000], Loss: 0.2476\n",
      "Epoch [73/1000], Loss: 0.2474\n",
      "Epoch [74/1000], Loss: 0.2473\n",
      "Epoch [75/1000], Loss: 0.2471\n",
      "Epoch [76/1000], Loss: 0.2470\n",
      "Epoch [77/1000], Loss: 0.2469\n",
      "Epoch [78/1000], Loss: 0.2467\n",
      "Epoch [79/1000], Loss: 0.2466\n",
      "Epoch [80/1000], Loss: 0.2465\n",
      "Epoch [81/1000], Loss: 0.2463\n",
      "Epoch [82/1000], Loss: 0.2462\n",
      "Epoch [83/1000], Loss: 0.2461\n",
      "Epoch [84/1000], Loss: 0.2460\n",
      "Epoch [85/1000], Loss: 0.2459\n",
      "Epoch [86/1000], Loss: 0.2457\n",
      "Epoch [87/1000], Loss: 0.2456\n",
      "Epoch [88/1000], Loss: 0.2455\n",
      "Epoch [89/1000], Loss: 0.2454\n",
      "Epoch [90/1000], Loss: 0.2453\n",
      "Epoch [91/1000], Loss: 0.2452\n",
      "Epoch [92/1000], Loss: 0.2451\n",
      "Epoch [93/1000], Loss: 0.2449\n",
      "Epoch [94/1000], Loss: 0.2448\n",
      "Epoch [95/1000], Loss: 0.2447\n",
      "Epoch [96/1000], Loss: 0.2446\n",
      "Epoch [97/1000], Loss: 0.2445\n",
      "Epoch [98/1000], Loss: 0.2444\n",
      "Epoch [99/1000], Loss: 0.2443\n",
      "Epoch [100/1000], Loss: 0.2442\n",
      "Epoch [101/1000], Loss: 0.2441\n",
      "Epoch [102/1000], Loss: 0.2440\n",
      "Epoch [103/1000], Loss: 0.2439\n",
      "Epoch [104/1000], Loss: 0.2439\n",
      "Epoch [105/1000], Loss: 0.2438\n",
      "Epoch [106/1000], Loss: 0.2437\n",
      "Epoch [107/1000], Loss: 0.2436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [108/1000], Loss: 0.2436\n",
      "Epoch [109/1000], Loss: 0.2435\n",
      "Epoch [110/1000], Loss: 0.2434\n",
      "Epoch [111/1000], Loss: 0.2434\n",
      "Epoch [112/1000], Loss: 0.2433\n",
      "Epoch [113/1000], Loss: 0.2432\n",
      "Epoch [114/1000], Loss: 0.2432\n",
      "Epoch [115/1000], Loss: 0.2431\n",
      "Epoch [116/1000], Loss: 0.2430\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 56.10 %\n",
      "Training model with batch_size: 400, lr :0.01, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.2388\n",
      "Epoch [2/1000], Loss: 0.2345\n",
      "Epoch [3/1000], Loss: 0.2333\n",
      "Epoch [4/1000], Loss: 0.2331\n",
      "Epoch [5/1000], Loss: 0.2325\n",
      "Epoch [6/1000], Loss: 0.2317\n",
      "Epoch [7/1000], Loss: 0.2311\n",
      "Epoch [8/1000], Loss: 0.2303\n",
      "Epoch [9/1000], Loss: 0.2294\n",
      "Epoch [10/1000], Loss: 0.2291\n",
      "Epoch [11/1000], Loss: 0.2283\n",
      "Epoch [12/1000], Loss: 0.2276\n",
      "Epoch [13/1000], Loss: 0.2269\n",
      "Epoch [14/1000], Loss: 0.2262\n",
      "Epoch [15/1000], Loss: 0.2255\n",
      "Epoch [16/1000], Loss: 0.2248\n",
      "Epoch [17/1000], Loss: 0.2243\n",
      "Epoch [18/1000], Loss: 0.2234\n",
      "Epoch [19/1000], Loss: 0.2229\n",
      "Epoch [20/1000], Loss: 0.2219\n",
      "Epoch [21/1000], Loss: 0.2213\n",
      "Epoch [22/1000], Loss: 0.2204\n",
      "Epoch [23/1000], Loss: 0.2196\n",
      "Epoch [24/1000], Loss: 0.2190\n",
      "Epoch [25/1000], Loss: 0.2182\n",
      "Epoch [26/1000], Loss: 0.2174\n",
      "Epoch [27/1000], Loss: 0.2167\n",
      "Epoch [28/1000], Loss: 0.2152\n",
      "Epoch [29/1000], Loss: 0.2143\n",
      "Epoch [30/1000], Loss: 0.2133\n",
      "Epoch [31/1000], Loss: 0.2123\n",
      "Epoch [32/1000], Loss: 0.2113\n",
      "Epoch [33/1000], Loss: 0.2103\n",
      "Epoch [34/1000], Loss: 0.2092\n",
      "Epoch [35/1000], Loss: 0.2082\n",
      "Epoch [36/1000], Loss: 0.2071\n",
      "Epoch [37/1000], Loss: 0.2057\n",
      "Epoch [38/1000], Loss: 0.2046\n",
      "Epoch [39/1000], Loss: 0.2034\n",
      "Epoch [40/1000], Loss: 0.2023\n",
      "Epoch [41/1000], Loss: 0.2010\n",
      "Epoch [42/1000], Loss: 0.1999\n",
      "Epoch [43/1000], Loss: 0.1987\n",
      "Epoch [44/1000], Loss: 0.1976\n",
      "Epoch [45/1000], Loss: 0.1962\n",
      "Epoch [46/1000], Loss: 0.1950\n",
      "Epoch [47/1000], Loss: 0.1940\n",
      "Epoch [48/1000], Loss: 0.1926\n",
      "Epoch [49/1000], Loss: 0.1914\n",
      "Epoch [50/1000], Loss: 0.1899\n",
      "Epoch [51/1000], Loss: 0.1886\n",
      "Epoch [52/1000], Loss: 0.1869\n",
      "Epoch [53/1000], Loss: 0.1855\n",
      "Epoch [54/1000], Loss: 0.1839\n",
      "Epoch [55/1000], Loss: 0.1825\n",
      "Epoch [56/1000], Loss: 0.1808\n",
      "Epoch [57/1000], Loss: 0.1796\n",
      "Epoch [58/1000], Loss: 0.1782\n",
      "Epoch [59/1000], Loss: 0.1769\n",
      "Epoch [60/1000], Loss: 0.1755\n",
      "Epoch [61/1000], Loss: 0.1742\n",
      "Epoch [62/1000], Loss: 0.1729\n",
      "Epoch [63/1000], Loss: 0.1715\n",
      "Epoch [64/1000], Loss: 0.1702\n",
      "Epoch [65/1000], Loss: 0.1690\n",
      "Epoch [66/1000], Loss: 0.1677\n",
      "Epoch [67/1000], Loss: 0.1665\n",
      "Epoch [68/1000], Loss: 0.1652\n",
      "Epoch [69/1000], Loss: 0.1639\n",
      "Epoch [70/1000], Loss: 0.1626\n",
      "Epoch [71/1000], Loss: 0.1615\n",
      "Epoch [72/1000], Loss: 0.1602\n",
      "Epoch [73/1000], Loss: 0.1595\n",
      "Epoch [74/1000], Loss: 0.1580\n",
      "Epoch [75/1000], Loss: 0.1567\n",
      "Epoch [76/1000], Loss: 0.1556\n",
      "Epoch [77/1000], Loss: 0.1544\n",
      "Epoch [78/1000], Loss: 0.1533\n",
      "Epoch [79/1000], Loss: 0.1523\n",
      "Epoch [80/1000], Loss: 0.1512\n",
      "Epoch [81/1000], Loss: 0.1500\n",
      "Epoch [82/1000], Loss: 0.1488\n",
      "Epoch [83/1000], Loss: 0.1477\n",
      "Epoch [84/1000], Loss: 0.1465\n",
      "Epoch [85/1000], Loss: 0.1453\n",
      "Epoch [86/1000], Loss: 0.1442\n",
      "Epoch [87/1000], Loss: 0.1431\n",
      "Epoch [88/1000], Loss: 0.1420\n",
      "Epoch [89/1000], Loss: 0.1409\n",
      "Epoch [90/1000], Loss: 0.1400\n",
      "Epoch [91/1000], Loss: 0.1389\n",
      "Epoch [92/1000], Loss: 0.1380\n",
      "Epoch [93/1000], Loss: 0.1369\n",
      "Epoch [94/1000], Loss: 0.1352\n",
      "Epoch [95/1000], Loss: 0.1333\n",
      "Epoch [96/1000], Loss: 0.1322\n",
      "Epoch [97/1000], Loss: 0.1311\n",
      "Epoch [98/1000], Loss: 0.1300\n",
      "Epoch [99/1000], Loss: 0.1289\n",
      "Epoch [100/1000], Loss: 0.1279\n",
      "Epoch [101/1000], Loss: 0.1272\n",
      "Epoch [102/1000], Loss: 0.1260\n",
      "Epoch [103/1000], Loss: 0.1248\n",
      "Epoch [104/1000], Loss: 0.1241\n",
      "Epoch [105/1000], Loss: 0.1233\n",
      "Epoch [106/1000], Loss: 0.1223\n",
      "Epoch [107/1000], Loss: 0.1212\n",
      "Epoch [108/1000], Loss: 0.1204\n",
      "Epoch [109/1000], Loss: 0.1196\n",
      "Epoch [110/1000], Loss: 0.1187\n",
      "Epoch [111/1000], Loss: 0.1180\n",
      "Epoch [112/1000], Loss: 0.1172\n",
      "Epoch [113/1000], Loss: 0.1161\n",
      "Epoch [114/1000], Loss: 0.1153\n",
      "Epoch [115/1000], Loss: 0.1146\n",
      "Epoch [116/1000], Loss: 0.1139\n",
      "Epoch [117/1000], Loss: 0.1129\n",
      "Epoch [118/1000], Loss: 0.1121\n",
      "Epoch [119/1000], Loss: 0.1114\n",
      "Epoch [120/1000], Loss: 0.1107\n",
      "Epoch [121/1000], Loss: 0.1097\n",
      "Epoch [122/1000], Loss: 0.1091\n",
      "Epoch [123/1000], Loss: 0.1082\n",
      "Epoch [124/1000], Loss: 0.1075\n",
      "Epoch [125/1000], Loss: 0.1068\n",
      "Epoch [126/1000], Loss: 0.1060\n",
      "Epoch [127/1000], Loss: 0.1052\n",
      "Epoch [128/1000], Loss: 0.1046\n",
      "Epoch [129/1000], Loss: 0.1037\n",
      "Epoch [130/1000], Loss: 0.1032\n",
      "Epoch [131/1000], Loss: 0.1023\n",
      "Epoch [132/1000], Loss: 0.1015\n",
      "Epoch [133/1000], Loss: 0.1008\n",
      "Epoch [134/1000], Loss: 0.1001\n",
      "Epoch [135/1000], Loss: 0.0994\n",
      "Epoch [136/1000], Loss: 0.0984\n",
      "Epoch [137/1000], Loss: 0.0978\n",
      "Epoch [138/1000], Loss: 0.0970\n",
      "Epoch [139/1000], Loss: 0.0954\n",
      "Epoch [140/1000], Loss: 0.0945\n",
      "Epoch [141/1000], Loss: 0.0937\n",
      "Epoch [142/1000], Loss: 0.0930\n",
      "Epoch [143/1000], Loss: 0.0924\n",
      "Epoch [144/1000], Loss: 0.0918\n",
      "Epoch [145/1000], Loss: 0.0909\n",
      "Epoch [146/1000], Loss: 0.0903\n",
      "Epoch [147/1000], Loss: 0.0896\n",
      "Epoch [148/1000], Loss: 0.0890\n",
      "Epoch [149/1000], Loss: 0.0883\n",
      "Epoch [150/1000], Loss: 0.0876\n",
      "Epoch [151/1000], Loss: 0.0871\n",
      "Epoch [152/1000], Loss: 0.0864\n",
      "Epoch [153/1000], Loss: 0.0858\n",
      "Epoch [154/1000], Loss: 0.0852\n",
      "Epoch [155/1000], Loss: 0.0846\n",
      "Epoch [156/1000], Loss: 0.0840\n",
      "Epoch [157/1000], Loss: 0.0835\n",
      "Epoch [158/1000], Loss: 0.0830\n",
      "Epoch [159/1000], Loss: 0.0823\n",
      "Epoch [160/1000], Loss: 0.0817\n",
      "Epoch [161/1000], Loss: 0.0813\n",
      "Epoch [162/1000], Loss: 0.0806\n",
      "Epoch [163/1000], Loss: 0.0801\n",
      "Epoch [164/1000], Loss: 0.0795\n",
      "Epoch [165/1000], Loss: 0.0789\n",
      "Epoch [166/1000], Loss: 0.0785\n",
      "Epoch [167/1000], Loss: 0.0779\n",
      "Epoch [168/1000], Loss: 0.0774\n",
      "Epoch [169/1000], Loss: 0.0769\n",
      "Epoch [170/1000], Loss: 0.0764\n",
      "Epoch [171/1000], Loss: 0.0758\n",
      "Epoch [172/1000], Loss: 0.0754\n",
      "Epoch [173/1000], Loss: 0.0747\n",
      "Epoch [174/1000], Loss: 0.0744\n",
      "Epoch [175/1000], Loss: 0.0738\n",
      "Epoch [176/1000], Loss: 0.0733\n",
      "Epoch [177/1000], Loss: 0.0728\n",
      "Epoch [178/1000], Loss: 0.0722\n",
      "Epoch [179/1000], Loss: 0.0718\n",
      "Epoch [180/1000], Loss: 0.0713\n",
      "Epoch [181/1000], Loss: 0.0709\n",
      "Epoch [182/1000], Loss: 0.0704\n",
      "Epoch [183/1000], Loss: 0.0698\n",
      "Epoch [184/1000], Loss: 0.0694\n",
      "Epoch [185/1000], Loss: 0.0688\n",
      "Epoch [186/1000], Loss: 0.0683\n",
      "Epoch [187/1000], Loss: 0.0679\n",
      "Epoch [188/1000], Loss: 0.0674\n",
      "Epoch [189/1000], Loss: 0.0670\n",
      "Epoch [190/1000], Loss: 0.0665\n",
      "Epoch [191/1000], Loss: 0.0660\n",
      "Epoch [192/1000], Loss: 0.0656\n",
      "Epoch [193/1000], Loss: 0.0653\n",
      "Epoch [194/1000], Loss: 0.0646\n",
      "Epoch [195/1000], Loss: 0.0642\n",
      "Epoch [196/1000], Loss: 0.0640\n",
      "Epoch [197/1000], Loss: 0.0634\n",
      "Epoch [198/1000], Loss: 0.0630\n",
      "Epoch [199/1000], Loss: 0.0626\n",
      "Epoch [200/1000], Loss: 0.0623\n",
      "Epoch [201/1000], Loss: 0.0617\n",
      "Epoch [202/1000], Loss: 0.0614\n",
      "Epoch [203/1000], Loss: 0.0610\n",
      "Epoch [204/1000], Loss: 0.0606\n",
      "Epoch [205/1000], Loss: 0.0602\n",
      "Epoch [206/1000], Loss: 0.0599\n",
      "Epoch [207/1000], Loss: 0.0594\n",
      "Epoch [208/1000], Loss: 0.0592\n",
      "Epoch [209/1000], Loss: 0.0588\n",
      "Epoch [210/1000], Loss: 0.0585\n",
      "Epoch [211/1000], Loss: 0.0581\n",
      "Epoch [212/1000], Loss: 0.0577\n",
      "Epoch [213/1000], Loss: 0.0572\n",
      "Epoch [214/1000], Loss: 0.0570\n",
      "Epoch [215/1000], Loss: 0.0565\n",
      "Epoch [216/1000], Loss: 0.0562\n",
      "Epoch [217/1000], Loss: 0.0559\n",
      "Epoch [218/1000], Loss: 0.0555\n",
      "Epoch [219/1000], Loss: 0.0552\n",
      "Epoch [220/1000], Loss: 0.0548\n",
      "Epoch [221/1000], Loss: 0.0545\n",
      "Epoch [222/1000], Loss: 0.0541\n",
      "Epoch [223/1000], Loss: 0.0539\n",
      "Epoch [224/1000], Loss: 0.0534\n",
      "Epoch [225/1000], Loss: 0.0531\n",
      "Epoch [226/1000], Loss: 0.0529\n",
      "Epoch [227/1000], Loss: 0.0525\n",
      "Epoch [228/1000], Loss: 0.0522\n",
      "Epoch [229/1000], Loss: 0.0519\n",
      "Epoch [230/1000], Loss: 0.0516\n",
      "Epoch [231/1000], Loss: 0.0512\n",
      "Epoch [232/1000], Loss: 0.0509\n",
      "Epoch [233/1000], Loss: 0.0505\n",
      "Epoch [234/1000], Loss: 0.0502\n",
      "Epoch [235/1000], Loss: 0.0499\n",
      "Epoch [236/1000], Loss: 0.0497\n",
      "Epoch [237/1000], Loss: 0.0494\n",
      "Epoch [238/1000], Loss: 0.0490\n",
      "Epoch [239/1000], Loss: 0.0486\n",
      "Epoch [240/1000], Loss: 0.0484\n",
      "Epoch [241/1000], Loss: 0.0480\n",
      "Epoch [242/1000], Loss: 0.0478\n",
      "Epoch [243/1000], Loss: 0.0475\n",
      "Epoch [244/1000], Loss: 0.0472\n",
      "Epoch [245/1000], Loss: 0.0468\n",
      "Epoch [246/1000], Loss: 0.0466\n",
      "Epoch [247/1000], Loss: 0.0463\n",
      "Epoch [248/1000], Loss: 0.0460\n",
      "Epoch [249/1000], Loss: 0.0458\n",
      "Epoch [250/1000], Loss: 0.0455\n",
      "Epoch [251/1000], Loss: 0.0452\n",
      "Epoch [252/1000], Loss: 0.0449\n",
      "Epoch [253/1000], Loss: 0.0447\n",
      "Epoch [254/1000], Loss: 0.0443\n",
      "Epoch [255/1000], Loss: 0.0442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [256/1000], Loss: 0.0438\n",
      "Epoch [257/1000], Loss: 0.0436\n",
      "Epoch [258/1000], Loss: 0.0433\n",
      "Epoch [259/1000], Loss: 0.0431\n",
      "Epoch [260/1000], Loss: 0.0429\n",
      "Epoch [261/1000], Loss: 0.0425\n",
      "Epoch [262/1000], Loss: 0.0423\n",
      "Epoch [263/1000], Loss: 0.0421\n",
      "Epoch [264/1000], Loss: 0.0418\n",
      "Epoch [265/1000], Loss: 0.0416\n",
      "Epoch [266/1000], Loss: 0.0414\n",
      "Epoch [267/1000], Loss: 0.0411\n",
      "Epoch [268/1000], Loss: 0.0409\n",
      "Epoch [269/1000], Loss: 0.0406\n",
      "Epoch [270/1000], Loss: 0.0404\n",
      "Epoch [271/1000], Loss: 0.0402\n",
      "Epoch [272/1000], Loss: 0.0399\n",
      "Epoch [273/1000], Loss: 0.0397\n",
      "Epoch [274/1000], Loss: 0.0394\n",
      "Epoch [275/1000], Loss: 0.0393\n",
      "Epoch [276/1000], Loss: 0.0391\n",
      "Epoch [277/1000], Loss: 0.0388\n",
      "Epoch [278/1000], Loss: 0.0386\n",
      "Epoch [279/1000], Loss: 0.0384\n",
      "Epoch [280/1000], Loss: 0.0382\n",
      "Epoch [281/1000], Loss: 0.0380\n",
      "Epoch [282/1000], Loss: 0.0377\n",
      "Epoch [283/1000], Loss: 0.0375\n",
      "Epoch [284/1000], Loss: 0.0373\n",
      "Epoch [285/1000], Loss: 0.0371\n",
      "Epoch [286/1000], Loss: 0.0369\n",
      "Epoch [287/1000], Loss: 0.0367\n",
      "Epoch [288/1000], Loss: 0.0365\n",
      "Epoch [289/1000], Loss: 0.0363\n",
      "Epoch [290/1000], Loss: 0.0361\n",
      "Epoch [291/1000], Loss: 0.0359\n",
      "Epoch [292/1000], Loss: 0.0357\n",
      "Epoch [293/1000], Loss: 0.0355\n",
      "Epoch [294/1000], Loss: 0.0352\n",
      "Epoch [295/1000], Loss: 0.0350\n",
      "Epoch [296/1000], Loss: 0.0349\n",
      "Epoch [297/1000], Loss: 0.0347\n",
      "Epoch [298/1000], Loss: 0.0344\n",
      "Epoch [299/1000], Loss: 0.0343\n",
      "Epoch [300/1000], Loss: 0.0341\n",
      "Epoch [301/1000], Loss: 0.0340\n",
      "Epoch [302/1000], Loss: 0.0338\n",
      "Epoch [303/1000], Loss: 0.0336\n",
      "Epoch [304/1000], Loss: 0.0334\n",
      "Epoch [305/1000], Loss: 0.0332\n",
      "Epoch [306/1000], Loss: 0.0330\n",
      "Epoch [307/1000], Loss: 0.0328\n",
      "Epoch [308/1000], Loss: 0.0327\n",
      "Epoch [309/1000], Loss: 0.0325\n",
      "Epoch [310/1000], Loss: 0.0324\n",
      "Epoch [311/1000], Loss: 0.0322\n",
      "Epoch [312/1000], Loss: 0.0320\n",
      "Epoch [313/1000], Loss: 0.0319\n",
      "Epoch [314/1000], Loss: 0.0317\n",
      "Epoch [315/1000], Loss: 0.0315\n",
      "Epoch [316/1000], Loss: 0.0314\n",
      "Epoch [317/1000], Loss: 0.0312\n",
      "Epoch [318/1000], Loss: 0.0310\n",
      "Epoch [319/1000], Loss: 0.0309\n",
      "Epoch [320/1000], Loss: 0.0307\n",
      "Epoch [321/1000], Loss: 0.0306\n",
      "Epoch [322/1000], Loss: 0.0304\n",
      "Epoch [323/1000], Loss: 0.0302\n",
      "Epoch [324/1000], Loss: 0.0301\n",
      "Epoch [325/1000], Loss: 0.0299\n",
      "Epoch [326/1000], Loss: 0.0298\n",
      "Epoch [327/1000], Loss: 0.0297\n",
      "Epoch [328/1000], Loss: 0.0295\n",
      "Epoch [329/1000], Loss: 0.0293\n",
      "Epoch [330/1000], Loss: 0.0292\n",
      "Epoch [331/1000], Loss: 0.0290\n",
      "Epoch [332/1000], Loss: 0.0289\n",
      "Epoch [333/1000], Loss: 0.0287\n",
      "Epoch [334/1000], Loss: 0.0286\n",
      "Epoch [335/1000], Loss: 0.0285\n",
      "Epoch [336/1000], Loss: 0.0284\n",
      "Epoch [337/1000], Loss: 0.0282\n",
      "Epoch [338/1000], Loss: 0.0281\n",
      "Epoch [339/1000], Loss: 0.0279\n",
      "Epoch [340/1000], Loss: 0.0278\n",
      "Epoch [341/1000], Loss: 0.0277\n",
      "Epoch [342/1000], Loss: 0.0275\n",
      "Epoch [343/1000], Loss: 0.0274\n",
      "Epoch [344/1000], Loss: 0.0273\n",
      "Epoch [345/1000], Loss: 0.0271\n",
      "Epoch [346/1000], Loss: 0.0270\n",
      "Epoch [347/1000], Loss: 0.0268\n",
      "Epoch [348/1000], Loss: 0.0267\n",
      "Epoch [349/1000], Loss: 0.0266\n",
      "Epoch [350/1000], Loss: 0.0264\n",
      "Epoch [351/1000], Loss: 0.0263\n",
      "Epoch [352/1000], Loss: 0.0262\n",
      "Epoch [353/1000], Loss: 0.0261\n",
      "Epoch [354/1000], Loss: 0.0260\n",
      "Epoch [355/1000], Loss: 0.0259\n",
      "Epoch [356/1000], Loss: 0.0257\n",
      "Epoch [357/1000], Loss: 0.0256\n",
      "Epoch [358/1000], Loss: 0.0255\n",
      "Epoch [359/1000], Loss: 0.0253\n",
      "Epoch [360/1000], Loss: 0.0252\n",
      "Epoch [361/1000], Loss: 0.0251\n",
      "Epoch [362/1000], Loss: 0.0250\n",
      "Epoch [363/1000], Loss: 0.0249\n",
      "Epoch [364/1000], Loss: 0.0248\n",
      "Epoch [365/1000], Loss: 0.0247\n",
      "Epoch [366/1000], Loss: 0.0246\n",
      "Epoch [367/1000], Loss: 0.0245\n",
      "Epoch [368/1000], Loss: 0.0243\n",
      "Epoch [369/1000], Loss: 0.0242\n",
      "Epoch [370/1000], Loss: 0.0241\n",
      "Epoch [371/1000], Loss: 0.0240\n",
      "Epoch [372/1000], Loss: 0.0239\n",
      "Epoch [373/1000], Loss: 0.0238\n",
      "Epoch [374/1000], Loss: 0.0237\n",
      "Epoch [375/1000], Loss: 0.0236\n",
      "Epoch [376/1000], Loss: 0.0234\n",
      "Epoch [377/1000], Loss: 0.0234\n",
      "Epoch [378/1000], Loss: 0.0233\n",
      "Epoch [379/1000], Loss: 0.0231\n",
      "Epoch [380/1000], Loss: 0.0231\n",
      "Epoch [381/1000], Loss: 0.0230\n",
      "Epoch [382/1000], Loss: 0.0229\n",
      "Epoch [383/1000], Loss: 0.0228\n",
      "Epoch [384/1000], Loss: 0.0227\n",
      "Epoch [385/1000], Loss: 0.0226\n",
      "Epoch [386/1000], Loss: 0.0225\n",
      "Epoch [387/1000], Loss: 0.0224\n",
      "Epoch [388/1000], Loss: 0.0222\n",
      "Epoch [389/1000], Loss: 0.0221\n",
      "Epoch [390/1000], Loss: 0.0221\n",
      "Epoch [391/1000], Loss: 0.0220\n",
      "Epoch [392/1000], Loss: 0.0219\n",
      "Epoch [393/1000], Loss: 0.0218\n",
      "Epoch [394/1000], Loss: 0.0217\n",
      "Epoch [395/1000], Loss: 0.0216\n",
      "Epoch [396/1000], Loss: 0.0215\n",
      "Epoch [397/1000], Loss: 0.0214\n",
      "Epoch [398/1000], Loss: 0.0213\n",
      "Epoch [399/1000], Loss: 0.0212\n",
      "Epoch [400/1000], Loss: 0.0211\n",
      "Epoch [401/1000], Loss: 0.0211\n",
      "Epoch [402/1000], Loss: 0.0210\n",
      "Epoch [403/1000], Loss: 0.0209\n",
      "Epoch [404/1000], Loss: 0.0208\n",
      "Epoch [405/1000], Loss: 0.0207\n",
      "Epoch [406/1000], Loss: 0.0207\n",
      "Epoch [407/1000], Loss: 0.0205\n",
      "Epoch [408/1000], Loss: 0.0204\n",
      "Epoch [409/1000], Loss: 0.0204\n",
      "Epoch [410/1000], Loss: 0.0203\n",
      "Epoch [411/1000], Loss: 0.0202\n",
      "Epoch [412/1000], Loss: 0.0202\n",
      "Epoch [413/1000], Loss: 0.0200\n",
      "Epoch [414/1000], Loss: 0.0200\n",
      "Epoch [415/1000], Loss: 0.0199\n",
      "Epoch [416/1000], Loss: 0.0198\n",
      "Epoch [417/1000], Loss: 0.0197\n",
      "Epoch [418/1000], Loss: 0.0197\n",
      "Epoch [419/1000], Loss: 0.0196\n",
      "Epoch [420/1000], Loss: 0.0195\n",
      "Epoch [421/1000], Loss: 0.0194\n",
      "Epoch [422/1000], Loss: 0.0193\n",
      "Epoch [423/1000], Loss: 0.0192\n",
      "Epoch [424/1000], Loss: 0.0191\n",
      "Epoch [425/1000], Loss: 0.0191\n",
      "Epoch [426/1000], Loss: 0.0190\n",
      "Epoch [427/1000], Loss: 0.0190\n",
      "Epoch [428/1000], Loss: 0.0189\n",
      "Epoch [429/1000], Loss: 0.0188\n",
      "Epoch [430/1000], Loss: 0.0187\n",
      "Epoch [431/1000], Loss: 0.0187\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 99.80 %\n",
      "Training model with batch_size: 400, lr :0.01, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.2470\n",
      "Epoch [2/1000], Loss: 0.2349\n",
      "Epoch [3/1000], Loss: 0.2317\n",
      "Epoch [4/1000], Loss: 0.2273\n",
      "Epoch [5/1000], Loss: 0.2228\n",
      "Epoch [6/1000], Loss: 0.2131\n",
      "Epoch [7/1000], Loss: 0.2011\n",
      "Epoch [8/1000], Loss: 0.1854\n",
      "Epoch [9/1000], Loss: 0.1672\n",
      "Epoch [10/1000], Loss: 0.1438\n",
      "Epoch [11/1000], Loss: 0.1228\n",
      "Epoch [12/1000], Loss: 0.1024\n",
      "Epoch [13/1000], Loss: 0.0849\n",
      "Epoch [14/1000], Loss: 0.0733\n",
      "Epoch [15/1000], Loss: 0.0627\n",
      "Epoch [16/1000], Loss: 0.0559\n",
      "Epoch [17/1000], Loss: 0.0481\n",
      "Epoch [18/1000], Loss: 0.0427\n",
      "Epoch [19/1000], Loss: 0.0354\n",
      "Epoch [20/1000], Loss: 0.0302\n",
      "Epoch [21/1000], Loss: 0.0251\n",
      "Epoch [22/1000], Loss: 0.0218\n",
      "Epoch [23/1000], Loss: 0.0189\n",
      "Epoch [24/1000], Loss: 0.0165\n",
      "Epoch [25/1000], Loss: 0.0161\n",
      "Epoch [26/1000], Loss: 0.0137\n",
      "Epoch [27/1000], Loss: 0.0120\n",
      "Epoch [28/1000], Loss: 0.0107\n",
      "Epoch [29/1000], Loss: 0.0098\n",
      "Epoch [30/1000], Loss: 0.0085\n",
      "Epoch [31/1000], Loss: 0.0076\n",
      "Epoch [32/1000], Loss: 0.0061\n",
      "Epoch [33/1000], Loss: 0.0055\n",
      "Epoch [34/1000], Loss: 0.0047\n",
      "Epoch [35/1000], Loss: 0.0039\n",
      "Epoch [36/1000], Loss: 0.0033\n",
      "Epoch [37/1000], Loss: 0.0029\n",
      "Epoch [38/1000], Loss: 0.0027\n",
      "Epoch [39/1000], Loss: 0.0024\n",
      "Epoch [40/1000], Loss: 0.0022\n",
      "Epoch [41/1000], Loss: 0.0021\n",
      "Epoch [42/1000], Loss: 0.0019\n",
      "Epoch [43/1000], Loss: 0.0018\n",
      "Epoch [44/1000], Loss: 0.0017\n",
      "Epoch [45/1000], Loss: 0.0016\n",
      "Epoch [46/1000], Loss: 0.0015\n",
      "Epoch [47/1000], Loss: 0.0014\n",
      "Epoch [48/1000], Loss: 0.0014\n",
      "Epoch [49/1000], Loss: 0.0012\n",
      "Epoch [50/1000], Loss: 0.0012\n",
      "Epoch [51/1000], Loss: 0.0011\n",
      "Epoch [52/1000], Loss: 0.0010\n",
      "Epoch [53/1000], Loss: 0.0010\n",
      "Epoch [54/1000], Loss: 0.0009\n",
      "Epoch [55/1000], Loss: 0.0009\n",
      "Epoch [56/1000], Loss: 0.0009\n",
      "Epoch [57/1000], Loss: 0.0008\n",
      "Epoch [58/1000], Loss: 0.0008\n",
      "Epoch [59/1000], Loss: 0.0008\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 400, lr :0.01, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.2480\n",
      "Epoch [2/1000], Loss: 0.2358\n",
      "Epoch [3/1000], Loss: 0.2305\n",
      "Epoch [4/1000], Loss: 0.2239\n",
      "Epoch [5/1000], Loss: 0.2174\n",
      "Epoch [6/1000], Loss: 0.2030\n",
      "Epoch [7/1000], Loss: 0.1879\n",
      "Epoch [8/1000], Loss: 0.1761\n",
      "Epoch [9/1000], Loss: 0.1592\n",
      "Epoch [10/1000], Loss: 0.1456\n",
      "Epoch [11/1000], Loss: 0.1369\n",
      "Epoch [12/1000], Loss: 0.1261\n",
      "Epoch [13/1000], Loss: 0.1048\n",
      "Epoch [14/1000], Loss: 0.1027\n",
      "Epoch [15/1000], Loss: 0.0935\n",
      "Epoch [16/1000], Loss: 0.0783\n",
      "Epoch [17/1000], Loss: 0.0659\n",
      "Epoch [18/1000], Loss: 0.0567\n",
      "Epoch [19/1000], Loss: 0.0469\n",
      "Epoch [20/1000], Loss: 0.0435\n",
      "Epoch [21/1000], Loss: 0.0378\n",
      "Epoch [22/1000], Loss: 0.0326\n",
      "Epoch [23/1000], Loss: 0.0303\n",
      "Epoch [24/1000], Loss: 0.0335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/1000], Loss: 0.0224\n",
      "Epoch [26/1000], Loss: 0.0207\n",
      "Epoch [27/1000], Loss: 0.0271\n",
      "Epoch [28/1000], Loss: 0.0319\n",
      "Epoch [29/1000], Loss: 0.0125\n",
      "Epoch [30/1000], Loss: 0.0104\n",
      "Epoch [31/1000], Loss: 0.0089\n",
      "Epoch [32/1000], Loss: 0.0073\n",
      "Epoch [33/1000], Loss: 0.0067\n",
      "Epoch [34/1000], Loss: 0.0061\n",
      "Epoch [35/1000], Loss: 0.0049\n",
      "Epoch [36/1000], Loss: 0.0042\n",
      "Epoch [37/1000], Loss: 0.0043\n",
      "Epoch [38/1000], Loss: 0.0052\n",
      "Epoch [39/1000], Loss: 0.0031\n",
      "Epoch [40/1000], Loss: 0.0027\n",
      "Epoch [41/1000], Loss: 0.0024\n",
      "Epoch [42/1000], Loss: 0.0023\n",
      "Epoch [43/1000], Loss: 0.0022\n",
      "Epoch [44/1000], Loss: 0.0019\n",
      "Epoch [45/1000], Loss: 0.0017\n",
      "Epoch [46/1000], Loss: 0.0016\n",
      "Epoch [47/1000], Loss: 0.0015\n",
      "Epoch [48/1000], Loss: 0.0014\n",
      "Epoch [49/1000], Loss: 0.0012\n",
      "Epoch [50/1000], Loss: 0.0012\n",
      "Epoch [51/1000], Loss: 0.0122\n",
      "Epoch [52/1000], Loss: 0.0895\n",
      "Epoch [53/1000], Loss: 0.0018\n",
      "Epoch [54/1000], Loss: 0.0014\n",
      "Epoch [55/1000], Loss: 0.0012\n",
      "Epoch [56/1000], Loss: 0.0011\n",
      "Epoch [57/1000], Loss: 0.0010\n",
      "Epoch [58/1000], Loss: 0.0010\n",
      "Epoch [59/1000], Loss: 0.0009\n",
      "Epoch [60/1000], Loss: 0.0008\n",
      "Epoch [61/1000], Loss: 0.0008\n",
      "Epoch [62/1000], Loss: 0.0007\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 400, lr :0.01, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2758\n",
      "Epoch [2/1000], Loss: 0.2681\n",
      "Epoch [3/1000], Loss: 0.2615\n",
      "Epoch [4/1000], Loss: 0.2562\n",
      "Epoch [5/1000], Loss: 0.2520\n",
      "Epoch [6/1000], Loss: 0.2487\n",
      "Epoch [7/1000], Loss: 0.2462\n",
      "Epoch [8/1000], Loss: 0.2444\n",
      "Epoch [9/1000], Loss: 0.2430\n",
      "Epoch [10/1000], Loss: 0.2419\n",
      "Epoch [11/1000], Loss: 0.2411\n",
      "Epoch [12/1000], Loss: 0.2405\n",
      "Epoch [13/1000], Loss: 0.2400\n",
      "Epoch [14/1000], Loss: 0.2395\n",
      "Epoch [15/1000], Loss: 0.2392\n",
      "Epoch [16/1000], Loss: 0.2389\n",
      "Epoch [17/1000], Loss: 0.2387\n",
      "Epoch [18/1000], Loss: 0.2385\n",
      "Epoch [19/1000], Loss: 0.2383\n",
      "Epoch [20/1000], Loss: 0.2381\n",
      "Epoch [21/1000], Loss: 0.2380\n",
      "Epoch [22/1000], Loss: 0.2379\n",
      "Epoch [23/1000], Loss: 0.2377\n",
      "Epoch [24/1000], Loss: 0.2376\n",
      "Epoch [25/1000], Loss: 0.2375\n",
      "Epoch [26/1000], Loss: 0.2375\n",
      "Epoch [27/1000], Loss: 0.2374\n",
      "Epoch [28/1000], Loss: 0.2373\n",
      "Epoch [29/1000], Loss: 0.2373\n",
      "Epoch [30/1000], Loss: 0.2372\n",
      "Epoch [31/1000], Loss: 0.2371\n",
      "Epoch [32/1000], Loss: 0.2371\n",
      "Epoch [33/1000], Loss: 0.2370\n",
      "Epoch [34/1000], Loss: 0.2370\n",
      "Epoch [35/1000], Loss: 0.2370\n",
      "Epoch [36/1000], Loss: 0.2369\n",
      "Epoch [37/1000], Loss: 0.2369\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 58.60 %\n",
      "Training model with batch_size: 400, lr :0.1, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.2489\n",
      "Epoch [2/1000], Loss: 0.2313\n",
      "Epoch [3/1000], Loss: 0.2221\n",
      "Epoch [4/1000], Loss: 0.2075\n",
      "Epoch [5/1000], Loss: 0.1962\n",
      "Epoch [6/1000], Loss: 0.1805\n",
      "Epoch [7/1000], Loss: 0.1602\n",
      "Epoch [8/1000], Loss: 0.1360\n",
      "Epoch [9/1000], Loss: 0.1263\n",
      "Epoch [10/1000], Loss: 0.1051\n",
      "Epoch [11/1000], Loss: 0.0843\n",
      "Epoch [12/1000], Loss: 0.0816\n",
      "Epoch [13/1000], Loss: 0.0605\n",
      "Epoch [14/1000], Loss: 0.0548\n",
      "Epoch [15/1000], Loss: 0.0453\n",
      "Epoch [16/1000], Loss: 0.0413\n",
      "Epoch [17/1000], Loss: 0.0325\n",
      "Epoch [18/1000], Loss: 0.0241\n",
      "Epoch [19/1000], Loss: 0.0239\n",
      "Epoch [20/1000], Loss: 0.0198\n",
      "Epoch [21/1000], Loss: 0.0178\n",
      "Epoch [22/1000], Loss: 0.0144\n",
      "Epoch [23/1000], Loss: 0.0129\n",
      "Epoch [24/1000], Loss: 0.0112\n",
      "Epoch [25/1000], Loss: 0.0115\n",
      "Epoch [26/1000], Loss: 0.0091\n",
      "Epoch [27/1000], Loss: 0.0082\n",
      "Epoch [28/1000], Loss: 0.0076\n",
      "Epoch [29/1000], Loss: 0.0071\n",
      "Epoch [30/1000], Loss: 0.0064\n",
      "Epoch [31/1000], Loss: 0.0060\n",
      "Epoch [32/1000], Loss: 0.0057\n",
      "Epoch [33/1000], Loss: 0.0059\n",
      "Epoch [34/1000], Loss: 0.0051\n",
      "Epoch [35/1000], Loss: 0.0047\n",
      "Epoch [36/1000], Loss: 0.0045\n",
      "Epoch [37/1000], Loss: 0.0041\n",
      "Epoch [38/1000], Loss: 0.0041\n",
      "Epoch [39/1000], Loss: 0.0039\n",
      "Epoch [40/1000], Loss: 0.0036\n",
      "Epoch [41/1000], Loss: 0.0035\n",
      "Epoch [42/1000], Loss: 0.0034\n",
      "Epoch [43/1000], Loss: 0.0032\n",
      "Epoch [44/1000], Loss: 0.0031\n",
      "Epoch [45/1000], Loss: 0.0029\n",
      "Epoch [46/1000], Loss: 0.0028\n",
      "Epoch [47/1000], Loss: 0.0027\n",
      "Epoch [48/1000], Loss: 0.0026\n",
      "Epoch [49/1000], Loss: 0.0025\n",
      "Epoch [50/1000], Loss: 0.0024\n",
      "Epoch [51/1000], Loss: 0.0024\n",
      "Epoch [52/1000], Loss: 0.0023\n",
      "Epoch [53/1000], Loss: 0.0022\n",
      "Epoch [54/1000], Loss: 0.0022\n",
      "Epoch [55/1000], Loss: 0.0021\n",
      "Epoch [56/1000], Loss: 0.0021\n",
      "Epoch [57/1000], Loss: 0.0020\n",
      "Epoch [58/1000], Loss: 0.0019\n",
      "Epoch [59/1000], Loss: 0.0018\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 400, lr :0.1, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.2660\n",
      "Epoch [2/1000], Loss: 0.2385\n",
      "Epoch [3/1000], Loss: 0.2287\n",
      "Epoch [4/1000], Loss: 0.2058\n",
      "Epoch [5/1000], Loss: 0.1774\n",
      "Epoch [6/1000], Loss: 0.1316\n",
      "Epoch [7/1000], Loss: 0.0875\n",
      "Epoch [8/1000], Loss: 0.0768\n",
      "Epoch [9/1000], Loss: 0.0752\n",
      "Epoch [10/1000], Loss: 0.0896\n",
      "Epoch [11/1000], Loss: 0.0618\n",
      "Epoch [12/1000], Loss: 0.0489\n",
      "Epoch [13/1000], Loss: 0.0425\n",
      "Epoch [14/1000], Loss: 0.0377\n",
      "Epoch [15/1000], Loss: 0.0275\n",
      "Epoch [16/1000], Loss: 0.0235\n",
      "Epoch [17/1000], Loss: 0.0178\n",
      "Epoch [18/1000], Loss: 0.0136\n",
      "Epoch [19/1000], Loss: 0.0134\n",
      "Epoch [20/1000], Loss: 0.0221\n",
      "Epoch [21/1000], Loss: 0.0173\n",
      "Epoch [22/1000], Loss: 0.0215\n",
      "Epoch [23/1000], Loss: 0.0121\n",
      "Epoch [24/1000], Loss: 0.0181\n",
      "Epoch [25/1000], Loss: 0.0132\n",
      "Epoch [26/1000], Loss: 0.0119\n",
      "Epoch [27/1000], Loss: 0.0096\n",
      "Epoch [28/1000], Loss: 0.0067\n",
      "Epoch [29/1000], Loss: 0.0043\n",
      "Epoch [30/1000], Loss: 0.0043\n",
      "Epoch [31/1000], Loss: 0.0038\n",
      "Epoch [32/1000], Loss: 0.0031\n",
      "Epoch [33/1000], Loss: 0.0044\n",
      "Epoch [34/1000], Loss: 0.0040\n",
      "Epoch [35/1000], Loss: 0.0144\n",
      "Epoch [36/1000], Loss: 0.0198\n",
      "Epoch [37/1000], Loss: 0.0188\n",
      "Epoch [38/1000], Loss: 0.0196\n",
      "Epoch [39/1000], Loss: 0.0069\n",
      "Epoch [40/1000], Loss: 0.0060\n",
      "Epoch [41/1000], Loss: 0.0027\n",
      "Epoch [42/1000], Loss: 0.0024\n",
      "Epoch [43/1000], Loss: 0.0020\n",
      "Epoch [44/1000], Loss: 0.0017\n",
      "Epoch [45/1000], Loss: 0.0015\n",
      "Epoch [46/1000], Loss: 0.0014\n",
      "Epoch [47/1000], Loss: 0.0013\n",
      "Epoch [48/1000], Loss: 0.0012\n",
      "Epoch [49/1000], Loss: 0.0011\n",
      "Epoch [50/1000], Loss: 0.0011\n",
      "Epoch [51/1000], Loss: 0.0009\n",
      "Epoch [52/1000], Loss: 0.0008\n",
      "Epoch [53/1000], Loss: 0.0007\n",
      "Epoch [54/1000], Loss: 0.0006\n",
      "Epoch [55/1000], Loss: 0.0006\n",
      "Epoch [56/1000], Loss: 0.0006\n",
      "Epoch [57/1000], Loss: 0.0017\n",
      "Epoch [58/1000], Loss: 0.0037\n",
      "Epoch [59/1000], Loss: 0.0067\n",
      "Epoch [60/1000], Loss: 0.0053\n",
      "Epoch [61/1000], Loss: 0.0028\n",
      "Epoch [62/1000], Loss: 0.0025\n",
      "Epoch [63/1000], Loss: 0.0037\n",
      "Epoch [64/1000], Loss: 0.0009\n",
      "Epoch [65/1000], Loss: 0.0011\n",
      "Epoch [66/1000], Loss: 0.0007\n",
      "Epoch [67/1000], Loss: 0.0006\n",
      "Epoch [68/1000], Loss: 0.0009\n",
      "Epoch [69/1000], Loss: 0.0023\n",
      "Epoch [70/1000], Loss: 0.0069\n",
      "Epoch [71/1000], Loss: 0.0089\n",
      "Epoch [72/1000], Loss: 0.0141\n",
      "Epoch [73/1000], Loss: 0.0133\n",
      "Epoch [74/1000], Loss: 0.0099\n",
      "Epoch [75/1000], Loss: 0.0092\n",
      "Epoch [76/1000], Loss: 0.0040\n",
      "Epoch [77/1000], Loss: 0.0094\n",
      "Epoch [78/1000], Loss: 0.0020\n",
      "Epoch [79/1000], Loss: 0.0018\n",
      "Epoch [80/1000], Loss: 0.0010\n",
      "Epoch [81/1000], Loss: 0.0009\n",
      "Epoch [82/1000], Loss: 0.0013\n",
      "Epoch [83/1000], Loss: 0.0009\n",
      "Epoch [84/1000], Loss: 0.0007\n",
      "Epoch [85/1000], Loss: 0.0007\n",
      "Epoch [86/1000], Loss: 0.0010\n",
      "Epoch [87/1000], Loss: 0.0008\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 99.90 %\n",
      "Training model with batch_size: 400, lr :0.1, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.4632\n",
      "Epoch [2/1000], Loss: 0.5000\n",
      "Epoch [3/1000], Loss: 0.5000\n",
      "Epoch [4/1000], Loss: 0.5000\n",
      "Epoch [5/1000], Loss: 0.5000\n",
      "Epoch [6/1000], Loss: 0.5000\n",
      "Epoch [7/1000], Loss: 0.5000\n",
      "Epoch [8/1000], Loss: 0.5000\n",
      "Epoch [9/1000], Loss: 0.5000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 400, lr :0.1, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2508\n",
      "Epoch [2/1000], Loss: 0.2437\n",
      "Epoch [3/1000], Loss: 0.2405\n",
      "Epoch [4/1000], Loss: 0.2387\n",
      "Epoch [5/1000], Loss: 0.2377\n",
      "Epoch [6/1000], Loss: 0.2369\n",
      "Epoch [7/1000], Loss: 0.2364\n",
      "Epoch [8/1000], Loss: 0.2359\n",
      "Epoch [9/1000], Loss: 0.2356\n",
      "Epoch [10/1000], Loss: 0.2353\n",
      "Epoch [11/1000], Loss: 0.2350\n",
      "Epoch [12/1000], Loss: 0.2349\n",
      "Epoch [13/1000], Loss: 0.2347\n",
      "Epoch [14/1000], Loss: 0.2344\n",
      "Epoch [15/1000], Loss: 0.2344\n",
      "Epoch [16/1000], Loss: 0.2341\n",
      "Epoch [17/1000], Loss: 0.2342\n",
      "Epoch [18/1000], Loss: 0.2341\n",
      "Epoch [19/1000], Loss: 0.2339\n",
      "Epoch [20/1000], Loss: 0.2338\n",
      "Epoch [21/1000], Loss: 0.2337\n",
      "Epoch [22/1000], Loss: 0.2337\n",
      "Epoch [23/1000], Loss: 0.2335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/1000], Loss: 0.2334\n",
      "Epoch [25/1000], Loss: 0.2334\n",
      "Epoch [26/1000], Loss: 0.2331\n",
      "Epoch [27/1000], Loss: 0.2331\n",
      "Epoch [28/1000], Loss: 0.2331\n",
      "Epoch [29/1000], Loss: 0.2329\n",
      "Epoch [30/1000], Loss: 0.2329\n",
      "Epoch [31/1000], Loss: 0.2327\n",
      "Epoch [32/1000], Loss: 0.2325\n",
      "Epoch [33/1000], Loss: 0.2325\n",
      "Epoch [34/1000], Loss: 0.2323\n",
      "Epoch [35/1000], Loss: 0.2322\n",
      "Epoch [36/1000], Loss: 0.2321\n",
      "Epoch [37/1000], Loss: 0.2319\n",
      "Epoch [38/1000], Loss: 0.2319\n",
      "Epoch [39/1000], Loss: 0.2316\n",
      "Epoch [40/1000], Loss: 0.2316\n",
      "Epoch [41/1000], Loss: 0.2317\n",
      "Epoch [42/1000], Loss: 0.2313\n",
      "Epoch [43/1000], Loss: 0.2315\n",
      "Epoch [44/1000], Loss: 0.2310\n",
      "Epoch [45/1000], Loss: 0.2311\n",
      "Epoch [46/1000], Loss: 0.2308\n",
      "Epoch [47/1000], Loss: 0.2308\n",
      "Epoch [48/1000], Loss: 0.2305\n",
      "Epoch [49/1000], Loss: 0.2305\n",
      "Epoch [50/1000], Loss: 0.2304\n",
      "Epoch [51/1000], Loss: 0.2302\n",
      "Epoch [52/1000], Loss: 0.2300\n",
      "Epoch [53/1000], Loss: 0.2300\n",
      "Epoch [54/1000], Loss: 0.2297\n",
      "Epoch [55/1000], Loss: 0.2296\n",
      "Epoch [56/1000], Loss: 0.2294\n",
      "Epoch [57/1000], Loss: 0.2292\n",
      "Epoch [58/1000], Loss: 0.2292\n",
      "Epoch [59/1000], Loss: 0.2291\n",
      "Epoch [60/1000], Loss: 0.2288\n",
      "Epoch [61/1000], Loss: 0.2287\n",
      "Epoch [62/1000], Loss: 0.2285\n",
      "Epoch [63/1000], Loss: 0.2285\n",
      "Epoch [64/1000], Loss: 0.2282\n",
      "Epoch [65/1000], Loss: 0.2283\n",
      "Epoch [66/1000], Loss: 0.2279\n",
      "Epoch [67/1000], Loss: 0.2280\n",
      "Epoch [68/1000], Loss: 0.2277\n",
      "Epoch [69/1000], Loss: 0.2274\n",
      "Epoch [70/1000], Loss: 0.2272\n",
      "Epoch [71/1000], Loss: 0.2270\n",
      "Epoch [72/1000], Loss: 0.2268\n",
      "Epoch [73/1000], Loss: 0.2267\n",
      "Epoch [74/1000], Loss: 0.2265\n",
      "Epoch [75/1000], Loss: 0.2261\n",
      "Epoch [76/1000], Loss: 0.2259\n",
      "Epoch [77/1000], Loss: 0.2257\n",
      "Epoch [78/1000], Loss: 0.2256\n",
      "Epoch [79/1000], Loss: 0.2252\n",
      "Epoch [80/1000], Loss: 0.2251\n",
      "Epoch [81/1000], Loss: 0.2248\n",
      "Epoch [82/1000], Loss: 0.2244\n",
      "Epoch [83/1000], Loss: 0.2244\n",
      "Epoch [84/1000], Loss: 0.2240\n",
      "Epoch [85/1000], Loss: 0.2236\n",
      "Epoch [86/1000], Loss: 0.2233\n",
      "Epoch [87/1000], Loss: 0.2231\n",
      "Epoch [88/1000], Loss: 0.2228\n",
      "Epoch [89/1000], Loss: 0.2224\n",
      "Epoch [90/1000], Loss: 0.2220\n",
      "Epoch [91/1000], Loss: 0.2217\n",
      "Epoch [92/1000], Loss: 0.2213\n",
      "Epoch [93/1000], Loss: 0.2212\n",
      "Epoch [94/1000], Loss: 0.2209\n",
      "Epoch [95/1000], Loss: 0.2202\n",
      "Epoch [96/1000], Loss: 0.2199\n",
      "Epoch [97/1000], Loss: 0.2196\n",
      "Epoch [98/1000], Loss: 0.2190\n",
      "Epoch [99/1000], Loss: 0.2189\n",
      "Epoch [100/1000], Loss: 0.2184\n",
      "Epoch [101/1000], Loss: 0.2178\n",
      "Epoch [102/1000], Loss: 0.2176\n",
      "Epoch [103/1000], Loss: 0.2171\n",
      "Epoch [104/1000], Loss: 0.2167\n",
      "Epoch [105/1000], Loss: 0.2161\n",
      "Epoch [106/1000], Loss: 0.2155\n",
      "Epoch [107/1000], Loss: 0.2151\n",
      "Epoch [108/1000], Loss: 0.2145\n",
      "Epoch [109/1000], Loss: 0.2140\n",
      "Epoch [110/1000], Loss: 0.2136\n",
      "Epoch [111/1000], Loss: 0.2132\n",
      "Epoch [112/1000], Loss: 0.2123\n",
      "Epoch [113/1000], Loss: 0.2121\n",
      "Epoch [114/1000], Loss: 0.2116\n",
      "Epoch [115/1000], Loss: 0.2108\n",
      "Epoch [116/1000], Loss: 0.2103\n",
      "Epoch [117/1000], Loss: 0.2100\n",
      "Epoch [118/1000], Loss: 0.2091\n",
      "Epoch [119/1000], Loss: 0.2085\n",
      "Epoch [120/1000], Loss: 0.2078\n",
      "Epoch [121/1000], Loss: 0.2071\n",
      "Epoch [122/1000], Loss: 0.2068\n",
      "Epoch [123/1000], Loss: 0.2056\n",
      "Epoch [124/1000], Loss: 0.2051\n",
      "Epoch [125/1000], Loss: 0.2046\n",
      "Epoch [126/1000], Loss: 0.2039\n",
      "Epoch [127/1000], Loss: 0.2033\n",
      "Epoch [128/1000], Loss: 0.2020\n",
      "Epoch [129/1000], Loss: 0.2015\n",
      "Epoch [130/1000], Loss: 0.2010\n",
      "Epoch [131/1000], Loss: 0.2001\n",
      "Epoch [132/1000], Loss: 0.1991\n",
      "Epoch [133/1000], Loss: 0.1984\n",
      "Epoch [134/1000], Loss: 0.1976\n",
      "Epoch [135/1000], Loss: 0.1969\n",
      "Epoch [136/1000], Loss: 0.1958\n",
      "Epoch [137/1000], Loss: 0.1956\n",
      "Epoch [138/1000], Loss: 0.1945\n",
      "Epoch [139/1000], Loss: 0.1938\n",
      "Epoch [140/1000], Loss: 0.1926\n",
      "Epoch [141/1000], Loss: 0.1918\n",
      "Epoch [142/1000], Loss: 0.1907\n",
      "Epoch [143/1000], Loss: 0.1894\n",
      "Epoch [144/1000], Loss: 0.1887\n",
      "Epoch [145/1000], Loss: 0.1872\n",
      "Epoch [146/1000], Loss: 0.1870\n",
      "Epoch [147/1000], Loss: 0.1858\n",
      "Epoch [148/1000], Loss: 0.1848\n",
      "Epoch [149/1000], Loss: 0.1836\n",
      "Epoch [150/1000], Loss: 0.1831\n",
      "Epoch [151/1000], Loss: 0.1813\n",
      "Epoch [152/1000], Loss: 0.1815\n",
      "Epoch [153/1000], Loss: 0.1793\n",
      "Epoch [154/1000], Loss: 0.1787\n",
      "Epoch [155/1000], Loss: 0.1776\n",
      "Epoch [156/1000], Loss: 0.1765\n",
      "Epoch [157/1000], Loss: 0.1751\n",
      "Epoch [158/1000], Loss: 0.1748\n",
      "Epoch [159/1000], Loss: 0.1735\n",
      "Epoch [160/1000], Loss: 0.1723\n",
      "Epoch [161/1000], Loss: 0.1729\n",
      "Epoch [162/1000], Loss: 0.1717\n",
      "Epoch [163/1000], Loss: 0.1691\n",
      "Epoch [164/1000], Loss: 0.1691\n",
      "Epoch [165/1000], Loss: 0.1670\n",
      "Epoch [166/1000], Loss: 0.1675\n",
      "Epoch [167/1000], Loss: 0.1677\n",
      "Epoch [168/1000], Loss: 0.1666\n",
      "Epoch [169/1000], Loss: 0.1643\n",
      "Epoch [170/1000], Loss: 0.1625\n",
      "Epoch [171/1000], Loss: 0.1630\n",
      "Epoch [172/1000], Loss: 0.1606\n",
      "Epoch [173/1000], Loss: 0.1599\n",
      "Epoch [174/1000], Loss: 0.1598\n",
      "Epoch [175/1000], Loss: 0.1645\n",
      "Epoch [176/1000], Loss: 0.1569\n",
      "Epoch [177/1000], Loss: 0.1609\n",
      "Epoch [178/1000], Loss: 0.1581\n",
      "Epoch [179/1000], Loss: 0.1551\n",
      "Epoch [180/1000], Loss: 0.1598\n",
      "Epoch [181/1000], Loss: 0.1536\n",
      "Epoch [182/1000], Loss: 0.1536\n",
      "Epoch [183/1000], Loss: 0.1493\n",
      "Epoch [184/1000], Loss: 0.1477\n",
      "Epoch [185/1000], Loss: 0.1496\n",
      "Epoch [186/1000], Loss: 0.1478\n",
      "Epoch [187/1000], Loss: 0.1444\n",
      "Epoch [188/1000], Loss: 0.1530\n",
      "Epoch [189/1000], Loss: 0.1483\n",
      "Epoch [190/1000], Loss: 0.1520\n",
      "Epoch [191/1000], Loss: 0.1451\n",
      "Epoch [192/1000], Loss: 0.1445\n",
      "Epoch [193/1000], Loss: 0.1410\n",
      "Epoch [194/1000], Loss: 0.1414\n",
      "Epoch [195/1000], Loss: 0.1432\n",
      "Epoch [196/1000], Loss: 0.1409\n",
      "Epoch [197/1000], Loss: 0.1428\n",
      "Epoch [198/1000], Loss: 0.1468\n",
      "Epoch [199/1000], Loss: 0.1441\n",
      "Epoch [200/1000], Loss: 0.1450\n",
      "Epoch [201/1000], Loss: 0.1425\n",
      "Epoch [202/1000], Loss: 0.1395\n",
      "Epoch [203/1000], Loss: 0.1432\n",
      "Epoch [204/1000], Loss: 0.1406\n",
      "Epoch [205/1000], Loss: 0.1348\n",
      "Epoch [206/1000], Loss: 0.1337\n",
      "Epoch [207/1000], Loss: 0.1316\n",
      "Epoch [208/1000], Loss: 0.1387\n",
      "Epoch [209/1000], Loss: 0.1324\n",
      "Epoch [210/1000], Loss: 0.1278\n",
      "Epoch [211/1000], Loss: 0.1258\n",
      "Epoch [212/1000], Loss: 0.1282\n",
      "Epoch [213/1000], Loss: 0.1313\n",
      "Epoch [214/1000], Loss: 0.1370\n",
      "Epoch [215/1000], Loss: 0.1347\n",
      "Epoch [216/1000], Loss: 0.1251\n",
      "Epoch [217/1000], Loss: 0.1263\n",
      "Epoch [218/1000], Loss: 0.1289\n",
      "Epoch [219/1000], Loss: 0.1326\n",
      "Epoch [220/1000], Loss: 0.1221\n",
      "Epoch [221/1000], Loss: 0.1250\n",
      "Epoch [222/1000], Loss: 0.1228\n",
      "Epoch [223/1000], Loss: 0.1219\n",
      "Epoch [224/1000], Loss: 0.1217\n",
      "Epoch [225/1000], Loss: 0.1345\n",
      "Epoch [226/1000], Loss: 0.1265\n",
      "Epoch [227/1000], Loss: 0.1216\n",
      "Epoch [228/1000], Loss: 0.1207\n",
      "Epoch [229/1000], Loss: 0.1177\n",
      "Epoch [230/1000], Loss: 0.1217\n",
      "Epoch [231/1000], Loss: 0.1169\n",
      "Epoch [232/1000], Loss: 0.1181\n",
      "Epoch [233/1000], Loss: 0.1154\n",
      "Epoch [234/1000], Loss: 0.1182\n",
      "Epoch [235/1000], Loss: 0.1148\n",
      "Epoch [236/1000], Loss: 0.1192\n",
      "Epoch [237/1000], Loss: 0.1108\n",
      "Epoch [238/1000], Loss: 0.1121\n",
      "Epoch [239/1000], Loss: 0.1133\n",
      "Epoch [240/1000], Loss: 0.1161\n",
      "Epoch [241/1000], Loss: 0.1190\n",
      "Epoch [242/1000], Loss: 0.1206\n",
      "Epoch [243/1000], Loss: 0.1170\n",
      "Epoch [244/1000], Loss: 0.1080\n",
      "Epoch [245/1000], Loss: 0.1140\n",
      "Epoch [246/1000], Loss: 0.1075\n",
      "Epoch [247/1000], Loss: 0.1112\n",
      "Epoch [248/1000], Loss: 0.1117\n",
      "Epoch [249/1000], Loss: 0.0997\n",
      "Epoch [250/1000], Loss: 0.1057\n",
      "Epoch [251/1000], Loss: 0.1051\n",
      "Epoch [252/1000], Loss: 0.1097\n",
      "Epoch [253/1000], Loss: 0.1100\n",
      "Epoch [254/1000], Loss: 0.1063\n",
      "Epoch [255/1000], Loss: 0.1035\n",
      "Epoch [256/1000], Loss: 0.1001\n",
      "Epoch [257/1000], Loss: 0.0983\n",
      "Epoch [258/1000], Loss: 0.1027\n",
      "Epoch [259/1000], Loss: 0.1020\n",
      "Epoch [260/1000], Loss: 0.1006\n",
      "Epoch [261/1000], Loss: 0.0913\n",
      "Epoch [262/1000], Loss: 0.0985\n",
      "Epoch [263/1000], Loss: 0.0987\n",
      "Epoch [264/1000], Loss: 0.0971\n",
      "Epoch [265/1000], Loss: 0.1015\n",
      "Epoch [266/1000], Loss: 0.1032\n",
      "Epoch [267/1000], Loss: 0.0905\n",
      "Epoch [268/1000], Loss: 0.0960\n",
      "Epoch [269/1000], Loss: 0.1007\n",
      "Epoch [270/1000], Loss: 0.0981\n",
      "Epoch [271/1000], Loss: 0.0857\n",
      "Epoch [272/1000], Loss: 0.0964\n",
      "Epoch [273/1000], Loss: 0.0875\n",
      "Epoch [274/1000], Loss: 0.0874\n",
      "Epoch [275/1000], Loss: 0.0971\n",
      "Epoch [276/1000], Loss: 0.0885\n",
      "Epoch [277/1000], Loss: 0.0935\n",
      "Epoch [278/1000], Loss: 0.0905\n",
      "Epoch [279/1000], Loss: 0.0831\n",
      "Epoch [280/1000], Loss: 0.0827\n",
      "Epoch [281/1000], Loss: 0.0934\n",
      "Epoch [282/1000], Loss: 0.0955\n",
      "Epoch [283/1000], Loss: 0.0847\n",
      "Epoch [284/1000], Loss: 0.0874\n",
      "Epoch [285/1000], Loss: 0.0892\n",
      "Epoch [286/1000], Loss: 0.0807\n",
      "Epoch [287/1000], Loss: 0.0825\n",
      "Epoch [288/1000], Loss: 0.0827\n",
      "Epoch [289/1000], Loss: 0.0874\n",
      "Epoch [290/1000], Loss: 0.0803\n",
      "Epoch [291/1000], Loss: 0.0784\n",
      "Epoch [292/1000], Loss: 0.0808\n",
      "Epoch [293/1000], Loss: 0.0760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [294/1000], Loss: 0.0763\n",
      "Epoch [295/1000], Loss: 0.0745\n",
      "Epoch [296/1000], Loss: 0.0731\n",
      "Epoch [297/1000], Loss: 0.0762\n",
      "Epoch [298/1000], Loss: 0.0743\n",
      "Epoch [299/1000], Loss: 0.0726\n",
      "Epoch [300/1000], Loss: 0.0729\n",
      "Epoch [301/1000], Loss: 0.0701\n",
      "Epoch [302/1000], Loss: 0.0734\n",
      "Epoch [303/1000], Loss: 0.0718\n",
      "Epoch [304/1000], Loss: 0.0682\n",
      "Epoch [305/1000], Loss: 0.0735\n",
      "Epoch [306/1000], Loss: 0.0661\n",
      "Epoch [307/1000], Loss: 0.0630\n",
      "Epoch [308/1000], Loss: 0.0661\n",
      "Epoch [309/1000], Loss: 0.0638\n",
      "Epoch [310/1000], Loss: 0.0615\n",
      "Epoch [311/1000], Loss: 0.0620\n",
      "Epoch [312/1000], Loss: 0.0604\n",
      "Epoch [313/1000], Loss: 0.0657\n",
      "Epoch [314/1000], Loss: 0.0577\n",
      "Epoch [315/1000], Loss: 0.0580\n",
      "Epoch [316/1000], Loss: 0.0669\n",
      "Epoch [317/1000], Loss: 0.0592\n",
      "Epoch [318/1000], Loss: 0.0586\n",
      "Epoch [319/1000], Loss: 0.0537\n",
      "Epoch [320/1000], Loss: 0.0585\n",
      "Epoch [321/1000], Loss: 0.0583\n",
      "Epoch [322/1000], Loss: 0.0565\n",
      "Epoch [323/1000], Loss: 0.0610\n",
      "Epoch [324/1000], Loss: 0.0503\n",
      "Epoch [325/1000], Loss: 0.0505\n",
      "Epoch [326/1000], Loss: 0.0494\n",
      "Epoch [327/1000], Loss: 0.0478\n",
      "Epoch [328/1000], Loss: 0.0474\n",
      "Epoch [329/1000], Loss: 0.0605\n",
      "Epoch [330/1000], Loss: 0.0426\n",
      "Epoch [331/1000], Loss: 0.0508\n",
      "Epoch [332/1000], Loss: 0.0465\n",
      "Epoch [333/1000], Loss: 0.0430\n",
      "Epoch [334/1000], Loss: 0.0391\n",
      "Epoch [335/1000], Loss: 0.0480\n",
      "Epoch [336/1000], Loss: 0.0355\n",
      "Epoch [337/1000], Loss: 0.0336\n",
      "Epoch [338/1000], Loss: 0.0462\n",
      "Epoch [339/1000], Loss: 0.0326\n",
      "Epoch [340/1000], Loss: 0.0362\n",
      "Epoch [341/1000], Loss: 0.0307\n",
      "Epoch [342/1000], Loss: 0.0355\n",
      "Epoch [343/1000], Loss: 0.0298\n",
      "Epoch [344/1000], Loss: 0.0298\n",
      "Epoch [345/1000], Loss: 0.0309\n",
      "Epoch [346/1000], Loss: 0.0273\n",
      "Epoch [347/1000], Loss: 0.0275\n",
      "Epoch [348/1000], Loss: 0.0272\n",
      "Epoch [349/1000], Loss: 0.0401\n",
      "Epoch [350/1000], Loss: 0.0258\n",
      "Epoch [351/1000], Loss: 0.0247\n",
      "Epoch [352/1000], Loss: 0.0469\n",
      "Epoch [353/1000], Loss: 0.0305\n",
      "Epoch [354/1000], Loss: 0.0235\n",
      "Epoch [355/1000], Loss: 0.0233\n",
      "Epoch [356/1000], Loss: 0.0221\n",
      "Epoch [357/1000], Loss: 0.0237\n",
      "Epoch [358/1000], Loss: 0.0247\n",
      "Epoch [359/1000], Loss: 0.0213\n",
      "Epoch [360/1000], Loss: 0.0217\n",
      "Epoch [361/1000], Loss: 0.0205\n",
      "Epoch [362/1000], Loss: 0.0204\n",
      "Epoch [363/1000], Loss: 0.0196\n",
      "Epoch [364/1000], Loss: 0.0202\n",
      "Epoch [365/1000], Loss: 0.0192\n",
      "Epoch [366/1000], Loss: 0.0190\n",
      "Epoch [367/1000], Loss: 0.0187\n",
      "Epoch [368/1000], Loss: 0.0192\n",
      "Epoch [369/1000], Loss: 0.0180\n",
      "Epoch [370/1000], Loss: 0.0177\n",
      "Epoch [371/1000], Loss: 0.0174\n",
      "Epoch [372/1000], Loss: 0.0173\n",
      "Epoch [373/1000], Loss: 0.0167\n",
      "Epoch [374/1000], Loss: 0.0172\n",
      "Epoch [375/1000], Loss: 0.0163\n",
      "Epoch [376/1000], Loss: 0.0159\n",
      "Epoch [377/1000], Loss: 0.0156\n",
      "Epoch [378/1000], Loss: 0.0156\n",
      "Epoch [379/1000], Loss: 0.0161\n",
      "Epoch [380/1000], Loss: 0.0151\n",
      "Epoch [381/1000], Loss: 0.0157\n",
      "Epoch [382/1000], Loss: 0.0145\n",
      "Epoch [383/1000], Loss: 0.0145\n",
      "Epoch [384/1000], Loss: 0.0143\n",
      "Epoch [385/1000], Loss: 0.0139\n",
      "Epoch [386/1000], Loss: 0.0138\n",
      "Epoch [387/1000], Loss: 0.0135\n",
      "Epoch [388/1000], Loss: 0.0135\n",
      "Epoch [389/1000], Loss: 0.0133\n",
      "Epoch [390/1000], Loss: 0.0133\n",
      "Epoch [391/1000], Loss: 0.0132\n",
      "Epoch [392/1000], Loss: 0.0131\n",
      "Epoch [393/1000], Loss: 0.0126\n",
      "Epoch [394/1000], Loss: 0.0126\n",
      "Epoch [395/1000], Loss: 0.0126\n",
      "Epoch [396/1000], Loss: 0.0123\n",
      "Epoch [397/1000], Loss: 0.0123\n",
      "Epoch [398/1000], Loss: 0.0124\n",
      "Epoch [399/1000], Loss: 0.0116\n",
      "Epoch [400/1000], Loss: 0.0115\n",
      "Epoch [401/1000], Loss: 0.0113\n",
      "Epoch [402/1000], Loss: 0.0116\n",
      "Epoch [403/1000], Loss: 0.0112\n",
      "Epoch [404/1000], Loss: 0.0118\n",
      "Epoch [405/1000], Loss: 0.0108\n",
      "Epoch [406/1000], Loss: 0.0106\n",
      "Epoch [407/1000], Loss: 0.0106\n",
      "Epoch [408/1000], Loss: 0.0110\n",
      "Epoch [409/1000], Loss: 0.0104\n",
      "Epoch [410/1000], Loss: 0.0104\n",
      "Epoch [411/1000], Loss: 0.0102\n",
      "Epoch [412/1000], Loss: 0.0100\n",
      "Epoch [413/1000], Loss: 0.0098\n",
      "Epoch [414/1000], Loss: 0.0100\n",
      "Epoch [415/1000], Loss: 0.0096\n",
      "Epoch [416/1000], Loss: 0.0097\n",
      "Epoch [417/1000], Loss: 0.0096\n",
      "Epoch [418/1000], Loss: 0.0095\n",
      "Epoch [419/1000], Loss: 0.0096\n",
      "Epoch [420/1000], Loss: 0.0092\n",
      "Epoch [421/1000], Loss: 0.0094\n",
      "Epoch [422/1000], Loss: 0.0089\n",
      "Epoch [423/1000], Loss: 0.0088\n",
      "Epoch [424/1000], Loss: 0.0090\n",
      "Epoch [425/1000], Loss: 0.0087\n",
      "Epoch [426/1000], Loss: 0.0086\n",
      "Epoch [427/1000], Loss: 0.0090\n",
      "Epoch [428/1000], Loss: 0.0085\n",
      "Epoch [429/1000], Loss: 0.0085\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 400, lr :1.0, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.4585\n",
      "Epoch [2/1000], Loss: 0.5000\n",
      "Epoch [3/1000], Loss: 0.5000\n",
      "Epoch [4/1000], Loss: 0.5000\n",
      "Epoch [5/1000], Loss: 0.5000\n",
      "Epoch [6/1000], Loss: 0.5000\n",
      "Epoch [7/1000], Loss: 0.5000\n",
      "Epoch [8/1000], Loss: 0.5000\n",
      "Epoch [9/1000], Loss: 0.5000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 400, lr :1.0, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.4547\n",
      "Epoch [2/1000], Loss: 0.5000\n",
      "Epoch [3/1000], Loss: 0.5000\n",
      "Epoch [4/1000], Loss: 0.5000\n",
      "Epoch [5/1000], Loss: 0.5000\n",
      "Epoch [6/1000], Loss: 0.5000\n",
      "Epoch [7/1000], Loss: 0.5000\n",
      "Epoch [8/1000], Loss: 0.5000\n",
      "Epoch [9/1000], Loss: 0.5000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 400, lr :1.0, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.4796\n",
      "Epoch [2/1000], Loss: 0.5000\n",
      "Epoch [3/1000], Loss: 0.5000\n",
      "Epoch [4/1000], Loss: 0.5000\n",
      "Epoch [5/1000], Loss: 0.5000\n",
      "Epoch [6/1000], Loss: 0.5000\n",
      "Epoch [7/1000], Loss: 0.5000\n",
      "Epoch [8/1000], Loss: 0.5000\n",
      "Epoch [9/1000], Loss: 0.5000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 400, lr :1.0, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2420\n",
      "Epoch [2/1000], Loss: 0.2359\n",
      "Epoch [3/1000], Loss: 0.2351\n",
      "Epoch [4/1000], Loss: 0.2342\n",
      "Epoch [5/1000], Loss: 0.2334\n",
      "Epoch [6/1000], Loss: 0.2325\n",
      "Epoch [7/1000], Loss: 0.2320\n",
      "Epoch [8/1000], Loss: 0.2316\n",
      "Epoch [9/1000], Loss: 0.2293\n",
      "Epoch [10/1000], Loss: 0.2288\n",
      "Epoch [11/1000], Loss: 0.2273\n",
      "Epoch [12/1000], Loss: 0.2245\n",
      "Epoch [13/1000], Loss: 0.2223\n",
      "Epoch [14/1000], Loss: 0.2143\n",
      "Epoch [15/1000], Loss: 0.2115\n",
      "Epoch [16/1000], Loss: 0.2042\n",
      "Epoch [17/1000], Loss: 0.1964\n",
      "Epoch [18/1000], Loss: 0.1841\n",
      "Epoch [19/1000], Loss: 0.1883\n",
      "Epoch [20/1000], Loss: 0.1755\n",
      "Epoch [21/1000], Loss: 0.1711\n",
      "Epoch [22/1000], Loss: 0.1618\n",
      "Epoch [23/1000], Loss: 0.1713\n",
      "Epoch [24/1000], Loss: 0.1680\n",
      "Epoch [25/1000], Loss: 0.1585\n",
      "Epoch [26/1000], Loss: 0.1516\n",
      "Epoch [27/1000], Loss: 0.1374\n",
      "Epoch [28/1000], Loss: 0.1564\n",
      "Epoch [29/1000], Loss: 0.1456\n",
      "Epoch [30/1000], Loss: 0.1391\n",
      "Epoch [31/1000], Loss: 0.1255\n",
      "Epoch [32/1000], Loss: 0.1122\n",
      "Epoch [33/1000], Loss: 0.1485\n",
      "Epoch [34/1000], Loss: 0.1317\n",
      "Epoch [35/1000], Loss: 0.1168\n",
      "Epoch [36/1000], Loss: 0.1366\n",
      "Epoch [37/1000], Loss: 0.1237\n",
      "Epoch [38/1000], Loss: 0.1132\n",
      "Epoch [39/1000], Loss: 0.1160\n",
      "Epoch [40/1000], Loss: 0.0920\n",
      "Epoch [41/1000], Loss: 0.1227\n",
      "Epoch [42/1000], Loss: 0.1232\n",
      "Epoch [43/1000], Loss: 0.0999\n",
      "Epoch [44/1000], Loss: 0.0914\n",
      "Epoch [45/1000], Loss: 0.0806\n",
      "Epoch [46/1000], Loss: 0.0855\n",
      "Epoch [47/1000], Loss: 0.1107\n",
      "Epoch [48/1000], Loss: 0.0779\n",
      "Epoch [49/1000], Loss: 0.0901\n",
      "Epoch [50/1000], Loss: 0.0664\n",
      "Epoch [51/1000], Loss: 0.0794\n",
      "Epoch [52/1000], Loss: 0.0861\n",
      "Epoch [53/1000], Loss: 0.1252\n",
      "Epoch [54/1000], Loss: 0.0670\n",
      "Epoch [55/1000], Loss: 0.0796\n",
      "Epoch [56/1000], Loss: 0.0940\n",
      "Epoch [57/1000], Loss: 0.0703\n",
      "Epoch [58/1000], Loss: 0.0711\n",
      "Epoch [59/1000], Loss: 0.0650\n",
      "Epoch [60/1000], Loss: 0.0593\n",
      "Epoch [61/1000], Loss: 0.0611\n",
      "Epoch [62/1000], Loss: 0.0857\n",
      "Epoch [63/1000], Loss: 0.0318\n",
      "Epoch [64/1000], Loss: 0.0687\n",
      "Epoch [65/1000], Loss: 0.0797\n",
      "Epoch [66/1000], Loss: 0.0831\n",
      "Epoch [67/1000], Loss: 0.0676\n",
      "Epoch [68/1000], Loss: 0.0401\n",
      "Epoch [69/1000], Loss: 0.0490\n",
      "Epoch [70/1000], Loss: 0.0694\n",
      "Epoch [71/1000], Loss: 0.0342\n",
      "Epoch [72/1000], Loss: 0.1153\n",
      "Epoch [73/1000], Loss: 0.0504\n",
      "Epoch [74/1000], Loss: 0.0286\n",
      "Epoch [75/1000], Loss: 0.0577\n",
      "Epoch [76/1000], Loss: 0.0449\n",
      "Epoch [77/1000], Loss: 0.0358\n",
      "Epoch [78/1000], Loss: 0.0270\n",
      "Epoch [79/1000], Loss: 0.0596\n",
      "Epoch [80/1000], Loss: 0.0427\n",
      "Epoch [81/1000], Loss: 0.0407\n",
      "Epoch [82/1000], Loss: 0.0403\n",
      "Epoch [83/1000], Loss: 0.0689\n",
      "Epoch [84/1000], Loss: 0.1088\n",
      "Epoch [85/1000], Loss: 0.0291\n",
      "Epoch [86/1000], Loss: 0.0575\n",
      "Epoch [87/1000], Loss: 0.0286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/1000], Loss: 0.0284\n",
      "Epoch [89/1000], Loss: 0.0492\n",
      "Epoch [90/1000], Loss: 0.0251\n",
      "Epoch [91/1000], Loss: 0.0537\n",
      "Epoch [92/1000], Loss: 0.0118\n",
      "Epoch [93/1000], Loss: 0.0101\n",
      "Epoch [94/1000], Loss: 0.0047\n",
      "Epoch [95/1000], Loss: 0.0040\n",
      "Epoch [96/1000], Loss: 0.0034\n",
      "Epoch [97/1000], Loss: 0.0032\n",
      "Epoch [98/1000], Loss: 0.0030\n",
      "Epoch [99/1000], Loss: 0.0030\n",
      "Epoch [100/1000], Loss: 0.0026\n",
      "Epoch [101/1000], Loss: 0.0024\n",
      "Epoch [102/1000], Loss: 0.0030\n",
      "Epoch [103/1000], Loss: 0.0022\n",
      "Epoch [104/1000], Loss: 0.0021\n",
      "Epoch [105/1000], Loss: 0.0020\n",
      "Epoch [106/1000], Loss: 0.0020\n",
      "Epoch [107/1000], Loss: 0.0019\n",
      "Epoch [108/1000], Loss: 0.0018\n",
      "Epoch [109/1000], Loss: 0.0016\n",
      "Epoch [110/1000], Loss: 0.0016\n",
      "Epoch [111/1000], Loss: 0.0015\n",
      "Epoch [112/1000], Loss: 0.0015\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with batch_size: 400, lr :10.0, optimizer : Adagrad\n",
      "Epoch [1/1000], Loss: 0.4741\n",
      "Epoch [2/1000], Loss: 0.5000\n",
      "Epoch [3/1000], Loss: 0.5000\n",
      "Epoch [4/1000], Loss: 0.5000\n",
      "Epoch [5/1000], Loss: 0.5000\n",
      "Epoch [6/1000], Loss: 0.5000\n",
      "Epoch [7/1000], Loss: 0.5000\n",
      "Epoch [8/1000], Loss: 0.5000\n",
      "Epoch [9/1000], Loss: 0.5000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 400, lr :10.0, optimizer : Adam\n",
      "Epoch [1/1000], Loss: 0.4757\n",
      "Epoch [2/1000], Loss: 0.5000\n",
      "Epoch [3/1000], Loss: 0.5000\n",
      "Epoch [4/1000], Loss: 0.5000\n",
      "Epoch [5/1000], Loss: 0.5000\n",
      "Epoch [6/1000], Loss: 0.5000\n",
      "Epoch [7/1000], Loss: 0.5000\n",
      "Epoch [8/1000], Loss: 0.5000\n",
      "Epoch [9/1000], Loss: 0.5000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 400, lr :10.0, optimizer : RMSprop\n",
      "Epoch [1/1000], Loss: 0.4786\n",
      "Epoch [2/1000], Loss: 0.5000\n",
      "Epoch [3/1000], Loss: 0.5000\n",
      "Epoch [4/1000], Loss: 0.5000\n",
      "Epoch [5/1000], Loss: 0.5000\n",
      "Epoch [6/1000], Loss: 0.5000\n",
      "Epoch [7/1000], Loss: 0.5000\n",
      "Epoch [8/1000], Loss: 0.5000\n",
      "Epoch [9/1000], Loss: 0.5000\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 50.00 %\n",
      "Training model with batch_size: 400, lr :10.0, optimizer : SGD\n",
      "Epoch [1/1000], Loss: 0.2766\n",
      "Epoch [2/1000], Loss: 0.2533\n",
      "Epoch [3/1000], Loss: 0.2494\n",
      "Epoch [4/1000], Loss: 0.2499\n",
      "Epoch [5/1000], Loss: 0.2509\n",
      "Epoch [6/1000], Loss: 0.2508\n",
      "Epoch [7/1000], Loss: 0.2518\n",
      "Epoch [8/1000], Loss: 0.2473\n",
      "Epoch [9/1000], Loss: 0.2497\n",
      "Epoch [10/1000], Loss: 0.2451\n",
      "Epoch [11/1000], Loss: 0.2465\n",
      "Epoch [12/1000], Loss: 0.2311\n",
      "Epoch [13/1000], Loss: 0.2239\n",
      "Epoch [14/1000], Loss: 0.2254\n",
      "Epoch [15/1000], Loss: 0.2191\n",
      "Epoch [16/1000], Loss: 0.2123\n",
      "Epoch [17/1000], Loss: 0.2328\n",
      "Epoch [18/1000], Loss: 0.2215\n",
      "Epoch [19/1000], Loss: 0.2209\n",
      "Epoch [20/1000], Loss: 0.2299\n",
      "Epoch [21/1000], Loss: 0.2375\n",
      "Epoch [22/1000], Loss: 0.2266\n",
      "Epoch [23/1000], Loss: 0.2128\n",
      "Epoch [24/1000], Loss: 0.2129\n",
      "Epoch [25/1000], Loss: 0.2387\n",
      "Epoch [26/1000], Loss: 0.2362\n",
      "Epoch [27/1000], Loss: 0.2268\n",
      "Epoch [28/1000], Loss: 0.2342\n",
      "Epoch [29/1000], Loss: 0.2402\n",
      "Epoch [30/1000], Loss: 0.2190\n",
      "Epoch [31/1000], Loss: 0.2074\n",
      "Epoch [32/1000], Loss: 0.2152\n",
      "Epoch [33/1000], Loss: 0.2620\n",
      "Epoch [34/1000], Loss: 0.2406\n",
      "Epoch [35/1000], Loss: 0.2390\n",
      "Epoch [36/1000], Loss: 0.2271\n",
      "Epoch [37/1000], Loss: 0.2214\n",
      "Epoch [38/1000], Loss: 0.2188\n",
      "Epoch [39/1000], Loss: 0.2177\n",
      "Epoch [40/1000], Loss: 0.2155\n",
      "Epoch [41/1000], Loss: 0.2143\n",
      "Epoch [42/1000], Loss: 0.2128\n",
      "Epoch [43/1000], Loss: 0.2099\n",
      "Epoch [44/1000], Loss: 0.2112\n",
      "Epoch [45/1000], Loss: 0.2240\n",
      "Epoch [46/1000], Loss: 0.2215\n",
      "Epoch [47/1000], Loss: 0.2095\n",
      "Epoch [48/1000], Loss: 0.2051\n",
      "Epoch [49/1000], Loss: 0.2028\n",
      "Epoch [50/1000], Loss: 0.2191\n",
      "Epoch [51/1000], Loss: 0.2409\n",
      "Epoch [52/1000], Loss: 0.2174\n",
      "Epoch [53/1000], Loss: 0.2212\n",
      "Epoch [54/1000], Loss: 0.2119\n",
      "Epoch [55/1000], Loss: 0.2294\n",
      "Epoch [56/1000], Loss: 0.2253\n",
      "Epoch [57/1000], Loss: 0.2058\n",
      "Epoch [58/1000], Loss: 0.2140\n",
      "Epoch [59/1000], Loss: 0.2165\n",
      "Epoch [60/1000], Loss: 0.2306\n",
      "Epoch [61/1000], Loss: 0.2317\n",
      "Epoch [62/1000], Loss: 0.2179\n",
      "Epoch [63/1000], Loss: 0.2065\n",
      "Epoch [64/1000], Loss: 0.2103\n",
      "Epoch [65/1000], Loss: 0.2108\n",
      "Epoch [66/1000], Loss: 0.2030\n",
      "Epoch [67/1000], Loss: 0.2142\n",
      "Epoch [68/1000], Loss: 0.2065\n",
      "Epoch [69/1000], Loss: 0.2024\n",
      "Epoch [70/1000], Loss: 0.2128\n",
      "Epoch [71/1000], Loss: 0.2013\n",
      "Epoch [72/1000], Loss: 0.2009\n",
      "Epoch [73/1000], Loss: 0.2041\n",
      "Epoch [74/1000], Loss: 0.2006\n",
      "Epoch [75/1000], Loss: 0.2266\n",
      "Epoch [76/1000], Loss: 0.2246\n",
      "Epoch [77/1000], Loss: 0.2228\n",
      "Epoch [78/1000], Loss: 0.2209\n",
      "Epoch [79/1000], Loss: 0.2188\n",
      "Epoch [80/1000], Loss: 0.2172\n",
      "Epoch [81/1000], Loss: 0.2160\n",
      "Epoch [82/1000], Loss: 0.2127\n",
      "Epoch [83/1000], Loss: 0.2149\n",
      "Epoch [84/1000], Loss: 0.2204\n",
      "Epoch [85/1000], Loss: 0.2170\n",
      "Epoch [86/1000], Loss: 0.2236\n",
      "Epoch [87/1000], Loss: 0.2285\n",
      "Epoch [88/1000], Loss: 0.2184\n",
      "Epoch [89/1000], Loss: 0.2058\n",
      "Epoch [90/1000], Loss: 0.2084\n",
      "Epoch [91/1000], Loss: 0.2056\n",
      "Epoch [92/1000], Loss: 0.2022\n",
      "Epoch [93/1000], Loss: 0.2326\n",
      "Epoch [94/1000], Loss: 0.2254\n",
      "Epoch [95/1000], Loss: 0.2087\n",
      "Epoch [96/1000], Loss: 0.2036\n",
      "Epoch [97/1000], Loss: 0.2006\n",
      "Epoch [98/1000], Loss: 0.2496\n",
      "Epoch [99/1000], Loss: 0.2815\n",
      "Epoch [100/1000], Loss: 0.2174\n",
      "Epoch [101/1000], Loss: 0.2108\n",
      "Epoch [102/1000], Loss: 0.2137\n",
      "Epoch [103/1000], Loss: 0.2067\n",
      "Epoch [104/1000], Loss: 0.2028\n",
      "Epoch [105/1000], Loss: 0.2014\n",
      "Epoch [106/1000], Loss: 0.2193\n",
      "Epoch [107/1000], Loss: 0.2353\n",
      "Epoch [108/1000], Loss: 0.2551\n",
      "Epoch [109/1000], Loss: 0.2199\n",
      "Epoch [110/1000], Loss: 0.2077\n",
      "Epoch [111/1000], Loss: 0.2039\n",
      "Epoch [112/1000], Loss: 0.2095\n",
      "Epoch [113/1000], Loss: 0.2072\n",
      "Epoch [114/1000], Loss: 0.2007\n",
      "Epoch [115/1000], Loss: 0.1971\n",
      "Epoch [116/1000], Loss: 0.1996\n",
      "Epoch [117/1000], Loss: 0.1926\n",
      "Epoch [118/1000], Loss: 0.2072\n",
      "Epoch [119/1000], Loss: 0.1910\n",
      "Epoch [120/1000], Loss: 0.1798\n",
      "Epoch [121/1000], Loss: 0.2134\n",
      "Epoch [122/1000], Loss: 0.2086\n",
      "Epoch [123/1000], Loss: 0.2027\n",
      "Epoch [124/1000], Loss: 0.2001\n",
      "Epoch [125/1000], Loss: 0.2228\n",
      "Epoch [126/1000], Loss: 0.2260\n",
      "Epoch [127/1000], Loss: 0.2230\n",
      "Epoch [128/1000], Loss: 0.2223\n",
      "Epoch [129/1000], Loss: 0.2233\n",
      "Epoch [130/1000], Loss: 0.2238\n",
      "Epoch [131/1000], Loss: 0.2206\n",
      "Epoch [132/1000], Loss: 0.2260\n",
      "Epoch [133/1000], Loss: 0.2225\n",
      "Epoch [134/1000], Loss: 0.2202\n",
      "Epoch [135/1000], Loss: 0.2332\n",
      "Epoch [136/1000], Loss: 0.2064\n",
      "Epoch [137/1000], Loss: 0.2143\n",
      "Epoch [138/1000], Loss: 0.1937\n",
      "Epoch [139/1000], Loss: 0.1900\n",
      "Epoch [140/1000], Loss: 0.1927\n",
      "Epoch [141/1000], Loss: 0.1815\n",
      "Epoch [142/1000], Loss: 0.2259\n",
      "Epoch [143/1000], Loss: 0.2218\n",
      "Epoch [144/1000], Loss: 0.1972\n",
      "Epoch [145/1000], Loss: 0.1813\n",
      "Epoch [146/1000], Loss: 0.1737\n",
      "Epoch [147/1000], Loss: 0.1842\n",
      "Epoch [148/1000], Loss: 0.1973\n",
      "Epoch [149/1000], Loss: 0.1867\n",
      "Epoch [150/1000], Loss: 0.1900\n",
      "Epoch [151/1000], Loss: 0.2033\n",
      "Epoch [152/1000], Loss: 0.1804\n",
      "Epoch [153/1000], Loss: 0.1633\n",
      "Epoch [154/1000], Loss: 0.1629\n",
      "Epoch [155/1000], Loss: 0.2140\n",
      "Epoch [156/1000], Loss: 0.2004\n",
      "Epoch [157/1000], Loss: 0.1669\n",
      "Epoch [158/1000], Loss: 0.1905\n",
      "Epoch [159/1000], Loss: 0.1736\n",
      "Epoch [160/1000], Loss: 0.1604\n",
      "Epoch [161/1000], Loss: 0.1927\n",
      "Epoch [162/1000], Loss: 0.2023\n",
      "Epoch [163/1000], Loss: 0.1886\n",
      "Epoch [164/1000], Loss: 0.1744\n",
      "Epoch [165/1000], Loss: 0.1696\n",
      "Epoch [166/1000], Loss: 0.2100\n",
      "Epoch [167/1000], Loss: 0.1657\n",
      "Epoch [168/1000], Loss: 0.1656\n",
      "Epoch [169/1000], Loss: 0.2003\n",
      "Epoch [170/1000], Loss: 0.1961\n",
      "Epoch [171/1000], Loss: 0.1889\n",
      "Epoch [172/1000], Loss: 0.1836\n",
      "Epoch [173/1000], Loss: 0.1833\n",
      "Epoch [174/1000], Loss: 0.1905\n",
      "Epoch [175/1000], Loss: 0.1804\n",
      "Epoch [176/1000], Loss: 0.1796\n",
      "Epoch [177/1000], Loss: 0.1794\n",
      "Epoch [178/1000], Loss: 0.1861\n",
      "Epoch [179/1000], Loss: 0.1778\n",
      "Epoch [180/1000], Loss: 0.1711\n",
      "Epoch [181/1000], Loss: 0.1677\n",
      "Epoch [182/1000], Loss: 0.1827\n",
      "Epoch [183/1000], Loss: 0.1710\n",
      "Epoch [184/1000], Loss: 0.1627\n",
      "Epoch [185/1000], Loss: 0.1690\n",
      "Epoch [186/1000], Loss: 0.1642\n",
      "Epoch [187/1000], Loss: 0.1695\n",
      "Epoch [188/1000], Loss: 0.1880\n",
      "Epoch [189/1000], Loss: 0.1690\n",
      "Epoch [190/1000], Loss: 0.1756\n",
      "Epoch [191/1000], Loss: 0.1671\n",
      "Epoch [192/1000], Loss: 0.1598\n",
      "Epoch [193/1000], Loss: 0.1593\n",
      "Epoch [194/1000], Loss: 0.1551\n",
      "Epoch [195/1000], Loss: 0.1949\n",
      "Epoch [196/1000], Loss: 0.1933\n",
      "Epoch [197/1000], Loss: 0.1634\n",
      "Epoch [198/1000], Loss: 0.1700\n",
      "Epoch [199/1000], Loss: 0.1731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [200/1000], Loss: 0.1550\n",
      "Epoch [201/1000], Loss: 0.1688\n",
      "Epoch [202/1000], Loss: 0.1719\n",
      "Epoch [203/1000], Loss: 0.1599\n",
      "Epoch [204/1000], Loss: 0.1552\n",
      "Epoch [205/1000], Loss: 0.2140\n",
      "Epoch [206/1000], Loss: 0.2121\n",
      "Epoch [207/1000], Loss: 0.2041\n",
      "Epoch [208/1000], Loss: 0.1973\n",
      "Epoch [209/1000], Loss: 0.1893\n",
      "Epoch [210/1000], Loss: 0.1806\n",
      "Epoch [211/1000], Loss: 0.1747\n",
      "Epoch [212/1000], Loss: 0.1767\n",
      "Epoch [213/1000], Loss: 0.1760\n",
      "Epoch [214/1000], Loss: 0.1782\n",
      "Epoch [215/1000], Loss: 0.2195\n",
      "Epoch [216/1000], Loss: 0.2244\n",
      "Epoch [217/1000], Loss: 0.2223\n",
      "Epoch [218/1000], Loss: 0.2214\n",
      "Epoch [219/1000], Loss: 0.2225\n",
      "Epoch [220/1000], Loss: 0.2218\n",
      "Epoch [221/1000], Loss: 0.2206\n",
      "Epoch [222/1000], Loss: 0.2196\n",
      "Epoch [223/1000], Loss: 0.2189\n",
      "Epoch [224/1000], Loss: 0.2188\n",
      "Epoch [225/1000], Loss: 0.2102\n",
      "Epoch [226/1000], Loss: 0.1857\n",
      "Epoch [227/1000], Loss: 0.1752\n",
      "Epoch [228/1000], Loss: 0.1687\n",
      "Epoch [229/1000], Loss: 0.1645\n",
      "Epoch [230/1000], Loss: 0.1621\n",
      "Epoch [231/1000], Loss: 0.1715\n",
      "Epoch [232/1000], Loss: 0.1843\n",
      "Epoch [233/1000], Loss: 0.1613\n",
      "Epoch [234/1000], Loss: 0.1599\n",
      "Epoch [235/1000], Loss: 0.1595\n",
      "Epoch [236/1000], Loss: 0.1577\n",
      "Epoch [237/1000], Loss: 0.1766\n",
      "Epoch [238/1000], Loss: 0.1681\n",
      "Epoch [239/1000], Loss: 0.1654\n",
      "Epoch [240/1000], Loss: 0.1638\n",
      "Epoch [241/1000], Loss: 0.2109\n",
      "Epoch [242/1000], Loss: 0.1855\n",
      "Epoch [243/1000], Loss: 0.2148\n",
      "Epoch [244/1000], Loss: 0.1793\n",
      "Epoch [245/1000], Loss: 0.1602\n",
      "Epoch [246/1000], Loss: 0.1628\n",
      "Epoch [247/1000], Loss: 0.1660\n",
      "Epoch [248/1000], Loss: 0.1682\n",
      "Epoch [249/1000], Loss: 0.1614\n",
      "Epoch [250/1000], Loss: 0.1631\n",
      "Epoch [251/1000], Loss: 0.1585\n",
      "Epoch [252/1000], Loss: 0.1565\n",
      "Epoch [253/1000], Loss: 0.1574\n",
      "Epoch [254/1000], Loss: 0.1594\n",
      "Epoch [255/1000], Loss: 0.1668\n",
      "Epoch [256/1000], Loss: 0.1632\n",
      "Epoch [257/1000], Loss: 0.1682\n",
      "Epoch [258/1000], Loss: 0.1637\n",
      "Epoch [259/1000], Loss: 0.1573\n",
      "Epoch [260/1000], Loss: 0.1570\n",
      "Epoch [261/1000], Loss: 0.1644\n",
      "Epoch [262/1000], Loss: 0.1604\n",
      "Epoch [263/1000], Loss: 0.1675\n",
      "Epoch [264/1000], Loss: 0.1827\n",
      "Epoch [265/1000], Loss: 0.1626\n",
      "Epoch [266/1000], Loss: 0.1724\n",
      "Epoch [267/1000], Loss: 0.1577\n",
      "Epoch [268/1000], Loss: 0.1568\n",
      "Epoch [269/1000], Loss: 0.1633\n",
      "Epoch [270/1000], Loss: 0.1809\n",
      "Epoch [271/1000], Loss: 0.1588\n",
      "Epoch [272/1000], Loss: 0.1743\n",
      "Epoch [273/1000], Loss: 0.1800\n",
      "Epoch [274/1000], Loss: 0.1741\n",
      "Epoch [275/1000], Loss: 0.1747\n",
      "Epoch [276/1000], Loss: 0.1616\n",
      "Epoch [277/1000], Loss: 0.1595\n",
      "Epoch [278/1000], Loss: 0.1646\n",
      "Epoch [279/1000], Loss: 0.1605\n",
      "Epoch [280/1000], Loss: 0.1729\n",
      "Epoch [281/1000], Loss: 0.1615\n",
      "Epoch [282/1000], Loss: 0.1586\n",
      "Epoch [283/1000], Loss: 0.1697\n",
      "Epoch [284/1000], Loss: 0.1633\n",
      "Epoch [285/1000], Loss: 0.1552\n",
      "Epoch [286/1000], Loss: 0.1682\n",
      "Epoch [287/1000], Loss: 0.1676\n",
      "Epoch [288/1000], Loss: 0.1660\n",
      "Epoch [289/1000], Loss: 0.1906\n",
      "Epoch [290/1000], Loss: 0.1823\n",
      "Epoch [291/1000], Loss: 0.1664\n",
      "Epoch [292/1000], Loss: 0.1563\n",
      "Epoch [293/1000], Loss: 0.1534\n",
      "Epoch [294/1000], Loss: 0.1663\n",
      "Epoch [295/1000], Loss: 0.1524\n",
      "Epoch [296/1000], Loss: 0.1508\n",
      "Epoch [297/1000], Loss: 0.1564\n",
      "Epoch [298/1000], Loss: 0.1581\n",
      "Epoch [299/1000], Loss: 0.1547\n",
      "Epoch [300/1000], Loss: 0.1512\n",
      "Epoch [301/1000], Loss: 0.1633\n",
      "Epoch [302/1000], Loss: 0.1640\n",
      "Epoch [303/1000], Loss: 0.1526\n",
      "Epoch [304/1000], Loss: 0.1741\n",
      "Epoch [305/1000], Loss: 0.1724\n",
      "Epoch [306/1000], Loss: 0.1568\n",
      "Epoch [307/1000], Loss: 0.1655\n",
      "Epoch [308/1000], Loss: 0.2078\n",
      "Epoch [309/1000], Loss: 0.1759\n",
      "Epoch [310/1000], Loss: 0.1621\n",
      "Epoch [311/1000], Loss: 0.1648\n",
      "Epoch [312/1000], Loss: 0.1520\n",
      "Epoch [313/1000], Loss: 0.1617\n",
      "Epoch [314/1000], Loss: 0.1588\n",
      "Epoch [315/1000], Loss: 0.1518\n",
      "Epoch [316/1000], Loss: 0.1622\n",
      "Epoch [317/1000], Loss: 0.1534\n",
      "Epoch [318/1000], Loss: 0.1538\n",
      "Epoch [319/1000], Loss: 0.1512\n",
      "Epoch [320/1000], Loss: 0.1509\n",
      "Epoch [321/1000], Loss: 0.1511\n",
      "Epoch [322/1000], Loss: 0.1502\n",
      "Epoch [323/1000], Loss: 0.1508\n",
      "Epoch [324/1000], Loss: 0.1570\n",
      "Epoch [325/1000], Loss: 0.1567\n",
      "Epoch [326/1000], Loss: 0.1523\n",
      "Epoch [327/1000], Loss: 0.1525\n",
      "Epoch [328/1000], Loss: 0.1510\n",
      "Epoch [329/1000], Loss: 0.1504\n",
      "Epoch [330/1000], Loss: 0.1498\n",
      "Epoch [331/1000], Loss: 0.1708\n",
      "Epoch [332/1000], Loss: 0.1779\n",
      "Epoch [333/1000], Loss: 0.1683\n",
      "Epoch [334/1000], Loss: 0.1553\n",
      "Epoch [335/1000], Loss: 0.1501\n",
      "Epoch [336/1000], Loss: 0.1540\n",
      "Epoch [337/1000], Loss: 0.1503\n",
      "Epoch [338/1000], Loss: 0.1496\n",
      "Epoch [339/1000], Loss: 0.1747\n",
      "Epoch [340/1000], Loss: 0.1589\n",
      "Epoch [341/1000], Loss: 0.1530\n",
      "Epoch [342/1000], Loss: 0.1598\n",
      "Epoch [343/1000], Loss: 0.1509\n",
      "Epoch [344/1000], Loss: 0.1494\n",
      "Epoch [345/1000], Loss: 0.1618\n",
      "Epoch [346/1000], Loss: 0.1740\n",
      "Epoch [347/1000], Loss: 0.1621\n",
      "Epoch [348/1000], Loss: 0.1695\n",
      "Epoch [349/1000], Loss: 0.1685\n",
      "Epoch [350/1000], Loss: 0.1582\n",
      "Epoch [351/1000], Loss: 0.1791\n",
      "Epoch [352/1000], Loss: 0.1607\n",
      "Epoch [353/1000], Loss: 0.1644\n",
      "Epoch [354/1000], Loss: 0.1726\n",
      "Epoch [355/1000], Loss: 0.1792\n",
      "Epoch [356/1000], Loss: 0.1603\n",
      "Epoch [357/1000], Loss: 0.1591\n",
      "Epoch [358/1000], Loss: 0.1578\n",
      "Epoch [359/1000], Loss: 0.1555\n",
      "Epoch [360/1000], Loss: 0.1673\n",
      "Epoch [361/1000], Loss: 0.1689\n",
      "Epoch [362/1000], Loss: 0.1628\n",
      "Epoch [363/1000], Loss: 0.1704\n",
      "Epoch [364/1000], Loss: 0.1623\n",
      "Epoch [365/1000], Loss: 0.1645\n",
      "Epoch [366/1000], Loss: 0.1587\n",
      "Epoch [367/1000], Loss: 0.1574\n",
      "Epoch [368/1000], Loss: 0.1616\n",
      "Epoch [369/1000], Loss: 0.1585\n",
      "Epoch [370/1000], Loss: 0.1595\n",
      "Epoch [371/1000], Loss: 0.1601\n",
      "Epoch [372/1000], Loss: 0.1624\n",
      "Epoch [373/1000], Loss: 0.1580\n",
      "Epoch [374/1000], Loss: 0.1578\n",
      "Epoch [375/1000], Loss: 0.1728\n",
      "Epoch [376/1000], Loss: 0.1681\n",
      "Epoch [377/1000], Loss: 0.1595\n",
      "Epoch [378/1000], Loss: 0.1581\n",
      "Epoch [379/1000], Loss: 0.1567\n",
      "Epoch [380/1000], Loss: 0.1572\n",
      "Epoch [381/1000], Loss: 0.1573\n",
      "Epoch [382/1000], Loss: 0.1777\n",
      "Epoch [383/1000], Loss: 0.1574\n",
      "Epoch [384/1000], Loss: 0.1582\n",
      "Epoch [385/1000], Loss: 0.1578\n",
      "Epoch [386/1000], Loss: 0.1582\n",
      "Epoch [387/1000], Loss: 0.1604\n",
      "Epoch [388/1000], Loss: 0.1586\n",
      "Epoch [389/1000], Loss: 0.1649\n",
      "Epoch [390/1000], Loss: 0.1671\n",
      "Epoch [391/1000], Loss: 0.1576\n",
      "Epoch [392/1000], Loss: 0.1582\n",
      "Epoch [393/1000], Loss: 0.1582\n",
      "Epoch [394/1000], Loss: 0.1571\n",
      "Epoch [395/1000], Loss: 0.1567\n",
      "Epoch [396/1000], Loss: 0.1579\n",
      "Epoch [397/1000], Loss: 0.1620\n",
      "Epoch [398/1000], Loss: 0.1563\n",
      "Epoch [399/1000], Loss: 0.1576\n",
      "Epoch [400/1000], Loss: 0.1635\n",
      "Epoch [401/1000], Loss: 0.1606\n",
      "Epoch [402/1000], Loss: 0.1724\n",
      "Epoch [403/1000], Loss: 0.1658\n",
      "Epoch [404/1000], Loss: 0.1630\n",
      "Epoch [405/1000], Loss: 0.1598\n",
      "Epoch [406/1000], Loss: 0.1723\n",
      "Epoch [407/1000], Loss: 0.1705\n",
      "Epoch [408/1000], Loss: 0.1571\n",
      "Epoch [409/1000], Loss: 0.1558\n",
      "Epoch [410/1000], Loss: 0.1551\n",
      "Epoch [411/1000], Loss: 0.1558\n",
      "Epoch [412/1000], Loss: 0.1557\n",
      "Epoch [413/1000], Loss: 0.1554\n",
      "Epoch [414/1000], Loss: 0.1566\n",
      "Epoch [415/1000], Loss: 0.1551\n",
      "Epoch [416/1000], Loss: 0.1582\n",
      "Epoch [417/1000], Loss: 0.1556\n",
      "Epoch [418/1000], Loss: 0.1584\n",
      "Epoch [419/1000], Loss: 0.1600\n",
      "Epoch [420/1000], Loss: 0.1549\n",
      "Epoch [421/1000], Loss: 0.1649\n",
      "Epoch [422/1000], Loss: 0.1780\n",
      "Epoch [423/1000], Loss: 0.2061\n",
      "Epoch [424/1000], Loss: 0.1588\n",
      "Epoch [425/1000], Loss: 0.1550\n",
      "Epoch [426/1000], Loss: 0.1556\n",
      "Epoch [427/1000], Loss: 0.1549\n",
      "Epoch [428/1000], Loss: 0.1570\n",
      "Epoch [429/1000], Loss: 0.1553\n",
      "Epoch [430/1000], Loss: 0.1626\n",
      "Epoch [431/1000], Loss: 0.1631\n",
      "Epoch [432/1000], Loss: 0.1581\n",
      "Epoch [433/1000], Loss: 0.1577\n",
      "Epoch [434/1000], Loss: 0.1588\n",
      "Epoch [435/1000], Loss: 0.1568\n",
      "Epoch [436/1000], Loss: 0.1562\n",
      "Epoch [437/1000], Loss: 0.1548\n",
      "Epoch [438/1000], Loss: 0.1547\n",
      "Epoch [439/1000], Loss: 0.1564\n",
      "Epoch [440/1000], Loss: 0.1561\n",
      "Epoch [441/1000], Loss: 0.1549\n",
      "Epoch [442/1000], Loss: 0.1552\n",
      "Epoch [443/1000], Loss: 0.1564\n",
      "Epoch [444/1000], Loss: 0.1577\n",
      "Epoch [445/1000], Loss: 0.1550\n",
      "Epoch [446/1000], Loss: 0.1551\n",
      "Epoch [447/1000], Loss: 0.1550\n",
      "Epoch [448/1000], Loss: 0.1587\n",
      "Epoch [449/1000], Loss: 0.1548\n",
      "Epoch [450/1000], Loss: 0.1568\n",
      "Epoch [451/1000], Loss: 0.1660\n",
      "Epoch [452/1000], Loss: 0.1554\n",
      "Epoch [453/1000], Loss: 0.1556\n",
      "Epoch [454/1000], Loss: 0.1616\n",
      "Epoch [455/1000], Loss: 0.1554\n",
      "Epoch [456/1000], Loss: 0.1560\n",
      "Epoch [457/1000], Loss: 0.1591\n",
      "Epoch [458/1000], Loss: 0.1707\n",
      "Epoch [459/1000], Loss: 0.1598\n",
      "Epoch [460/1000], Loss: 0.1562\n",
      "Epoch [461/1000], Loss: 0.1594\n",
      "Epoch [462/1000], Loss: 0.1582\n",
      "Epoch [463/1000], Loss: 0.1528\n",
      "Epoch [464/1000], Loss: 0.1538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [465/1000], Loss: 0.1719\n",
      "Epoch [466/1000], Loss: 0.1986\n",
      "Epoch [467/1000], Loss: 0.1686\n",
      "Epoch [468/1000], Loss: 0.1576\n",
      "Epoch [469/1000], Loss: 0.1555\n",
      "Epoch [470/1000], Loss: 0.1580\n",
      "Epoch [471/1000], Loss: 0.1561\n",
      "Epoch [472/1000], Loss: 0.1549\n",
      "Epoch [473/1000], Loss: 0.1555\n",
      "Epoch [474/1000], Loss: 0.1560\n",
      "Epoch [475/1000], Loss: 0.1742\n",
      "Epoch [476/1000], Loss: 0.1557\n",
      "Epoch [477/1000], Loss: 0.1518\n",
      "Epoch [478/1000], Loss: 0.1586\n",
      "Epoch [479/1000], Loss: 0.1555\n",
      "Epoch [480/1000], Loss: 0.1671\n",
      "Epoch [481/1000], Loss: 0.1549\n",
      "Epoch [482/1000], Loss: 0.1512\n",
      "Epoch [483/1000], Loss: 0.1547\n",
      "Epoch [484/1000], Loss: 0.1537\n",
      "Epoch [485/1000], Loss: 0.1602\n",
      "Epoch [486/1000], Loss: 0.1523\n",
      "Epoch [487/1000], Loss: 0.1544\n",
      "Epoch [488/1000], Loss: 0.1528\n",
      "Epoch [489/1000], Loss: 0.1614\n",
      "Epoch [490/1000], Loss: 0.1545\n",
      "Epoch [491/1000], Loss: 0.1519\n",
      "Epoch [492/1000], Loss: 0.1642\n",
      "Epoch [493/1000], Loss: 0.1542\n",
      "Epoch [494/1000], Loss: 0.1523\n",
      "Epoch [495/1000], Loss: 0.1506\n",
      "Epoch [496/1000], Loss: 0.1504\n",
      "Epoch [497/1000], Loss: 0.1519\n",
      "Epoch [498/1000], Loss: 0.1573\n",
      "Epoch [499/1000], Loss: 0.1509\n",
      "Epoch [500/1000], Loss: 0.1709\n",
      "Epoch [501/1000], Loss: 0.1526\n",
      "Epoch [502/1000], Loss: 0.1577\n",
      "Epoch [503/1000], Loss: 0.1550\n",
      "Epoch [504/1000], Loss: 0.1504\n",
      "Epoch [505/1000], Loss: 0.1518\n",
      "Epoch [506/1000], Loss: 0.1620\n",
      "Epoch [507/1000], Loss: 0.1573\n",
      "Epoch [508/1000], Loss: 0.1632\n",
      "Epoch [509/1000], Loss: 0.1529\n",
      "Epoch [510/1000], Loss: 0.1563\n",
      "Epoch [511/1000], Loss: 0.1615\n",
      "Epoch [512/1000], Loss: 0.1520\n",
      "Epoch [513/1000], Loss: 0.1516\n",
      "Epoch [514/1000], Loss: 0.1523\n",
      "Epoch [515/1000], Loss: 0.1552\n",
      "Epoch [516/1000], Loss: 0.1651\n",
      "Epoch [517/1000], Loss: 0.1811\n",
      "Epoch [518/1000], Loss: 0.1769\n",
      "Epoch [519/1000], Loss: 0.1755\n",
      "Epoch [520/1000], Loss: 0.1673\n",
      "Epoch [521/1000], Loss: 0.1620\n",
      "Epoch [522/1000], Loss: 0.1609\n",
      "Epoch [523/1000], Loss: 0.1658\n",
      "Epoch [524/1000], Loss: 0.1667\n",
      "Epoch [525/1000], Loss: 0.1552\n",
      "Epoch [526/1000], Loss: 0.1592\n",
      "Epoch [527/1000], Loss: 0.1525\n",
      "Epoch [528/1000], Loss: 0.1544\n",
      "Epoch [529/1000], Loss: 0.1629\n",
      "Epoch [530/1000], Loss: 0.1545\n",
      "Epoch [531/1000], Loss: 0.1538\n",
      "Epoch [532/1000], Loss: 0.1516\n",
      "Epoch [533/1000], Loss: 0.1519\n",
      "Epoch [534/1000], Loss: 0.1504\n",
      "Epoch [535/1000], Loss: 0.1537\n",
      "Epoch [536/1000], Loss: 0.1514\n",
      "Epoch [537/1000], Loss: 0.1521\n",
      "Epoch [538/1000], Loss: 0.1531\n",
      "Epoch [539/1000], Loss: 0.1522\n",
      "Epoch [540/1000], Loss: 0.1507\n",
      "Epoch [541/1000], Loss: 0.1567\n",
      "Epoch [542/1000], Loss: 0.1532\n",
      "Epoch [543/1000], Loss: 0.1503\n",
      "Epoch [544/1000], Loss: 0.1526\n",
      "Epoch [545/1000], Loss: 0.1508\n",
      "Epoch [546/1000], Loss: 0.1587\n",
      "Epoch [547/1000], Loss: 0.1522\n",
      "Epoch [548/1000], Loss: 0.1519\n",
      "Epoch [549/1000], Loss: 0.1527\n",
      "Epoch [550/1000], Loss: 0.1509\n",
      "Epoch [551/1000], Loss: 0.1508\n",
      "Epoch [552/1000], Loss: 0.1531\n",
      "Epoch [553/1000], Loss: 0.1540\n",
      "Epoch [554/1000], Loss: 0.1567\n",
      "Epoch [555/1000], Loss: 0.1506\n",
      "Epoch [556/1000], Loss: 0.1501\n",
      "Epoch [557/1000], Loss: 0.1525\n",
      "Epoch [558/1000], Loss: 0.1502\n",
      "Epoch [559/1000], Loss: 0.1507\n",
      "Epoch [560/1000], Loss: 0.1555\n",
      "Epoch [561/1000], Loss: 0.1507\n",
      "Epoch [562/1000], Loss: 0.1494\n",
      "Epoch [563/1000], Loss: 0.1511\n",
      "Epoch [564/1000], Loss: 0.1488\n",
      "Epoch [565/1000], Loss: 0.1484\n",
      "Epoch [566/1000], Loss: 0.1501\n",
      "Epoch [567/1000], Loss: 0.1501\n",
      "Epoch [568/1000], Loss: 0.1494\n",
      "Epoch [569/1000], Loss: 0.1505\n",
      "Epoch [570/1000], Loss: 0.1501\n",
      "Epoch [571/1000], Loss: 0.1503\n",
      "Epoch [572/1000], Loss: 0.1484\n",
      "Epoch [573/1000], Loss: 0.1487\n",
      "Epoch [574/1000], Loss: 0.1487\n",
      "Epoch [575/1000], Loss: 0.1484\n",
      "Epoch [576/1000], Loss: 0.1483\n",
      "Epoch [577/1000], Loss: 0.1492\n",
      "Epoch [578/1000], Loss: 0.1538\n",
      "Epoch [579/1000], Loss: 0.1526\n",
      "Epoch [580/1000], Loss: 0.1489\n",
      "Epoch [581/1000], Loss: 0.1484\n",
      "Epoch [582/1000], Loss: 0.1504\n",
      "Epoch [583/1000], Loss: 0.1491\n",
      "Epoch [584/1000], Loss: 0.1552\n",
      "Epoch [585/1000], Loss: 0.1532\n",
      "Epoch [586/1000], Loss: 0.1502\n",
      "Epoch [587/1000], Loss: 0.1489\n",
      "Epoch [588/1000], Loss: 0.1481\n",
      "Epoch [589/1000], Loss: 0.1534\n",
      "Epoch [590/1000], Loss: 0.1591\n",
      "Epoch [591/1000], Loss: 0.1482\n",
      "Epoch [592/1000], Loss: 0.1477\n",
      "Epoch [593/1000], Loss: 0.1476\n",
      "Epoch [594/1000], Loss: 0.1691\n",
      "Epoch [595/1000], Loss: 0.2018\n",
      "Epoch [596/1000], Loss: 0.1958\n",
      "Epoch [597/1000], Loss: 0.1929\n",
      "Epoch [598/1000], Loss: 0.1929\n",
      "Epoch [599/1000], Loss: 0.1912\n",
      "Epoch [600/1000], Loss: 0.1878\n",
      "Epoch [601/1000], Loss: 0.1896\n",
      "Epoch [602/1000], Loss: 0.1856\n",
      "Epoch [603/1000], Loss: 0.1600\n",
      "Epoch [604/1000], Loss: 0.1534\n",
      "Epoch [605/1000], Loss: 0.1574\n",
      "Epoch [606/1000], Loss: 0.1539\n",
      "Epoch [607/1000], Loss: 0.1490\n",
      "Epoch [608/1000], Loss: 0.1501\n",
      "Epoch [609/1000], Loss: 0.1522\n",
      "Epoch [610/1000], Loss: 0.1506\n",
      "Epoch [611/1000], Loss: 0.1498\n",
      "Epoch [612/1000], Loss: 0.1526\n",
      "Epoch [613/1000], Loss: 0.1484\n",
      "Epoch [614/1000], Loss: 0.1483\n",
      "Epoch [615/1000], Loss: 0.1502\n",
      "Epoch [616/1000], Loss: 0.1530\n",
      "Epoch [617/1000], Loss: 0.1478\n",
      "Epoch [618/1000], Loss: 0.1544\n",
      "Epoch [619/1000], Loss: 0.1550\n",
      "Epoch [620/1000], Loss: 0.1483\n",
      "Epoch [621/1000], Loss: 0.1487\n",
      "Epoch [622/1000], Loss: 0.1500\n",
      "Epoch [623/1000], Loss: 0.1514\n",
      "Epoch [624/1000], Loss: 0.1700\n",
      "Epoch [625/1000], Loss: 0.1480\n",
      "Epoch [626/1000], Loss: 0.1577\n",
      "Epoch [627/1000], Loss: 0.1497\n",
      "Epoch [628/1000], Loss: 0.1471\n",
      "Epoch [629/1000], Loss: 0.1478\n",
      "Epoch [630/1000], Loss: 0.1542\n",
      "Epoch [631/1000], Loss: 0.1479\n",
      "Epoch [632/1000], Loss: 0.1469\n",
      "Epoch [633/1000], Loss: 0.1472\n",
      "Epoch [634/1000], Loss: 0.1472\n",
      "Epoch [635/1000], Loss: 0.1464\n",
      "Epoch [636/1000], Loss: 0.1484\n",
      "Epoch [637/1000], Loss: 0.1582\n",
      "Epoch [638/1000], Loss: 0.1522\n",
      "Epoch [639/1000], Loss: 0.1496\n",
      "Epoch [640/1000], Loss: 0.1485\n",
      "Epoch [641/1000], Loss: 0.1468\n",
      "Epoch [642/1000], Loss: 0.1504\n",
      "Epoch [643/1000], Loss: 0.1468\n",
      "Epoch [644/1000], Loss: 0.1470\n",
      "Epoch [645/1000], Loss: 0.1463\n",
      "Epoch [646/1000], Loss: 0.1458\n",
      "Epoch [647/1000], Loss: 0.1469\n",
      "Epoch [648/1000], Loss: 0.1466\n",
      "Epoch [649/1000], Loss: 0.1479\n",
      "Epoch [650/1000], Loss: 0.1474\n",
      "Epoch [651/1000], Loss: 0.1472\n",
      "Epoch [652/1000], Loss: 0.1957\n",
      "Epoch [653/1000], Loss: 0.1828\n",
      "Epoch [654/1000], Loss: 0.1795\n",
      "Epoch [655/1000], Loss: 0.1755\n",
      "Epoch [656/1000], Loss: 0.1690\n",
      "Epoch [657/1000], Loss: 0.1604\n",
      "Epoch [658/1000], Loss: 0.1625\n",
      "Epoch [659/1000], Loss: 0.1651\n",
      "Epoch [660/1000], Loss: 0.1594\n",
      "Epoch [661/1000], Loss: 0.1717\n",
      "Epoch [662/1000], Loss: 0.1698\n",
      "Epoch [663/1000], Loss: 0.1644\n",
      "Epoch [664/1000], Loss: 0.1669\n",
      "Epoch [665/1000], Loss: 0.1634\n",
      "Epoch [666/1000], Loss: 0.1595\n",
      "Epoch [667/1000], Loss: 0.1638\n",
      "Epoch [668/1000], Loss: 0.1615\n",
      "Epoch [669/1000], Loss: 0.1746\n",
      "Epoch [670/1000], Loss: 0.1633\n",
      "Epoch [671/1000], Loss: 0.1634\n",
      "Epoch [672/1000], Loss: 0.1588\n",
      "Epoch [673/1000], Loss: 0.1770\n",
      "Epoch [674/1000], Loss: 0.1532\n",
      "Epoch [675/1000], Loss: 0.1621\n",
      "Epoch [676/1000], Loss: 0.1678\n",
      "Epoch [677/1000], Loss: 0.1634\n",
      "Epoch [678/1000], Loss: 0.1593\n",
      "Epoch [679/1000], Loss: 0.1671\n",
      "Epoch [680/1000], Loss: 0.1662\n",
      "Epoch [681/1000], Loss: 0.1557\n",
      "Epoch [682/1000], Loss: 0.1684\n",
      "Epoch [683/1000], Loss: 0.1611\n",
      "Epoch [684/1000], Loss: 0.1552\n",
      "Epoch [685/1000], Loss: 0.1653\n",
      "Epoch [686/1000], Loss: 0.1579\n",
      "Epoch [687/1000], Loss: 0.1554\n",
      "Epoch [688/1000], Loss: 0.1700\n",
      "Epoch [689/1000], Loss: 0.1615\n",
      "Epoch [690/1000], Loss: 0.1613\n",
      "Epoch [691/1000], Loss: 0.1582\n",
      "Epoch [692/1000], Loss: 0.1507\n",
      "Epoch [693/1000], Loss: 0.1595\n",
      "Epoch [694/1000], Loss: 0.1548\n",
      "Epoch [695/1000], Loss: 0.1542\n",
      "Epoch [696/1000], Loss: 0.1578\n",
      "Epoch [697/1000], Loss: 0.1552\n",
      "Epoch [698/1000], Loss: 0.1753\n",
      "Epoch [699/1000], Loss: 0.1614\n",
      "Epoch [700/1000], Loss: 0.1536\n",
      "Epoch [701/1000], Loss: 0.1543\n",
      "Epoch [702/1000], Loss: 0.1543\n",
      "Epoch [703/1000], Loss: 0.1597\n",
      "Epoch [704/1000], Loss: 0.1492\n",
      "Epoch [705/1000], Loss: 0.1513\n",
      "Epoch [706/1000], Loss: 0.1525\n",
      "Epoch [707/1000], Loss: 0.1520\n",
      "Epoch [708/1000], Loss: 0.1572\n",
      "Epoch [709/1000], Loss: 0.1528\n",
      "Epoch [710/1000], Loss: 0.1496\n",
      "Epoch [711/1000], Loss: 0.1592\n",
      "Epoch [712/1000], Loss: 0.1710\n",
      "Epoch [713/1000], Loss: 0.1552\n",
      "Epoch [714/1000], Loss: 0.1640\n",
      "Epoch [715/1000], Loss: 0.1665\n",
      "Epoch [716/1000], Loss: 0.1626\n",
      "Epoch [717/1000], Loss: 0.1782\n",
      "Epoch [718/1000], Loss: 0.1639\n",
      "Epoch [719/1000], Loss: 0.1511\n",
      "Epoch [720/1000], Loss: 0.1787\n",
      "Epoch [721/1000], Loss: 0.1699\n",
      "Epoch [722/1000], Loss: 0.1525\n",
      "Epoch [723/1000], Loss: 0.1509\n",
      "Epoch [724/1000], Loss: 0.1506\n",
      "Epoch [725/1000], Loss: 0.1503\n",
      "Epoch [726/1000], Loss: 0.1512\n",
      "Epoch [727/1000], Loss: 0.1628\n",
      "Epoch [728/1000], Loss: 0.1538\n",
      "Epoch [729/1000], Loss: 0.1503\n",
      "Epoch [730/1000], Loss: 0.1631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [731/1000], Loss: 0.1559\n",
      "Epoch [732/1000], Loss: 0.1500\n",
      "Epoch [733/1000], Loss: 0.1519\n",
      "Epoch [734/1000], Loss: 0.1499\n",
      "Epoch [735/1000], Loss: 0.1638\n",
      "Epoch [736/1000], Loss: 0.1657\n",
      "Epoch [737/1000], Loss: 0.1514\n",
      "Epoch [738/1000], Loss: 0.1607\n",
      "Epoch [739/1000], Loss: 0.1616\n",
      "Epoch [740/1000], Loss: 0.1779\n",
      "Epoch [741/1000], Loss: 0.1651\n",
      "Epoch [742/1000], Loss: 0.1546\n",
      "Epoch [743/1000], Loss: 0.1514\n",
      "Epoch [744/1000], Loss: 0.1506\n",
      "Epoch [745/1000], Loss: 0.1506\n",
      "Epoch [746/1000], Loss: 0.1535\n",
      "Epoch [747/1000], Loss: 0.1580\n",
      "Epoch [748/1000], Loss: 0.1545\n",
      "Epoch [749/1000], Loss: 0.1527\n",
      "Epoch [750/1000], Loss: 0.1495\n",
      "Epoch [751/1000], Loss: 0.1497\n",
      "Epoch [752/1000], Loss: 0.1497\n",
      "Epoch [753/1000], Loss: 0.1503\n",
      "Epoch [754/1000], Loss: 0.1731\n",
      "Epoch [755/1000], Loss: 0.1548\n",
      "Epoch [756/1000], Loss: 0.1502\n",
      "Epoch [757/1000], Loss: 0.1508\n",
      "Epoch [758/1000], Loss: 0.1491\n",
      "Epoch [759/1000], Loss: 0.1489\n",
      "Epoch [760/1000], Loss: 0.1496\n",
      "Epoch [761/1000], Loss: 0.1491\n",
      "Epoch [762/1000], Loss: 0.1559\n",
      "Epoch [763/1000], Loss: 0.1510\n",
      "Epoch [764/1000], Loss: 0.1559\n",
      "Epoch [765/1000], Loss: 0.1615\n",
      "Epoch [766/1000], Loss: 0.1797\n",
      "Epoch [767/1000], Loss: 0.1865\n",
      "Epoch [768/1000], Loss: 0.1571\n",
      "Epoch [769/1000], Loss: 0.1504\n",
      "Epoch [770/1000], Loss: 0.1498\n",
      "Epoch [771/1000], Loss: 0.1867\n",
      "Epoch [772/1000], Loss: 0.1554\n",
      "Epoch [773/1000], Loss: 0.1508\n",
      "Epoch [774/1000], Loss: 0.1530\n",
      "Epoch [775/1000], Loss: 0.1561\n",
      "Epoch [776/1000], Loss: 0.1488\n",
      "Epoch [777/1000], Loss: 0.1515\n",
      "Epoch [778/1000], Loss: 0.1506\n",
      "Epoch [779/1000], Loss: 0.1499\n",
      "Epoch [780/1000], Loss: 0.1490\n",
      "Epoch [781/1000], Loss: 0.1496\n",
      "Epoch [782/1000], Loss: 0.1491\n",
      "Epoch [783/1000], Loss: 0.1551\n",
      "Epoch [784/1000], Loss: 0.1494\n",
      "Epoch [785/1000], Loss: 0.1571\n",
      "Epoch [786/1000], Loss: 0.1494\n",
      "Epoch [787/1000], Loss: 0.1493\n",
      "Epoch [788/1000], Loss: 0.1555\n",
      "Epoch [789/1000], Loss: 0.1563\n",
      "Epoch [790/1000], Loss: 0.1566\n",
      "Epoch [791/1000], Loss: 0.1522\n",
      "Epoch [792/1000], Loss: 0.1590\n",
      "Epoch [793/1000], Loss: 0.1521\n",
      "Epoch [794/1000], Loss: 0.1540\n",
      "Epoch [795/1000], Loss: 0.1643\n",
      "Epoch [796/1000], Loss: 0.1767\n",
      "Epoch [797/1000], Loss: 0.1598\n",
      "Epoch [798/1000], Loss: 0.1642\n",
      "Epoch [799/1000], Loss: 0.1566\n",
      "Epoch [800/1000], Loss: 0.1671\n",
      "Epoch [801/1000], Loss: 0.1556\n",
      "Epoch [802/1000], Loss: 0.1507\n",
      "Epoch [803/1000], Loss: 0.1488\n",
      "Epoch [804/1000], Loss: 0.1496\n",
      "Epoch [805/1000], Loss: 0.1622\n",
      "Epoch [806/1000], Loss: 0.1591\n",
      "Epoch [807/1000], Loss: 0.1544\n",
      "Epoch [808/1000], Loss: 0.1499\n",
      "Epoch [809/1000], Loss: 0.1610\n",
      "Epoch [810/1000], Loss: 0.1586\n",
      "Epoch [811/1000], Loss: 0.1488\n",
      "Epoch [812/1000], Loss: 0.1488\n",
      "Epoch [813/1000], Loss: 0.1473\n",
      "Epoch [814/1000], Loss: 0.1678\n",
      "Epoch [815/1000], Loss: 0.1816\n",
      "Epoch [816/1000], Loss: 0.1508\n",
      "Epoch [817/1000], Loss: 0.1777\n",
      "Epoch [818/1000], Loss: 0.1666\n",
      "Epoch [819/1000], Loss: 0.1620\n",
      "Epoch [820/1000], Loss: 0.1561\n",
      "Epoch [821/1000], Loss: 0.1491\n",
      "Epoch [822/1000], Loss: 0.1540\n",
      "Epoch [823/1000], Loss: 0.1507\n",
      "Epoch [824/1000], Loss: 0.1605\n",
      "Epoch [825/1000], Loss: 0.1505\n",
      "Epoch [826/1000], Loss: 0.1487\n",
      "Epoch [827/1000], Loss: 0.1500\n",
      "Epoch [828/1000], Loss: 0.1547\n",
      "Epoch [829/1000], Loss: 0.1594\n",
      "Epoch [830/1000], Loss: 0.1610\n",
      "Epoch [831/1000], Loss: 0.1489\n",
      "Epoch [832/1000], Loss: 0.1477\n",
      "Epoch [833/1000], Loss: 0.1536\n",
      "Epoch [834/1000], Loss: 0.1514\n",
      "Epoch [835/1000], Loss: 0.1498\n",
      "Epoch [836/1000], Loss: 0.1479\n",
      "Epoch [837/1000], Loss: 0.1484\n",
      "Epoch [838/1000], Loss: 0.1484\n",
      "Epoch [839/1000], Loss: 0.1489\n",
      "Epoch [840/1000], Loss: 0.1494\n",
      "Epoch [841/1000], Loss: 0.1600\n",
      "Epoch [842/1000], Loss: 0.1479\n",
      "Epoch [843/1000], Loss: 0.1586\n",
      "Epoch [844/1000], Loss: 0.1632\n",
      "Epoch [845/1000], Loss: 0.1512\n",
      "Epoch [846/1000], Loss: 0.1474\n",
      "Epoch [847/1000], Loss: 0.1528\n",
      "Epoch [848/1000], Loss: 0.1496\n",
      "Epoch [849/1000], Loss: 0.1556\n",
      "Epoch [850/1000], Loss: 0.1633\n",
      "Epoch [851/1000], Loss: 0.1578\n",
      "Epoch [852/1000], Loss: 0.1498\n",
      "Epoch [853/1000], Loss: 0.1475\n",
      "Epoch [854/1000], Loss: 0.1468\n",
      "Epoch [855/1000], Loss: 0.1547\n",
      "Epoch [856/1000], Loss: 0.1483\n",
      "Epoch [857/1000], Loss: 0.1486\n",
      "Epoch [858/1000], Loss: 0.1524\n",
      "Epoch [859/1000], Loss: 0.1634\n",
      "Epoch [860/1000], Loss: 0.1493\n",
      "Epoch [861/1000], Loss: 0.1495\n",
      "Epoch [862/1000], Loss: 0.1506\n",
      "Epoch [863/1000], Loss: 0.1540\n",
      "Epoch [864/1000], Loss: 0.1583\n",
      "Epoch [865/1000], Loss: 0.1480\n",
      "Epoch [866/1000], Loss: 0.1466\n",
      "Epoch [867/1000], Loss: 0.1491\n",
      "Epoch [868/1000], Loss: 0.1480\n",
      "Epoch [869/1000], Loss: 0.1576\n",
      "Epoch [870/1000], Loss: 0.1482\n",
      "Epoch [871/1000], Loss: 0.1462\n",
      "Epoch [872/1000], Loss: 0.1468\n",
      "Epoch [873/1000], Loss: 0.1463\n",
      "Epoch [874/1000], Loss: 0.1483\n",
      "Epoch [875/1000], Loss: 0.1535\n",
      "Epoch [876/1000], Loss: 0.1482\n",
      "Epoch [877/1000], Loss: 0.1608\n",
      "Epoch [878/1000], Loss: 0.1906\n",
      "Epoch [879/1000], Loss: 0.1838\n",
      "Epoch [880/1000], Loss: 0.1571\n",
      "Epoch [881/1000], Loss: 0.1483\n",
      "Epoch [882/1000], Loss: 0.1536\n",
      "Epoch [883/1000], Loss: 0.1475\n",
      "Epoch [884/1000], Loss: 0.1559\n",
      "Epoch [885/1000], Loss: 0.1504\n",
      "Epoch [886/1000], Loss: 0.1467\n",
      "Epoch [887/1000], Loss: 0.1566\n",
      "Epoch [888/1000], Loss: 0.1468\n",
      "Epoch [889/1000], Loss: 0.1545\n",
      "Epoch [890/1000], Loss: 0.1510\n",
      "Epoch [891/1000], Loss: 0.1561\n",
      "Epoch [892/1000], Loss: 0.1613\n",
      "Epoch [893/1000], Loss: 0.1609\n",
      "Epoch [894/1000], Loss: 0.1480\n",
      "Epoch [895/1000], Loss: 0.1484\n",
      "Epoch [896/1000], Loss: 0.1484\n",
      "Epoch [897/1000], Loss: 0.1566\n",
      "Epoch [898/1000], Loss: 0.1521\n",
      "Epoch [899/1000], Loss: 0.1498\n",
      "Epoch [900/1000], Loss: 0.1489\n",
      "Epoch [901/1000], Loss: 0.1472\n",
      "Epoch [902/1000], Loss: 0.1482\n",
      "Epoch [903/1000], Loss: 0.1541\n",
      "Epoch [904/1000], Loss: 0.1621\n",
      "Epoch [905/1000], Loss: 0.1722\n",
      "Epoch [906/1000], Loss: 0.1607\n",
      "Epoch [907/1000], Loss: 0.1497\n",
      "Epoch [908/1000], Loss: 0.1471\n",
      "Epoch [909/1000], Loss: 0.1473\n",
      "Epoch [910/1000], Loss: 0.1479\n",
      "Epoch [911/1000], Loss: 0.1459\n",
      "Epoch [912/1000], Loss: 0.1493\n",
      "Epoch [913/1000], Loss: 0.1571\n",
      "Epoch [914/1000], Loss: 0.1569\n",
      "Epoch [915/1000], Loss: 0.1473\n",
      "Epoch [916/1000], Loss: 0.1461\n",
      "Epoch [917/1000], Loss: 0.1460\n",
      "Epoch [918/1000], Loss: 0.1526\n",
      "Epoch [919/1000], Loss: 0.1494\n",
      "Epoch [920/1000], Loss: 0.1467\n",
      "Epoch [921/1000], Loss: 0.1934\n",
      "Epoch [922/1000], Loss: 0.1719\n",
      "Epoch [923/1000], Loss: 0.1593\n",
      "Epoch [924/1000], Loss: 0.1541\n",
      "Epoch [925/1000], Loss: 0.1686\n",
      "Epoch [926/1000], Loss: 0.1489\n",
      "Epoch [927/1000], Loss: 0.1508\n",
      "Epoch [928/1000], Loss: 0.1499\n",
      "Epoch [929/1000], Loss: 0.1467\n",
      "Epoch [930/1000], Loss: 0.1463\n",
      "Epoch [931/1000], Loss: 0.1470\n",
      "Epoch [932/1000], Loss: 0.1478\n",
      "Epoch [933/1000], Loss: 0.1463\n",
      "Epoch [934/1000], Loss: 0.1529\n",
      "Epoch [935/1000], Loss: 0.1512\n",
      "Epoch [936/1000], Loss: 0.1551\n",
      "Epoch [937/1000], Loss: 0.1459\n",
      "Epoch [938/1000], Loss: 0.1457\n",
      "Epoch [939/1000], Loss: 0.1578\n",
      "Epoch [940/1000], Loss: 0.1551\n",
      "Epoch [941/1000], Loss: 0.1477\n",
      "Epoch [942/1000], Loss: 0.1575\n",
      "Epoch [943/1000], Loss: 0.1542\n",
      "Epoch [944/1000], Loss: 0.1492\n",
      "Epoch [945/1000], Loss: 0.1471\n",
      "Epoch [946/1000], Loss: 0.1537\n",
      "Epoch [947/1000], Loss: 0.1556\n",
      "Epoch [948/1000], Loss: 0.1504\n",
      "Epoch [949/1000], Loss: 0.1518\n",
      "Epoch [950/1000], Loss: 0.1475\n",
      "Epoch [951/1000], Loss: 0.1465\n",
      "Epoch [952/1000], Loss: 0.1531\n",
      "Epoch [953/1000], Loss: 0.1482\n",
      "Epoch [954/1000], Loss: 0.1479\n",
      "Epoch [955/1000], Loss: 0.1465\n",
      "Epoch [956/1000], Loss: 0.1456\n",
      "Epoch [957/1000], Loss: 0.1517\n",
      "Epoch [958/1000], Loss: 0.1486\n",
      "Epoch [959/1000], Loss: 0.1485\n",
      "Epoch [960/1000], Loss: 0.1623\n",
      "Epoch [961/1000], Loss: 0.1474\n",
      "Epoch [962/1000], Loss: 0.1472\n",
      "Epoch [963/1000], Loss: 0.1545\n",
      "Epoch [964/1000], Loss: 0.1469\n",
      "Epoch [965/1000], Loss: 0.1560\n",
      "Epoch [966/1000], Loss: 0.1562\n",
      "Epoch [967/1000], Loss: 0.1461\n",
      "Epoch [968/1000], Loss: 0.1475\n",
      "Epoch [969/1000], Loss: 0.1498\n",
      "Epoch [970/1000], Loss: 0.1503\n",
      "Epoch [971/1000], Loss: 0.1450\n",
      "Epoch [972/1000], Loss: 0.1503\n",
      "Epoch [973/1000], Loss: 0.1510\n",
      "Epoch [974/1000], Loss: 0.1562\n",
      "Epoch [975/1000], Loss: 0.1523\n",
      "Epoch [976/1000], Loss: 0.1472\n",
      "Epoch [977/1000], Loss: 0.1465\n",
      "Epoch [978/1000], Loss: 0.1465\n",
      "Epoch [979/1000], Loss: 0.1506\n",
      "Epoch [980/1000], Loss: 0.1570\n",
      "Epoch [981/1000], Loss: 0.1582\n",
      "Epoch [982/1000], Loss: 0.1596\n",
      "Epoch [983/1000], Loss: 0.1458\n",
      "Epoch [984/1000], Loss: 0.1523\n",
      "Epoch [985/1000], Loss: 0.1592\n",
      "Epoch [986/1000], Loss: 0.1488\n",
      "Epoch [987/1000], Loss: 0.1505\n",
      "Epoch [988/1000], Loss: 0.1452\n",
      "Epoch [989/1000], Loss: 0.1452\n",
      "Epoch [990/1000], Loss: 0.1461\n",
      "Epoch [991/1000], Loss: 0.1497\n",
      "Epoch [992/1000], Loss: 0.1458\n",
      "Epoch [993/1000], Loss: 0.1459\n",
      "Epoch [994/1000], Loss: 0.1458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [995/1000], Loss: 0.1475\n",
      "Epoch [996/1000], Loss: 0.1476\n",
      "Epoch [997/1000], Loss: 0.1610\n",
      "Epoch [998/1000], Loss: 0.1576\n",
      "Epoch [999/1000], Loss: 0.1729\n",
      "Epoch [1000/1000], Loss: 0.1743\n",
      "Accuracy of the network on the 1000 validation data: 65.80 %\n",
      "Grid evaluation took 1736.5833048820496 sec\n"
     ]
    }
   ],
   "source": [
    "results = {\"batch_size\": [], \"lr\":[], \"optimizer\":[], \"acc\":[], \"num_epochs\":[]}\n",
    "start_time = time.time()\n",
    "for batch_size in batch_size_list:\n",
    "    for lr in lr_list: \n",
    "        for optim_name, optimizer in optimizer_dict.items():     \n",
    "            print(f\"Training model with batch_size: {batch_size}, lr :{lr}, optimizer : {optim_name}\")\n",
    "            model = Model(activation=activation, n_neurons=[neurons]*depth)\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optimizer(model.parameters(), lr=lr)\n",
    "            train_error, _num_epochs = train(num_epochs, batch_size, criterion, optimizer, model, training_set)\n",
    "            \n",
    "            # predict labels for validation set\n",
    "            model.eval() # set the model to test mode\n",
    "            with torch.no_grad():\n",
    "                y_pre = model(X_val).view(-1)\n",
    "                \n",
    "            acc = accuracy(y_val, y_pre)\n",
    "            \n",
    "            curr_res = {\"batch_size\": batch_size, \"lr\":lr, \"optimizer\":optim_name, \"acc\":acc, \"num_epochs\":_num_epochs}\n",
    "            [results[key].append(val) for key, val in curr_res.items()]\n",
    "            \n",
    "print(f\"Grid evaluation took {time.time()-start_time} sec\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame.from_dict(results)\n",
    "df_results.to_csv(\"ex2_grid_search.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3: Impact of the loss function\n",
    "\n",
    "The current model uses a mean square error (MSE) loss. While this loss can be used in this case, it is now rarely used for classification, and instead a Binary Cross Entropy (BCE) is used. It consists in interpreting the output of the network as the probability $p(y | x)$ of the point $x$ to belong to the class $y$, and in maximizing the probability to be correct for all samples $x$, that is, in maximizing $\\displaystyle \\prod_{(x,y) \\in Dataset} p(y|x)$. Applying $-\\log$ to this quantity, we obtain the following criterion to minimize:\n",
    "\n",
    "$$ \\sum_{(x,y) \\in Dataset} - \\log p(y | x) $$\n",
    "\n",
    "This is implemented as such by the [BCELoss](https://pytorch.org/docs/stable/nn.html?highlight=bce#torch.nn.BCELoss) of pytorch. Note that this criterion requires its input to be a probability, i.e. in $[0,1]$, which requires the use of an appropriate activation function beforehand, e.g., a sigmoid.\n",
    "\n",
    "It turns out that, for numerical stability reasons, it is better to incorporate this sigmoid and the BCELoss into a single function; this is done by the [BCEWithLogitsLoss](https://pytorch.org/docs/stable/nn.html?highlight=bcewithlogit#torch.nn.BCEWithLogitsLoss). Try to replace the MSE by this one and see how this changes the behavior in the network. This can also interact with the changes of the two previous exercices.\n",
    "\n",
    "**Note:** As a consequence, when using the BCEWithLogitsLoss, the last layer of your network should not be followed by an activation function, as BCEWithLogitsLoss already adds a sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_dict = {\"MSELoss\": nn.MSELoss, \"BCELoss\": nn.BCELoss, \"BCEWithLogitsLoss\": nn.BCEWithLogitsLoss}\n",
    "criterion_w_logits = [\"BCEWithLogitsLoss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation, depth, neurons, optimizer, lr, batch_size = \"relu\", 2, 20, torch.optim.Adam, 1e-3, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with criterion: MSELoss\n",
      "Epoch [1/1000], Loss: 0.2356\n",
      "Epoch [2/1000], Loss: 0.2220\n",
      "Epoch [3/1000], Loss: 0.2073\n",
      "Epoch [4/1000], Loss: 0.1907\n",
      "Epoch [5/1000], Loss: 0.1728\n",
      "Epoch [6/1000], Loss: 0.1542\n",
      "Epoch [7/1000], Loss: 0.1302\n",
      "Epoch [8/1000], Loss: 0.1043\n",
      "Epoch [9/1000], Loss: 0.0773\n",
      "Epoch [10/1000], Loss: 0.0560\n",
      "Epoch [11/1000], Loss: 0.0401\n",
      "Epoch [12/1000], Loss: 0.0292\n",
      "Epoch [13/1000], Loss: 0.0216\n",
      "Epoch [14/1000], Loss: 0.0153\n",
      "Epoch [15/1000], Loss: 0.0114\n",
      "Epoch [16/1000], Loss: 0.0086\n",
      "Epoch [17/1000], Loss: 0.0065\n",
      "Epoch [18/1000], Loss: 0.0050\n",
      "Epoch [19/1000], Loss: 0.0040\n",
      "Epoch [20/1000], Loss: 0.0031\n",
      "Epoch [21/1000], Loss: 0.0025\n",
      "Epoch [22/1000], Loss: 0.0020\n",
      "Epoch [23/1000], Loss: 0.0017\n",
      "Epoch [24/1000], Loss: 0.0014\n",
      "Epoch [25/1000], Loss: 0.0011\n",
      "Epoch [26/1000], Loss: 0.0010\n",
      "Epoch [27/1000], Loss: 0.0008\n",
      "Epoch [28/1000], Loss: 0.0006\n",
      "Epoch [29/1000], Loss: 0.0006\n",
      "Epoch [30/1000], Loss: 0.0007\n",
      "Epoch [31/1000], Loss: 0.0005\n",
      "Epoch [32/1000], Loss: 0.0004\n",
      "Epoch [33/1000], Loss: 0.0005\n",
      "Epoch [34/1000], Loss: 0.0003\n",
      "Epoch [35/1000], Loss: 0.0003\n",
      "Epoch [36/1000], Loss: 0.0003\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with criterion: BCELoss\n",
      "Epoch [1/1000], Loss: 0.6699\n",
      "Epoch [2/1000], Loss: 0.6450\n",
      "Epoch [3/1000], Loss: 0.6103\n",
      "Epoch [4/1000], Loss: 0.5650\n",
      "Epoch [5/1000], Loss: 0.5106\n",
      "Epoch [6/1000], Loss: 0.4472\n",
      "Epoch [7/1000], Loss: 0.3800\n",
      "Epoch [8/1000], Loss: 0.3032\n",
      "Epoch [9/1000], Loss: 0.2205\n",
      "Epoch [10/1000], Loss: 0.1519\n",
      "Epoch [11/1000], Loss: 0.1049\n",
      "Epoch [12/1000], Loss: 0.0733\n",
      "Epoch [13/1000], Loss: 0.0538\n",
      "Epoch [14/1000], Loss: 0.0398\n",
      "Epoch [15/1000], Loss: 0.0302\n",
      "Epoch [16/1000], Loss: 0.0233\n",
      "Epoch [17/1000], Loss: 0.0181\n",
      "Epoch [18/1000], Loss: 0.0145\n",
      "Epoch [19/1000], Loss: 0.0117\n",
      "Epoch [20/1000], Loss: 0.0095\n",
      "Epoch [21/1000], Loss: 0.0077\n",
      "Epoch [22/1000], Loss: 0.0065\n",
      "Epoch [23/1000], Loss: 0.0054\n",
      "Epoch [24/1000], Loss: 0.0047\n",
      "Epoch [25/1000], Loss: 0.0039\n",
      "Epoch [26/1000], Loss: 0.0033\n",
      "Epoch [27/1000], Loss: 0.0029\n",
      "Epoch [28/1000], Loss: 0.0023\n",
      "Epoch [29/1000], Loss: 0.0022\n",
      "Epoch [30/1000], Loss: 0.0020\n",
      "Epoch [31/1000], Loss: 0.0017\n",
      "Epoch [32/1000], Loss: 0.0015\n",
      "Epoch [33/1000], Loss: 0.0016\n",
      "Epoch [34/1000], Loss: 0.0011\n",
      "Epoch [35/1000], Loss: 0.0028\n",
      "Epoch [36/1000], Loss: 0.0009\n",
      "Epoch [37/1000], Loss: 0.0010\n",
      "Epoch [38/1000], Loss: 0.0009\n",
      "Epoch [39/1000], Loss: 0.0008\n",
      "Epoch [40/1000], Loss: 0.0007\n",
      "Epoch [41/1000], Loss: 0.0006\n",
      "Epoch [42/1000], Loss: 0.0007\n",
      "Epoch [43/1000], Loss: 0.0006\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Training model with criterion: BCEWithLogitsLoss\n",
      "Epoch [1/1000], Loss: 0.6685\n",
      "Epoch [2/1000], Loss: 0.6611\n",
      "Epoch [3/1000], Loss: 0.6577\n",
      "Epoch [4/1000], Loss: 0.6555\n",
      "Epoch [5/1000], Loss: 0.6508\n",
      "Epoch [6/1000], Loss: 0.6494\n",
      "Epoch [7/1000], Loss: 0.6455\n",
      "Epoch [8/1000], Loss: 0.6397\n",
      "Epoch [9/1000], Loss: 0.6345\n",
      "Epoch [10/1000], Loss: 0.6251\n",
      "Epoch [11/1000], Loss: 0.6114\n",
      "Epoch [12/1000], Loss: 0.5952\n",
      "Epoch [13/1000], Loss: 0.5775\n",
      "Epoch [14/1000], Loss: 0.5593\n",
      "Epoch [15/1000], Loss: 0.5339\n",
      "Epoch [16/1000], Loss: 0.4972\n",
      "Epoch [17/1000], Loss: 0.4366\n",
      "Epoch [18/1000], Loss: 0.3756\n",
      "Epoch [19/1000], Loss: 0.3139\n",
      "Epoch [20/1000], Loss: 0.2573\n",
      "Epoch [21/1000], Loss: 0.2071\n",
      "Epoch [22/1000], Loss: 0.1610\n",
      "Epoch [23/1000], Loss: 0.1316\n",
      "Epoch [24/1000], Loss: 0.1058\n",
      "Epoch [25/1000], Loss: 0.0886\n",
      "Epoch [26/1000], Loss: 0.0704\n",
      "Epoch [27/1000], Loss: 0.0601\n",
      "Epoch [28/1000], Loss: 0.0489\n",
      "Epoch [29/1000], Loss: 0.0419\n",
      "Epoch [30/1000], Loss: 0.0358\n",
      "Epoch [31/1000], Loss: 0.0303\n",
      "Epoch [32/1000], Loss: 0.0260\n",
      "Epoch [33/1000], Loss: 0.0224\n",
      "Epoch [34/1000], Loss: 0.0191\n",
      "Epoch [35/1000], Loss: 0.0166\n",
      "Epoch [36/1000], Loss: 0.0137\n",
      "Epoch [37/1000], Loss: 0.0138\n",
      "Epoch [38/1000], Loss: 0.0103\n",
      "Epoch [39/1000], Loss: 0.0083\n",
      "Epoch [40/1000], Loss: 0.0071\n",
      "Epoch [41/1000], Loss: 0.0069\n",
      "Epoch [42/1000], Loss: 0.0058\n",
      "Epoch [43/1000], Loss: 0.0054\n",
      "Epoch [44/1000], Loss: 0.0047\n",
      "Epoch [45/1000], Loss: 0.0040\n",
      "Epoch [46/1000], Loss: 0.0033\n",
      "Epoch [47/1000], Loss: 0.0032\n",
      "Epoch [48/1000], Loss: 0.0055\n",
      "Epoch [49/1000], Loss: 0.0027\n",
      "Epoch [50/1000], Loss: 0.0019\n",
      "Epoch [51/1000], Loss: 0.0019\n",
      "Epoch [52/1000], Loss: 0.0016\n",
      "Epoch [53/1000], Loss: 0.0019\n",
      "Epoch [54/1000], Loss: 0.0014\n",
      "Epoch [55/1000], Loss: 0.0017\n",
      "Epoch [56/1000], Loss: 0.0070\n",
      "Epoch [57/1000], Loss: 0.0012\n",
      "Epoch [58/1000], Loss: 0.0010\n",
      "Epoch [59/1000], Loss: 0.0010\n",
      "Epoch [60/1000], Loss: 0.0010\n",
      "Epoch [61/1000], Loss: 0.0010\n",
      "Epoch [62/1000], Loss: 0.0010\n",
      "Epoch [63/1000], Loss: 0.0008\n",
      "Epoch [64/1000], Loss: 0.0008\n",
      "No improvement for 7 epochs, stopping\n",
      "Accuracy of the network on the 1000 validation data: 100.00 %\n",
      "Grid evaluation took 40.930206060409546 sec\n"
     ]
    }
   ],
   "source": [
    "results = {\"criterion\": [], \"acc\":[], \"num_epochs\":[]}\n",
    "start_time = time.time()\n",
    "for criterion_name, criterion in criterion_dict.items():     \n",
    "    print(f\"Training model with criterion: {criterion_name}\")\n",
    "    logits = True if criterion_name in criterion_w_logits else False\n",
    "    model = Model(activation=activation, n_neurons=[neurons]*depth, logits=logits)\n",
    "    _criterion = criterion()\n",
    "    _optimizer = optimizer(model.parameters(), lr=lr)\n",
    "    train_error, _num_epochs = train(num_epochs, batch_size, _criterion, _optimizer, model, training_set)\n",
    "\n",
    "    # predict labels for validation set\n",
    "    model.eval() # set the model to test mode\n",
    "    with torch.no_grad():\n",
    "        y_pre = model(X_val).view(-1)\n",
    "\n",
    "    acc = accuracy(y_val, y_pre)\n",
    "    \n",
    "    curr_res = {\"criterion\": criterion_name, \"acc\":acc, \"num_epochs\":_num_epochs}\n",
    "    [results[key].append(val) for key, val in curr_res.items()]\n",
    "\n",
    "print(f\"Grid evaluation took {time.time()-start_time} sec\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame.from_dict(results)\n",
    "df_results.to_csv(\"ex3_grid_search.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 4: Prediction on test set\n",
    "\n",
    "Once you have a model that seems satisfying on the validation dataset, you SHOULD evaluate it on a test dataset that has never been used before, to obtain a final accuracy value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a test dataset. Use it similarly to the validaiton dataset above\n",
    "# to compute the final performance of your model\n",
    "X_test, y_test = generate_data(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation, depth, neurons, optimizer, lr, batch_size, criterion = \"relu\", 2, 20, torch.optim.Adam, 1e-3, 10, nn.BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 0.6939\n",
      "Epoch [2/1000], Loss: 0.6811\n",
      "Epoch [3/1000], Loss: 0.6756\n",
      "Epoch [4/1000], Loss: 0.6703\n",
      "Epoch [5/1000], Loss: 0.6638\n",
      "Epoch [6/1000], Loss: 0.6555\n",
      "Epoch [7/1000], Loss: 0.6376\n",
      "Epoch [8/1000], Loss: 0.6245\n",
      "Epoch [9/1000], Loss: 0.6162\n",
      "Epoch [10/1000], Loss: 0.6110\n",
      "Epoch [11/1000], Loss: 0.6068\n",
      "Epoch [12/1000], Loss: 0.6019\n",
      "Epoch [13/1000], Loss: 0.5970\n",
      "Epoch [14/1000], Loss: 0.5900\n",
      "Epoch [15/1000], Loss: 0.5820\n",
      "Epoch [16/1000], Loss: 0.5748\n",
      "Epoch [17/1000], Loss: 0.5652\n",
      "Epoch [18/1000], Loss: 0.5559\n",
      "Epoch [19/1000], Loss: 0.5457\n",
      "Epoch [20/1000], Loss: 0.5358\n",
      "Epoch [21/1000], Loss: 0.5297\n",
      "Epoch [22/1000], Loss: 0.5244\n",
      "Epoch [23/1000], Loss: 0.5180\n",
      "Epoch [24/1000], Loss: 0.5134\n",
      "Epoch [25/1000], Loss: 0.5102\n",
      "Epoch [26/1000], Loss: 0.5083\n",
      "Epoch [27/1000], Loss: 0.5073\n",
      "Epoch [28/1000], Loss: 0.5064\n",
      "Epoch [29/1000], Loss: 0.5059\n",
      "Epoch [30/1000], Loss: 0.5056\n",
      "Epoch [31/1000], Loss: 0.5051\n",
      "Epoch [32/1000], Loss: 0.5049\n",
      "Epoch [33/1000], Loss: 0.5046\n",
      "Epoch [34/1000], Loss: 0.5045\n",
      "Epoch [35/1000], Loss: 0.5042\n",
      "Epoch [36/1000], Loss: 0.5043\n",
      "Epoch [37/1000], Loss: 0.5041\n",
      "Epoch [38/1000], Loss: 0.5041\n",
      "Epoch [39/1000], Loss: 0.5038\n",
      "Epoch [40/1000], Loss: 0.5037\n",
      "Epoch [41/1000], Loss: 0.5038\n",
      "Epoch [42/1000], Loss: 0.5036\n",
      "Epoch [43/1000], Loss: 0.5036\n",
      "Epoch [44/1000], Loss: 0.5037\n",
      "No improvement for 7 epochs, stopping\n"
     ]
    }
   ],
   "source": [
    "model = Model(activation=activation, n_neurons=[neurons]*depth, logits=False)\n",
    "_criterion = criterion()\n",
    "_optimizer = optimizer(model.parameters(), lr=lr)\n",
    "train_error, _num_epochs = train(num_epochs, batch_size, _criterion, _optimizer, model, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # set the model to test mode\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_pred(X_test, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1000 validation data: 100.00 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_test, y_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
